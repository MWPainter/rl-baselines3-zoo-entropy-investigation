Running experiment tst_entm
 
	GCC 9.1.0 environment now loaded

	CUDA-11.2 loaded

W&B offline. Running your script from this directory will only write metadata locally. Use wandb disabled to completely turn off W&B.
========== Ant-v4 ==========
Seed: 2104302908
wandb: Tracking run with wandb version 0.16.2
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Loading hyperparameters from: /jmain02/home/J2AD008/wga37/mmp10-wga37/rl-baselines3-zoo-entropy-investigation/hyperparams/ppo.yml
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('n_timesteps', 1000000.0),
             ('normalize', True),
             ('policy', 'MlpPolicy'),
             ('ppo_mode', 'dbltrn')])
Using 1 environments
Overwriting n_timesteps with n=2000000
Creating test environment
Normalization activated: {'norm_reward': False, 'training': False}
Normalizing input and reward
Using cuda device
Log path: /jmain02/home/J2AD008/wga37/mmp10-wga37/rl-baselines3-zoo-entropy-investigation/logs/tst_entm/Ant-v4/"dbltrn"/ppo/Ant-v4_1_ba6ff0bd-67d4-4288-84ae-f96bcad6ed4e
Logging to runs/Ant-v4_dbltrn_2104302908_1706462596/Ant-v4/PPO_1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 203      |
|    ep_rew_mean     | -200     |
| time/              |          |
|    fps             | 273      |
|    iterations      | 1        |
|    time_elapsed    | 7        |
|    total_timesteps | 2048     |
---------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 326         |
|    ep_rew_mean              | -342        |
| time/                       |             |
|    fps                      | 230         |
|    iterations               | 2           |
|    time_elapsed             | 17          |
|    total_timesteps          | 4096        |
| train/                      |             |
|    approx_kl                | 0.01782126  |
|    clip_fraction            | 0.16        |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.017637188 |
|    ent_clip_fraction        | 0.156       |
|    ent_entropy_loss         | -11.3       |
|    ent_loss                 | 0.0543      |
|    ent_policy_gradient_loss | -0.0305     |
|    ent_std                  | 0.993       |
|    ent_value_loss           | 0.531       |
|    entropy_loss             | -11.3       |
|    explained_variance       | -0.383      |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0279      |
|    n_updates                | 10          |
|    policy_gradient_loss     | -0.031      |
|    std                      | 0.993       |
|    value_loss               | 0.545       |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 205         |
|    ep_rew_mean              | -216        |
| time/                       |             |
|    fps                      | 216         |
|    iterations               | 3           |
|    time_elapsed             | 28          |
|    total_timesteps          | 6144        |
| train/                      |             |
|    approx_kl                | 0.018855536 |
|    clip_fraction            | 0.178       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.016394049 |
|    ent_clip_fraction        | 0.158       |
|    ent_entropy_loss         | -11.3       |
|    ent_loss                 | -0.0308     |
|    ent_policy_gradient_loss | -0.0333     |
|    ent_std                  | 0.984       |
|    ent_value_loss           | 0.0726      |
|    entropy_loss             | -11.3       |
|    explained_variance       | -1.09       |
|    learning_rate            | 0.0003      |
|    loss                     | -0.0501     |
|    n_updates                | 20          |
|    policy_gradient_loss     | -0.032      |
|    std                      | 0.985       |
|    value_loss               | 0.0759      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 178         |
|    ep_rew_mean              | -187        |
| time/                       |             |
|    fps                      | 212         |
|    iterations               | 4           |
|    time_elapsed             | 38          |
|    total_timesteps          | 8192        |
| train/                      |             |
|    approx_kl                | 0.01820261  |
|    clip_fraction            | 0.187       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.016075913 |
|    ent_clip_fraction        | 0.153       |
|    ent_entropy_loss         | -11.2       |
|    ent_loss                 | -0.0212     |
|    ent_policy_gradient_loss | -0.0324     |
|    ent_std                  | 0.978       |
|    ent_value_loss           | 0.0742      |
|    entropy_loss             | -11.2       |
|    explained_variance       | 0.159       |
|    learning_rate            | 0.0003      |
|    loss                     | -0.0257     |
|    n_updates                | 30          |
|    policy_gradient_loss     | -0.0294     |
|    std                      | 0.979       |
|    value_loss               | 0.072       |
---------------------------------------------
Eval num_timesteps=10000, episode_reward=980.18 +/- 9.36
Episode length: 1000.00 +/- 0.00
---------------------------------------------
| eval/                       |             |
|    mean_ep_length           | 1e+03       |
|    mean_reward              | 980         |
| time/                       |             |
|    total_timesteps          | 10000       |
| train/                      |             |
|    approx_kl                | 0.018047547 |
|    clip_fraction            | 0.219       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.015858602 |
|    ent_clip_fraction        | 0.148       |
|    ent_entropy_loss         | -11.2       |
|    ent_loss                 | -0.00342    |
|    ent_policy_gradient_loss | -0.0343     |
|    ent_std                  | 0.973       |
|    ent_value_loss           | 0.093       |
|    entropy_loss             | -11.2       |
|    explained_variance       | 0.442       |
|    learning_rate            | 0.0003      |
|    loss                     | -0.00265    |
|    n_updates                | 40          |
|    policy_gradient_loss     | -0.0215     |
|    std                      | 0.974       |
|    value_loss               | 0.0925      |
---------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 168      |
|    ep_rew_mean     | -176     |
| time/              |          |
|    fps             | 151      |
|    iterations      | 5        |
|    time_elapsed    | 67       |
|    total_timesteps | 10240    |
---------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 172         |
|    ep_rew_mean              | -178        |
| time/                       |             |
|    fps                      | 158         |
|    iterations               | 6           |
|    time_elapsed             | 77          |
|    total_timesteps          | 12288       |
| train/                      |             |
|    approx_kl                | 0.022366963 |
|    clip_fraction            | 0.255       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.016974002 |
|    ent_clip_fraction        | 0.171       |
|    ent_entropy_loss         | -11.1       |
|    ent_loss                 | -0.0252     |
|    ent_policy_gradient_loss | -0.0357     |
|    ent_std                  | 0.964       |
|    ent_value_loss           | 0.108       |
|    entropy_loss             | -11.1       |
|    explained_variance       | 0.534       |
|    learning_rate            | 0.0003      |
|    loss                     | -0.00182    |
|    n_updates                | 50          |
|    policy_gradient_loss     | -0.031      |
|    std                      | 0.965       |
|    value_loss               | 0.107       |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 175         |
|    ep_rew_mean              | -181        |
| time/                       |             |
|    fps                      | 163         |
|    iterations               | 7           |
|    time_elapsed             | 87          |
|    total_timesteps          | 14336       |
| train/                      |             |
|    approx_kl                | 0.022105794 |
|    clip_fraction            | 0.246       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.019405829 |
|    ent_clip_fraction        | 0.197       |
|    ent_entropy_loss         | -11         |
|    ent_loss                 | -0.0429     |
|    ent_policy_gradient_loss | -0.0349     |
|    ent_std                  | 0.955       |
|    ent_value_loss           | 0.0669      |
|    entropy_loss             | -11         |
|    explained_variance       | 0.612       |
|    learning_rate            | 0.0003      |
|    loss                     | -0.0267     |
|    n_updates                | 60          |
|    policy_gradient_loss     | -0.0304     |
|    std                      | 0.955       |
|    value_loss               | 0.0662      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 150         |
|    ep_rew_mean              | -157        |
| time/                       |             |
|    fps                      | 168         |
|    iterations               | 8           |
|    time_elapsed             | 97          |
|    total_timesteps          | 16384       |
| train/                      |             |
|    approx_kl                | 0.024282336 |
|    clip_fraction            | 0.256       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.02176778  |
|    ent_clip_fraction        | 0.223       |
|    ent_entropy_loss         | -11         |
|    ent_loss                 | -0.011      |
|    ent_policy_gradient_loss | -0.0343     |
|    ent_std                  | 0.952       |
|    ent_value_loss           | 0.102       |
|    entropy_loss             | -11         |
|    explained_variance       | 0.606       |
|    learning_rate            | 0.0003      |
|    loss                     | -0.0287     |
|    n_updates                | 70          |
|    policy_gradient_loss     | -0.0282     |
|    std                      | 0.951       |
|    value_loss               | 0.1         |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 125         |
|    ep_rew_mean              | -128        |
| time/                       |             |
|    fps                      | 172         |
|    iterations               | 9           |
|    time_elapsed             | 107         |
|    total_timesteps          | 18432       |
| train/                      |             |
|    approx_kl                | 0.028328124 |
|    clip_fraction            | 0.336       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.016489014 |
|    ent_clip_fraction        | 0.171       |
|    ent_entropy_loss         | -10.9       |
|    ent_loss                 | 0.0376      |
|    ent_policy_gradient_loss | -0.038      |
|    ent_std                  | 0.941       |
|    ent_value_loss           | 0.124       |
|    entropy_loss             | -10.9       |
|    explained_variance       | 0.642       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.053       |
|    n_updates                | 80          |
|    policy_gradient_loss     | -0.0219     |
|    std                      | 0.942       |
|    value_loss               | 0.125       |
---------------------------------------------
Eval num_timesteps=20000, episode_reward=958.91 +/- 24.79
Episode length: 1000.00 +/- 0.00
---------------------------------------------
| eval/                       |             |
|    mean_ep_length           | 1e+03       |
|    mean_reward              | 959         |
| time/                       |             |
|    total_timesteps          | 20000       |
| train/                      |             |
|    approx_kl                | 0.030838542 |
|    clip_fraction            | 0.321       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.023708787 |
|    ent_clip_fraction        | 0.245       |
|    ent_entropy_loss         | -10.8       |
|    ent_loss                 | -0.0232     |
|    ent_policy_gradient_loss | -0.0381     |
|    ent_std                  | 0.935       |
|    ent_value_loss           | 0.097       |
|    entropy_loss             | -10.8       |
|    explained_variance       | 0.717       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.00361     |
|    n_updates                | 90          |
|    policy_gradient_loss     | -0.0282     |
|    std                      | 0.936       |
|    value_loss               | 0.102       |
---------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 136      |
|    ep_rew_mean     | -136     |
| time/              |          |
|    fps             | 151      |
|    iterations      | 10       |
|    time_elapsed    | 135      |
|    total_timesteps | 20480    |
---------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 144         |
|    ep_rew_mean              | -145        |
| time/                       |             |
|    fps                      | 154         |
|    iterations               | 11          |
|    time_elapsed             | 145         |
|    total_timesteps          | 22528       |
| train/                      |             |
|    approx_kl                | 0.033644423 |
|    clip_fraction            | 0.346       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.020395529 |
|    ent_clip_fraction        | 0.194       |
|    ent_entropy_loss         | -10.8       |
|    ent_loss                 | 0.0132      |
|    ent_policy_gradient_loss | -0.0305     |
|    ent_std                  | 0.923       |
|    ent_value_loss           | 0.103       |
|    entropy_loss             | -10.8       |
|    explained_variance       | 0.68        |
|    learning_rate            | 0.0003      |
|    loss                     | 0.00193     |
|    n_updates                | 100         |
|    policy_gradient_loss     | -0.0226     |
|    std                      | 0.925       |
|    value_loss               | 0.103       |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 132         |
|    ep_rew_mean              | -131        |
| time/                       |             |
|    fps                      | 158         |
|    iterations               | 12          |
|    time_elapsed             | 155         |
|    total_timesteps          | 24576       |
| train/                      |             |
|    approx_kl                | 0.03221029  |
|    clip_fraction            | 0.345       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.020187877 |
|    ent_clip_fraction        | 0.203       |
|    ent_entropy_loss         | -10.7       |
|    ent_loss                 | -0.0408     |
|    ent_policy_gradient_loss | -0.0334     |
|    ent_std                  | 0.912       |
|    ent_value_loss           | 0.0353      |
|    entropy_loss             | -10.7       |
|    explained_variance       | 0.681       |
|    learning_rate            | 0.0003      |
|    loss                     | -0.0248     |
|    n_updates                | 110         |
|    policy_gradient_loss     | -0.0227     |
|    std                      | 0.915       |
|    value_loss               | 0.0361      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 121         |
|    ep_rew_mean              | -117        |
| time/                       |             |
|    fps                      | 161         |
|    iterations               | 13          |
|    time_elapsed             | 165         |
|    total_timesteps          | 26624       |
| train/                      |             |
|    approx_kl                | 0.03266184  |
|    clip_fraction            | 0.355       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.022274623 |
|    ent_clip_fraction        | 0.228       |
|    ent_entropy_loss         | -10.6       |
|    ent_loss                 | -3.13e-05   |
|    ent_policy_gradient_loss | -0.0351     |
|    ent_std                  | 0.905       |
|    ent_value_loss           | 0.128       |
|    entropy_loss             | -10.6       |
|    explained_variance       | 0.69        |
|    learning_rate            | 0.0003      |
|    loss                     | -0.00863    |
|    n_updates                | 120         |
|    policy_gradient_loss     | -0.0225     |
|    std                      | 0.907       |
|    value_loss               | 0.128       |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 131         |
|    ep_rew_mean              | -124        |
| time/                       |             |
|    fps                      | 163         |
|    iterations               | 14          |
|    time_elapsed             | 175         |
|    total_timesteps          | 28672       |
| train/                      |             |
|    approx_kl                | 0.036360156 |
|    clip_fraction            | 0.383       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.018613422 |
|    ent_clip_fraction        | 0.192       |
|    ent_entropy_loss         | -10.5       |
|    ent_loss                 | 0.00879     |
|    ent_policy_gradient_loss | -0.0378     |
|    ent_std                  | 0.902       |
|    ent_value_loss           | 0.078       |
|    entropy_loss             | -10.6       |
|    explained_variance       | 0.845       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.00922     |
|    n_updates                | 130         |
|    policy_gradient_loss     | -0.0145     |
|    std                      | 0.904       |
|    value_loss               | 0.0795      |
---------------------------------------------
Eval num_timesteps=30000, episode_reward=435.94 +/- 359.85
Episode length: 523.48 +/- 434.84
---------------------------------------------
| eval/                       |             |
|    mean_ep_length           | 523         |
|    mean_reward              | 436         |
| time/                       |             |
|    total_timesteps          | 30000       |
| train/                      |             |
|    approx_kl                | 0.032621615 |
|    clip_fraction            | 0.322       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.03234462  |
|    ent_clip_fraction        | 0.311       |
|    ent_entropy_loss         | -10.5       |
|    ent_loss                 | -0.0167     |
|    ent_policy_gradient_loss | -0.0287     |
|    ent_std                  | 0.896       |
|    ent_value_loss           | 0.0412      |
|    entropy_loss             | -10.5       |
|    explained_variance       | 0.785       |
|    learning_rate            | 0.0003      |
|    loss                     | -0.0168     |
|    n_updates                | 140         |
|    policy_gradient_loss     | -0.0275     |
|    std                      | 0.895       |
|    value_loss               | 0.0431      |
---------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 119      |
|    ep_rew_mean     | -111     |
| time/              |          |
|    fps             | 154      |
|    iterations      | 15       |
|    time_elapsed    | 199      |
|    total_timesteps | 30720    |
---------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 87          |
|    ep_rew_mean              | -79.5       |
| time/                       |             |
|    fps                      | 156         |
|    iterations               | 16          |
|    time_elapsed             | 209         |
|    total_timesteps          | 32768       |
| train/                      |             |
|    approx_kl                | 0.03672248  |
|    clip_fraction            | 0.416       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.020168845 |
|    ent_clip_fraction        | 0.215       |
|    ent_entropy_loss         | -10.4       |
|    ent_loss                 | -0.0035     |
|    ent_policy_gradient_loss | -0.0428     |
|    ent_std                  | 0.892       |
|    ent_value_loss           | 0.131       |
|    entropy_loss             | -10.4       |
|    explained_variance       | 0.527       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0618      |
|    n_updates                | 150         |
|    policy_gradient_loss     | -0.00663    |
|    std                      | 0.892       |
|    value_loss               | 0.131       |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 82.8        |
|    ep_rew_mean              | -78.6       |
| time/                       |             |
|    fps                      | 158         |
|    iterations               | 17          |
|    time_elapsed             | 219         |
|    total_timesteps          | 34816       |
| train/                      |             |
|    approx_kl                | 0.04176309  |
|    clip_fraction            | 0.418       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.021247774 |
|    ent_clip_fraction        | 0.239       |
|    ent_entropy_loss         | -10.4       |
|    ent_loss                 | -0.0407     |
|    ent_policy_gradient_loss | -0.0431     |
|    ent_std                  | 0.887       |
|    ent_value_loss           | 0.0849      |
|    entropy_loss             | -10.4       |
|    explained_variance       | 0.805       |
|    learning_rate            | 0.0003      |
|    loss                     | -0.0368     |
|    n_updates                | 160         |
|    policy_gradient_loss     | -0.0199     |
|    std                      | 0.892       |
|    value_loss               | 0.088       |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 82.7        |
|    ep_rew_mean              | -78.1       |
| time/                       |             |
|    fps                      | 160         |
|    iterations               | 18          |
|    time_elapsed             | 230         |
|    total_timesteps          | 36864       |
| train/                      |             |
|    approx_kl                | 0.049000237 |
|    clip_fraction            | 0.435       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.02169193  |
|    ent_clip_fraction        | 0.227       |
|    ent_entropy_loss         | -10.4       |
|    ent_loss                 | 0.0115      |
|    ent_policy_gradient_loss | -0.039      |
|    ent_std                  | 0.882       |
|    ent_value_loss           | 0.0974      |
|    entropy_loss             | -10.4       |
|    explained_variance       | 0.815       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0511      |
|    n_updates                | 170         |
|    policy_gradient_loss     | -0.0154     |
|    std                      | 0.886       |
|    value_loss               | 0.0971      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 88.2        |
|    ep_rew_mean              | -83.5       |
| time/                       |             |
|    fps                      | 161         |
|    iterations               | 19          |
|    time_elapsed             | 240         |
|    total_timesteps          | 38912       |
| train/                      |             |
|    approx_kl                | 0.045219142 |
|    clip_fraction            | 0.439       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.019165454 |
|    ent_clip_fraction        | 0.191       |
|    ent_entropy_loss         | -10.3       |
|    ent_loss                 | -0.0101     |
|    ent_policy_gradient_loss | -0.0367     |
|    ent_std                  | 0.878       |
|    ent_value_loss           | 0.0393      |
|    entropy_loss             | -10.4       |
|    explained_variance       | 0.666       |
|    learning_rate            | 0.0003      |
|    loss                     | -0.00829    |
|    n_updates                | 180         |
|    policy_gradient_loss     | -0.0213     |
|    std                      | 0.881       |
|    value_loss               | 0.0438      |
---------------------------------------------
Eval num_timesteps=40000, episode_reward=339.89 +/- 265.70
Episode length: 510.08 +/- 369.16
---------------------------------------------
| eval/                       |             |
|    mean_ep_length           | 510         |
|    mean_reward              | 340         |
| time/                       |             |
|    total_timesteps          | 40000       |
| train/                      |             |
|    approx_kl                | 0.04149859  |
|    clip_fraction            | 0.424       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.024768107 |
|    ent_clip_fraction        | 0.254       |
|    ent_entropy_loss         | -10.3       |
|    ent_loss                 | -0.00359    |
|    ent_policy_gradient_loss | -0.0322     |
|    ent_std                  | 0.874       |
|    ent_value_loss           | 0.104       |
|    entropy_loss             | -10.3       |
|    explained_variance       | 0.766       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0064      |
|    n_updates                | 190         |
|    policy_gradient_loss     | -0.0224     |
|    std                      | 0.877       |
|    value_loss               | 0.102       |
---------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 79.4     |
|    ep_rew_mean     | -75.7    |
| time/              |          |
|    fps             | 155      |
|    iterations      | 20       |
|    time_elapsed    | 264      |
|    total_timesteps | 40960    |
---------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 88          |
|    ep_rew_mean              | -80.3       |
| time/                       |             |
|    fps                      | 156         |
|    iterations               | 21          |
|    time_elapsed             | 274         |
|    total_timesteps          | 43008       |
| train/                      |             |
|    approx_kl                | 0.054271176 |
|    clip_fraction            | 0.486       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.01943883  |
|    ent_clip_fraction        | 0.195       |
|    ent_entropy_loss         | -10.2       |
|    ent_loss                 | -0.00922    |
|    ent_policy_gradient_loss | -0.0433     |
|    ent_std                  | 0.867       |
|    ent_value_loss           | 0.117       |
|    entropy_loss             | -10.3       |
|    explained_variance       | 0.749       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0494      |
|    n_updates                | 200         |
|    policy_gradient_loss     | -0.00878    |
|    std                      | 0.872       |
|    value_loss               | 0.111       |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 76.4        |
|    ep_rew_mean              | -67.9       |
| time/                       |             |
|    fps                      | 158         |
|    iterations               | 22          |
|    time_elapsed             | 284         |
|    total_timesteps          | 45056       |
| train/                      |             |
|    approx_kl                | 0.053487763 |
|    clip_fraction            | 0.481       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.02172954  |
|    ent_clip_fraction        | 0.214       |
|    ent_entropy_loss         | -10.2       |
|    ent_loss                 | -0.0408     |
|    ent_policy_gradient_loss | -0.0382     |
|    ent_std                  | 0.864       |
|    ent_value_loss           | 0.0413      |
|    entropy_loss             | -10.2       |
|    explained_variance       | 0.9         |
|    learning_rate            | 0.0003      |
|    loss                     | -0.0432     |
|    n_updates                | 210         |
|    policy_gradient_loss     | -0.0153     |
|    std                      | 0.867       |
|    value_loss               | 0.0409      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 75.7        |
|    ep_rew_mean              | -66.7       |
| time/                       |             |
|    fps                      | 159         |
|    iterations               | 23          |
|    time_elapsed             | 294         |
|    total_timesteps          | 47104       |
| train/                      |             |
|    approx_kl                | 0.067427605 |
|    clip_fraction            | 0.526       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.018665504 |
|    ent_clip_fraction        | 0.21        |
|    ent_entropy_loss         | -10.2       |
|    ent_loss                 | -0.03       |
|    ent_policy_gradient_loss | -0.0448     |
|    ent_std                  | 0.861       |
|    ent_value_loss           | 0.132       |
|    entropy_loss             | -10.2       |
|    explained_variance       | 0.436       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0241      |
|    n_updates                | 220         |
|    policy_gradient_loss     | -0.00277    |
|    std                      | 0.866       |
|    value_loss               | 0.13        |
---------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 75.6       |
|    ep_rew_mean              | -66.2      |
| time/                       |            |
|    fps                      | 161        |
|    iterations               | 24         |
|    time_elapsed             | 305        |
|    total_timesteps          | 49152      |
| train/                      |            |
|    approx_kl                | 0.05638931 |
|    clip_fraction            | 0.471      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.02379153 |
|    ent_clip_fraction        | 0.238      |
|    ent_entropy_loss         | -10.1      |
|    ent_loss                 | 0.0125     |
|    ent_policy_gradient_loss | -0.0372    |
|    ent_std                  | 0.852      |
|    ent_value_loss           | 0.0564     |
|    entropy_loss             | -10.1      |
|    explained_variance       | 0.802      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.000717   |
|    n_updates                | 230        |
|    policy_gradient_loss     | -0.0188    |
|    std                      | 0.855      |
|    value_loss               | 0.0549     |
--------------------------------------------
Eval num_timesteps=50000, episode_reward=139.73 +/- 210.34
Episode length: 183.12 +/- 294.24
---------------------------------------------
| eval/                       |             |
|    mean_ep_length           | 183         |
|    mean_reward              | 140         |
| time/                       |             |
|    total_timesteps          | 50000       |
| train/                      |             |
|    approx_kl                | 0.06057252  |
|    clip_fraction            | 0.513       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.017976392 |
|    ent_clip_fraction        | 0.198       |
|    ent_entropy_loss         | -10.1       |
|    ent_loss                 | -0.0273     |
|    ent_policy_gradient_loss | -0.0433     |
|    ent_std                  | 0.851       |
|    ent_value_loss           | 0.107       |
|    entropy_loss             | -10.1       |
|    explained_variance       | 0.667       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0312      |
|    n_updates                | 240         |
|    policy_gradient_loss     | 0.0123      |
|    std                      | 0.853       |
|    value_loss               | 0.105       |
---------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 74.6     |
|    ep_rew_mean     | -66.5    |
| time/              |          |
|    fps             | 158      |
|    iterations      | 25       |
|    time_elapsed    | 323      |
|    total_timesteps | 51200    |
---------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 90.8        |
|    ep_rew_mean              | -81.2       |
| time/                       |             |
|    fps                      | 159         |
|    iterations               | 26          |
|    time_elapsed             | 333         |
|    total_timesteps          | 53248       |
| train/                      |             |
|    approx_kl                | 0.056914575 |
|    clip_fraction            | 0.509       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.015872955 |
|    ent_clip_fraction        | 0.179       |
|    ent_entropy_loss         | -10         |
|    ent_loss                 | -0.0222     |
|    ent_policy_gradient_loss | -0.0387     |
|    ent_std                  | 0.847       |
|    ent_value_loss           | 0.062       |
|    entropy_loss             | -10.1       |
|    explained_variance       | 0.812       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0244      |
|    n_updates                | 250         |
|    policy_gradient_loss     | -0.00454    |
|    std                      | 0.853       |
|    value_loss               | 0.0615      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 88.8        |
|    ep_rew_mean              | -77.1       |
| time/                       |             |
|    fps                      | 161         |
|    iterations               | 27          |
|    time_elapsed             | 343         |
|    total_timesteps          | 55296       |
| train/                      |             |
|    approx_kl                | 0.059489205 |
|    clip_fraction            | 0.505       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.025587587 |
|    ent_clip_fraction        | 0.245       |
|    ent_entropy_loss         | -9.98       |
|    ent_loss                 | -0.0229     |
|    ent_policy_gradient_loss | -0.0295     |
|    ent_std                  | 0.84        |
|    ent_value_loss           | 0.0417      |
|    entropy_loss             | -10         |
|    explained_variance       | 0.864       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.05        |
|    n_updates                | 260         |
|    policy_gradient_loss     | -0.0091     |
|    std                      | 0.844       |
|    value_loss               | 0.044       |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 90.3        |
|    ep_rew_mean              | -78         |
| time/                       |             |
|    fps                      | 162         |
|    iterations               | 28          |
|    time_elapsed             | 353         |
|    total_timesteps          | 57344       |
| train/                      |             |
|    approx_kl                | 0.059987452 |
|    clip_fraction            | 0.511       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.023149714 |
|    ent_clip_fraction        | 0.215       |
|    ent_entropy_loss         | -9.91       |
|    ent_loss                 | -0.00783    |
|    ent_policy_gradient_loss | -0.0332     |
|    ent_std                  | 0.833       |
|    ent_value_loss           | 0.0937      |
|    entropy_loss             | -9.95       |
|    explained_variance       | 0.803       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0137      |
|    n_updates                | 270         |
|    policy_gradient_loss     | 0.00141     |
|    std                      | 0.837       |
|    value_loss               | 0.0953      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 109         |
|    ep_rew_mean              | -93.2       |
| time/                       |             |
|    fps                      | 163         |
|    iterations               | 29          |
|    time_elapsed             | 364         |
|    total_timesteps          | 59392       |
| train/                      |             |
|    approx_kl                | 0.057579704 |
|    clip_fraction            | 0.471       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.03724986  |
|    ent_clip_fraction        | 0.336       |
|    ent_entropy_loss         | -9.86       |
|    ent_loss                 | -0.00882    |
|    ent_policy_gradient_loss | -0.0295     |
|    ent_std                  | 0.828       |
|    ent_value_loss           | 0.0526      |
|    entropy_loss             | -9.89       |
|    explained_variance       | 0.75        |
|    learning_rate            | 0.0003      |
|    loss                     | -0.0161     |
|    n_updates                | 280         |
|    policy_gradient_loss     | -0.021      |
|    std                      | 0.831       |
|    value_loss               | 0.0487      |
---------------------------------------------
Eval num_timesteps=60000, episode_reward=63.49 +/- 49.15
Episode length: 74.56 +/- 70.26
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 74.6       |
|    mean_reward              | 63.5       |
| time/                       |            |
|    total_timesteps          | 60000      |
| train/                      |            |
|    approx_kl                | 0.07410636 |
|    clip_fraction            | 0.547      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.02190543 |
|    ent_clip_fraction        | 0.244      |
|    ent_entropy_loss         | -9.8       |
|    ent_loss                 | -0.0116    |
|    ent_policy_gradient_loss | -0.0426    |
|    ent_std                  | 0.821      |
|    ent_value_loss           | 0.0814     |
|    entropy_loss             | -9.84      |
|    explained_variance       | 0.796      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.00497    |
|    n_updates                | 290        |
|    policy_gradient_loss     | -0.0069    |
|    std                      | 0.826      |
|    value_loss               | 0.0811     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 109      |
|    ep_rew_mean     | -88.6    |
| time/              |          |
|    fps             | 163      |
|    iterations      | 30       |
|    time_elapsed    | 376      |
|    total_timesteps | 61440    |
---------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 101         |
|    ep_rew_mean              | -79.4       |
| time/                       |             |
|    fps                      | 164         |
|    iterations               | 31          |
|    time_elapsed             | 386         |
|    total_timesteps          | 63488       |
| train/                      |             |
|    approx_kl                | 0.07740181  |
|    clip_fraction            | 0.56        |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.019290306 |
|    ent_clip_fraction        | 0.221       |
|    ent_entropy_loss         | -9.7        |
|    ent_loss                 | -0.0367     |
|    ent_policy_gradient_loss | -0.0483     |
|    ent_std                  | 0.81        |
|    ent_value_loss           | 0.083       |
|    entropy_loss             | -9.76       |
|    explained_variance       | 0.834       |
|    learning_rate            | 0.0003      |
|    loss                     | -0.00759    |
|    n_updates                | 300         |
|    policy_gradient_loss     | 0.00392     |
|    std                      | 0.815       |
|    value_loss               | 0.0763      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 77          |
|    ep_rew_mean              | -58         |
| time/                       |             |
|    fps                      | 164         |
|    iterations               | 32          |
|    time_elapsed             | 397         |
|    total_timesteps          | 65536       |
| train/                      |             |
|    approx_kl                | 0.061805017 |
|    clip_fraction            | 0.517       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.031238735 |
|    ent_clip_fraction        | 0.282       |
|    ent_entropy_loss         | -9.63       |
|    ent_loss                 | -0.0269     |
|    ent_policy_gradient_loss | -0.0334     |
|    ent_std                  | 0.805       |
|    ent_value_loss           | 0.0729      |
|    entropy_loss             | -9.68       |
|    explained_variance       | 0.851       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.00742     |
|    n_updates                | 310         |
|    policy_gradient_loss     | -0.00464    |
|    std                      | 0.809       |
|    value_loss               | 0.0709      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 97.2        |
|    ep_rew_mean              | -74.3       |
| time/                       |             |
|    fps                      | 165         |
|    iterations               | 33          |
|    time_elapsed             | 407         |
|    total_timesteps          | 67584       |
| train/                      |             |
|    approx_kl                | 0.059878483 |
|    clip_fraction            | 0.458       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.0436002   |
|    ent_clip_fraction        | 0.358       |
|    ent_entropy_loss         | -9.6        |
|    ent_loss                 | 0.0199      |
|    ent_policy_gradient_loss | -0.0179     |
|    ent_std                  | 0.803       |
|    ent_value_loss           | 0.0663      |
|    entropy_loss             | -9.62       |
|    explained_variance       | 0.882       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.00616     |
|    n_updates                | 320         |
|    policy_gradient_loss     | -0.018      |
|    std                      | 0.803       |
|    value_loss               | 0.0647      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 64.9        |
|    ep_rew_mean              | -51.7       |
| time/                       |             |
|    fps                      | 166         |
|    iterations               | 34          |
|    time_elapsed             | 417         |
|    total_timesteps          | 69632       |
| train/                      |             |
|    approx_kl                | 0.077182055 |
|    clip_fraction            | 0.567       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.021768594 |
|    ent_clip_fraction        | 0.23        |
|    ent_entropy_loss         | -9.54       |
|    ent_loss                 | -0.0506     |
|    ent_policy_gradient_loss | -0.0355     |
|    ent_std                  | 0.793       |
|    ent_value_loss           | 0.0285      |
|    entropy_loss             | -9.58       |
|    explained_variance       | 0.834       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0191      |
|    n_updates                | 330         |
|    policy_gradient_loss     | 0.00151     |
|    std                      | 0.799       |
|    value_loss               | 0.0284      |
---------------------------------------------
Eval num_timesteps=70000, episode_reward=102.74 +/- 170.30
Episode length: 141.00 +/- 260.17
---------------------------------------------
| eval/                       |             |
|    mean_ep_length           | 141         |
|    mean_reward              | 103         |
| time/                       |             |
|    total_timesteps          | 70000       |
| train/                      |             |
|    approx_kl                | 0.080673195 |
|    clip_fraction            | 0.564       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.020866044 |
|    ent_clip_fraction        | 0.229       |
|    ent_entropy_loss         | -9.45       |
|    ent_loss                 | -0.00536    |
|    ent_policy_gradient_loss | -0.0422     |
|    ent_std                  | 0.787       |
|    ent_value_loss           | 0.0978      |
|    entropy_loss             | -9.52       |
|    explained_variance       | -0.0326     |
|    learning_rate            | 0.0003      |
|    loss                     | 0.00238     |
|    n_updates                | 340         |
|    policy_gradient_loss     | 0.00832     |
|    std                      | 0.793       |
|    value_loss               | 0.095       |
---------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 65.9     |
|    ep_rew_mean     | -51.5    |
| time/              |          |
|    fps             | 165      |
|    iterations      | 35       |
|    time_elapsed    | 432      |
|    total_timesteps | 71680    |
---------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 76.8        |
|    ep_rew_mean              | -58         |
| time/                       |             |
|    fps                      | 166         |
|    iterations               | 36          |
|    time_elapsed             | 443         |
|    total_timesteps          | 73728       |
| train/                      |             |
|    approx_kl                | 0.085619554 |
|    clip_fraction            | 0.577       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.022654176 |
|    ent_clip_fraction        | 0.251       |
|    ent_entropy_loss         | -9.37       |
|    ent_loss                 | -0.0595     |
|    ent_policy_gradient_loss | -0.0459     |
|    ent_std                  | 0.777       |
|    ent_value_loss           | 0.0448      |
|    entropy_loss             | -9.42       |
|    explained_variance       | 0.861       |
|    learning_rate            | 0.0003      |
|    loss                     | -0.0214     |
|    n_updates                | 350         |
|    policy_gradient_loss     | -0.0128     |
|    std                      | 0.781       |
|    value_loss               | 0.0421      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 74.4        |
|    ep_rew_mean              | -54.3       |
| time/                       |             |
|    fps                      | 167         |
|    iterations               | 37          |
|    time_elapsed             | 453         |
|    total_timesteps          | 75776       |
| train/                      |             |
|    approx_kl                | 0.08966227  |
|    clip_fraction            | 0.583       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.022136394 |
|    ent_clip_fraction        | 0.228       |
|    ent_entropy_loss         | -9.28       |
|    ent_loss                 | -0.0406     |
|    ent_policy_gradient_loss | -0.0431     |
|    ent_std                  | 0.769       |
|    ent_value_loss           | 0.0495      |
|    entropy_loss             | -9.33       |
|    explained_variance       | 0.868       |
|    learning_rate            | 0.0003      |
|    loss                     | -0.00308    |
|    n_updates                | 360         |
|    policy_gradient_loss     | 0.00931     |
|    std                      | 0.774       |
|    value_loss               | 0.0469      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 87          |
|    ep_rew_mean              | -60.6       |
| time/                       |             |
|    fps                      | 167         |
|    iterations               | 38          |
|    time_elapsed             | 463         |
|    total_timesteps          | 77824       |
| train/                      |             |
|    approx_kl                | 0.086033314 |
|    clip_fraction            | 0.591       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.025444478 |
|    ent_clip_fraction        | 0.265       |
|    ent_entropy_loss         | -9.22       |
|    ent_loss                 | -0.0431     |
|    ent_policy_gradient_loss | -0.044      |
|    ent_std                  | 0.766       |
|    ent_value_loss           | 0.0355      |
|    entropy_loss             | -9.27       |
|    explained_variance       | 0.92        |
|    learning_rate            | 0.0003      |
|    loss                     | 0.00689     |
|    n_updates                | 370         |
|    policy_gradient_loss     | 0.0019      |
|    std                      | 0.77        |
|    value_loss               | 0.0348      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 106         |
|    ep_rew_mean              | -74.8       |
| time/                       |             |
|    fps                      | 168         |
|    iterations               | 39          |
|    time_elapsed             | 474         |
|    total_timesteps          | 79872       |
| train/                      |             |
|    approx_kl                | 0.085113384 |
|    clip_fraction            | 0.56        |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.036992084 |
|    ent_clip_fraction        | 0.302       |
|    ent_entropy_loss         | -9.19       |
|    ent_loss                 | -0.0471     |
|    ent_policy_gradient_loss | -0.0254     |
|    ent_std                  | 0.762       |
|    ent_value_loss           | 0.0566      |
|    entropy_loss             | -9.22       |
|    explained_variance       | 0.876       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0262      |
|    n_updates                | 380         |
|    policy_gradient_loss     | -0.00075    |
|    std                      | 0.765       |
|    value_loss               | 0.055       |
---------------------------------------------
Eval num_timesteps=80000, episode_reward=72.73 +/- 120.32
Episode length: 84.12 +/- 190.94
---------------------------------------------
| eval/                       |             |
|    mean_ep_length           | 84.1        |
|    mean_reward              | 72.7        |
| time/                       |             |
|    total_timesteps          | 80000       |
| train/                      |             |
|    approx_kl                | 0.09817292  |
|    clip_fraction            | 0.607       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.022090705 |
|    ent_clip_fraction        | 0.241       |
|    ent_entropy_loss         | -9.11       |
|    ent_loss                 | -0.0559     |
|    ent_policy_gradient_loss | -0.0414     |
|    ent_std                  | 0.751       |
|    ent_value_loss           | 0.0259      |
|    entropy_loss             | -9.17       |
|    explained_variance       | 0.821       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.00155     |
|    n_updates                | 390         |
|    policy_gradient_loss     | 0.00455     |
|    std                      | 0.758       |
|    value_loss               | 0.0255      |
---------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 116      |
|    ep_rew_mean     | -80.1    |
| time/              |          |
|    fps             | 167      |
|    iterations      | 40       |
|    time_elapsed    | 488      |
|    total_timesteps | 81920    |
---------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 127         |
|    ep_rew_mean              | -85.4       |
| time/                       |             |
|    fps                      | 168         |
|    iterations               | 41          |
|    time_elapsed             | 498         |
|    total_timesteps          | 83968       |
| train/                      |             |
|    approx_kl                | 0.103963666 |
|    clip_fraction            | 0.598       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.021693729 |
|    ent_clip_fraction        | 0.245       |
|    ent_entropy_loss         | -9.03       |
|    ent_loss                 | -0.0332     |
|    ent_policy_gradient_loss | -0.0459     |
|    ent_std                  | 0.746       |
|    ent_value_loss           | 0.0467      |
|    entropy_loss             | -9.09       |
|    explained_variance       | 0.869       |
|    learning_rate            | 0.0003      |
|    loss                     | -0.0173     |
|    n_updates                | 400         |
|    policy_gradient_loss     | 0.0115      |
|    std                      | 0.751       |
|    value_loss               | 0.0456      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 119         |
|    ep_rew_mean              | -77.1       |
| time/                       |             |
|    fps                      | 168         |
|    iterations               | 42          |
|    time_elapsed             | 509         |
|    total_timesteps          | 86016       |
| train/                      |             |
|    approx_kl                | 0.08928351  |
|    clip_fraction            | 0.592       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.029706135 |
|    ent_clip_fraction        | 0.273       |
|    ent_entropy_loss         | -8.97       |
|    ent_loss                 | -0.0124     |
|    ent_policy_gradient_loss | -0.0408     |
|    ent_std                  | 0.74        |
|    ent_value_loss           | 0.0337      |
|    entropy_loss             | -9.01       |
|    explained_variance       | 0.798       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.00236     |
|    n_updates                | 410         |
|    policy_gradient_loss     | -0.0104     |
|    std                      | 0.743       |
|    value_loss               | 0.033       |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 139         |
|    ep_rew_mean              | -90.3       |
| time/                       |             |
|    fps                      | 169         |
|    iterations               | 43          |
|    time_elapsed             | 519         |
|    total_timesteps          | 88064       |
| train/                      |             |
|    approx_kl                | 0.108024545 |
|    clip_fraction            | 0.619       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.026527207 |
|    ent_clip_fraction        | 0.245       |
|    ent_entropy_loss         | -8.91       |
|    ent_loss                 | -0.00785    |
|    ent_policy_gradient_loss | -0.0473     |
|    ent_std                  | 0.735       |
|    ent_value_loss           | 0.0626      |
|    entropy_loss             | -8.95       |
|    explained_variance       | 0.831       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0489      |
|    n_updates                | 420         |
|    policy_gradient_loss     | 0.00829     |
|    std                      | 0.74        |
|    value_loss               | 0.0605      |
---------------------------------------------
Eval num_timesteps=90000, episode_reward=165.55 +/- 241.43
Episode length: 262.12 +/- 390.02
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 262        |
|    mean_reward              | 166        |
| time/                       |            |
|    total_timesteps          | 90000      |
| train/                      |            |
|    approx_kl                | 0.09909992 |
|    clip_fraction            | 0.577      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.04028269 |
|    ent_clip_fraction        | 0.325      |
|    ent_entropy_loss         | -8.86      |
|    ent_loss                 | -0.0448    |
|    ent_policy_gradient_loss | -0.0314    |
|    ent_std                  | 0.732      |
|    ent_value_loss           | 0.0213     |
|    entropy_loss             | -8.9       |
|    explained_variance       | 0.779      |
|    learning_rate            | 0.0003     |
|    loss                     | -0.0206    |
|    n_updates                | 430        |
|    policy_gradient_loss     | -0.00344   |
|    std                      | 0.735      |
|    value_loss               | 0.0219     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 132      |
|    ep_rew_mean     | -85.4    |
| time/              |          |
|    fps             | 167      |
|    iterations      | 44       |
|    time_elapsed    | 537      |
|    total_timesteps | 90112    |
---------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 112         |
|    ep_rew_mean              | -67.6       |
| time/                       |             |
|    fps                      | 168         |
|    iterations               | 45          |
|    time_elapsed             | 547         |
|    total_timesteps          | 92160       |
| train/                      |             |
|    approx_kl                | 0.094274774 |
|    clip_fraction            | 0.566       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.042516664 |
|    ent_clip_fraction        | 0.325       |
|    ent_entropy_loss         | -8.8        |
|    ent_loss                 | -0.0284     |
|    ent_policy_gradient_loss | -0.0265     |
|    ent_std                  | 0.723       |
|    ent_value_loss           | 0.0688      |
|    entropy_loss             | -8.84       |
|    explained_variance       | 0.814       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0433      |
|    n_updates                | 440         |
|    policy_gradient_loss     | 0.00454     |
|    std                      | 0.728       |
|    value_loss               | 0.0679      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 77.2        |
|    ep_rew_mean              | -44.1       |
| time/                       |             |
|    fps                      | 168         |
|    iterations               | 46          |
|    time_elapsed             | 558         |
|    total_timesteps          | 94208       |
| train/                      |             |
|    approx_kl                | 0.07267326  |
|    clip_fraction            | 0.471       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.069084615 |
|    ent_clip_fraction        | 0.425       |
|    ent_entropy_loss         | -8.74       |
|    ent_loss                 | -0.0278     |
|    ent_policy_gradient_loss | -0.00838    |
|    ent_std                  | 0.721       |
|    ent_value_loss           | 0.0579      |
|    entropy_loss             | -8.77       |
|    explained_variance       | 0.863       |
|    learning_rate            | 0.0003      |
|    loss                     | -0.02       |
|    n_updates                | 450         |
|    policy_gradient_loss     | -0.0196     |
|    std                      | 0.723       |
|    value_loss               | 0.057       |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 69.5        |
|    ep_rew_mean              | -39.7       |
| time/                       |             |
|    fps                      | 169         |
|    iterations               | 47          |
|    time_elapsed             | 567         |
|    total_timesteps          | 96256       |
| train/                      |             |
|    approx_kl                | 0.11709986  |
|    clip_fraction            | 0.634       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.022424186 |
|    ent_clip_fraction        | 0.245       |
|    ent_entropy_loss         | -8.7        |
|    ent_loss                 | -0.0362     |
|    ent_policy_gradient_loss | -0.0461     |
|    ent_std                  | 0.717       |
|    ent_value_loss           | 0.0589      |
|    entropy_loss             | -8.74       |
|    explained_variance       | 0.873       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0104      |
|    n_updates                | 460         |
|    policy_gradient_loss     | 0.0124      |
|    std                      | 0.722       |
|    value_loss               | 0.0596      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 79.1        |
|    ep_rew_mean              | -46         |
| time/                       |             |
|    fps                      | 170         |
|    iterations               | 48          |
|    time_elapsed             | 577         |
|    total_timesteps          | 98304       |
| train/                      |             |
|    approx_kl                | 0.11408825  |
|    clip_fraction            | 0.64        |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.026179094 |
|    ent_clip_fraction        | 0.259       |
|    ent_entropy_loss         | -8.64       |
|    ent_loss                 | -0.0471     |
|    ent_policy_gradient_loss | -0.0427     |
|    ent_std                  | 0.711       |
|    ent_value_loss           | 0.032       |
|    entropy_loss             | -8.73       |
|    explained_variance       | 0.91        |
|    learning_rate            | 0.0003      |
|    loss                     | -0.0295     |
|    n_updates                | 470         |
|    policy_gradient_loss     | 0.0155      |
|    std                      | 0.72        |
|    value_loss               | 0.031       |
---------------------------------------------
Eval num_timesteps=100000, episode_reward=299.37 +/- 322.60
Episode length: 391.44 +/- 421.48
---------------------------------------------
| eval/                       |             |
|    mean_ep_length           | 391         |
|    mean_reward              | 299         |
| time/                       |             |
|    total_timesteps          | 100000      |
| train/                      |             |
|    approx_kl                | 0.09568334  |
|    clip_fraction            | 0.596       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.036894806 |
|    ent_clip_fraction        | 0.291       |
|    ent_entropy_loss         | -8.57       |
|    ent_loss                 | -0.00283    |
|    ent_policy_gradient_loss | -0.0309     |
|    ent_std                  | 0.703       |
|    ent_value_loss           | 0.0368      |
|    entropy_loss             | -8.65       |
|    explained_variance       | 0.902       |
|    learning_rate            | 0.0003      |
|    loss                     | -0.0136     |
|    n_updates                | 480         |
|    policy_gradient_loss     | 0.00274     |
|    std                      | 0.711       |
|    value_loss               | 0.0344      |
---------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 78       |
|    ep_rew_mean     | -47.2    |
| time/              |          |
|    fps             | 167      |
|    iterations      | 49       |
|    time_elapsed    | 599      |
|    total_timesteps | 100352   |
---------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 96.5        |
|    ep_rew_mean              | -59.3       |
| time/                       |             |
|    fps                      | 168         |
|    iterations               | 50          |
|    time_elapsed             | 609         |
|    total_timesteps          | 102400      |
| train/                      |             |
|    approx_kl                | 0.10031265  |
|    clip_fraction            | 0.595       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.032869346 |
|    ent_clip_fraction        | 0.281       |
|    ent_entropy_loss         | -8.51       |
|    ent_loss                 | -0.0593     |
|    ent_policy_gradient_loss | -0.0297     |
|    ent_std                  | 0.7         |
|    ent_value_loss           | 0.0375      |
|    entropy_loss             | -8.58       |
|    explained_variance       | 0.902       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.00455     |
|    n_updates                | 490         |
|    policy_gradient_loss     | 0.00177     |
|    std                      | 0.704       |
|    value_loss               | 0.0345      |
---------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 98         |
|    ep_rew_mean              | -56.7      |
| time/                       |            |
|    fps                      | 168        |
|    iterations               | 51         |
|    time_elapsed             | 619        |
|    total_timesteps          | 104448     |
| train/                      |            |
|    approx_kl                | 0.10171567 |
|    clip_fraction            | 0.594      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.03390529 |
|    ent_clip_fraction        | 0.291      |
|    ent_entropy_loss         | -8.43      |
|    ent_loss                 | -0.0351    |
|    ent_policy_gradient_loss | -0.0302    |
|    ent_std                  | 0.691      |
|    ent_value_loss           | 0.0252     |
|    entropy_loss             | -8.48      |
|    explained_variance       | 0.831      |
|    learning_rate            | 0.0003     |
|    loss                     | -0.0391    |
|    n_updates                | 500        |
|    policy_gradient_loss     | -0.00465   |
|    std                      | 0.695      |
|    value_loss               | 0.0248     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 108        |
|    ep_rew_mean              | -62.1      |
| time/                       |            |
|    fps                      | 169        |
|    iterations               | 52         |
|    time_elapsed             | 629        |
|    total_timesteps          | 106496     |
| train/                      |            |
|    approx_kl                | 0.12278432 |
|    clip_fraction            | 0.619      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.02422186 |
|    ent_clip_fraction        | 0.249      |
|    ent_entropy_loss         | -8.37      |
|    ent_loss                 | -0.041     |
|    ent_policy_gradient_loss | -0.045     |
|    ent_std                  | 0.688      |
|    ent_value_loss           | 0.0458     |
|    entropy_loss             | -8.44      |
|    explained_variance       | 0.819      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.00422    |
|    n_updates                | 510        |
|    policy_gradient_loss     | 0.0236     |
|    std                      | 0.696      |
|    value_loss               | 0.0464     |
--------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 108         |
|    ep_rew_mean              | -61         |
| time/                       |             |
|    fps                      | 169         |
|    iterations               | 53          |
|    time_elapsed             | 639         |
|    total_timesteps          | 108544      |
| train/                      |             |
|    approx_kl                | 0.122554325 |
|    clip_fraction            | 0.643       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.020113898 |
|    ent_clip_fraction        | 0.227       |
|    ent_entropy_loss         | -8.31       |
|    ent_loss                 | -0.0581     |
|    ent_policy_gradient_loss | -0.0419     |
|    ent_std                  | 0.682       |
|    ent_value_loss           | 0.0144      |
|    entropy_loss             | -8.4        |
|    explained_variance       | 0.738       |
|    learning_rate            | 0.0003      |
|    loss                     | -0.0236     |
|    n_updates                | 520         |
|    policy_gradient_loss     | 0.0171      |
|    std                      | 0.689       |
|    value_loss               | 0.0142      |
---------------------------------------------
Eval num_timesteps=110000, episode_reward=191.91 +/- 225.82
Episode length: 266.32 +/- 328.89
---------------------------------------------
| eval/                       |             |
|    mean_ep_length           | 266         |
|    mean_reward              | 192         |
| time/                       |             |
|    total_timesteps          | 110000      |
| train/                      |             |
|    approx_kl                | 0.1079209   |
|    clip_fraction            | 0.59        |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.047945857 |
|    ent_clip_fraction        | 0.323       |
|    ent_entropy_loss         | -8.24       |
|    ent_loss                 | -0.0608     |
|    ent_policy_gradient_loss | -0.0236     |
|    ent_std                  | 0.675       |
|    ent_value_loss           | 0.0438      |
|    entropy_loss             | -8.32       |
|    explained_variance       | 0.804       |
|    learning_rate            | 0.0003      |
|    loss                     | -0.0277     |
|    n_updates                | 530         |
|    policy_gradient_loss     | 0.00639     |
|    std                      | 0.682       |
|    value_loss               | 0.0422      |
---------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 111      |
|    ep_rew_mean     | -60.2    |
| time/              |          |
|    fps             | 168      |
|    iterations      | 54       |
|    time_elapsed    | 654      |
|    total_timesteps | 110592   |
---------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 91.5        |
|    ep_rew_mean              | -47         |
| time/                       |             |
|    fps                      | 169         |
|    iterations               | 55          |
|    time_elapsed             | 665         |
|    total_timesteps          | 112640      |
| train/                      |             |
|    approx_kl                | 0.11335837  |
|    clip_fraction            | 0.617       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.042167194 |
|    ent_clip_fraction        | 0.342       |
|    ent_entropy_loss         | -8.17       |
|    ent_loss                 | -0.0298     |
|    ent_policy_gradient_loss | -0.031      |
|    ent_std                  | 0.67        |
|    ent_value_loss           | 0.038       |
|    entropy_loss             | -8.24       |
|    explained_variance       | 0.866       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0235      |
|    n_updates                | 540         |
|    policy_gradient_loss     | 0.0122      |
|    std                      | 0.676       |
|    value_loss               | 0.0398      |
---------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 45.6       |
|    ep_rew_mean              | -19.6      |
| time/                       |            |
|    fps                      | 169        |
|    iterations               | 56         |
|    time_elapsed             | 675        |
|    total_timesteps          | 114688     |
| train/                      |            |
|    approx_kl                | 0.12509961 |
|    clip_fraction            | 0.63       |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.03994651 |
|    ent_clip_fraction        | 0.312      |
|    ent_entropy_loss         | -8.09      |
|    ent_loss                 | -0.00638   |
|    ent_policy_gradient_loss | -0.0409    |
|    ent_std                  | 0.663      |
|    ent_value_loss           | 0.0561     |
|    entropy_loss             | -8.15      |
|    explained_variance       | 0.845      |
|    learning_rate            | 0.0003     |
|    loss                     | -0.0318    |
|    n_updates                | 550        |
|    policy_gradient_loss     | 0.00309    |
|    std                      | 0.667      |
|    value_loss               | 0.0555     |
--------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 54.5        |
|    ep_rew_mean              | -23.6       |
| time/                       |             |
|    fps                      | 170         |
|    iterations               | 57          |
|    time_elapsed             | 685         |
|    total_timesteps          | 116736      |
| train/                      |             |
|    approx_kl                | 0.13459718  |
|    clip_fraction            | 0.651       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.019451955 |
|    ent_clip_fraction        | 0.245       |
|    ent_entropy_loss         | -8          |
|    ent_loss                 | -0.0309     |
|    ent_policy_gradient_loss | -0.0513     |
|    ent_std                  | 0.656       |
|    ent_value_loss           | 0.0692      |
|    entropy_loss             | -8.07       |
|    explained_variance       | 0.153       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0441      |
|    n_updates                | 560         |
|    policy_gradient_loss     | 0.0325      |
|    std                      | 0.662       |
|    value_loss               | 0.0678      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 64          |
|    ep_rew_mean              | -28         |
| time/                       |             |
|    fps                      | 170         |
|    iterations               | 58          |
|    time_elapsed             | 695         |
|    total_timesteps          | 118784      |
| train/                      |             |
|    approx_kl                | 0.14126188  |
|    clip_fraction            | 0.673       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.021811696 |
|    ent_clip_fraction        | 0.237       |
|    ent_entropy_loss         | -7.93       |
|    ent_loss                 | -0.0436     |
|    ent_policy_gradient_loss | -0.0485     |
|    ent_std                  | 0.65        |
|    ent_value_loss           | 0.0305      |
|    entropy_loss             | -8.02       |
|    explained_variance       | 0.853       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.00309     |
|    n_updates                | 570         |
|    policy_gradient_loss     | 0.0231      |
|    std                      | 0.658       |
|    value_loss               | 0.0315      |
---------------------------------------------
Eval num_timesteps=120000, episode_reward=261.33 +/- 327.38
Episode length: 355.68 +/- 444.49
---------------------------------------------
| eval/                       |             |
|    mean_ep_length           | 356         |
|    mean_reward              | 261         |
| time/                       |             |
|    total_timesteps          | 120000      |
| train/                      |             |
|    approx_kl                | 0.113552935 |
|    clip_fraction            | 0.626       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.037492074 |
|    ent_clip_fraction        | 0.294       |
|    ent_entropy_loss         | -7.85       |
|    ent_loss                 | -0.032      |
|    ent_policy_gradient_loss | -0.0377     |
|    ent_std                  | 0.643       |
|    ent_value_loss           | 0.0225      |
|    entropy_loss             | -7.96       |
|    explained_variance       | 0.786       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0229      |
|    n_updates                | 580         |
|    policy_gradient_loss     | 0.0144      |
|    std                      | 0.653       |
|    value_loss               | 0.0231      |
---------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.2     |
|    ep_rew_mean     | -30.9    |
| time/              |          |
|    fps             | 168      |
|    iterations      | 59       |
|    time_elapsed    | 717      |
|    total_timesteps | 120832   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 94.3       |
|    ep_rew_mean              | -40.9      |
| time/                       |            |
|    fps                      | 168        |
|    iterations               | 60         |
|    time_elapsed             | 727        |
|    total_timesteps          | 122880     |
| train/                      |            |
|    approx_kl                | 0.12097804 |
|    clip_fraction            | 0.644      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.04451354 |
|    ent_clip_fraction        | 0.328      |
|    ent_entropy_loss         | -7.76      |
|    ent_loss                 | -0.0208    |
|    ent_policy_gradient_loss | -0.031     |
|    ent_std                  | 0.637      |
|    ent_value_loss           | 0.0288     |
|    entropy_loss             | -7.88      |
|    explained_variance       | 0.89       |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0239     |
|    n_updates                | 590        |
|    policy_gradient_loss     | 0.0137     |
|    std                      | 0.646      |
|    value_loss               | 0.0302     |
--------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 104         |
|    ep_rew_mean              | -45.4       |
| time/                       |             |
|    fps                      | 169         |
|    iterations               | 61          |
|    time_elapsed             | 738         |
|    total_timesteps          | 124928      |
| train/                      |             |
|    approx_kl                | 0.12894885  |
|    clip_fraction            | 0.64        |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.039024524 |
|    ent_clip_fraction        | 0.322       |
|    ent_entropy_loss         | -7.69       |
|    ent_loss                 | -0.0211     |
|    ent_policy_gradient_loss | -0.0404     |
|    ent_std                  | 0.63        |
|    ent_value_loss           | 0.0137      |
|    entropy_loss             | -7.79       |
|    explained_variance       | 0.825       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0262      |
|    n_updates                | 600         |
|    policy_gradient_loss     | 0.00509     |
|    std                      | 0.637       |
|    value_loss               | 0.0138      |
---------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 117        |
|    ep_rew_mean              | -49.7      |
| time/                       |            |
|    fps                      | 169        |
|    iterations               | 62         |
|    time_elapsed             | 748        |
|    total_timesteps          | 126976     |
| train/                      |            |
|    approx_kl                | 0.14624637 |
|    clip_fraction            | 0.655      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.03437376 |
|    ent_clip_fraction        | 0.313      |
|    ent_entropy_loss         | -7.6       |
|    ent_loss                 | -0.0491    |
|    ent_policy_gradient_loss | -0.0374    |
|    ent_std                  | 0.623      |
|    ent_value_loss           | 0.0254     |
|    entropy_loss             | -7.7       |
|    explained_variance       | 0.876      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0379     |
|    n_updates                | 610        |
|    policy_gradient_loss     | 0.0188     |
|    std                      | 0.633      |
|    value_loss               | 0.0233     |
--------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 53.5        |
|    ep_rew_mean              | -16.5       |
| time/                       |             |
|    fps                      | 170         |
|    iterations               | 63          |
|    time_elapsed             | 758         |
|    total_timesteps          | 129024      |
| train/                      |             |
|    approx_kl                | 0.1487193   |
|    clip_fraction            | 0.68        |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.024713054 |
|    ent_clip_fraction        | 0.261       |
|    ent_entropy_loss         | -7.54       |
|    ent_loss                 | -0.0577     |
|    ent_policy_gradient_loss | -0.0517     |
|    ent_std                  | 0.621       |
|    ent_value_loss           | 0.0588      |
|    entropy_loss             | -7.65       |
|    explained_variance       | 0.592       |
|    learning_rate            | 0.0003      |
|    loss                     | -0.000829   |
|    n_updates                | 620         |
|    policy_gradient_loss     | 0.0464      |
|    std                      | 0.627       |
|    value_loss               | 0.0587      |
---------------------------------------------
Eval num_timesteps=130000, episode_reward=227.58 +/- 304.30
Episode length: 269.00 +/- 371.18
---------------------------------------------
| eval/                       |             |
|    mean_ep_length           | 269         |
|    mean_reward              | 228         |
| time/                       |             |
|    total_timesteps          | 130000      |
| train/                      |             |
|    approx_kl                | 0.15641192  |
|    clip_fraction            | 0.686       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.020107767 |
|    ent_clip_fraction        | 0.251       |
|    ent_entropy_loss         | -7.5        |
|    ent_loss                 | -0.0475     |
|    ent_policy_gradient_loss | -0.053      |
|    ent_std                  | 0.617       |
|    ent_value_loss           | 0.0577      |
|    entropy_loss             | -7.6        |
|    explained_variance       | 0.266       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0331      |
|    n_updates                | 630         |
|    policy_gradient_loss     | 0.0389      |
|    std                      | 0.625       |
|    value_loss               | 0.0579      |
---------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 64       |
|    ep_rew_mean     | -22.4    |
| time/              |          |
|    fps             | 168      |
|    iterations      | 64       |
|    time_elapsed    | 777      |
|    total_timesteps | 131072   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 73.5       |
|    ep_rew_mean              | -25.6      |
| time/                       |            |
|    fps                      | 168        |
|    iterations               | 65         |
|    time_elapsed             | 788        |
|    total_timesteps          | 133120     |
| train/                      |            |
|    approx_kl                | 0.16731086 |
|    clip_fraction            | 0.701      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.02363563 |
|    ent_clip_fraction        | 0.263      |
|    ent_entropy_loss         | -7.45      |
|    ent_loss                 | -0.0691    |
|    ent_policy_gradient_loss | -0.0481    |
|    ent_std                  | 0.613      |
|    ent_value_loss           | 0.0223     |
|    entropy_loss             | -7.56      |
|    explained_variance       | 0.821      |
|    learning_rate            | 0.0003     |
|    loss                     | -0.0335    |
|    n_updates                | 640        |
|    policy_gradient_loss     | 0.0231     |
|    std                      | 0.621      |
|    value_loss               | 0.0229     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 79         |
|    ep_rew_mean              | -26.5      |
| time/                       |            |
|    fps                      | 169        |
|    iterations               | 66         |
|    time_elapsed             | 798        |
|    total_timesteps          | 135168     |
| train/                      |            |
|    approx_kl                | 0.13815555 |
|    clip_fraction            | 0.639      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.04964553 |
|    ent_clip_fraction        | 0.336      |
|    ent_entropy_loss         | -7.39      |
|    ent_loss                 | -0.0562    |
|    ent_policy_gradient_loss | -0.0237    |
|    ent_std                  | 0.607      |
|    ent_value_loss           | 0.0156     |
|    entropy_loss             | -7.5       |
|    explained_variance       | 0.547      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0198     |
|    n_updates                | 650        |
|    policy_gradient_loss     | 0.0158     |
|    std                      | 0.616      |
|    value_loss               | 0.0159     |
--------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 92.7        |
|    ep_rew_mean              | -33.3       |
| time/                       |             |
|    fps                      | 169         |
|    iterations               | 67          |
|    time_elapsed             | 808         |
|    total_timesteps          | 137216      |
| train/                      |             |
|    approx_kl                | 0.14387588  |
|    clip_fraction            | 0.656       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.042100504 |
|    ent_clip_fraction        | 0.324       |
|    ent_entropy_loss         | -7.31       |
|    ent_loss                 | -0.0657     |
|    ent_policy_gradient_loss | -0.0424     |
|    ent_std                  | 0.602       |
|    ent_value_loss           | 0.03        |
|    entropy_loss             | -7.42       |
|    explained_variance       | 0.837       |
|    learning_rate            | 0.0003      |
|    loss                     | -0.014      |
|    n_updates                | 660         |
|    policy_gradient_loss     | 0.0298      |
|    std                      | 0.61        |
|    value_loss               | 0.0316      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 112         |
|    ep_rew_mean              | -38.8       |
| time/                       |             |
|    fps                      | 169         |
|    iterations               | 68          |
|    time_elapsed             | 819         |
|    total_timesteps          | 139264      |
| train/                      |             |
|    approx_kl                | 0.16748434  |
|    clip_fraction            | 0.695       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.026761627 |
|    ent_clip_fraction        | 0.258       |
|    ent_entropy_loss         | -7.24       |
|    ent_loss                 | -0.0363     |
|    ent_policy_gradient_loss | -0.051      |
|    ent_std                  | 0.598       |
|    ent_value_loss           | 0.0698      |
|    entropy_loss             | -7.36       |
|    explained_variance       | 0.691       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0378      |
|    n_updates                | 670         |
|    policy_gradient_loss     | 0.0443      |
|    std                      | 0.605       |
|    value_loss               | 0.0689      |
---------------------------------------------
Eval num_timesteps=140000, episode_reward=214.24 +/- 268.86
Episode length: 290.16 +/- 400.43
---------------------------------------------
| eval/                       |             |
|    mean_ep_length           | 290         |
|    mean_reward              | 214         |
| time/                       |             |
|    total_timesteps          | 140000      |
| train/                      |             |
|    approx_kl                | 0.11102417  |
|    clip_fraction            | 0.522       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.114517055 |
|    ent_clip_fraction        | 0.567       |
|    ent_entropy_loss         | -7.2        |
|    ent_loss                 | -0.0353     |
|    ent_policy_gradient_loss | -0.00351    |
|    ent_std                  | 0.593       |
|    ent_value_loss           | 0.0202      |
|    entropy_loss             | -7.26       |
|    explained_variance       | 0.814       |
|    learning_rate            | 0.0003      |
|    loss                     | -0.0322     |
|    n_updates                | 680         |
|    policy_gradient_loss     | -0.00453    |
|    std                      | 0.597       |
|    value_loss               | 0.0195      |
---------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 109      |
|    ep_rew_mean     | -37      |
| time/              |          |
|    fps             | 168      |
|    iterations      | 69       |
|    time_elapsed    | 837      |
|    total_timesteps | 141312   |
---------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 93.8        |
|    ep_rew_mean              | -29.4       |
| time/                       |             |
|    fps                      | 169         |
|    iterations               | 70          |
|    time_elapsed             | 847         |
|    total_timesteps          | 143360      |
| train/                      |             |
|    approx_kl                | 0.18486597  |
|    clip_fraction            | 0.703       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.020654075 |
|    ent_clip_fraction        | 0.247       |
|    ent_entropy_loss         | -7.12       |
|    ent_loss                 | -0.0543     |
|    ent_policy_gradient_loss | -0.0468     |
|    ent_std                  | 0.588       |
|    ent_value_loss           | 0.0321      |
|    entropy_loss             | -7.19       |
|    explained_variance       | 0.848       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0396      |
|    n_updates                | 690         |
|    policy_gradient_loss     | 0.0235      |
|    std                      | 0.593       |
|    value_loss               | 0.0304      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 94.8        |
|    ep_rew_mean              | -30.2       |
| time/                       |             |
|    fps                      | 169         |
|    iterations               | 71          |
|    time_elapsed             | 858         |
|    total_timesteps          | 145408      |
| train/                      |             |
|    approx_kl                | 0.18429375  |
|    clip_fraction            | 0.71        |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.028626325 |
|    ent_clip_fraction        | 0.275       |
|    ent_entropy_loss         | -7.07       |
|    ent_loss                 | -0.0465     |
|    ent_policy_gradient_loss | -0.0503     |
|    ent_std                  | 0.585       |
|    ent_value_loss           | 0.0447      |
|    entropy_loss             | -7.18       |
|    explained_variance       | 0.81        |
|    learning_rate            | 0.0003      |
|    loss                     | 0.00259     |
|    n_updates                | 700         |
|    policy_gradient_loss     | 0.0356      |
|    std                      | 0.595       |
|    value_loss               | 0.0424      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 84          |
|    ep_rew_mean              | -24.3       |
| time/                       |             |
|    fps                      | 169         |
|    iterations               | 72          |
|    time_elapsed             | 868         |
|    total_timesteps          | 147456      |
| train/                      |             |
|    approx_kl                | 0.1667018   |
|    clip_fraction            | 0.678       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.052977804 |
|    ent_clip_fraction        | 0.352       |
|    ent_entropy_loss         | -7.03       |
|    ent_loss                 | -0.00281    |
|    ent_policy_gradient_loss | -0.0346     |
|    ent_std                  | 0.582       |
|    ent_value_loss           | 0.0439      |
|    entropy_loss             | -7.17       |
|    explained_variance       | 0.777       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.00433     |
|    n_updates                | 710         |
|    policy_gradient_loss     | 0.0264      |
|    std                      | 0.593       |
|    value_loss               | 0.0434      |
---------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 88.1       |
|    ep_rew_mean              | -25.4      |
| time/                       |            |
|    fps                      | 170        |
|    iterations               | 73         |
|    time_elapsed             | 878        |
|    total_timesteps          | 149504     |
| train/                      |            |
|    approx_kl                | 0.17766318 |
|    clip_fraction            | 0.694      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.02687035 |
|    ent_clip_fraction        | 0.248      |
|    ent_entropy_loss         | -6.98      |
|    ent_loss                 | -0.068     |
|    ent_policy_gradient_loss | -0.0442    |
|    ent_std                  | 0.579      |
|    ent_value_loss           | 0.0385     |
|    entropy_loss             | -7.13      |
|    explained_variance       | 0.786      |
|    learning_rate            | 0.0003     |
|    loss                     | -0.00725   |
|    n_updates                | 720        |
|    policy_gradient_loss     | 0.0444     |
|    std                      | 0.589      |
|    value_loss               | 0.0379     |
--------------------------------------------
Eval num_timesteps=150000, episode_reward=190.80 +/- 219.44
Episode length: 254.68 +/- 332.67
---------------------------------------------
| eval/                       |             |
|    mean_ep_length           | 255         |
|    mean_reward              | 191         |
| time/                       |             |
|    total_timesteps          | 150000      |
| train/                      |             |
|    approx_kl                | 0.19798642  |
|    clip_fraction            | 0.722       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.027724728 |
|    ent_clip_fraction        | 0.28        |
|    ent_entropy_loss         | -6.93       |
|    ent_loss                 | -0.0485     |
|    ent_policy_gradient_loss | -0.0485     |
|    ent_std                  | 0.576       |
|    ent_value_loss           | 0.0374      |
|    entropy_loss             | -7.07       |
|    explained_variance       | 0.743       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0318      |
|    n_updates                | 730         |
|    policy_gradient_loss     | 0.0259      |
|    std                      | 0.585       |
|    value_loss               | 0.0365      |
---------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 106      |
|    ep_rew_mean     | -31.1    |
| time/              |          |
|    fps             | 168      |
|    iterations      | 74       |
|    time_elapsed    | 897      |
|    total_timesteps | 151552   |
---------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 91.2        |
|    ep_rew_mean              | -24.2       |
| time/                       |             |
|    fps                      | 169         |
|    iterations               | 75          |
|    time_elapsed             | 907         |
|    total_timesteps          | 153600      |
| train/                      |             |
|    approx_kl                | 0.17667064  |
|    clip_fraction            | 0.71        |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.034460872 |
|    ent_clip_fraction        | 0.302       |
|    ent_entropy_loss         | -6.86       |
|    ent_loss                 | -0.0532     |
|    ent_policy_gradient_loss | -0.0342     |
|    ent_std                  | 0.568       |
|    ent_value_loss           | 0.015       |
|    entropy_loss             | -6.99       |
|    explained_variance       | 0.818       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0253      |
|    n_updates                | 740         |
|    policy_gradient_loss     | 0.0292      |
|    std                      | 0.577       |
|    value_loss               | 0.0145      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 100         |
|    ep_rew_mean              | -27.6       |
| time/                       |             |
|    fps                      | 169         |
|    iterations               | 76          |
|    time_elapsed             | 917         |
|    total_timesteps          | 155648      |
| train/                      |             |
|    approx_kl                | 0.18408635  |
|    clip_fraction            | 0.697       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.051818468 |
|    ent_clip_fraction        | 0.357       |
|    ent_entropy_loss         | -6.78       |
|    ent_loss                 | -0.0467     |
|    ent_policy_gradient_loss | -0.0434     |
|    ent_std                  | 0.563       |
|    ent_value_loss           | 0.0452      |
|    entropy_loss             | -6.89       |
|    explained_variance       | 0.704       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0461      |
|    n_updates                | 750         |
|    policy_gradient_loss     | 0.0447      |
|    std                      | 0.57        |
|    value_loss               | 0.0436      |
---------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 103        |
|    ep_rew_mean              | -27.3      |
| time/                       |            |
|    fps                      | 169        |
|    iterations               | 77         |
|    time_elapsed             | 927        |
|    total_timesteps          | 157696     |
| train/                      |            |
|    approx_kl                | 0.1919826  |
|    clip_fraction            | 0.724      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.02277714 |
|    ent_clip_fraction        | 0.257      |
|    ent_entropy_loss         | -6.7       |
|    ent_loss                 | -0.0771    |
|    ent_policy_gradient_loss | -0.0528    |
|    ent_std                  | 0.557      |
|    ent_value_loss           | 0.0259     |
|    entropy_loss             | -6.82      |
|    explained_variance       | 0.824      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0744     |
|    n_updates                | 760        |
|    policy_gradient_loss     | 0.0403     |
|    std                      | 0.566      |
|    value_loss               | 0.0262     |
--------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 104         |
|    ep_rew_mean              | -25.4       |
| time/                       |             |
|    fps                      | 170         |
|    iterations               | 78          |
|    time_elapsed             | 938         |
|    total_timesteps          | 159744      |
| train/                      |             |
|    approx_kl                | 0.1954892   |
|    clip_fraction            | 0.714       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.042588662 |
|    ent_clip_fraction        | 0.323       |
|    ent_entropy_loss         | -6.64       |
|    ent_loss                 | -0.0324     |
|    ent_policy_gradient_loss | -0.0412     |
|    ent_std                  | 0.554       |
|    ent_value_loss           | 0.0382      |
|    entropy_loss             | -6.75       |
|    explained_variance       | 0.747       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0602      |
|    n_updates                | 770         |
|    policy_gradient_loss     | 0.0316      |
|    std                      | 0.561       |
|    value_loss               | 0.038       |
---------------------------------------------
Eval num_timesteps=160000, episode_reward=272.13 +/- 292.81
Episode length: 356.64 +/- 385.67
---------------------------------------------
| eval/                       |             |
|    mean_ep_length           | 357         |
|    mean_reward              | 272         |
| time/                       |             |
|    total_timesteps          | 160000      |
| train/                      |             |
|    approx_kl                | 0.198264    |
|    clip_fraction            | 0.709       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.037283488 |
|    ent_clip_fraction        | 0.313       |
|    ent_entropy_loss         | -6.62       |
|    ent_loss                 | -0.0393     |
|    ent_policy_gradient_loss | -0.0379     |
|    ent_std                  | 0.553       |
|    ent_value_loss           | 0.0374      |
|    entropy_loss             | -6.71       |
|    explained_variance       | 0.724       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0303      |
|    n_updates                | 780         |
|    policy_gradient_loss     | 0.0323      |
|    std                      | 0.561       |
|    value_loss               | 0.0371      |
---------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 106      |
|    ep_rew_mean     | -25.7    |
| time/              |          |
|    fps             | 168      |
|    iterations      | 79       |
|    time_elapsed    | 959      |
|    total_timesteps | 161792   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 113        |
|    ep_rew_mean              | -25.4      |
| time/                       |            |
|    fps                      | 168        |
|    iterations               | 80         |
|    time_elapsed             | 970        |
|    total_timesteps          | 163840     |
| train/                      |            |
|    approx_kl                | 0.14799325 |
|    clip_fraction            | 0.572      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.09752532 |
|    ent_clip_fraction        | 0.474      |
|    ent_entropy_loss         | -6.58      |
|    ent_loss                 | -0.0325    |
|    ent_policy_gradient_loss | -0.0077    |
|    ent_std                  | 0.55       |
|    ent_value_loss           | 0.0196     |
|    entropy_loss             | -6.66      |
|    explained_variance       | 0.61       |
|    learning_rate            | 0.0003     |
|    loss                     | -0.0149    |
|    n_updates                | 790        |
|    policy_gradient_loss     | 0.0178     |
|    std                      | 0.554      |
|    value_loss               | 0.0196     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 121        |
|    ep_rew_mean              | -25.8      |
| time/                       |            |
|    fps                      | 169        |
|    iterations               | 81         |
|    time_elapsed             | 980        |
|    total_timesteps          | 165888     |
| train/                      |            |
|    approx_kl                | 0.18617505 |
|    clip_fraction            | 0.669      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.07509184 |
|    ent_clip_fraction        | 0.413      |
|    ent_entropy_loss         | -6.53      |
|    ent_loss                 | -0.0476    |
|    ent_policy_gradient_loss | -0.0208    |
|    ent_std                  | 0.547      |
|    ent_value_loss           | 0.031      |
|    entropy_loss             | -6.58      |
|    explained_variance       | 0.719      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0272     |
|    n_updates                | 800        |
|    policy_gradient_loss     | 0.0279     |
|    std                      | 0.549      |
|    value_loss               | 0.0305     |
--------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 110         |
|    ep_rew_mean              | -22.1       |
| time/                       |             |
|    fps                      | 169         |
|    iterations               | 82          |
|    time_elapsed             | 989         |
|    total_timesteps          | 167936      |
| train/                      |             |
|    approx_kl                | 0.195018    |
|    clip_fraction            | 0.687       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.057205394 |
|    ent_clip_fraction        | 0.36        |
|    ent_entropy_loss         | -6.48       |
|    ent_loss                 | -0.0115     |
|    ent_policy_gradient_loss | -0.0352     |
|    ent_std                  | 0.544       |
|    ent_value_loss           | 0.0394      |
|    entropy_loss             | -6.55       |
|    explained_variance       | 0.733       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0265      |
|    n_updates                | 810         |
|    policy_gradient_loss     | 0.0365      |
|    std                      | 0.55        |
|    value_loss               | 0.0394      |
---------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 95.9       |
|    ep_rew_mean              | -17.8      |
| time/                       |            |
|    fps                      | 169        |
|    iterations               | 83         |
|    time_elapsed             | 1000       |
|    total_timesteps          | 169984     |
| train/                      |            |
|    approx_kl                | 0.21189316 |
|    clip_fraction            | 0.726      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.02784637 |
|    ent_clip_fraction        | 0.278      |
|    ent_entropy_loss         | -6.4       |
|    ent_loss                 | -0.0794    |
|    ent_policy_gradient_loss | -0.0536    |
|    ent_std                  | 0.536      |
|    ent_value_loss           | 0.023      |
|    entropy_loss             | -6.51      |
|    explained_variance       | 0.841      |
|    learning_rate            | 0.0003     |
|    loss                     | -0.00828   |
|    n_updates                | 820        |
|    policy_gradient_loss     | 0.0504     |
|    std                      | 0.542      |
|    value_loss               | 0.0242     |
--------------------------------------------
Eval num_timesteps=170000, episode_reward=318.07 +/- 314.40
Episode length: 400.28 +/- 417.41
---------------------------------------------
| eval/                       |             |
|    mean_ep_length           | 400         |
|    mean_reward              | 318         |
| time/                       |             |
|    total_timesteps          | 170000      |
| train/                      |             |
|    approx_kl                | 0.21888658  |
|    clip_fraction            | 0.725       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.041415684 |
|    ent_clip_fraction        | 0.326       |
|    ent_entropy_loss         | -6.34       |
|    ent_loss                 | -0.07       |
|    ent_policy_gradient_loss | -0.046      |
|    ent_std                  | 0.535       |
|    ent_value_loss           | 0.0331      |
|    entropy_loss             | -6.43       |
|    explained_variance       | 0.739       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.00197     |
|    n_updates                | 830         |
|    policy_gradient_loss     | 0.0431      |
|    std                      | 0.541       |
|    value_loss               | 0.0343      |
---------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 83.5     |
|    ep_rew_mean     | -11.2    |
| time/              |          |
|    fps             | 168      |
|    iterations      | 84       |
|    time_elapsed    | 1021     |
|    total_timesteps | 172032   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 84.1       |
|    ep_rew_mean              | -13.7      |
| time/                       |            |
|    fps                      | 168        |
|    iterations               | 85         |
|    time_elapsed             | 1031       |
|    total_timesteps          | 174080     |
| train/                      |            |
|    approx_kl                | 0.23079482 |
|    clip_fraction            | 0.701      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.07291576 |
|    ent_clip_fraction        | 0.406      |
|    ent_entropy_loss         | -6.28      |
|    ent_loss                 | -0.0538    |
|    ent_policy_gradient_loss | -0.0184    |
|    ent_std                  | 0.529      |
|    ent_value_loss           | 0.0319     |
|    entropy_loss             | -6.38      |
|    explained_variance       | 0.746      |
|    learning_rate            | 0.0003     |
|    loss                     | -0.0102    |
|    n_updates                | 840        |
|    policy_gradient_loss     | 0.031      |
|    std                      | 0.536      |
|    value_loss               | 0.0331     |
--------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 95.4        |
|    ep_rew_mean              | -11.7       |
| time/                       |             |
|    fps                      | 169         |
|    iterations               | 86          |
|    time_elapsed             | 1042        |
|    total_timesteps          | 176128      |
| train/                      |             |
|    approx_kl                | 0.23342097  |
|    clip_fraction            | 0.72        |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.057636403 |
|    ent_clip_fraction        | 0.324       |
|    ent_entropy_loss         | -6.19       |
|    ent_loss                 | -0.0448     |
|    ent_policy_gradient_loss | -0.0378     |
|    ent_std                  | 0.523       |
|    ent_value_loss           | 0.0286      |
|    entropy_loss             | -6.3        |
|    explained_variance       | 0.753       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.02        |
|    n_updates                | 850         |
|    policy_gradient_loss     | 0.0398      |
|    std                      | 0.53        |
|    value_loss               | 0.0295      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 87.7        |
|    ep_rew_mean              | -2.98       |
| time/                       |             |
|    fps                      | 169         |
|    iterations               | 87          |
|    time_elapsed             | 1052        |
|    total_timesteps          | 178176      |
| train/                      |             |
|    approx_kl                | 0.22240046  |
|    clip_fraction            | 0.735       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.031907618 |
|    ent_clip_fraction        | 0.29        |
|    ent_entropy_loss         | -6.1        |
|    ent_loss                 | -0.0612     |
|    ent_policy_gradient_loss | -0.0498     |
|    ent_std                  | 0.517       |
|    ent_value_loss           | 0.0257      |
|    entropy_loss             | -6.22       |
|    explained_variance       | 0.839       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0266      |
|    n_updates                | 860         |
|    policy_gradient_loss     | 0.0473      |
|    std                      | 0.526       |
|    value_loss               | 0.0263      |
---------------------------------------------
Eval num_timesteps=180000, episode_reward=428.83 +/- 332.32
Episode length: 538.32 +/- 452.82
---------------------------------------------
| eval/                       |             |
|    mean_ep_length           | 538         |
|    mean_reward              | 429         |
| time/                       |             |
|    total_timesteps          | 180000      |
| train/                      |             |
|    approx_kl                | 0.23002937  |
|    clip_fraction            | 0.752       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.025166623 |
|    ent_clip_fraction        | 0.269       |
|    ent_entropy_loss         | -6.03       |
|    ent_loss                 | -0.0767     |
|    ent_policy_gradient_loss | -0.0547     |
|    ent_std                  | 0.513       |
|    ent_value_loss           | 0.0352      |
|    entropy_loss             | -6.18       |
|    explained_variance       | 0.706       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0347      |
|    n_updates                | 870         |
|    policy_gradient_loss     | 0.0727      |
|    std                      | 0.524       |
|    value_loss               | 0.036       |
---------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 76.5     |
|    ep_rew_mean     | -2.13    |
| time/              |          |
|    fps             | 167      |
|    iterations      | 88       |
|    time_elapsed    | 1077     |
|    total_timesteps | 180224   |
---------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 87.7        |
|    ep_rew_mean              | -0.999      |
| time/                       |             |
|    fps                      | 167         |
|    iterations               | 89          |
|    time_elapsed             | 1087        |
|    total_timesteps          | 182272      |
| train/                      |             |
|    approx_kl                | 0.21769594  |
|    clip_fraction            | 0.744       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.020764548 |
|    ent_clip_fraction        | 0.244       |
|    ent_entropy_loss         | -5.95       |
|    ent_loss                 | -0.0729     |
|    ent_policy_gradient_loss | -0.0494     |
|    ent_std                  | 0.508       |
|    ent_value_loss           | 0.0151      |
|    entropy_loss             | -6.14       |
|    explained_variance       | 0.788       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.00487     |
|    n_updates                | 880         |
|    policy_gradient_loss     | 0.0523      |
|    std                      | 0.52        |
|    value_loss               | 0.0152      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 97.6        |
|    ep_rew_mean              | -2.6        |
| time/                       |             |
|    fps                      | 167         |
|    iterations               | 90          |
|    time_elapsed             | 1097        |
|    total_timesteps          | 184320      |
| train/                      |             |
|    approx_kl                | 0.20515609  |
|    clip_fraction            | 0.637       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.081931986 |
|    ent_clip_fraction        | 0.449       |
|    ent_entropy_loss         | -5.88       |
|    ent_loss                 | 0.00216     |
|    ent_policy_gradient_loss | -0.0143     |
|    ent_std                  | 0.504       |
|    ent_value_loss           | 0.0191      |
|    entropy_loss             | -6.05       |
|    explained_variance       | 0.758       |
|    learning_rate            | 0.0003      |
|    loss                     | -0.0124     |
|    n_updates                | 890         |
|    policy_gradient_loss     | 0.0335      |
|    std                      | 0.514       |
|    value_loss               | 0.0204      |
---------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 97         |
|    ep_rew_mean              | 0.198      |
| time/                       |            |
|    fps                      | 168        |
|    iterations               | 91         |
|    time_elapsed             | 1107       |
|    total_timesteps          | 186368     |
| train/                      |            |
|    approx_kl                | 0.22405806 |
|    clip_fraction            | 0.731      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.05239655 |
|    ent_clip_fraction        | 0.364      |
|    ent_entropy_loss         | -5.79      |
|    ent_loss                 | -0.0546    |
|    ent_policy_gradient_loss | -0.034     |
|    ent_std                  | 0.497      |
|    ent_value_loss           | 0.00684    |
|    entropy_loss             | -5.95      |
|    explained_variance       | 0.778      |
|    learning_rate            | 0.0003     |
|    loss                     | -0.0172    |
|    n_updates                | 900        |
|    policy_gradient_loss     | 0.0239     |
|    std                      | 0.506      |
|    value_loss               | 0.00664    |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 115        |
|    ep_rew_mean              | -1.12      |
| time/                       |            |
|    fps                      | 168        |
|    iterations               | 92         |
|    time_elapsed             | 1118       |
|    total_timesteps          | 188416     |
| train/                      |            |
|    approx_kl                | 0.25917846 |
|    clip_fraction            | 0.756      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.03597481 |
|    ent_clip_fraction        | 0.311      |
|    ent_entropy_loss         | -5.69      |
|    ent_loss                 | -0.0372    |
|    ent_policy_gradient_loss | -0.0486    |
|    ent_std                  | 0.492      |
|    ent_value_loss           | 0.0212     |
|    entropy_loss             | -5.84      |
|    explained_variance       | 0.797      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0101     |
|    n_updates                | 910        |
|    policy_gradient_loss     | 0.0484     |
|    std                      | 0.5        |
|    value_loss               | 0.0219     |
--------------------------------------------
Eval num_timesteps=190000, episode_reward=430.37 +/- 380.21
Episode length: 486.04 +/- 446.93
---------------------------------------------
| eval/                       |             |
|    mean_ep_length           | 486         |
|    mean_reward              | 430         |
| time/                       |             |
|    total_timesteps          | 190000      |
| train/                      |             |
|    approx_kl                | 0.23729002  |
|    clip_fraction            | 0.735       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.059241436 |
|    ent_clip_fraction        | 0.366       |
|    ent_entropy_loss         | -5.61       |
|    ent_loss                 | -0.0257     |
|    ent_policy_gradient_loss | -0.0363     |
|    ent_std                  | 0.487       |
|    ent_value_loss           | 0.0181      |
|    entropy_loss             | -5.74       |
|    explained_variance       | 0.838       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0266      |
|    n_updates                | 920         |
|    policy_gradient_loss     | 0.0468      |
|    std                      | 0.493       |
|    value_loss               | 0.0194      |
---------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 128      |
|    ep_rew_mean     | -3.4     |
| time/              |          |
|    fps             | 166      |
|    iterations      | 93       |
|    time_elapsed    | 1143     |
|    total_timesteps | 190464   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 121        |
|    ep_rew_mean              | -2.33      |
| time/                       |            |
|    fps                      | 166        |
|    iterations               | 94         |
|    time_elapsed             | 1153       |
|    total_timesteps          | 192512     |
| train/                      |            |
|    approx_kl                | 0.2679114  |
|    clip_fraction            | 0.751      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.03575725 |
|    ent_clip_fraction        | 0.319      |
|    ent_entropy_loss         | -5.55      |
|    ent_loss                 | -0.0716    |
|    ent_policy_gradient_loss | -0.0509    |
|    ent_std                  | 0.484      |
|    ent_value_loss           | 0.0261     |
|    entropy_loss             | -5.66      |
|    explained_variance       | 0.695      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0385     |
|    n_updates                | 930        |
|    policy_gradient_loss     | 0.0622     |
|    std                      | 0.49       |
|    value_loss               | 0.0264     |
--------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 97.4        |
|    ep_rew_mean              | 2.4         |
| time/                       |             |
|    fps                      | 167         |
|    iterations               | 95          |
|    time_elapsed             | 1163        |
|    total_timesteps          | 194560      |
| train/                      |             |
|    approx_kl                | 0.2734059   |
|    clip_fraction            | 0.771       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.026137482 |
|    ent_clip_fraction        | 0.295       |
|    ent_entropy_loss         | -5.49       |
|    ent_loss                 | -0.0746     |
|    ent_policy_gradient_loss | -0.0568     |
|    ent_std                  | 0.48        |
|    ent_value_loss           | 0.0229      |
|    entropy_loss             | -5.62       |
|    explained_variance       | 0.657       |
|    learning_rate            | 0.0003      |
|    loss                     | -0.0055     |
|    n_updates                | 940         |
|    policy_gradient_loss     | 0.0634      |
|    std                      | 0.488       |
|    value_loss               | 0.0224      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 118         |
|    ep_rew_mean              | 1.37        |
| time/                       |             |
|    fps                      | 167         |
|    iterations               | 96          |
|    time_elapsed             | 1173        |
|    total_timesteps          | 196608      |
| train/                      |             |
|    approx_kl                | 0.26683846  |
|    clip_fraction            | 0.769       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.025716824 |
|    ent_clip_fraction        | 0.293       |
|    ent_entropy_loss         | -5.41       |
|    ent_loss                 | -0.0549     |
|    ent_policy_gradient_loss | -0.0555     |
|    ent_std                  | 0.474       |
|    ent_value_loss           | 0.0217      |
|    entropy_loss             | -5.55       |
|    explained_variance       | 0.724       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0172      |
|    n_updates                | 950         |
|    policy_gradient_loss     | 0.0652      |
|    std                      | 0.483       |
|    value_loss               | 0.0211      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 110         |
|    ep_rew_mean              | 1.02        |
| time/                       |             |
|    fps                      | 167         |
|    iterations               | 97          |
|    time_elapsed             | 1184        |
|    total_timesteps          | 198656      |
| train/                      |             |
|    approx_kl                | 0.24689214  |
|    clip_fraction            | 0.748       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.035321705 |
|    ent_clip_fraction        | 0.315       |
|    ent_entropy_loss         | -5.32       |
|    ent_loss                 | -0.0718     |
|    ent_policy_gradient_loss | -0.0359     |
|    ent_std                  | 0.47        |
|    ent_value_loss           | 0.00651     |
|    entropy_loss             | -5.45       |
|    explained_variance       | 0.764       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0171      |
|    n_updates                | 960         |
|    policy_gradient_loss     | 0.0545      |
|    std                      | 0.476       |
|    value_loss               | 0.00656     |
---------------------------------------------
Eval num_timesteps=200000, episode_reward=579.59 +/- 381.95
Episode length: 663.76 +/- 449.20
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 664        |
|    mean_reward              | 580        |
| time/                       |            |
|    total_timesteps          | 200000     |
| train/                      |            |
|    approx_kl                | 0.21337149 |
|    clip_fraction            | 0.683      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.11950714 |
|    ent_clip_fraction        | 0.469      |
|    ent_entropy_loss         | -5.26      |
|    ent_loss                 | -0.0125    |
|    ent_policy_gradient_loss | -0.0183    |
|    ent_std                  | 0.467      |
|    ent_value_loss           | 0.0284     |
|    entropy_loss             | -5.37      |
|    explained_variance       | 0.577      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0223     |
|    n_updates                | 970        |
|    policy_gradient_loss     | 0.0329     |
|    std                      | 0.474      |
|    value_loss               | 0.0283     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 104      |
|    ep_rew_mean     | 2.97     |
| time/              |          |
|    fps             | 165      |
|    iterations      | 98       |
|    time_elapsed    | 1209     |
|    total_timesteps | 200704   |
---------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 87.7        |
|    ep_rew_mean              | 8.36        |
| time/                       |             |
|    fps                      | 166         |
|    iterations               | 99          |
|    time_elapsed             | 1218        |
|    total_timesteps          | 202752      |
| train/                      |             |
|    approx_kl                | 0.22034487  |
|    clip_fraction            | 0.732       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.060503066 |
|    ent_clip_fraction        | 0.36        |
|    ent_entropy_loss         | -5.22       |
|    ent_loss                 | -0.0106     |
|    ent_policy_gradient_loss | -0.0334     |
|    ent_std                  | 0.465       |
|    ent_value_loss           | 0.0586      |
|    entropy_loss             | -5.35       |
|    explained_variance       | 0.486       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0696      |
|    n_updates                | 980         |
|    policy_gradient_loss     | 0.0803      |
|    std                      | 0.472       |
|    value_loss               | 0.0577      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 102         |
|    ep_rew_mean              | 7.77        |
| time/                       |             |
|    fps                      | 166         |
|    iterations               | 100         |
|    time_elapsed             | 1229        |
|    total_timesteps          | 204800      |
| train/                      |             |
|    approx_kl                | 0.30419478  |
|    clip_fraction            | 0.778       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.026168235 |
|    ent_clip_fraction        | 0.309       |
|    ent_entropy_loss         | -5.16       |
|    ent_loss                 | -0.0526     |
|    ent_policy_gradient_loss | -0.059      |
|    ent_std                  | 0.461       |
|    ent_value_loss           | 0.0363      |
|    entropy_loss             | -5.31       |
|    explained_variance       | 0.401       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0311      |
|    n_updates                | 990         |
|    policy_gradient_loss     | 0.078       |
|    std                      | 0.47        |
|    value_loss               | 0.0381      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 94.3        |
|    ep_rew_mean              | 9.28        |
| time/                       |             |
|    fps                      | 166         |
|    iterations               | 101         |
|    time_elapsed             | 1239        |
|    total_timesteps          | 206848      |
| train/                      |             |
|    approx_kl                | 0.27869403  |
|    clip_fraction            | 0.738       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.059926137 |
|    ent_clip_fraction        | 0.4         |
|    ent_entropy_loss         | -5.1        |
|    ent_loss                 | -0.0321     |
|    ent_policy_gradient_loss | -0.0426     |
|    ent_std                  | 0.457       |
|    ent_value_loss           | 0.0175      |
|    entropy_loss             | -5.28       |
|    explained_variance       | 0.526       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.00965     |
|    n_updates                | 1000        |
|    policy_gradient_loss     | 0.0598      |
|    std                      | 0.468       |
|    value_loss               | 0.018       |
---------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 112        |
|    ep_rew_mean              | 12.4       |
| time/                       |            |
|    fps                      | 167        |
|    iterations               | 102        |
|    time_elapsed             | 1249       |
|    total_timesteps          | 208896     |
| train/                      |            |
|    approx_kl                | 0.21528846 |
|    clip_fraction            | 0.687      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.12785164 |
|    ent_clip_fraction        | 0.491      |
|    ent_entropy_loss         | -5.03      |
|    ent_loss                 | -0.0354    |
|    ent_policy_gradient_loss | -0.0104    |
|    ent_std                  | 0.453      |
|    ent_value_loss           | 0.00921    |
|    entropy_loss             | -5.21      |
|    explained_variance       | 0.58       |
|    learning_rate            | 0.0003     |
|    loss                     | 0.00282    |
|    n_updates                | 1010       |
|    policy_gradient_loss     | 0.0304     |
|    std                      | 0.462      |
|    value_loss               | 0.0095     |
--------------------------------------------
Eval num_timesteps=210000, episode_reward=554.47 +/- 322.68
Episode length: 735.20 +/- 425.67
---------------------------------------------
| eval/                       |             |
|    mean_ep_length           | 735         |
|    mean_reward              | 554         |
| time/                       |             |
|    total_timesteps          | 210000      |
| train/                      |             |
|    approx_kl                | 0.32741845  |
|    clip_fraction            | 0.779       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.037543137 |
|    ent_clip_fraction        | 0.317       |
|    ent_entropy_loss         | -4.94       |
|    ent_loss                 | -0.0586     |
|    ent_policy_gradient_loss | -0.0463     |
|    ent_std                  | 0.448       |
|    ent_value_loss           | 0.0142      |
|    entropy_loss             | -5.13       |
|    explained_variance       | 0.566       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0837      |
|    n_updates                | 1020        |
|    policy_gradient_loss     | 0.0628      |
|    std                      | 0.458       |
|    value_loss               | 0.014       |
---------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 113      |
|    ep_rew_mean     | 12.5     |
| time/              |          |
|    fps             | 164      |
|    iterations      | 103      |
|    time_elapsed    | 1278     |
|    total_timesteps | 210944   |
---------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 120         |
|    ep_rew_mean              | 14.1        |
| time/                       |             |
|    fps                      | 165         |
|    iterations               | 104         |
|    time_elapsed             | 1289        |
|    total_timesteps          | 212992      |
| train/                      |             |
|    approx_kl                | 0.28167337  |
|    clip_fraction            | 0.777       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.036779325 |
|    ent_clip_fraction        | 0.324       |
|    ent_entropy_loss         | -4.85       |
|    ent_loss                 | -0.0707     |
|    ent_policy_gradient_loss | -0.0491     |
|    ent_std                  | 0.442       |
|    ent_value_loss           | 0.013       |
|    entropy_loss             | -5.04       |
|    explained_variance       | 0.413       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0718      |
|    n_updates                | 1030        |
|    policy_gradient_loss     | 0.076       |
|    std                      | 0.452       |
|    value_loss               | 0.0132      |
---------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 128        |
|    ep_rew_mean              | 14.3       |
| time/                       |            |
|    fps                      | 165        |
|    iterations               | 105        |
|    time_elapsed             | 1299       |
|    total_timesteps          | 215040     |
| train/                      |            |
|    approx_kl                | 0.27543092 |
|    clip_fraction            | 0.747      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.07268489 |
|    ent_clip_fraction        | 0.358      |
|    ent_entropy_loss         | -4.77      |
|    ent_loss                 | -0.0446    |
|    ent_policy_gradient_loss | -0.0268    |
|    ent_std                  | 0.439      |
|    ent_value_loss           | 0.0188     |
|    entropy_loss             | -4.95      |
|    explained_variance       | 0.566      |
|    learning_rate            | 0.0003     |
|    loss                     | -0.0181    |
|    n_updates                | 1040       |
|    policy_gradient_loss     | 0.0599     |
|    std                      | 0.448      |
|    value_loss               | 0.0194     |
--------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 147         |
|    ep_rew_mean              | 18          |
| time/                       |             |
|    fps                      | 165         |
|    iterations               | 106         |
|    time_elapsed             | 1309        |
|    total_timesteps          | 217088      |
| train/                      |             |
|    approx_kl                | 0.32877272  |
|    clip_fraction            | 0.785       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.050457343 |
|    ent_clip_fraction        | 0.327       |
|    ent_entropy_loss         | -4.73       |
|    ent_loss                 | -0.0674     |
|    ent_policy_gradient_loss | -0.0356     |
|    ent_std                  | 0.437       |
|    ent_value_loss           | 0.0177      |
|    entropy_loss             | -4.89       |
|    explained_variance       | 0.577       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.137       |
|    n_updates                | 1050        |
|    policy_gradient_loss     | 0.0626      |
|    std                      | 0.445       |
|    value_loss               | 0.0179      |
---------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 132        |
|    ep_rew_mean              | 17.4       |
| time/                       |            |
|    fps                      | 166        |
|    iterations               | 107        |
|    time_elapsed             | 1319       |
|    total_timesteps          | 219136     |
| train/                      |            |
|    approx_kl                | 0.25221604 |
|    clip_fraction            | 0.688      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.1595811  |
|    ent_clip_fraction        | 0.513      |
|    ent_entropy_loss         | -4.7       |
|    ent_loss                 | -0.019     |
|    ent_policy_gradient_loss | 0.012      |
|    ent_std                  | 0.436      |
|    ent_value_loss           | 0.0323     |
|    entropy_loss             | -4.85      |
|    explained_variance       | 0.436      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0129     |
|    n_updates                | 1060       |
|    policy_gradient_loss     | 0.0219     |
|    std                      | 0.443      |
|    value_loss               | 0.035      |
--------------------------------------------
Eval num_timesteps=220000, episode_reward=361.90 +/- 302.37
Episode length: 478.00 +/- 421.48
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 478        |
|    mean_reward              | 362        |
| time/                       |            |
|    total_timesteps          | 220000     |
| train/                      |            |
|    approx_kl                | 0.32723105 |
|    clip_fraction            | 0.761      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.07550572 |
|    ent_clip_fraction        | 0.376      |
|    ent_entropy_loss         | -4.66      |
|    ent_loss                 | -0.0555    |
|    ent_policy_gradient_loss | -0.0328    |
|    ent_std                  | 0.432      |
|    ent_value_loss           | 0.03       |
|    entropy_loss             | -4.79      |
|    explained_variance       | 0.406      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0296     |
|    n_updates                | 1070       |
|    policy_gradient_loss     | 0.0479     |
|    std                      | 0.438      |
|    value_loss               | 0.0305     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 95.3     |
|    ep_rew_mean     | 17.2     |
| time/              |          |
|    fps             | 165      |
|    iterations      | 108      |
|    time_elapsed    | 1339     |
|    total_timesteps | 221184   |
---------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 107         |
|    ep_rew_mean              | 21.3        |
| time/                       |             |
|    fps                      | 165         |
|    iterations               | 109         |
|    time_elapsed             | 1349        |
|    total_timesteps          | 223232      |
| train/                      |             |
|    approx_kl                | 0.35977626  |
|    clip_fraction            | 0.791       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.024875976 |
|    ent_clip_fraction        | 0.284       |
|    ent_entropy_loss         | -4.57       |
|    ent_loss                 | -0.0629     |
|    ent_policy_gradient_loss | -0.0543     |
|    ent_std                  | 0.428       |
|    ent_value_loss           | 0.0561      |
|    entropy_loss             | -4.69       |
|    explained_variance       | 0.511       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.138       |
|    n_updates                | 1080        |
|    policy_gradient_loss     | 0.105       |
|    std                      | 0.434       |
|    value_loss               | 0.0565      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 115         |
|    ep_rew_mean              | 22.3        |
| time/                       |             |
|    fps                      | 165         |
|    iterations               | 110         |
|    time_elapsed             | 1360        |
|    total_timesteps          | 225280      |
| train/                      |             |
|    approx_kl                | 0.28678402  |
|    clip_fraction            | 0.78        |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.042288814 |
|    ent_clip_fraction        | 0.308       |
|    ent_entropy_loss         | -4.5        |
|    ent_loss                 | -0.052      |
|    ent_policy_gradient_loss | -0.0419     |
|    ent_std                  | 0.425       |
|    ent_value_loss           | 0.027       |
|    entropy_loss             | -4.67       |
|    explained_variance       | 0.532       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.101       |
|    n_updates                | 1090        |
|    policy_gradient_loss     | 0.0651      |
|    std                      | 0.435       |
|    value_loss               | 0.0275      |
---------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 125        |
|    ep_rew_mean              | 23.4       |
| time/                       |            |
|    fps                      | 165        |
|    iterations               | 111        |
|    time_elapsed             | 1370       |
|    total_timesteps          | 227328     |
| train/                      |            |
|    approx_kl                | 0.33276504 |
|    clip_fraction            | 0.786      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.03952265 |
|    ent_clip_fraction        | 0.332      |
|    ent_entropy_loss         | -4.41      |
|    ent_loss                 | -0.0814    |
|    ent_policy_gradient_loss | -0.0499    |
|    ent_std                  | 0.418      |
|    ent_value_loss           | 0.0102     |
|    entropy_loss             | -4.66      |
|    explained_variance       | 0.326      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0555     |
|    n_updates                | 1100       |
|    policy_gradient_loss     | 0.0687     |
|    std                      | 0.433      |
|    value_loss               | 0.0108     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 122        |
|    ep_rew_mean              | 20.1       |
| time/                       |            |
|    fps                      | 166        |
|    iterations               | 112        |
|    time_elapsed             | 1380       |
|    total_timesteps          | 229376     |
| train/                      |            |
|    approx_kl                | 0.27521244 |
|    clip_fraction            | 0.758      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.08054538 |
|    ent_clip_fraction        | 0.397      |
|    ent_entropy_loss         | -4.33      |
|    ent_loss                 | -0.0482    |
|    ent_policy_gradient_loss | -0.0289    |
|    ent_std                  | 0.414      |
|    ent_value_loss           | 0.012      |
|    entropy_loss             | -4.6       |
|    explained_variance       | 0.587      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0306     |
|    n_updates                | 1110       |
|    policy_gradient_loss     | 0.0523     |
|    std                      | 0.429      |
|    value_loss               | 0.0122     |
--------------------------------------------
Eval num_timesteps=230000, episode_reward=494.68 +/- 324.90
Episode length: 663.88 +/- 448.97
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 664        |
|    mean_reward              | 495        |
| time/                       |            |
|    total_timesteps          | 230000     |
| train/                      |            |
|    approx_kl                | 0.353809   |
|    clip_fraction            | 0.799      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.04049801 |
|    ent_clip_fraction        | 0.313      |
|    ent_entropy_loss         | -4.26      |
|    ent_loss                 | -0.039     |
|    ent_policy_gradient_loss | -0.0486    |
|    ent_std                  | 0.412      |
|    ent_value_loss           | 0.0417     |
|    entropy_loss             | -4.56      |
|    explained_variance       | 0.574      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.094      |
|    n_updates                | 1120       |
|    policy_gradient_loss     | 0.0829     |
|    std                      | 0.427      |
|    value_loss               | 0.0412     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 138      |
|    ep_rew_mean     | 21.5     |
| time/              |          |
|    fps             | 164      |
|    iterations      | 113      |
|    time_elapsed    | 1405     |
|    total_timesteps | 231424   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 138        |
|    ep_rew_mean              | 21.4       |
| time/                       |            |
|    fps                      | 164        |
|    iterations               | 114        |
|    time_elapsed             | 1415       |
|    total_timesteps          | 233472     |
| train/                      |            |
|    approx_kl                | 0.32096547 |
|    clip_fraction            | 0.758      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.11283821 |
|    ent_clip_fraction        | 0.459      |
|    ent_entropy_loss         | -4.23      |
|    ent_loss                 | -0.0334    |
|    ent_policy_gradient_loss | -0.0137    |
|    ent_std                  | 0.411      |
|    ent_value_loss           | 0.0182     |
|    entropy_loss             | -4.54      |
|    explained_variance       | 0.761      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0234     |
|    n_updates                | 1130       |
|    policy_gradient_loss     | 0.064      |
|    std                      | 0.428      |
|    value_loss               | 0.0183     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 155        |
|    ep_rew_mean              | 25.6       |
| time/                       |            |
|    fps                      | 165        |
|    iterations               | 115        |
|    time_elapsed             | 1425       |
|    total_timesteps          | 235520     |
| train/                      |            |
|    approx_kl                | 0.405209   |
|    clip_fraction            | 0.807      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.02896069 |
|    ent_clip_fraction        | 0.312      |
|    ent_entropy_loss         | -4.21      |
|    ent_loss                 | -0.0881    |
|    ent_policy_gradient_loss | -0.0589    |
|    ent_std                  | 0.41       |
|    ent_value_loss           | 0.0349     |
|    entropy_loss             | -4.51      |
|    explained_variance       | 0.738      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0587     |
|    n_updates                | 1140       |
|    policy_gradient_loss     | 0.106      |
|    std                      | 0.424      |
|    value_loss               | 0.0359     |
--------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 170         |
|    ep_rew_mean              | 28.3        |
| time/                       |             |
|    fps                      | 165         |
|    iterations               | 116         |
|    time_elapsed             | 1435        |
|    total_timesteps          | 237568      |
| train/                      |             |
|    approx_kl                | 0.41070873  |
|    clip_fraction            | 0.8         |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.037025392 |
|    ent_clip_fraction        | 0.319       |
|    ent_entropy_loss         | -4.17       |
|    ent_loss                 | -0.0751     |
|    ent_policy_gradient_loss | -0.0536     |
|    ent_std                  | 0.407       |
|    ent_value_loss           | 0.0259      |
|    entropy_loss             | -4.47       |
|    explained_variance       | 0.625       |
|    learning_rate            | 0.0003      |
|    loss                     | -0.0185     |
|    n_updates                | 1150        |
|    policy_gradient_loss     | 0.0873      |
|    std                      | 0.423       |
|    value_loss               | 0.0259      |
---------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 171        |
|    ep_rew_mean              | 28.7       |
| time/                       |            |
|    fps                      | 165        |
|    iterations               | 117        |
|    time_elapsed             | 1445       |
|    total_timesteps          | 239616     |
| train/                      |            |
|    approx_kl                | 0.3608445  |
|    clip_fraction            | 0.788      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.09248873 |
|    ent_clip_fraction        | 0.406      |
|    ent_entropy_loss         | -4.13      |
|    ent_loss                 | -0.0774    |
|    ent_policy_gradient_loss | -0.0372    |
|    ent_std                  | 0.405      |
|    ent_value_loss           | 0.0171     |
|    entropy_loss             | -4.44      |
|    explained_variance       | 0.604      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.00172    |
|    n_updates                | 1160       |
|    policy_gradient_loss     | 0.0993     |
|    std                      | 0.421      |
|    value_loss               | 0.0166     |
--------------------------------------------
Eval num_timesteps=240000, episode_reward=576.28 +/- 310.23
Episode length: 746.76 +/- 410.11
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 747        |
|    mean_reward              | 576        |
| time/                       |            |
|    total_timesteps          | 240000     |
| train/                      |            |
|    approx_kl                | 0.36217058 |
|    clip_fraction            | 0.805      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.07308003 |
|    ent_clip_fraction        | 0.375      |
|    ent_entropy_loss         | -4.05      |
|    ent_loss                 | -0.0624    |
|    ent_policy_gradient_loss | -0.0352    |
|    ent_std                  | 0.4        |
|    ent_value_loss           | 0.0198     |
|    entropy_loss             | -4.36      |
|    explained_variance       | 0.543      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0446     |
|    n_updates                | 1170       |
|    policy_gradient_loss     | 0.0843     |
|    std                      | 0.416      |
|    value_loss               | 0.0199     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 192      |
|    ep_rew_mean     | 30.9     |
| time/              |          |
|    fps             | 163      |
|    iterations      | 118      |
|    time_elapsed    | 1473     |
|    total_timesteps | 241664   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 169        |
|    ep_rew_mean              | 31.1       |
| time/                       |            |
|    fps                      | 164        |
|    iterations               | 119        |
|    time_elapsed             | 1483       |
|    total_timesteps          | 243712     |
| train/                      |            |
|    approx_kl                | 0.3051174  |
|    clip_fraction            | 0.737      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.12799169 |
|    ent_clip_fraction        | 0.469      |
|    ent_entropy_loss         | -3.98      |
|    ent_loss                 | 0.026      |
|    ent_policy_gradient_loss | 0.00671    |
|    ent_std                  | 0.399      |
|    ent_value_loss           | 0.0178     |
|    entropy_loss             | -4.26      |
|    explained_variance       | 0.518      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.06       |
|    n_updates                | 1180       |
|    policy_gradient_loss     | 0.0379     |
|    std                      | 0.411      |
|    value_loss               | 0.0187     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 179        |
|    ep_rew_mean              | 34.9       |
| time/                       |            |
|    fps                      | 164        |
|    iterations               | 120        |
|    time_elapsed             | 1494       |
|    total_timesteps          | 245760     |
| train/                      |            |
|    approx_kl                | 0.37719005 |
|    clip_fraction            | 0.783      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.08262559 |
|    ent_clip_fraction        | 0.409      |
|    ent_entropy_loss         | -3.96      |
|    ent_loss                 | -0.0202    |
|    ent_policy_gradient_loss | -0.0225    |
|    ent_std                  | 0.397      |
|    ent_value_loss           | 0.0312     |
|    entropy_loss             | -4.19      |
|    explained_variance       | 0.529      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0669     |
|    n_updates                | 1190       |
|    policy_gradient_loss     | 0.0634     |
|    std                      | 0.408      |
|    value_loss               | 0.0313     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 178        |
|    ep_rew_mean              | 37.5       |
| time/                       |            |
|    fps                      | 164        |
|    iterations               | 121        |
|    time_elapsed             | 1504       |
|    total_timesteps          | 247808     |
| train/                      |            |
|    approx_kl                | 0.34470123 |
|    clip_fraction            | 0.769      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.09361641 |
|    ent_clip_fraction        | 0.391      |
|    ent_entropy_loss         | -3.91      |
|    ent_loss                 | 0.0167     |
|    ent_policy_gradient_loss | -0.0179    |
|    ent_std                  | 0.394      |
|    ent_value_loss           | 0.00808    |
|    entropy_loss             | -4.14      |
|    explained_variance       | 0.444      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0208     |
|    n_updates                | 1200       |
|    policy_gradient_loss     | 0.0613     |
|    std                      | 0.405      |
|    value_loss               | 0.00796    |
--------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 181         |
|    ep_rew_mean              | 42.4        |
| time/                       |             |
|    fps                      | 164         |
|    iterations               | 122         |
|    time_elapsed             | 1514        |
|    total_timesteps          | 249856      |
| train/                      |             |
|    approx_kl                | 0.42735085  |
|    clip_fraction            | 0.831       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.028520655 |
|    ent_clip_fraction        | 0.305       |
|    ent_entropy_loss         | -3.86       |
|    ent_loss                 | -0.0723     |
|    ent_policy_gradient_loss | -0.0558     |
|    ent_std                  | 0.392       |
|    ent_value_loss           | 0.0206      |
|    entropy_loss             | -4.09       |
|    explained_variance       | 0.611       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0718      |
|    n_updates                | 1210        |
|    policy_gradient_loss     | 0.0973      |
|    std                      | 0.403       |
|    value_loss               | 0.0197      |
---------------------------------------------
Eval num_timesteps=250000, episode_reward=594.36 +/- 255.86
Episode length: 764.32 +/- 343.62
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 764        |
|    mean_reward              | 594        |
| time/                       |            |
|    total_timesteps          | 250000     |
| train/                      |            |
|    approx_kl                | 0.29731494 |
|    clip_fraction            | 0.745      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.13679135 |
|    ent_clip_fraction        | 0.476      |
|    ent_entropy_loss         | -3.83      |
|    ent_loss                 | -0.052     |
|    ent_policy_gradient_loss | -0.0123    |
|    ent_std                  | 0.391      |
|    ent_value_loss           | 0.0138     |
|    entropy_loss             | -4.05      |
|    explained_variance       | 0.479      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0303     |
|    n_updates                | 1220       |
|    policy_gradient_loss     | 0.0398     |
|    std                      | 0.401      |
|    value_loss               | 0.014      |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 198      |
|    ep_rew_mean     | 45.7     |
| time/              |          |
|    fps             | 163      |
|    iterations      | 123      |
|    time_elapsed    | 1541     |
|    total_timesteps | 251904   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 211        |
|    ep_rew_mean              | 49.9       |
| time/                       |            |
|    fps                      | 163        |
|    iterations               | 124        |
|    time_elapsed             | 1551       |
|    total_timesteps          | 253952     |
| train/                      |            |
|    approx_kl                | 0.40390244 |
|    clip_fraction            | 0.799      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.06986602 |
|    ent_clip_fraction        | 0.361      |
|    ent_entropy_loss         | -3.78      |
|    ent_loss                 | -0.0424    |
|    ent_policy_gradient_loss | -0.0527    |
|    ent_std                  | 0.388      |
|    ent_value_loss           | 0.0137     |
|    entropy_loss             | -4         |
|    explained_variance       | 0.726      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0146     |
|    n_updates                | 1230       |
|    policy_gradient_loss     | 0.0706     |
|    std                      | 0.399      |
|    value_loss               | 0.0137     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 229        |
|    ep_rew_mean              | 53.6       |
| time/                       |            |
|    fps                      | 163        |
|    iterations               | 125        |
|    time_elapsed             | 1561       |
|    total_timesteps          | 256000     |
| train/                      |            |
|    approx_kl                | 0.36940175 |
|    clip_fraction            | 0.804      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.06914305 |
|    ent_clip_fraction        | 0.361      |
|    ent_entropy_loss         | -3.7       |
|    ent_loss                 | -0.0017    |
|    ent_policy_gradient_loss | -0.0302    |
|    ent_std                  | 0.384      |
|    ent_value_loss           | 0.0152     |
|    entropy_loss             | -3.95      |
|    explained_variance       | 0.778      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0149     |
|    n_updates                | 1240       |
|    policy_gradient_loss     | 0.102      |
|    std                      | 0.396      |
|    value_loss               | 0.0147     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 215        |
|    ep_rew_mean              | 51.5       |
| time/                       |            |
|    fps                      | 164        |
|    iterations               | 126        |
|    time_elapsed             | 1572       |
|    total_timesteps          | 258048     |
| train/                      |            |
|    approx_kl                | 0.35109836 |
|    clip_fraction            | 0.779      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.07130494 |
|    ent_clip_fraction        | 0.379      |
|    ent_entropy_loss         | -3.61      |
|    ent_loss                 | -0.0682    |
|    ent_policy_gradient_loss | -0.0083    |
|    ent_std                  | 0.379      |
|    ent_value_loss           | 0.0068     |
|    entropy_loss             | -3.85      |
|    explained_variance       | 0.373      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0762     |
|    n_updates                | 1250       |
|    policy_gradient_loss     | 0.0294     |
|    std                      | 0.39       |
|    value_loss               | 0.00716    |
--------------------------------------------
Eval num_timesteps=260000, episode_reward=649.42 +/- 282.95
Episode length: 821.16 +/- 359.16
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 821        |
|    mean_reward              | 649        |
| time/                       |            |
|    total_timesteps          | 260000     |
| train/                      |            |
|    approx_kl                | 0.49102625 |
|    clip_fraction            | 0.823      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.02731128 |
|    ent_clip_fraction        | 0.312      |
|    ent_entropy_loss         | -3.56      |
|    ent_loss                 | -0.0742    |
|    ent_policy_gradient_loss | -0.0568    |
|    ent_std                  | 0.378      |
|    ent_value_loss           | 0.0361     |
|    entropy_loss             | -3.79      |
|    explained_variance       | 0.583      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.116      |
|    n_updates                | 1260       |
|    policy_gradient_loss     | 0.106      |
|    std                      | 0.389      |
|    value_loss               | 0.0356     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 216      |
|    ep_rew_mean     | 52.5     |
| time/              |          |
|    fps             | 162      |
|    iterations      | 127      |
|    time_elapsed    | 1601     |
|    total_timesteps | 260096   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 230        |
|    ep_rew_mean              | 57.8       |
| time/                       |            |
|    fps                      | 162        |
|    iterations               | 128        |
|    time_elapsed             | 1611       |
|    total_timesteps          | 262144     |
| train/                      |            |
|    approx_kl                | 0.45033014 |
|    clip_fraction            | 0.814      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.0393239  |
|    ent_clip_fraction        | 0.331      |
|    ent_entropy_loss         | -3.49      |
|    ent_loss                 | -0.0828    |
|    ent_policy_gradient_loss | -0.0552    |
|    ent_std                  | 0.373      |
|    ent_value_loss           | 0.0204     |
|    entropy_loss             | -3.75      |
|    explained_variance       | 0.725      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0313     |
|    n_updates                | 1270       |
|    policy_gradient_loss     | 0.107      |
|    std                      | 0.386      |
|    value_loss               | 0.0196     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 218        |
|    ep_rew_mean              | 57.7       |
| time/                       |            |
|    fps                      | 162        |
|    iterations               | 129        |
|    time_elapsed             | 1621       |
|    total_timesteps          | 264192     |
| train/                      |            |
|    approx_kl                | 0.4440027  |
|    clip_fraction            | 0.813      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.08407867 |
|    ent_clip_fraction        | 0.44       |
|    ent_entropy_loss         | -3.4       |
|    ent_loss                 | -0.0403    |
|    ent_policy_gradient_loss | -0.0235    |
|    ent_std                  | 0.369      |
|    ent_value_loss           | 0.0104     |
|    entropy_loss             | -3.65      |
|    explained_variance       | 0.477      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0756     |
|    n_updates                | 1280       |
|    policy_gradient_loss     | 0.0583     |
|    std                      | 0.379      |
|    value_loss               | 0.0104     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 236        |
|    ep_rew_mean              | 62.3       |
| time/                       |            |
|    fps                      | 163        |
|    iterations               | 130        |
|    time_elapsed             | 1631       |
|    total_timesteps          | 266240     |
| train/                      |            |
|    approx_kl                | 0.39262435 |
|    clip_fraction            | 0.788      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.10974589 |
|    ent_clip_fraction        | 0.454      |
|    ent_entropy_loss         | -3.33      |
|    ent_loss                 | -0.025     |
|    ent_policy_gradient_loss | -0.031     |
|    ent_std                  | 0.366      |
|    ent_value_loss           | 0.0343     |
|    entropy_loss             | -3.57      |
|    explained_variance       | 0.562      |
|    learning_rate            | 0.0003     |
|    loss                     | -0.0242    |
|    n_updates                | 1290       |
|    policy_gradient_loss     | 0.0719     |
|    std                      | 0.377      |
|    value_loss               | 0.034      |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 250        |
|    ep_rew_mean              | 65.7       |
| time/                       |            |
|    fps                      | 163        |
|    iterations               | 131        |
|    time_elapsed             | 1641       |
|    total_timesteps          | 268288     |
| train/                      |            |
|    approx_kl                | 0.42819533 |
|    clip_fraction            | 0.794      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.09892337 |
|    ent_clip_fraction        | 0.397      |
|    ent_entropy_loss         | -3.28      |
|    ent_loss                 | -0.00428   |
|    ent_policy_gradient_loss | -0.028     |
|    ent_std                  | 0.365      |
|    ent_value_loss           | 0.0188     |
|    entropy_loss             | -3.54      |
|    explained_variance       | 0.739      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0529     |
|    n_updates                | 1300       |
|    policy_gradient_loss     | 0.0748     |
|    std                      | 0.377      |
|    value_loss               | 0.0198     |
--------------------------------------------
Eval num_timesteps=270000, episode_reward=677.45 +/- 208.53
Episode length: 893.00 +/- 290.59
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 893        |
|    mean_reward              | 677        |
| time/                       |            |
|    total_timesteps          | 270000     |
| train/                      |            |
|    approx_kl                | 0.46301752 |
|    clip_fraction            | 0.831      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.03393641 |
|    ent_clip_fraction        | 0.334      |
|    ent_entropy_loss         | -3.24      |
|    ent_loss                 | -0.0878    |
|    ent_policy_gradient_loss | -0.0596    |
|    ent_std                  | 0.362      |
|    ent_value_loss           | 0.0162     |
|    entropy_loss             | -3.52      |
|    explained_variance       | 0.679      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.137      |
|    n_updates                | 1310       |
|    policy_gradient_loss     | 0.101      |
|    std                      | 0.375      |
|    value_loss               | 0.0162     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | 68.1     |
| time/              |          |
|    fps             | 161      |
|    iterations      | 132      |
|    time_elapsed    | 1671     |
|    total_timesteps | 270336   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 257        |
|    ep_rew_mean              | 74.5       |
| time/                       |            |
|    fps                      | 162        |
|    iterations               | 133        |
|    time_elapsed             | 1681       |
|    total_timesteps          | 272384     |
| train/                      |            |
|    approx_kl                | 0.35711342 |
|    clip_fraction            | 0.764      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.14542246 |
|    ent_clip_fraction        | 0.48       |
|    ent_entropy_loss         | -3.18      |
|    ent_loss                 | -0.0465    |
|    ent_policy_gradient_loss | -0.0244    |
|    ent_std                  | 0.359      |
|    ent_value_loss           | 0.0147     |
|    entropy_loss             | -3.46      |
|    explained_variance       | 0.672      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0158     |
|    n_updates                | 1320       |
|    policy_gradient_loss     | 0.0513     |
|    std                      | 0.372      |
|    value_loss               | 0.0142     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 274        |
|    ep_rew_mean              | 79.7       |
| time/                       |            |
|    fps                      | 162        |
|    iterations               | 134        |
|    time_elapsed             | 1691       |
|    total_timesteps          | 274432     |
| train/                      |            |
|    approx_kl                | 0.4448716  |
|    clip_fraction            | 0.809      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.06425547 |
|    ent_clip_fraction        | 0.372      |
|    ent_entropy_loss         | -3.11      |
|    ent_loss                 | -0.0472    |
|    ent_policy_gradient_loss | -0.0376    |
|    ent_std                  | 0.357      |
|    ent_value_loss           | 0.0277     |
|    entropy_loss             | -3.42      |
|    explained_variance       | 0.498      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0403     |
|    n_updates                | 1330       |
|    policy_gradient_loss     | 0.0953     |
|    std                      | 0.371      |
|    value_loss               | 0.027      |
--------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 284         |
|    ep_rew_mean              | 83.4        |
| time/                       |             |
|    fps                      | 162         |
|    iterations               | 135         |
|    time_elapsed             | 1701        |
|    total_timesteps          | 276480      |
| train/                      |             |
|    approx_kl                | 0.37673056  |
|    clip_fraction            | 0.785       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.116899535 |
|    ent_clip_fraction        | 0.442       |
|    ent_entropy_loss         | -3.05       |
|    ent_loss                 | -0.0936     |
|    ent_policy_gradient_loss | -0.0181     |
|    ent_std                  | 0.353       |
|    ent_value_loss           | 0.00721     |
|    entropy_loss             | -3.38       |
|    explained_variance       | 0.579       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0621      |
|    n_updates                | 1340        |
|    policy_gradient_loss     | 0.0749      |
|    std                      | 0.369       |
|    value_loss               | 0.00741     |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 287         |
|    ep_rew_mean              | 85.7        |
| time/                       |             |
|    fps                      | 162         |
|    iterations               | 136         |
|    time_elapsed             | 1711        |
|    total_timesteps          | 278528      |
| train/                      |             |
|    approx_kl                | 0.37894538  |
|    clip_fraction            | 0.802       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.109644555 |
|    ent_clip_fraction        | 0.398       |
|    ent_entropy_loss         | -2.99       |
|    ent_loss                 | -0.0459     |
|    ent_policy_gradient_loss | -0.0195     |
|    ent_std                  | 0.352       |
|    ent_value_loss           | 0.0193      |
|    entropy_loss             | -3.34       |
|    explained_variance       | 0.525       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0678      |
|    n_updates                | 1350        |
|    policy_gradient_loss     | 0.086       |
|    std                      | 0.368       |
|    value_loss               | 0.02        |
---------------------------------------------
Eval num_timesteps=280000, episode_reward=764.42 +/- 132.16
Episode length: 966.24 +/- 165.39
---------------------------------------------
| eval/                       |             |
|    mean_ep_length           | 966         |
|    mean_reward              | 764         |
| time/                       |             |
|    total_timesteps          | 280000      |
| train/                      |             |
|    approx_kl                | 0.5145844   |
|    clip_fraction            | 0.839       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.046442717 |
|    ent_clip_fraction        | 0.355       |
|    ent_entropy_loss         | -2.95       |
|    ent_loss                 | -0.0766     |
|    ent_policy_gradient_loss | -0.0499     |
|    ent_std                  | 0.35        |
|    ent_value_loss           | 0.0145      |
|    entropy_loss             | -3.32       |
|    explained_variance       | 0.596       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0475      |
|    n_updates                | 1360        |
|    policy_gradient_loss     | 0.0905      |
|    std                      | 0.365       |
|    value_loss               | 0.0144      |
---------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 287      |
|    ep_rew_mean     | 85.6     |
| time/              |          |
|    fps             | 161      |
|    iterations      | 137      |
|    time_elapsed    | 1740     |
|    total_timesteps | 280576   |
---------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 288         |
|    ep_rew_mean              | 93.6        |
| time/                       |             |
|    fps                      | 161         |
|    iterations               | 138         |
|    time_elapsed             | 1751        |
|    total_timesteps          | 282624      |
| train/                      |             |
|    approx_kl                | 0.51045305  |
|    clip_fraction            | 0.841       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.029161273 |
|    ent_clip_fraction        | 0.315       |
|    ent_entropy_loss         | -2.91       |
|    ent_loss                 | -0.0639     |
|    ent_policy_gradient_loss | -0.0508     |
|    ent_std                  | 0.348       |
|    ent_value_loss           | 0.0169      |
|    entropy_loss             | -3.27       |
|    explained_variance       | 0.612       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0433      |
|    n_updates                | 1370        |
|    policy_gradient_loss     | 0.102       |
|    std                      | 0.364       |
|    value_loss               | 0.0168      |
---------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 280        |
|    ep_rew_mean              | 92.5       |
| time/                       |            |
|    fps                      | 161        |
|    iterations               | 139        |
|    time_elapsed             | 1762       |
|    total_timesteps          | 284672     |
| train/                      |            |
|    approx_kl                | 0.45642054 |
|    clip_fraction            | 0.797      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.08533785 |
|    ent_clip_fraction        | 0.416      |
|    ent_entropy_loss         | -2.89      |
|    ent_loss                 | -0.0209    |
|    ent_policy_gradient_loss | -0.0312    |
|    ent_std                  | 0.348      |
|    ent_value_loss           | 0.0246     |
|    entropy_loss             | -3.24      |
|    explained_variance       | 0.506      |
|    learning_rate            | 0.0003     |
|    loss                     | -0.00256   |
|    n_updates                | 1380       |
|    policy_gradient_loss     | 0.0865     |
|    std                      | 0.363      |
|    value_loss               | 0.0252     |
--------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 292         |
|    ep_rew_mean              | 96.7        |
| time/                       |             |
|    fps                      | 161         |
|    iterations               | 140         |
|    time_elapsed             | 1772        |
|    total_timesteps          | 286720      |
| train/                      |             |
|    approx_kl                | 0.44396302  |
|    clip_fraction            | 0.822       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.030216828 |
|    ent_clip_fraction        | 0.321       |
|    ent_entropy_loss         | -2.89       |
|    ent_loss                 | -0.0756     |
|    ent_policy_gradient_loss | -0.06       |
|    ent_std                  | 0.347       |
|    ent_value_loss           | 0.0215      |
|    entropy_loss             | -3.23       |
|    explained_variance       | 0.559       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.113       |
|    n_updates                | 1390        |
|    policy_gradient_loss     | 0.0831      |
|    std                      | 0.363       |
|    value_loss               | 0.0213      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 312         |
|    ep_rew_mean              | 103         |
| time/                       |             |
|    fps                      | 162         |
|    iterations               | 141         |
|    time_elapsed             | 1782        |
|    total_timesteps          | 288768      |
| train/                      |             |
|    approx_kl                | 0.5764837   |
|    clip_fraction            | 0.846       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.033162702 |
|    ent_clip_fraction        | 0.327       |
|    ent_entropy_loss         | -2.84       |
|    ent_loss                 | -0.103      |
|    ent_policy_gradient_loss | -0.0556     |
|    ent_std                  | 0.345       |
|    ent_value_loss           | 0.0186      |
|    entropy_loss             | -3.22       |
|    explained_variance       | 0.557       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0144      |
|    n_updates                | 1400        |
|    policy_gradient_loss     | 0.112       |
|    std                      | 0.362       |
|    value_loss               | 0.0189      |
---------------------------------------------
Eval num_timesteps=290000, episode_reward=786.16 +/- 151.86
Episode length: 962.64 +/- 183.03
---------------------------------------------
| eval/                       |             |
|    mean_ep_length           | 963         |
|    mean_reward              | 786         |
| time/                       |             |
|    total_timesteps          | 290000      |
| train/                      |             |
|    approx_kl                | 0.5777476   |
|    clip_fraction            | 0.82        |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.090629786 |
|    ent_clip_fraction        | 0.417       |
|    ent_entropy_loss         | -2.78       |
|    ent_loss                 | -0.0681     |
|    ent_policy_gradient_loss | -0.0459     |
|    ent_std                  | 0.342       |
|    ent_value_loss           | 0.0174      |
|    entropy_loss             | -3.17       |
|    explained_variance       | 0.548       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0884      |
|    n_updates                | 1410        |
|    policy_gradient_loss     | 0.101       |
|    std                      | 0.358       |
|    value_loss               | 0.0168      |
---------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 313      |
|    ep_rew_mean     | 107      |
| time/              |          |
|    fps             | 160      |
|    iterations      | 142      |
|    time_elapsed    | 1811     |
|    total_timesteps | 290816   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 307        |
|    ep_rew_mean              | 105        |
| time/                       |            |
|    fps                      | 160        |
|    iterations               | 143        |
|    time_elapsed             | 1821       |
|    total_timesteps          | 292864     |
| train/                      |            |
|    approx_kl                | 0.48814693 |
|    clip_fraction            | 0.79       |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.15993854 |
|    ent_clip_fraction        | 0.548      |
|    ent_entropy_loss         | -2.76      |
|    ent_loss                 | 0.0881     |
|    ent_policy_gradient_loss | 0.0297     |
|    ent_std                  | 0.342      |
|    ent_value_loss           | 0.0244     |
|    entropy_loss             | -3.09      |
|    explained_variance       | 0.563      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.00662    |
|    n_updates                | 1420       |
|    policy_gradient_loss     | 0.0407     |
|    std                      | 0.356      |
|    value_loss               | 0.0243     |
--------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 316         |
|    ep_rew_mean              | 109         |
| time/                       |             |
|    fps                      | 160         |
|    iterations               | 144         |
|    time_elapsed             | 1832        |
|    total_timesteps          | 294912      |
| train/                      |             |
|    approx_kl                | 0.48214194  |
|    clip_fraction            | 0.835       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.034138888 |
|    ent_clip_fraction        | 0.342       |
|    ent_entropy_loss         | -2.74       |
|    ent_loss                 | -0.0735     |
|    ent_policy_gradient_loss | -0.0562     |
|    ent_std                  | 0.341       |
|    ent_value_loss           | 0.0181      |
|    entropy_loss             | -3.06       |
|    explained_variance       | 0.556       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.104       |
|    n_updates                | 1430        |
|    policy_gradient_loss     | 0.102       |
|    std                      | 0.354       |
|    value_loss               | 0.019       |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 310         |
|    ep_rew_mean              | 110         |
| time/                       |             |
|    fps                      | 161         |
|    iterations               | 145         |
|    time_elapsed             | 1842        |
|    total_timesteps          | 296960      |
| train/                      |             |
|    approx_kl                | 0.5527122   |
|    clip_fraction            | 0.838       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.039359942 |
|    ent_clip_fraction        | 0.355       |
|    ent_entropy_loss         | -2.69       |
|    ent_loss                 | -0.0781     |
|    ent_policy_gradient_loss | -0.0558     |
|    ent_std                  | 0.338       |
|    ent_value_loss           | 0.0207      |
|    entropy_loss             | -3.01       |
|    explained_variance       | 0.727       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0453      |
|    n_updates                | 1440        |
|    policy_gradient_loss     | 0.111       |
|    std                      | 0.352       |
|    value_loss               | 0.0205      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 284         |
|    ep_rew_mean              | 106         |
| time/                       |             |
|    fps                      | 161         |
|    iterations               | 146         |
|    time_elapsed             | 1852        |
|    total_timesteps          | 299008      |
| train/                      |             |
|    approx_kl                | 0.5016179   |
|    clip_fraction            | 0.827       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.058252137 |
|    ent_clip_fraction        | 0.373       |
|    ent_entropy_loss         | -2.64       |
|    ent_loss                 | -0.042      |
|    ent_policy_gradient_loss | -0.0498     |
|    ent_std                  | 0.336       |
|    ent_value_loss           | 0.0253      |
|    entropy_loss             | -2.99       |
|    explained_variance       | 0.593       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0522      |
|    n_updates                | 1450        |
|    policy_gradient_loss     | 0.109       |
|    std                      | 0.352       |
|    value_loss               | 0.0267      |
---------------------------------------------
Eval num_timesteps=300000, episode_reward=835.23 +/- 25.32
Episode length: 1000.00 +/- 0.00
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 1e+03      |
|    mean_reward              | 835        |
| time/                       |            |
|    total_timesteps          | 300000     |
| train/                      |            |
|    approx_kl                | 0.5504586  |
|    clip_fraction            | 0.842      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.03494592 |
|    ent_clip_fraction        | 0.355      |
|    ent_entropy_loss         | -2.59      |
|    ent_loss                 | -0.0798    |
|    ent_policy_gradient_loss | -0.0605    |
|    ent_std                  | 0.334      |
|    ent_value_loss           | 0.036      |
|    entropy_loss             | -2.96      |
|    explained_variance       | 0.411      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0185     |
|    n_updates                | 1460       |
|    policy_gradient_loss     | 0.103      |
|    std                      | 0.349      |
|    value_loss               | 0.0361     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 297      |
|    ep_rew_mean     | 109      |
| time/              |          |
|    fps             | 160      |
|    iterations      | 147      |
|    time_elapsed    | 1881     |
|    total_timesteps | 301056   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 303        |
|    ep_rew_mean              | 112        |
| time/                       |            |
|    fps                      | 160        |
|    iterations               | 148        |
|    time_elapsed             | 1891       |
|    total_timesteps          | 303104     |
| train/                      |            |
|    approx_kl                | 0.49574104 |
|    clip_fraction            | 0.827      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.08950817 |
|    ent_clip_fraction        | 0.413      |
|    ent_entropy_loss         | -2.55      |
|    ent_loss                 | -0.0369    |
|    ent_policy_gradient_loss | -0.0227    |
|    ent_std                  | 0.333      |
|    ent_value_loss           | 0.0181     |
|    entropy_loss             | -2.89      |
|    explained_variance       | 0.702      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0457     |
|    n_updates                | 1470       |
|    policy_gradient_loss     | 0.0998     |
|    std                      | 0.346      |
|    value_loss               | 0.0181     |
--------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 299         |
|    ep_rew_mean              | 112         |
| time/                       |             |
|    fps                      | 160         |
|    iterations               | 149         |
|    time_elapsed             | 1902        |
|    total_timesteps          | 305152      |
| train/                      |             |
|    approx_kl                | 0.4727805   |
|    clip_fraction            | 0.84        |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.029415358 |
|    ent_clip_fraction        | 0.309       |
|    ent_entropy_loss         | -2.49       |
|    ent_loss                 | -0.0534     |
|    ent_policy_gradient_loss | -0.0542     |
|    ent_std                  | 0.329       |
|    ent_value_loss           | 0.0199      |
|    entropy_loss             | -2.82       |
|    explained_variance       | 0.623       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.124       |
|    n_updates                | 1480        |
|    policy_gradient_loss     | 0.124       |
|    std                      | 0.344       |
|    value_loss               | 0.0208      |
---------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 306        |
|    ep_rew_mean              | 115        |
| time/                       |            |
|    fps                      | 160        |
|    iterations               | 150        |
|    time_elapsed             | 1912       |
|    total_timesteps          | 307200     |
| train/                      |            |
|    approx_kl                | 0.504522   |
|    clip_fraction            | 0.822      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.10858739 |
|    ent_clip_fraction        | 0.433      |
|    ent_entropy_loss         | -2.42      |
|    ent_loss                 | -0.0534    |
|    ent_policy_gradient_loss | -0.033     |
|    ent_std                  | 0.327      |
|    ent_value_loss           | 0.0275     |
|    entropy_loss             | -2.79      |
|    explained_variance       | 0.604      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.121      |
|    n_updates                | 1490       |
|    policy_gradient_loss     | 0.114      |
|    std                      | 0.342      |
|    value_loss               | 0.0269     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 309        |
|    ep_rew_mean              | 117        |
| time/                       |            |
|    fps                      | 160        |
|    iterations               | 151        |
|    time_elapsed             | 1922       |
|    total_timesteps          | 309248     |
| train/                      |            |
|    approx_kl                | 0.59720165 |
|    clip_fraction            | 0.843      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.07311706 |
|    ent_clip_fraction        | 0.395      |
|    ent_entropy_loss         | -2.36      |
|    ent_loss                 | -0.0536    |
|    ent_policy_gradient_loss | -0.0298    |
|    ent_std                  | 0.325      |
|    ent_value_loss           | 0.0109     |
|    entropy_loss             | -2.72      |
|    explained_variance       | 0.813      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0714     |
|    n_updates                | 1500       |
|    policy_gradient_loss     | 0.116      |
|    std                      | 0.339      |
|    value_loss               | 0.0111     |
--------------------------------------------
Eval num_timesteps=310000, episode_reward=899.30 +/- 36.33
Episode length: 1000.00 +/- 0.00
---------------------------------------------
| eval/                       |             |
|    mean_ep_length           | 1e+03       |
|    mean_reward              | 899         |
| time/                       |             |
|    total_timesteps          | 310000      |
| train/                      |             |
|    approx_kl                | 0.57312906  |
|    clip_fraction            | 0.848       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.054747373 |
|    ent_clip_fraction        | 0.362       |
|    ent_entropy_loss         | -2.33       |
|    ent_loss                 | -0.0763     |
|    ent_policy_gradient_loss | -0.0404     |
|    ent_std                  | 0.323       |
|    ent_value_loss           | 0.0151      |
|    entropy_loss             | -2.66       |
|    explained_variance       | 0.611       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0634      |
|    n_updates                | 1510        |
|    policy_gradient_loss     | 0.108       |
|    std                      | 0.338       |
|    value_loss               | 0.0161      |
---------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 328      |
|    ep_rew_mean     | 124      |
| time/              |          |
|    fps             | 159      |
|    iterations      | 152      |
|    time_elapsed    | 1950     |
|    total_timesteps | 311296   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 345        |
|    ep_rew_mean              | 131        |
| time/                       |            |
|    fps                      | 159        |
|    iterations               | 153        |
|    time_elapsed             | 1960       |
|    total_timesteps          | 313344     |
| train/                      |            |
|    approx_kl                | 0.41677463 |
|    clip_fraction            | 0.81       |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.26622376 |
|    ent_clip_fraction        | 0.558      |
|    ent_entropy_loss         | -2.27      |
|    ent_loss                 | 0.00111    |
|    ent_policy_gradient_loss | 0.0188     |
|    ent_std                  | 0.321      |
|    ent_value_loss           | 0.00275    |
|    entropy_loss             | -2.6       |
|    explained_variance       | 0.32       |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0677     |
|    n_updates                | 1520       |
|    policy_gradient_loss     | 0.0933     |
|    std                      | 0.334      |
|    value_loss               | 0.00266    |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 358        |
|    ep_rew_mean              | 138        |
| time/                       |            |
|    fps                      | 160        |
|    iterations               | 154        |
|    time_elapsed             | 1970       |
|    total_timesteps          | 315392     |
| train/                      |            |
|    approx_kl                | 0.42285514 |
|    clip_fraction            | 0.792      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.17106068 |
|    ent_clip_fraction        | 0.496      |
|    ent_entropy_loss         | -2.21      |
|    ent_loss                 | -0.0659    |
|    ent_policy_gradient_loss | -0.0103    |
|    ent_std                  | 0.319      |
|    ent_value_loss           | 0.0101     |
|    entropy_loss             | -2.52      |
|    explained_variance       | 0.508      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.091      |
|    n_updates                | 1530       |
|    policy_gradient_loss     | 0.0446     |
|    std                      | 0.33       |
|    value_loss               | 0.00963    |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 371        |
|    ep_rew_mean              | 147        |
| time/                       |            |
|    fps                      | 160        |
|    iterations               | 155        |
|    time_elapsed             | 1980       |
|    total_timesteps          | 317440     |
| train/                      |            |
|    approx_kl                | 0.47784263 |
|    clip_fraction            | 0.741      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.2167893  |
|    ent_clip_fraction        | 0.559      |
|    ent_entropy_loss         | -2.2       |
|    ent_loss                 | 0.00869    |
|    ent_policy_gradient_loss | 0.0276     |
|    ent_std                  | 0.32       |
|    ent_value_loss           | 0.0121     |
|    entropy_loss             | -2.47      |
|    explained_variance       | 0.684      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.00562    |
|    n_updates                | 1540       |
|    policy_gradient_loss     | 0.0486     |
|    std                      | 0.33       |
|    value_loss               | 0.0128     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 380        |
|    ep_rew_mean              | 153        |
| time/                       |            |
|    fps                      | 160        |
|    iterations               | 156        |
|    time_elapsed             | 1991       |
|    total_timesteps          | 319488     |
| train/                      |            |
|    approx_kl                | 0.42244703 |
|    clip_fraction            | 0.777      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.15326759 |
|    ent_clip_fraction        | 0.505      |
|    ent_entropy_loss         | -2.21      |
|    ent_loss                 | -0.0433    |
|    ent_policy_gradient_loss | -0.0189    |
|    ent_std                  | 0.319      |
|    ent_value_loss           | 0.0183     |
|    entropy_loss             | -2.45      |
|    explained_variance       | 0.648      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0979     |
|    n_updates                | 1550       |
|    policy_gradient_loss     | 0.0852     |
|    std                      | 0.329      |
|    value_loss               | 0.0186     |
--------------------------------------------
Eval num_timesteps=320000, episode_reward=861.64 +/- 68.54
Episode length: 1000.00 +/- 0.00
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 1e+03      |
|    mean_reward              | 862        |
| time/                       |            |
|    total_timesteps          | 320000     |
| train/                      |            |
|    approx_kl                | 0.5124478  |
|    clip_fraction            | 0.814      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.10314122 |
|    ent_clip_fraction        | 0.443      |
|    ent_entropy_loss         | -2.16      |
|    ent_loss                 | -0.0247    |
|    ent_policy_gradient_loss | -0.0249    |
|    ent_std                  | 0.316      |
|    ent_value_loss           | 0.021      |
|    entropy_loss             | -2.41      |
|    explained_variance       | 0.531      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.114      |
|    n_updates                | 1560       |
|    policy_gradient_loss     | 0.0687     |
|    std                      | 0.326      |
|    value_loss               | 0.0211     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 393      |
|    ep_rew_mean     | 161      |
| time/              |          |
|    fps             | 159      |
|    iterations      | 157      |
|    time_elapsed    | 2019     |
|    total_timesteps | 321536   |
---------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 387         |
|    ep_rew_mean              | 162         |
| time/                       |             |
|    fps                      | 159         |
|    iterations               | 158         |
|    time_elapsed             | 2029        |
|    total_timesteps          | 323584      |
| train/                      |             |
|    approx_kl                | 0.521428    |
|    clip_fraction            | 0.823       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.102058575 |
|    ent_clip_fraction        | 0.447       |
|    ent_entropy_loss         | -2.09       |
|    ent_loss                 | -0.0477     |
|    ent_policy_gradient_loss | -0.00519    |
|    ent_std                  | 0.314       |
|    ent_value_loss           | 0.0205      |
|    entropy_loss             | -2.33       |
|    explained_variance       | 0.562       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0167      |
|    n_updates                | 1570        |
|    policy_gradient_loss     | 0.0699      |
|    std                      | 0.323       |
|    value_loss               | 0.0208      |
---------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 394        |
|    ep_rew_mean              | 168        |
| time/                       |            |
|    fps                      | 159        |
|    iterations               | 159        |
|    time_elapsed             | 2040       |
|    total_timesteps          | 325632     |
| train/                      |            |
|    approx_kl                | 0.52620804 |
|    clip_fraction            | 0.837      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.07633379 |
|    ent_clip_fraction        | 0.396      |
|    ent_entropy_loss         | -2.05      |
|    ent_loss                 | -0.0375    |
|    ent_policy_gradient_loss | -0.0414    |
|    ent_std                  | 0.313      |
|    ent_value_loss           | 0.0313     |
|    entropy_loss             | -2.3       |
|    explained_variance       | 0.531      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0152     |
|    n_updates                | 1580       |
|    policy_gradient_loss     | 0.0812     |
|    std                      | 0.323      |
|    value_loss               | 0.0303     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 401        |
|    ep_rew_mean              | 175        |
| time/                       |            |
|    fps                      | 159        |
|    iterations               | 160        |
|    time_elapsed             | 2050       |
|    total_timesteps          | 327680     |
| train/                      |            |
|    approx_kl                | 0.51592004 |
|    clip_fraction            | 0.852      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.03371411 |
|    ent_clip_fraction        | 0.349      |
|    ent_entropy_loss         | -2         |
|    ent_loss                 | -0.045     |
|    ent_policy_gradient_loss | -0.056     |
|    ent_std                  | 0.31       |
|    ent_value_loss           | 0.0382     |
|    entropy_loss             | -2.27      |
|    explained_variance       | 0.798      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0528     |
|    n_updates                | 1590       |
|    policy_gradient_loss     | 0.109      |
|    std                      | 0.321      |
|    value_loss               | 0.039      |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 400        |
|    ep_rew_mean              | 182        |
| time/                       |            |
|    fps                      | 160        |
|    iterations               | 161        |
|    time_elapsed             | 2059       |
|    total_timesteps          | 329728     |
| train/                      |            |
|    approx_kl                | 0.39424977 |
|    clip_fraction            | 0.768      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.18737477 |
|    ent_clip_fraction        | 0.511      |
|    ent_entropy_loss         | -1.96      |
|    ent_loss                 | -0.0468    |
|    ent_policy_gradient_loss | -0.00514   |
|    ent_std                  | 0.309      |
|    ent_value_loss           | 0.0247     |
|    entropy_loss             | -2.24      |
|    explained_variance       | 0.739      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0613     |
|    n_updates                | 1600       |
|    policy_gradient_loss     | 0.0847     |
|    std                      | 0.32       |
|    value_loss               | 0.0258     |
--------------------------------------------
Eval num_timesteps=330000, episode_reward=897.46 +/- 53.81
Episode length: 1000.00 +/- 0.00
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 1e+03      |
|    mean_reward              | 897        |
| time/                       |            |
|    total_timesteps          | 330000     |
| train/                      |            |
|    approx_kl                | 0.5481404  |
|    clip_fraction            | 0.843      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.03214021 |
|    ent_clip_fraction        | 0.35       |
|    ent_entropy_loss         | -1.9       |
|    ent_loss                 | -0.0488    |
|    ent_policy_gradient_loss | -0.0529    |
|    ent_std                  | 0.306      |
|    ent_value_loss           | 0.0402     |
|    entropy_loss             | -2.21      |
|    explained_variance       | 0.533      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0776     |
|    n_updates                | 1610       |
|    policy_gradient_loss     | 0.105      |
|    std                      | 0.318      |
|    value_loss               | 0.0409     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 417      |
|    ep_rew_mean     | 193      |
| time/              |          |
|    fps             | 158      |
|    iterations      | 162      |
|    time_elapsed    | 2087     |
|    total_timesteps | 331776   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 431        |
|    ep_rew_mean              | 201        |
| time/                       |            |
|    fps                      | 159        |
|    iterations               | 163        |
|    time_elapsed             | 2097       |
|    total_timesteps          | 333824     |
| train/                      |            |
|    approx_kl                | 0.25674346 |
|    clip_fraction            | 0.579      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.3031267  |
|    ent_clip_fraction        | 0.694      |
|    ent_entropy_loss         | -1.9       |
|    ent_loss                 | 0.0489     |
|    ent_policy_gradient_loss | 0.0723     |
|    ent_std                  | 0.309      |
|    ent_value_loss           | 0.024      |
|    entropy_loss             | -2.17      |
|    explained_variance       | 0.814      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0124     |
|    n_updates                | 1620       |
|    policy_gradient_loss     | 0.0313     |
|    std                      | 0.317      |
|    value_loss               | 0.0246     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 445        |
|    ep_rew_mean              | 209        |
| time/                       |            |
|    fps                      | 159        |
|    iterations               | 164        |
|    time_elapsed             | 2107       |
|    total_timesteps          | 335872     |
| train/                      |            |
|    approx_kl                | 0.49791706 |
|    clip_fraction            | 0.833      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.05246236 |
|    ent_clip_fraction        | 0.35       |
|    ent_entropy_loss         | -1.92      |
|    ent_loss                 | -0.0499    |
|    ent_policy_gradient_loss | -0.0395    |
|    ent_std                  | 0.307      |
|    ent_value_loss           | 0.0118     |
|    entropy_loss             | -2.17      |
|    explained_variance       | 0.722      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.108      |
|    n_updates                | 1630       |
|    policy_gradient_loss     | 0.106      |
|    std                      | 0.318      |
|    value_loss               | 0.0116     |
--------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 455         |
|    ep_rew_mean              | 216         |
| time/                       |             |
|    fps                      | 159         |
|    iterations               | 165         |
|    time_elapsed             | 2117        |
|    total_timesteps          | 337920      |
| train/                      |             |
|    approx_kl                | 0.487602    |
|    clip_fraction            | 0.842       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.065260574 |
|    ent_clip_fraction        | 0.369       |
|    ent_entropy_loss         | -1.87       |
|    ent_loss                 | -0.0519     |
|    ent_policy_gradient_loss | -0.0363     |
|    ent_std                  | 0.305       |
|    ent_value_loss           | 0.016       |
|    entropy_loss             | -2.14       |
|    explained_variance       | 0.619       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0614      |
|    n_updates                | 1640        |
|    policy_gradient_loss     | 0.0753      |
|    std                      | 0.315       |
|    value_loss               | 0.0166      |
---------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 458        |
|    ep_rew_mean              | 220        |
| time/                       |            |
|    fps                      | 159        |
|    iterations               | 166        |
|    time_elapsed             | 2127       |
|    total_timesteps          | 339968     |
| train/                      |            |
|    approx_kl                | 0.4329611  |
|    clip_fraction            | 0.797      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.11630252 |
|    ent_clip_fraction        | 0.418      |
|    ent_entropy_loss         | -1.82      |
|    ent_loss                 | -0.0645    |
|    ent_policy_gradient_loss | -0.0219    |
|    ent_std                  | 0.303      |
|    ent_value_loss           | 0.0189     |
|    entropy_loss             | -2.06      |
|    explained_variance       | 0.669      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.11       |
|    n_updates                | 1650       |
|    policy_gradient_loss     | 0.0895     |
|    std                      | 0.312      |
|    value_loss               | 0.0194     |
--------------------------------------------
Eval num_timesteps=340000, episode_reward=693.20 +/- 50.08
Episode length: 1000.00 +/- 0.00
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 1e+03      |
|    mean_reward              | 693        |
| time/                       |            |
|    total_timesteps          | 340000     |
| train/                      |            |
|    approx_kl                | 0.4463063  |
|    clip_fraction            | 0.823      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.09080617 |
|    ent_clip_fraction        | 0.44       |
|    ent_entropy_loss         | -1.77      |
|    ent_loss                 | -0.0764    |
|    ent_policy_gradient_loss | 0.000592   |
|    ent_std                  | 0.301      |
|    ent_value_loss           | 0.0101     |
|    entropy_loss             | -2         |
|    explained_variance       | 0.502      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.103      |
|    n_updates                | 1660       |
|    policy_gradient_loss     | 0.0997     |
|    std                      | 0.311      |
|    value_loss               | 0.0103     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 227      |
| time/              |          |
|    fps             | 158      |
|    iterations      | 167      |
|    time_elapsed    | 2156     |
|    total_timesteps | 342016   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 483        |
|    ep_rew_mean              | 235        |
| time/                       |            |
|    fps                      | 158        |
|    iterations               | 168        |
|    time_elapsed             | 2166       |
|    total_timesteps          | 344064     |
| train/                      |            |
|    approx_kl                | 0.40399766 |
|    clip_fraction            | 0.79       |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.13084045 |
|    ent_clip_fraction        | 0.445      |
|    ent_entropy_loss         | -1.73      |
|    ent_loss                 | -0.0471    |
|    ent_policy_gradient_loss | -0.0217    |
|    ent_std                  | 0.3        |
|    ent_value_loss           | 0.0117     |
|    entropy_loss             | -2         |
|    explained_variance       | 0.875      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0514     |
|    n_updates                | 1670       |
|    policy_gradient_loss     | 0.0895     |
|    std                      | 0.311      |
|    value_loss               | 0.0115     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 509        |
|    ep_rew_mean              | 247        |
| time/                       |            |
|    fps                      | 159        |
|    iterations               | 169        |
|    time_elapsed             | 2176       |
|    total_timesteps          | 346112     |
| train/                      |            |
|    approx_kl                | 0.44708323 |
|    clip_fraction            | 0.82       |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.07346493 |
|    ent_clip_fraction        | 0.387      |
|    ent_entropy_loss         | -1.68      |
|    ent_loss                 | -0.0102    |
|    ent_policy_gradient_loss | -0.036     |
|    ent_std                  | 0.298      |
|    ent_value_loss           | 0.0101     |
|    entropy_loss             | -1.96      |
|    explained_variance       | 0.877      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0572     |
|    n_updates                | 1680       |
|    policy_gradient_loss     | 0.0876     |
|    std                      | 0.308      |
|    value_loss               | 0.0103     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 527        |
|    ep_rew_mean              | 260        |
| time/                       |            |
|    fps                      | 159        |
|    iterations               | 170        |
|    time_elapsed             | 2186       |
|    total_timesteps          | 348160     |
| train/                      |            |
|    approx_kl                | 0.41543496 |
|    clip_fraction            | 0.76       |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.1781128  |
|    ent_clip_fraction        | 0.508      |
|    ent_entropy_loss         | -1.66      |
|    ent_loss                 | -0.0402    |
|    ent_policy_gradient_loss | 0.00967    |
|    ent_std                  | 0.298      |
|    ent_value_loss           | 0.00753    |
|    entropy_loss             | -1.9       |
|    explained_variance       | 0.821      |
|    learning_rate            | 0.0003     |
|    loss                     | -0.00655   |
|    n_updates                | 1690       |
|    policy_gradient_loss     | 0.0546     |
|    std                      | 0.306      |
|    value_loss               | 0.00753    |
--------------------------------------------
Eval num_timesteps=350000, episode_reward=880.18 +/- 91.51
Episode length: 1000.00 +/- 0.00
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 1e+03      |
|    mean_reward              | 880        |
| time/                       |            |
|    total_timesteps          | 350000     |
| train/                      |            |
|    approx_kl                | 0.3636654  |
|    clip_fraction            | 0.71       |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.24280936 |
|    ent_clip_fraction        | 0.558      |
|    ent_entropy_loss         | -1.62      |
|    ent_loss                 | -0.0117    |
|    ent_policy_gradient_loss | 0.0123     |
|    ent_std                  | 0.295      |
|    ent_value_loss           | 0.0115     |
|    entropy_loss             | -1.85      |
|    explained_variance       | 0.791      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0709     |
|    n_updates                | 1700       |
|    policy_gradient_loss     | 0.0858     |
|    std                      | 0.305      |
|    value_loss               | 0.0115     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 541      |
|    ep_rew_mean     | 270      |
| time/              |          |
|    fps             | 158      |
|    iterations      | 171      |
|    time_elapsed    | 2215     |
|    total_timesteps | 350208   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 559        |
|    ep_rew_mean              | 281        |
| time/                       |            |
|    fps                      | 158        |
|    iterations               | 172        |
|    time_elapsed             | 2226       |
|    total_timesteps          | 352256     |
| train/                      |            |
|    approx_kl                | 0.41359445 |
|    clip_fraction            | 0.796      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.11135028 |
|    ent_clip_fraction        | 0.477      |
|    ent_entropy_loss         | -1.54      |
|    ent_loss                 | 0.000478   |
|    ent_policy_gradient_loss | -0.0136    |
|    ent_std                  | 0.293      |
|    ent_value_loss           | 0.0156     |
|    entropy_loss             | -1.79      |
|    explained_variance       | 0.741      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0804     |
|    n_updates                | 1710       |
|    policy_gradient_loss     | 0.0894     |
|    std                      | 0.301      |
|    value_loss               | 0.0162     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 568        |
|    ep_rew_mean              | 291        |
| time/                       |            |
|    fps                      | 158        |
|    iterations               | 173        |
|    time_elapsed             | 2236       |
|    total_timesteps          | 354304     |
| train/                      |            |
|    approx_kl                | 0.36013064 |
|    clip_fraction            | 0.717      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.2463441  |
|    ent_clip_fraction        | 0.592      |
|    ent_entropy_loss         | -1.52      |
|    ent_loss                 | -0.0114    |
|    ent_policy_gradient_loss | 0.0234     |
|    ent_std                  | 0.293      |
|    ent_value_loss           | 0.0162     |
|    entropy_loss             | -1.72      |
|    explained_variance       | 0.687      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0356     |
|    n_updates                | 1720       |
|    policy_gradient_loss     | 0.063      |
|    std                      | 0.3        |
|    value_loss               | 0.0164     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 584       |
|    ep_rew_mean              | 302       |
| time/                       |           |
|    fps                      | 158       |
|    iterations               | 174       |
|    time_elapsed             | 2246      |
|    total_timesteps          | 356352    |
| train/                      |           |
|    approx_kl                | 0.4045633 |
|    clip_fraction            | 0.724     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.2426072 |
|    ent_clip_fraction        | 0.569     |
|    ent_entropy_loss         | -1.53     |
|    ent_loss                 | 0.013     |
|    ent_policy_gradient_loss | 0.0333    |
|    ent_std                  | 0.294     |
|    ent_value_loss           | 0.00947   |
|    entropy_loss             | -1.73     |
|    explained_variance       | 0.797     |
|    learning_rate            | 0.0003    |
|    loss                     | -0.0135   |
|    n_updates                | 1730      |
|    policy_gradient_loss     | 0.0693    |
|    std                      | 0.301     |
|    value_loss               | 0.00963   |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 608        |
|    ep_rew_mean              | 317        |
| time/                       |            |
|    fps                      | 158        |
|    iterations               | 175        |
|    time_elapsed             | 2256       |
|    total_timesteps          | 358400     |
| train/                      |            |
|    approx_kl                | 0.45546782 |
|    clip_fraction            | 0.786      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.1433345  |
|    ent_clip_fraction        | 0.463      |
|    ent_entropy_loss         | -1.55      |
|    ent_loss                 | -0.0233    |
|    ent_policy_gradient_loss | 0.00292    |
|    ent_std                  | 0.295      |
|    ent_value_loss           | 0.00993    |
|    entropy_loss             | -1.76      |
|    explained_variance       | 0.833      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0696     |
|    n_updates                | 1740       |
|    policy_gradient_loss     | 0.113      |
|    std                      | 0.303      |
|    value_loss               | 0.01       |
--------------------------------------------
Eval num_timesteps=360000, episode_reward=865.13 +/- 32.14
Episode length: 1000.00 +/- 0.00
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 1e+03      |
|    mean_reward              | 865        |
| time/                       |            |
|    total_timesteps          | 360000     |
| train/                      |            |
|    approx_kl                | 0.48950785 |
|    clip_fraction            | 0.773      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.18303427 |
|    ent_clip_fraction        | 0.53       |
|    ent_entropy_loss         | -1.55      |
|    ent_loss                 | -0.0411    |
|    ent_policy_gradient_loss | -0.00717   |
|    ent_std                  | 0.293      |
|    ent_value_loss           | 0.0136     |
|    entropy_loss             | -1.75      |
|    explained_variance       | 0.705      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.03       |
|    n_updates                | 1750       |
|    policy_gradient_loss     | 0.0735     |
|    std                      | 0.301      |
|    value_loss               | 0.0136     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 626      |
|    ep_rew_mean     | 329      |
| time/              |          |
|    fps             | 157      |
|    iterations      | 176      |
|    time_elapsed    | 2284     |
|    total_timesteps | 360448   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 632        |
|    ep_rew_mean              | 334        |
| time/                       |            |
|    fps                      | 157        |
|    iterations               | 177        |
|    time_elapsed             | 2294       |
|    total_timesteps          | 362496     |
| train/                      |            |
|    approx_kl                | 0.4394765  |
|    clip_fraction            | 0.781      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.15823752 |
|    ent_clip_fraction        | 0.486      |
|    ent_entropy_loss         | -1.51      |
|    ent_loss                 | -0.0534    |
|    ent_policy_gradient_loss | -0.00186   |
|    ent_std                  | 0.293      |
|    ent_value_loss           | 0.00933    |
|    entropy_loss             | -1.7       |
|    explained_variance       | 0.677      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0154     |
|    n_updates                | 1760       |
|    policy_gradient_loss     | 0.11       |
|    std                      | 0.299      |
|    value_loss               | 0.00942    |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 641        |
|    ep_rew_mean              | 343        |
| time/                       |            |
|    fps                      | 158        |
|    iterations               | 178        |
|    time_elapsed             | 2305       |
|    total_timesteps          | 364544     |
| train/                      |            |
|    approx_kl                | 0.5255457  |
|    clip_fraction            | 0.824      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.06471429 |
|    ent_clip_fraction        | 0.409      |
|    ent_entropy_loss         | -1.5       |
|    ent_loss                 | -0.0488    |
|    ent_policy_gradient_loss | -0.0425    |
|    ent_std                  | 0.292      |
|    ent_value_loss           | 0.0169     |
|    entropy_loss             | -1.69      |
|    explained_variance       | 0.535      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0656     |
|    n_updates                | 1770       |
|    policy_gradient_loss     | 0.081      |
|    std                      | 0.299      |
|    value_loss               | 0.0164     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 652        |
|    ep_rew_mean              | 355        |
| time/                       |            |
|    fps                      | 158        |
|    iterations               | 179        |
|    time_elapsed             | 2315       |
|    total_timesteps          | 366592     |
| train/                      |            |
|    approx_kl                | 0.36233473 |
|    clip_fraction            | 0.758      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.25844008 |
|    ent_clip_fraction        | 0.565      |
|    ent_entropy_loss         | -1.46      |
|    ent_loss                 | -0.0283    |
|    ent_policy_gradient_loss | -1.72e-05  |
|    ent_std                  | 0.291      |
|    ent_value_loss           | 0.0162     |
|    entropy_loss             | -1.7       |
|    explained_variance       | 0.421      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0896     |
|    n_updates                | 1780       |
|    policy_gradient_loss     | 0.0678     |
|    std                      | 0.3        |
|    value_loss               | 0.0172     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 670        |
|    ep_rew_mean              | 363        |
| time/                       |            |
|    fps                      | 158        |
|    iterations               | 180        |
|    time_elapsed             | 2325       |
|    total_timesteps          | 368640     |
| train/                      |            |
|    approx_kl                | 0.35925633 |
|    clip_fraction            | 0.71       |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.52783185 |
|    ent_clip_fraction        | 0.601      |
|    ent_entropy_loss         | -1.42      |
|    ent_loss                 | -0.0709    |
|    ent_policy_gradient_loss | 0.00707    |
|    ent_std                  | 0.289      |
|    ent_value_loss           | 0.0117     |
|    entropy_loss             | -1.71      |
|    explained_variance       | 0.701      |
|    learning_rate            | 0.0003     |
|    loss                     | -0.0144    |
|    n_updates                | 1790       |
|    policy_gradient_loss     | 0.0663     |
|    std                      | 0.3        |
|    value_loss               | 0.0119     |
--------------------------------------------
Eval num_timesteps=370000, episode_reward=983.71 +/- 83.98
Episode length: 1000.00 +/- 0.00
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 1e+03      |
|    mean_reward              | 984        |
| time/                       |            |
|    total_timesteps          | 370000     |
| train/                      |            |
|    approx_kl                | 0.5223984  |
|    clip_fraction            | 0.781      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.17537948 |
|    ent_clip_fraction        | 0.493      |
|    ent_entropy_loss         | -1.37      |
|    ent_loss                 | -0.0256    |
|    ent_policy_gradient_loss | 0.00217    |
|    ent_std                  | 0.287      |
|    ent_value_loss           | 0.0105     |
|    entropy_loss             | -1.64      |
|    explained_variance       | 0.865      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.00502    |
|    n_updates                | 1800       |
|    policy_gradient_loss     | 0.075      |
|    std                      | 0.295      |
|    value_loss               | 0.0113     |
--------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 686      |
|    ep_rew_mean     | 377      |
| time/              |          |
|    fps             | 157      |
|    iterations      | 181      |
|    time_elapsed    | 2354     |
|    total_timesteps | 370688   |
---------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 686         |
|    ep_rew_mean              | 387         |
| time/                       |             |
|    fps                      | 157         |
|    iterations               | 182         |
|    time_elapsed             | 2364        |
|    total_timesteps          | 372736      |
| train/                      |             |
|    approx_kl                | 0.44470078  |
|    clip_fraction            | 0.799       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.091067955 |
|    ent_clip_fraction        | 0.43        |
|    ent_entropy_loss         | -1.33       |
|    ent_loss                 | -0.0619     |
|    ent_policy_gradient_loss | -0.0277     |
|    ent_std                  | 0.286       |
|    ent_value_loss           | 0.0107      |
|    entropy_loss             | -1.56       |
|    explained_variance       | 0.145       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0959      |
|    n_updates                | 1810        |
|    policy_gradient_loss     | 0.0902      |
|    std                      | 0.294       |
|    value_loss               | 0.0104      |
---------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 694        |
|    ep_rew_mean              | 398        |
| time/                       |            |
|    fps                      | 157        |
|    iterations               | 183        |
|    time_elapsed             | 2374       |
|    total_timesteps          | 374784     |
| train/                      |            |
|    approx_kl                | 0.4584432  |
|    clip_fraction            | 0.803      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.09646216 |
|    ent_clip_fraction        | 0.423      |
|    ent_entropy_loss         | -1.28      |
|    ent_loss                 | -0.0538    |
|    ent_policy_gradient_loss | -0.0368    |
|    ent_std                  | 0.284      |
|    ent_value_loss           | 0.0163     |
|    entropy_loss             | -1.54      |
|    explained_variance       | 0.418      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0687     |
|    n_updates                | 1820       |
|    policy_gradient_loss     | 0.107      |
|    std                      | 0.294      |
|    value_loss               | 0.0162     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 703        |
|    ep_rew_mean              | 412        |
| time/                       |            |
|    fps                      | 158        |
|    iterations               | 184        |
|    time_elapsed             | 2384       |
|    total_timesteps          | 376832     |
| train/                      |            |
|    approx_kl                | 0.3750562  |
|    clip_fraction            | 0.768      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.20181373 |
|    ent_clip_fraction        | 0.541      |
|    ent_entropy_loss         | -1.23      |
|    ent_loss                 | -0.0421    |
|    ent_policy_gradient_loss | -0.0139    |
|    ent_std                  | 0.282      |
|    ent_value_loss           | 0.0272     |
|    entropy_loss             | -1.52      |
|    explained_variance       | 0.123      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0475     |
|    n_updates                | 1830       |
|    policy_gradient_loss     | 0.0923     |
|    std                      | 0.292      |
|    value_loss               | 0.0294     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 703        |
|    ep_rew_mean              | 421        |
| time/                       |            |
|    fps                      | 158        |
|    iterations               | 185        |
|    time_elapsed             | 2395       |
|    total_timesteps          | 378880     |
| train/                      |            |
|    approx_kl                | 0.5462936  |
|    clip_fraction            | 0.762      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.22539064 |
|    ent_clip_fraction        | 0.591      |
|    ent_entropy_loss         | -1.22      |
|    ent_loss                 | -0.0515    |
|    ent_policy_gradient_loss | 0.0199     |
|    ent_std                  | 0.283      |
|    ent_value_loss           | 0.00986    |
|    entropy_loss             | -1.47      |
|    explained_variance       | 0.505      |
|    learning_rate            | 0.0003     |
|    loss                     | -0.0229    |
|    n_updates                | 1840       |
|    policy_gradient_loss     | 0.0533     |
|    std                      | 0.291      |
|    value_loss               | 0.0101     |
--------------------------------------------
Eval num_timesteps=380000, episode_reward=1100.04 +/- 127.53
Episode length: 1000.00 +/- 0.00
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 1e+03      |
|    mean_reward              | 1.1e+03    |
| time/                       |            |
|    total_timesteps          | 380000     |
| train/                      |            |
|    approx_kl                | 0.4159673  |
|    clip_fraction            | 0.747      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.20110576 |
|    ent_clip_fraction        | 0.565      |
|    ent_entropy_loss         | -1.23      |
|    ent_loss                 | 0.0058     |
|    ent_policy_gradient_loss | 0.0154     |
|    ent_std                  | 0.283      |
|    ent_value_loss           | 0.0188     |
|    entropy_loss             | -1.41      |
|    explained_variance       | 0.414      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0651     |
|    n_updates                | 1850       |
|    policy_gradient_loss     | 0.0644     |
|    std                      | 0.288      |
|    value_loss               | 0.0195     |
--------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 690      |
|    ep_rew_mean     | 428      |
| time/              |          |
|    fps             | 157      |
|    iterations      | 186      |
|    time_elapsed    | 2423     |
|    total_timesteps | 380928   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 686        |
|    ep_rew_mean              | 432        |
| time/                       |            |
|    fps                      | 157        |
|    iterations               | 187        |
|    time_elapsed             | 2433       |
|    total_timesteps          | 382976     |
| train/                      |            |
|    approx_kl                | 0.41621593 |
|    clip_fraction            | 0.772      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.13682419 |
|    ent_clip_fraction        | 0.488      |
|    ent_entropy_loss         | -1.23      |
|    ent_loss                 | -0.0195    |
|    ent_policy_gradient_loss | -0.0167    |
|    ent_std                  | 0.283      |
|    ent_value_loss           | 0.0251     |
|    entropy_loss             | -1.38      |
|    explained_variance       | 0.379      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0252     |
|    n_updates                | 1860       |
|    policy_gradient_loss     | 0.0746     |
|    std                      | 0.289      |
|    value_loss               | 0.025      |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 696        |
|    ep_rew_mean              | 441        |
| time/                       |            |
|    fps                      | 157        |
|    iterations               | 188        |
|    time_elapsed             | 2444       |
|    total_timesteps          | 385024     |
| train/                      |            |
|    approx_kl                | 0.45741314 |
|    clip_fraction            | 0.828      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.06241303 |
|    ent_clip_fraction        | 0.394      |
|    ent_entropy_loss         | -1.21      |
|    ent_loss                 | -0.0865    |
|    ent_policy_gradient_loss | -0.0403    |
|    ent_std                  | 0.281      |
|    ent_value_loss           | 0.0182     |
|    entropy_loss             | -1.4       |
|    explained_variance       | 0.715      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0522     |
|    n_updates                | 1870       |
|    policy_gradient_loss     | 0.12       |
|    std                      | 0.29       |
|    value_loss               | 0.0186     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 690        |
|    ep_rew_mean              | 442        |
| time/                       |            |
|    fps                      | 157        |
|    iterations               | 189        |
|    time_elapsed             | 2454       |
|    total_timesteps          | 387072     |
| train/                      |            |
|    approx_kl                | 0.67373693 |
|    clip_fraction            | 0.778      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.34034225 |
|    ent_clip_fraction        | 0.629      |
|    ent_entropy_loss         | -1.18      |
|    ent_loss                 | -0.0237    |
|    ent_policy_gradient_loss | 0.0341     |
|    ent_std                  | 0.281      |
|    ent_value_loss           | 0.00701    |
|    entropy_loss             | -1.4       |
|    explained_variance       | 0.843      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0387     |
|    n_updates                | 1880       |
|    policy_gradient_loss     | 0.0665     |
|    std                      | 0.289      |
|    value_loss               | 0.00726    |
--------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 698         |
|    ep_rew_mean              | 452         |
| time/                       |             |
|    fps                      | 157         |
|    iterations               | 190         |
|    time_elapsed             | 2464        |
|    total_timesteps          | 389120      |
| train/                      |             |
|    approx_kl                | 0.5988368   |
|    clip_fraction            | 0.841       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.082914494 |
|    ent_clip_fraction        | 0.402       |
|    ent_entropy_loss         | -1.16       |
|    ent_loss                 | -0.0666     |
|    ent_policy_gradient_loss | -0.0318     |
|    ent_std                  | 0.279       |
|    ent_value_loss           | 0.0166      |
|    entropy_loss             | -1.38       |
|    explained_variance       | 0.709       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0438      |
|    n_updates                | 1890        |
|    policy_gradient_loss     | 0.0704      |
|    std                      | 0.287       |
|    value_loss               | 0.0166      |
---------------------------------------------
Eval num_timesteps=390000, episode_reward=1199.03 +/- 123.55
Episode length: 1000.00 +/- 0.00
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 1e+03      |
|    mean_reward              | 1.2e+03    |
| time/                       |            |
|    total_timesteps          | 390000     |
| train/                      |            |
|    approx_kl                | 0.42873144 |
|    clip_fraction            | 0.782      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.17617926 |
|    ent_clip_fraction        | 0.506      |
|    ent_entropy_loss         | -1.13      |
|    ent_loss                 | -0.0878    |
|    ent_policy_gradient_loss | -0.0233    |
|    ent_std                  | 0.279      |
|    ent_value_loss           | 0.0131     |
|    entropy_loss             | -1.33      |
|    explained_variance       | 0.493      |
|    learning_rate            | 0.0003     |
|    loss                     | -0.013     |
|    n_updates                | 1900       |
|    policy_gradient_loss     | 0.0794     |
|    std                      | 0.286      |
|    value_loss               | 0.0127     |
--------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 694      |
|    ep_rew_mean     | 456      |
| time/              |          |
|    fps             | 156      |
|    iterations      | 191      |
|    time_elapsed    | 2492     |
|    total_timesteps | 391168   |
---------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 709         |
|    ep_rew_mean              | 468         |
| time/                       |             |
|    fps                      | 157         |
|    iterations               | 192         |
|    time_elapsed             | 2503        |
|    total_timesteps          | 393216      |
| train/                      |             |
|    approx_kl                | 0.53024006  |
|    clip_fraction            | 0.835       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.050194748 |
|    ent_clip_fraction        | 0.365       |
|    ent_entropy_loss         | -1.1        |
|    ent_loss                 | -0.0745     |
|    ent_policy_gradient_loss | -0.049      |
|    ent_std                  | 0.278       |
|    ent_value_loss           | 0.0234      |
|    entropy_loss             | -1.3        |
|    explained_variance       | 0.775       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.106       |
|    n_updates                | 1910        |
|    policy_gradient_loss     | 0.122       |
|    std                      | 0.285       |
|    value_loss               | 0.0236      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 730         |
|    ep_rew_mean              | 483         |
| time/                       |             |
|    fps                      | 157         |
|    iterations               | 193         |
|    time_elapsed             | 2513        |
|    total_timesteps          | 395264      |
| train/                      |             |
|    approx_kl                | 0.69571614  |
|    clip_fraction            | 0.853       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.052748486 |
|    ent_clip_fraction        | 0.363       |
|    ent_entropy_loss         | -1.05       |
|    ent_loss                 | -0.0399     |
|    ent_policy_gradient_loss | -0.0438     |
|    ent_std                  | 0.276       |
|    ent_value_loss           | 0.0331      |
|    entropy_loss             | -1.26       |
|    explained_variance       | 0.613       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0442      |
|    n_updates                | 1920        |
|    policy_gradient_loss     | 0.0884      |
|    std                      | 0.283       |
|    value_loss               | 0.0316      |
---------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 725       |
|    ep_rew_mean              | 490       |
| time/                       |           |
|    fps                      | 157       |
|    iterations               | 194       |
|    time_elapsed             | 2523      |
|    total_timesteps          | 397312    |
| train/                      |           |
|    approx_kl                | 0.6275882 |
|    clip_fraction            | 0.85      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.1319441 |
|    ent_clip_fraction        | 0.466     |
|    ent_entropy_loss         | -1        |
|    ent_loss                 | -0.0637   |
|    ent_policy_gradient_loss | -0.026    |
|    ent_std                  | 0.274     |
|    ent_value_loss           | 0.0144    |
|    entropy_loss             | -1.24     |
|    explained_variance       | 0.808     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0408    |
|    n_updates                | 1930      |
|    policy_gradient_loss     | 0.0907    |
|    std                      | 0.284     |
|    value_loss               | 0.0144    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 730        |
|    ep_rew_mean              | 501        |
| time/                       |            |
|    fps                      | 157        |
|    iterations               | 195        |
|    time_elapsed             | 2533       |
|    total_timesteps          | 399360     |
| train/                      |            |
|    approx_kl                | 0.6300421  |
|    clip_fraction            | 0.821      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.11775472 |
|    ent_clip_fraction        | 0.453      |
|    ent_entropy_loss         | -0.935     |
|    ent_loss                 | -0.0154    |
|    ent_policy_gradient_loss | -0.0244    |
|    ent_std                  | 0.271      |
|    ent_value_loss           | 0.0289     |
|    entropy_loss             | -1.22      |
|    explained_variance       | 0.67       |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0787     |
|    n_updates                | 1940       |
|    policy_gradient_loss     | 0.0746     |
|    std                      | 0.282      |
|    value_loss               | 0.0286     |
--------------------------------------------
Eval num_timesteps=400000, episode_reward=1176.95 +/- 124.18
Episode length: 1000.00 +/- 0.00
---------------------------------------------
| eval/                       |             |
|    mean_ep_length           | 1e+03       |
|    mean_reward              | 1.18e+03    |
| time/                       |             |
|    total_timesteps          | 400000      |
| train/                      |             |
|    approx_kl                | 0.5894462   |
|    clip_fraction            | 0.851       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.065143704 |
|    ent_clip_fraction        | 0.392       |
|    ent_entropy_loss         | -0.897      |
|    ent_loss                 | -0.018      |
|    ent_policy_gradient_loss | -0.0401     |
|    ent_std                  | 0.271       |
|    ent_value_loss           | 0.0261      |
|    entropy_loss             | -1.19       |
|    explained_variance       | 0.591       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0148      |
|    n_updates                | 1950        |
|    policy_gradient_loss     | 0.0834      |
|    std                      | 0.282       |
|    value_loss               | 0.0261      |
---------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 740      |
|    ep_rew_mean     | 509      |
| time/              |          |
|    fps             | 156      |
|    iterations      | 196      |
|    time_elapsed    | 2562     |
|    total_timesteps | 401408   |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 742       |
|    ep_rew_mean              | 514       |
| time/                       |           |
|    fps                      | 156       |
|    iterations               | 197       |
|    time_elapsed             | 2572      |
|    total_timesteps          | 403456    |
| train/                      |           |
|    approx_kl                | 0.5818992 |
|    clip_fraction            | 0.813     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.2164487 |
|    ent_clip_fraction        | 0.534     |
|    ent_entropy_loss         | -0.856    |
|    ent_loss                 | -0.0816   |
|    ent_policy_gradient_loss | -0.0285   |
|    ent_std                  | 0.269     |
|    ent_value_loss           | 0.00928   |
|    entropy_loss             | -1.15     |
|    explained_variance       | 0.841     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.15      |
|    n_updates                | 1960      |
|    policy_gradient_loss     | 0.0856    |
|    std                      | 0.28      |
|    value_loss               | 0.00957   |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 740        |
|    ep_rew_mean              | 521        |
| time/                       |            |
|    fps                      | 156        |
|    iterations               | 198        |
|    time_elapsed             | 2582       |
|    total_timesteps          | 405504     |
| train/                      |            |
|    approx_kl                | 0.53662866 |
|    clip_fraction            | 0.836      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.06264602 |
|    ent_clip_fraction        | 0.398      |
|    ent_entropy_loss         | -0.798     |
|    ent_loss                 | -0.047     |
|    ent_policy_gradient_loss | -0.0451    |
|    ent_std                  | 0.267      |
|    ent_value_loss           | 0.0373     |
|    entropy_loss             | -1.13      |
|    explained_variance       | 0.4        |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0896     |
|    n_updates                | 1970       |
|    policy_gradient_loss     | 0.0942     |
|    std                      | 0.279      |
|    value_loss               | 0.0384     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 732        |
|    ep_rew_mean              | 527        |
| time/                       |            |
|    fps                      | 157        |
|    iterations               | 199        |
|    time_elapsed             | 2592       |
|    total_timesteps          | 407552     |
| train/                      |            |
|    approx_kl                | 0.6180773  |
|    clip_fraction            | 0.86       |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.03863544 |
|    ent_clip_fraction        | 0.362      |
|    ent_entropy_loss         | -0.747     |
|    ent_loss                 | -0.0671    |
|    ent_policy_gradient_loss | -0.0494    |
|    ent_std                  | 0.266      |
|    ent_value_loss           | 0.0335     |
|    entropy_loss             | -1.12      |
|    explained_variance       | 0.425      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.109      |
|    n_updates                | 1980       |
|    policy_gradient_loss     | 0.131      |
|    std                      | 0.278      |
|    value_loss               | 0.0342     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 741        |
|    ep_rew_mean              | 538        |
| time/                       |            |
|    fps                      | 157        |
|    iterations               | 200        |
|    time_elapsed             | 2602       |
|    total_timesteps          | 409600     |
| train/                      |            |
|    approx_kl                | 0.46187574 |
|    clip_fraction            | 0.766      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.2632913  |
|    ent_clip_fraction        | 0.594      |
|    ent_entropy_loss         | -0.723     |
|    ent_loss                 | -0.0185    |
|    ent_policy_gradient_loss | 0.0151     |
|    ent_std                  | 0.265      |
|    ent_value_loss           | 0.0381     |
|    entropy_loss             | -1.08      |
|    explained_variance       | 0.432      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0798     |
|    n_updates                | 1990       |
|    policy_gradient_loss     | 0.0641     |
|    std                      | 0.277      |
|    value_loss               | 0.0377     |
--------------------------------------------
Eval num_timesteps=410000, episode_reward=1139.18 +/- 204.62
Episode length: 956.52 +/- 147.54
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 957        |
|    mean_reward              | 1.14e+03   |
| time/                       |            |
|    total_timesteps          | 410000     |
| train/                      |            |
|    approx_kl                | 0.86178404 |
|    clip_fraction            | 0.86       |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.10391174 |
|    ent_clip_fraction        | 0.434      |
|    ent_entropy_loss         | -0.68      |
|    ent_loss                 | -0.0376    |
|    ent_policy_gradient_loss | -0.0355    |
|    ent_std                  | 0.263      |
|    ent_value_loss           | 0.00876    |
|    entropy_loss             | -1.04      |
|    explained_variance       | 0.868      |
|    learning_rate            | 0.0003     |
|    loss                     | -0.000698  |
|    n_updates                | 2000       |
|    policy_gradient_loss     | 0.0971     |
|    std                      | 0.275      |
|    value_loss               | 0.00913    |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 728      |
|    ep_rew_mean     | 541      |
| time/              |          |
|    fps             | 156      |
|    iterations      | 201      |
|    time_elapsed    | 2630     |
|    total_timesteps | 411648   |
---------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 718         |
|    ep_rew_mean              | 545         |
| time/                       |             |
|    fps                      | 156         |
|    iterations               | 202         |
|    time_elapsed             | 2639        |
|    total_timesteps          | 413696      |
| train/                      |             |
|    approx_kl                | 0.61420333  |
|    clip_fraction            | 0.856       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.037891008 |
|    ent_clip_fraction        | 0.366       |
|    ent_entropy_loss         | -0.631      |
|    ent_loss                 | -0.0422     |
|    ent_policy_gradient_loss | -0.051      |
|    ent_std                  | 0.262       |
|    ent_value_loss           | 0.0431      |
|    entropy_loss             | -0.984      |
|    explained_variance       | 0.502       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.00532     |
|    n_updates                | 2010        |
|    policy_gradient_loss     | 0.115       |
|    std                      | 0.273       |
|    value_loss               | 0.0428      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 718         |
|    ep_rew_mean              | 557         |
| time/                       |             |
|    fps                      | 156         |
|    iterations               | 203         |
|    time_elapsed             | 2650        |
|    total_timesteps          | 415744      |
| train/                      |             |
|    approx_kl                | 0.55373985  |
|    clip_fraction            | 0.848       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.050050084 |
|    ent_clip_fraction        | 0.375       |
|    ent_entropy_loss         | -0.594      |
|    ent_loss                 | -0.0501     |
|    ent_policy_gradient_loss | -0.0394     |
|    ent_std                  | 0.26        |
|    ent_value_loss           | 0.0484      |
|    entropy_loss             | -0.941      |
|    explained_variance       | 0.434       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0347      |
|    n_updates                | 2020        |
|    policy_gradient_loss     | 0.0946      |
|    std                      | 0.271       |
|    value_loss               | 0.0481      |
---------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 716        |
|    ep_rew_mean              | 567        |
| time/                       |            |
|    fps                      | 157        |
|    iterations               | 204        |
|    time_elapsed             | 2659       |
|    total_timesteps          | 417792     |
| train/                      |            |
|    approx_kl                | 0.40958688 |
|    clip_fraction            | 0.729      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.28976637 |
|    ent_clip_fraction        | 0.607      |
|    ent_entropy_loss         | -0.542     |
|    ent_loss                 | -0.0364    |
|    ent_policy_gradient_loss | -0.00725   |
|    ent_std                  | 0.259      |
|    ent_value_loss           | 0.00943    |
|    entropy_loss             | -0.884     |
|    explained_variance       | 0.321      |
|    learning_rate            | 0.0003     |
|    loss                     | 1.82e-05   |
|    n_updates                | 2030       |
|    policy_gradient_loss     | 0.0767     |
|    std                      | 0.271      |
|    value_loss               | 0.00982    |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 674        |
|    ep_rew_mean              | 547        |
| time/                       |            |
|    fps                      | 157        |
|    iterations               | 205        |
|    time_elapsed             | 2669       |
|    total_timesteps          | 419840     |
| train/                      |            |
|    approx_kl                | 0.6333287  |
|    clip_fraction            | 0.824      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.16203672 |
|    ent_clip_fraction        | 0.514      |
|    ent_entropy_loss         | -0.522     |
|    ent_loss                 | -0.0565    |
|    ent_policy_gradient_loss | -0.0157    |
|    ent_std                  | 0.259      |
|    ent_value_loss           | 0.0196     |
|    entropy_loss             | -0.89      |
|    explained_variance       | 0.846      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.125      |
|    n_updates                | 2040       |
|    policy_gradient_loss     | 0.0821     |
|    std                      | 0.271      |
|    value_loss               | 0.02       |
--------------------------------------------
Eval num_timesteps=420000, episode_reward=1286.21 +/- 287.21
Episode length: 933.12 +/- 199.59
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 933        |
|    mean_reward              | 1.29e+03   |
| time/                       |            |
|    total_timesteps          | 420000     |
| train/                      |            |
|    approx_kl                | 0.6495708  |
|    clip_fraction            | 0.862      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.04047772 |
|    ent_clip_fraction        | 0.392      |
|    ent_entropy_loss         | -0.492     |
|    ent_loss                 | -0.0175    |
|    ent_policy_gradient_loss | -0.0492    |
|    ent_std                  | 0.257      |
|    ent_value_loss           | 0.0641     |
|    entropy_loss             | -0.875     |
|    explained_variance       | 0.395      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.108      |
|    n_updates                | 2050       |
|    policy_gradient_loss     | 0.103      |
|    std                      | 0.27       |
|    value_loss               | 0.0635     |
--------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 667      |
|    ep_rew_mean     | 553      |
| time/              |          |
|    fps             | 156      |
|    iterations      | 206      |
|    time_elapsed    | 2697     |
|    total_timesteps | 421888   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 662        |
|    ep_rew_mean              | 557        |
| time/                       |            |
|    fps                      | 156        |
|    iterations               | 207        |
|    time_elapsed             | 2707       |
|    total_timesteps          | 423936     |
| train/                      |            |
|    approx_kl                | 0.526404   |
|    clip_fraction            | 0.818      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.17760527 |
|    ent_clip_fraction        | 0.525      |
|    ent_entropy_loss         | -0.473     |
|    ent_loss                 | -0.0258    |
|    ent_policy_gradient_loss | -0.00271   |
|    ent_std                  | 0.258      |
|    ent_value_loss           | 0.0331     |
|    entropy_loss             | -0.838     |
|    explained_variance       | 0.474      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0917     |
|    n_updates                | 2060       |
|    policy_gradient_loss     | 0.0849     |
|    std                      | 0.269      |
|    value_loss               | 0.0324     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 651        |
|    ep_rew_mean              | 552        |
| time/                       |            |
|    fps                      | 156        |
|    iterations               | 208        |
|    time_elapsed             | 2717       |
|    total_timesteps          | 425984     |
| train/                      |            |
|    approx_kl                | 0.62711513 |
|    clip_fraction            | 0.837      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.15200321 |
|    ent_clip_fraction        | 0.478      |
|    ent_entropy_loss         | -0.449     |
|    ent_loss                 | -0.0558    |
|    ent_policy_gradient_loss | -0.0255    |
|    ent_std                  | 0.256      |
|    ent_value_loss           | 0.0243     |
|    entropy_loss             | -0.803     |
|    explained_variance       | 0.785      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0484     |
|    n_updates                | 2070       |
|    policy_gradient_loss     | 0.135      |
|    std                      | 0.267      |
|    value_loss               | 0.0258     |
--------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 647         |
|    ep_rew_mean              | 559         |
| time/                       |             |
|    fps                      | 156         |
|    iterations               | 209         |
|    time_elapsed             | 2726        |
|    total_timesteps          | 428032      |
| train/                      |             |
|    approx_kl                | 0.59677154  |
|    clip_fraction            | 0.85        |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.075450785 |
|    ent_clip_fraction        | 0.408       |
|    ent_entropy_loss         | -0.381      |
|    ent_loss                 | -0.0721     |
|    ent_policy_gradient_loss | -0.0437     |
|    ent_std                  | 0.253       |
|    ent_value_loss           | 0.0257      |
|    entropy_loss             | -0.75       |
|    explained_variance       | 0.822       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0794      |
|    n_updates                | 2080        |
|    policy_gradient_loss     | 0.109       |
|    std                      | 0.265       |
|    value_loss               | 0.0253      |
---------------------------------------------
Eval num_timesteps=430000, episode_reward=1438.82 +/- 273.78
Episode length: 965.04 +/- 171.27
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 965        |
|    mean_reward              | 1.44e+03   |
| time/                       |            |
|    total_timesteps          | 430000     |
| train/                      |            |
|    approx_kl                | 0.59318984 |
|    clip_fraction            | 0.804      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.19888598 |
|    ent_clip_fraction        | 0.518      |
|    ent_entropy_loss         | -0.327     |
|    ent_loss                 | -0.0242    |
|    ent_policy_gradient_loss | -0.0232    |
|    ent_std                  | 0.252      |
|    ent_value_loss           | 0.0406     |
|    entropy_loss             | -0.703     |
|    explained_variance       | 0.0474     |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0961     |
|    n_updates                | 2090       |
|    policy_gradient_loss     | 0.0698     |
|    std                      | 0.264      |
|    value_loss               | 0.0401     |
--------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 640      |
|    ep_rew_mean     | 568      |
| time/              |          |
|    fps             | 156      |
|    iterations      | 210      |
|    time_elapsed    | 2754     |
|    total_timesteps | 430080   |
---------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 624         |
|    ep_rew_mean              | 567         |
| time/                       |             |
|    fps                      | 156         |
|    iterations               | 211         |
|    time_elapsed             | 2764        |
|    total_timesteps          | 432128      |
| train/                      |             |
|    approx_kl                | 0.61682665  |
|    clip_fraction            | 0.865       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.039784756 |
|    ent_clip_fraction        | 0.389       |
|    ent_entropy_loss         | -0.296      |
|    ent_loss                 | -0.0633     |
|    ent_policy_gradient_loss | -0.0482     |
|    ent_std                  | 0.251       |
|    ent_value_loss           | 0.0523      |
|    entropy_loss             | -0.657      |
|    explained_variance       | 0.202       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0836      |
|    n_updates                | 2100        |
|    policy_gradient_loss     | 0.0977      |
|    std                      | 0.262       |
|    value_loss               | 0.0488      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 619         |
|    ep_rew_mean              | 565         |
| time/                       |             |
|    fps                      | 156         |
|    iterations               | 212         |
|    time_elapsed             | 2774        |
|    total_timesteps          | 434176      |
| train/                      |             |
|    approx_kl                | 0.6546262   |
|    clip_fraction            | 0.859       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.047956318 |
|    ent_clip_fraction        | 0.395       |
|    ent_entropy_loss         | -0.253      |
|    ent_loss                 | -0.0406     |
|    ent_policy_gradient_loss | -0.0433     |
|    ent_std                  | 0.25        |
|    ent_value_loss           | 0.0435      |
|    entropy_loss             | -0.607      |
|    explained_variance       | 0.289       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0693      |
|    n_updates                | 2110        |
|    policy_gradient_loss     | 0.103       |
|    std                      | 0.26        |
|    value_loss               | 0.0428      |
---------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 621        |
|    ep_rew_mean              | 568        |
| time/                       |            |
|    fps                      | 156        |
|    iterations               | 213        |
|    time_elapsed             | 2784       |
|    total_timesteps          | 436224     |
| train/                      |            |
|    approx_kl                | 0.33168685 |
|    clip_fraction            | 0.67       |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.48609263 |
|    ent_clip_fraction        | 0.691      |
|    ent_entropy_loss         | -0.195     |
|    ent_loss                 | -0.0164    |
|    ent_policy_gradient_loss | 0.0173     |
|    ent_std                  | 0.247      |
|    ent_value_loss           | 0.0183     |
|    entropy_loss             | -0.551     |
|    explained_variance       | 0.859      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.145      |
|    n_updates                | 2120       |
|    policy_gradient_loss     | 0.0807     |
|    std                      | 0.259      |
|    value_loss               | 0.0182     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 611        |
|    ep_rew_mean              | 561        |
| time/                       |            |
|    fps                      | 156        |
|    iterations               | 214        |
|    time_elapsed             | 2795       |
|    total_timesteps          | 438272     |
| train/                      |            |
|    approx_kl                | 0.9460094  |
|    clip_fraction            | 0.863      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.07882583 |
|    ent_clip_fraction        | 0.414      |
|    ent_entropy_loss         | -0.173     |
|    ent_loss                 | -0.0411    |
|    ent_policy_gradient_loss | -0.0351    |
|    ent_std                  | 0.248      |
|    ent_value_loss           | 0.0286     |
|    entropy_loss             | -0.535     |
|    explained_variance       | 0.728      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0651     |
|    n_updates                | 2130       |
|    policy_gradient_loss     | 0.0694     |
|    std                      | 0.259      |
|    value_loss               | 0.0282     |
--------------------------------------------
Eval num_timesteps=440000, episode_reward=1052.02 +/- 134.58
Episode length: 1000.00 +/- 0.00
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 1e+03      |
|    mean_reward              | 1.05e+03   |
| time/                       |            |
|    total_timesteps          | 440000     |
| train/                      |            |
|    approx_kl                | 0.63172925 |
|    clip_fraction            | 0.834      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.13126855 |
|    ent_clip_fraction        | 0.486      |
|    ent_entropy_loss         | -0.147     |
|    ent_loss                 | -0.0626    |
|    ent_policy_gradient_loss | -0.033     |
|    ent_std                  | 0.247      |
|    ent_value_loss           | 0.0407     |
|    entropy_loss             | -0.522     |
|    explained_variance       | 0.656      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0732     |
|    n_updates                | 2140       |
|    policy_gradient_loss     | 0.0857     |
|    std                      | 0.258      |
|    value_loss               | 0.0396     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 611      |
|    ep_rew_mean     | 560      |
| time/              |          |
|    fps             | 155      |
|    iterations      | 215      |
|    time_elapsed    | 2823     |
|    total_timesteps | 440320   |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 611       |
|    ep_rew_mean              | 566       |
| time/                       |           |
|    fps                      | 156       |
|    iterations               | 216       |
|    time_elapsed             | 2833      |
|    total_timesteps          | 442368    |
| train/                      |           |
|    approx_kl                | 0.6429918 |
|    clip_fraction            | 0.823     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.1680693 |
|    ent_clip_fraction        | 0.486     |
|    ent_entropy_loss         | -0.124    |
|    ent_loss                 | -0.0225   |
|    ent_policy_gradient_loss | -0.0205   |
|    ent_std                  | 0.246     |
|    ent_value_loss           | 0.0217    |
|    entropy_loss             | -0.512    |
|    explained_variance       | 0.871     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0497    |
|    n_updates                | 2150      |
|    policy_gradient_loss     | 0.0633    |
|    std                      | 0.258     |
|    value_loss               | 0.0225    |
-------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 594         |
|    ep_rew_mean              | 563         |
| time/                       |             |
|    fps                      | 156         |
|    iterations               | 217         |
|    time_elapsed             | 2843        |
|    total_timesteps          | 444416      |
| train/                      |             |
|    approx_kl                | 0.7559805   |
|    clip_fraction            | 0.864       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.058827467 |
|    ent_clip_fraction        | 0.379       |
|    ent_entropy_loss         | -0.0934     |
|    ent_loss                 | -0.0753     |
|    ent_policy_gradient_loss | -0.0397     |
|    ent_std                  | 0.245       |
|    ent_value_loss           | 0.028       |
|    entropy_loss             | -0.504      |
|    explained_variance       | 0.28        |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0821      |
|    n_updates                | 2160        |
|    policy_gradient_loss     | 0.161       |
|    std                      | 0.258       |
|    value_loss               | 0.0297      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 603         |
|    ep_rew_mean              | 582         |
| time/                       |             |
|    fps                      | 156         |
|    iterations               | 218         |
|    time_elapsed             | 2853        |
|    total_timesteps          | 446464      |
| train/                      |             |
|    approx_kl                | 0.6266558   |
|    clip_fraction            | 0.858       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.080856755 |
|    ent_clip_fraction        | 0.417       |
|    ent_entropy_loss         | -0.0482     |
|    ent_loss                 | -0.051      |
|    ent_policy_gradient_loss | -0.0421     |
|    ent_std                  | 0.243       |
|    ent_value_loss           | 0.0466      |
|    entropy_loss             | -0.45       |
|    explained_variance       | 0.285       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0829      |
|    n_updates                | 2170        |
|    policy_gradient_loss     | 0.101       |
|    std                      | 0.255       |
|    value_loss               | 0.0463      |
---------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 596        |
|    ep_rew_mean              | 584        |
| time/                       |            |
|    fps                      | 156        |
|    iterations               | 219        |
|    time_elapsed             | 2863       |
|    total_timesteps          | 448512     |
| train/                      |            |
|    approx_kl                | 0.74472666 |
|    clip_fraction            | 0.841      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.1598449  |
|    ent_clip_fraction        | 0.52       |
|    ent_entropy_loss         | -0.0156    |
|    ent_loss                 | 0.0677     |
|    ent_policy_gradient_loss | -0.00435   |
|    ent_std                  | 0.243      |
|    ent_value_loss           | 0.0114     |
|    entropy_loss             | -0.404     |
|    explained_variance       | 0.924      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.067      |
|    n_updates                | 2180       |
|    policy_gradient_loss     | 0.08       |
|    std                      | 0.255      |
|    value_loss               | 0.0122     |
--------------------------------------------
Eval num_timesteps=450000, episode_reward=1502.39 +/- 147.03
Episode length: 975.00 +/- 94.19
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 975       |
|    mean_reward              | 1.5e+03   |
| time/                       |           |
|    total_timesteps          | 450000    |
| train/                      |           |
|    approx_kl                | 0.6300044 |
|    clip_fraction            | 0.84      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.1550238 |
|    ent_clip_fraction        | 0.473     |
|    ent_entropy_loss         | 0.0129    |
|    ent_loss                 | -0.000428 |
|    ent_policy_gradient_loss | -0.0189   |
|    ent_std                  | 0.241     |
|    ent_value_loss           | 0.0286    |
|    entropy_loss             | -0.395    |
|    explained_variance       | 0.598     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0481    |
|    n_updates                | 2190      |
|    policy_gradient_loss     | 0.0886    |
|    std                      | 0.254     |
|    value_loss               | 0.0285    |
-------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 602      |
|    ep_rew_mean     | 596      |
| time/              |          |
|    fps             | 155      |
|    iterations      | 220      |
|    time_elapsed    | 2891     |
|    total_timesteps | 450560   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 610        |
|    ep_rew_mean              | 612        |
| time/                       |            |
|    fps                      | 155        |
|    iterations               | 221        |
|    time_elapsed             | 2902       |
|    total_timesteps          | 452608     |
| train/                      |            |
|    approx_kl                | 0.7210157  |
|    clip_fraction            | 0.84       |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.15137438 |
|    ent_clip_fraction        | 0.498      |
|    ent_entropy_loss         | 0.0545     |
|    ent_loss                 | -0.0312    |
|    ent_policy_gradient_loss | -0.0176    |
|    ent_std                  | 0.24       |
|    ent_value_loss           | 0.0257     |
|    entropy_loss             | -0.376     |
|    explained_variance       | 0.412      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.00222    |
|    n_updates                | 2200       |
|    policy_gradient_loss     | 0.109      |
|    std                      | 0.253      |
|    value_loss               | 0.025      |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 610        |
|    ep_rew_mean              | 616        |
| time/                       |            |
|    fps                      | 156        |
|    iterations               | 222        |
|    time_elapsed             | 2912       |
|    total_timesteps          | 454656     |
| train/                      |            |
|    approx_kl                | 0.66150683 |
|    clip_fraction            | 0.831      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.17275006 |
|    ent_clip_fraction        | 0.522      |
|    ent_entropy_loss         | 0.0896     |
|    ent_loss                 | -0.0627    |
|    ent_policy_gradient_loss | -0.0308    |
|    ent_std                  | 0.239      |
|    ent_value_loss           | 0.0278     |
|    entropy_loss             | -0.351     |
|    explained_variance       | 0.563      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0402     |
|    n_updates                | 2210       |
|    policy_gradient_loss     | 0.0979     |
|    std                      | 0.252      |
|    value_loss               | 0.0274     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 615        |
|    ep_rew_mean              | 624        |
| time/                       |            |
|    fps                      | 156        |
|    iterations               | 223        |
|    time_elapsed             | 2922       |
|    total_timesteps          | 456704     |
| train/                      |            |
|    approx_kl                | 0.8578     |
|    clip_fraction            | 0.83       |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.24896239 |
|    ent_clip_fraction        | 0.539      |
|    ent_entropy_loss         | 0.13       |
|    ent_loss                 | -0.0233    |
|    ent_policy_gradient_loss | 0.0255     |
|    ent_std                  | 0.238      |
|    ent_value_loss           | 0.00921    |
|    entropy_loss             | -0.308     |
|    explained_variance       | 0.93       |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0149     |
|    n_updates                | 2220       |
|    policy_gradient_loss     | 0.119      |
|    std                      | 0.251      |
|    value_loss               | 0.00959    |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 610        |
|    ep_rew_mean              | 627        |
| time/                       |            |
|    fps                      | 156        |
|    iterations               | 224        |
|    time_elapsed             | 2932       |
|    total_timesteps          | 458752     |
| train/                      |            |
|    approx_kl                | 0.94518065 |
|    clip_fraction            | 0.891      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.07378782 |
|    ent_clip_fraction        | 0.427      |
|    ent_entropy_loss         | 0.195      |
|    ent_loss                 | -0.086     |
|    ent_policy_gradient_loss | -0.0494    |
|    ent_std                  | 0.236      |
|    ent_value_loss           | 0.0152     |
|    entropy_loss             | -0.285     |
|    explained_variance       | 0.907      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0495     |
|    n_updates                | 2230       |
|    policy_gradient_loss     | 0.148      |
|    std                      | 0.25       |
|    value_loss               | 0.0147     |
--------------------------------------------
Eval num_timesteps=460000, episode_reward=1392.85 +/- 296.63
Episode length: 961.16 +/- 190.28
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 961        |
|    mean_reward              | 1.39e+03   |
| time/                       |            |
|    total_timesteps          | 460000     |
| train/                      |            |
|    approx_kl                | 0.8227363  |
|    clip_fraction            | 0.88       |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.08909419 |
|    ent_clip_fraction        | 0.416      |
|    ent_entropy_loss         | 0.237      |
|    ent_loss                 | -0.0447    |
|    ent_policy_gradient_loss | -0.0358    |
|    ent_std                  | 0.235      |
|    ent_value_loss           | 0.0404     |
|    entropy_loss             | -0.222     |
|    explained_variance       | 0.804      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0343     |
|    n_updates                | 2240       |
|    policy_gradient_loss     | 0.107      |
|    std                      | 0.248      |
|    value_loss               | 0.0408     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 618      |
|    ep_rew_mean     | 640      |
| time/              |          |
|    fps             | 155      |
|    iterations      | 225      |
|    time_elapsed    | 2960     |
|    total_timesteps | 460800   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 611        |
|    ep_rew_mean              | 637        |
| time/                       |            |
|    fps                      | 155        |
|    iterations               | 226        |
|    time_elapsed             | 2971       |
|    total_timesteps          | 462848     |
| train/                      |            |
|    approx_kl                | 0.5815312  |
|    clip_fraction            | 0.781      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.32544526 |
|    ent_clip_fraction        | 0.602      |
|    ent_entropy_loss         | 0.239      |
|    ent_loss                 | -0.0375    |
|    ent_policy_gradient_loss | 0.0388     |
|    ent_std                  | 0.236      |
|    ent_value_loss           | 0.0126     |
|    entropy_loss             | -0.2       |
|    explained_variance       | -0.061     |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0687     |
|    n_updates                | 2250       |
|    policy_gradient_loss     | 0.117      |
|    std                      | 0.249      |
|    value_loss               | 0.014      |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 619        |
|    ep_rew_mean              | 647        |
| time/                       |            |
|    fps                      | 155        |
|    iterations               | 227        |
|    time_elapsed             | 2981       |
|    total_timesteps          | 464896     |
| train/                      |            |
|    approx_kl                | 0.6427026  |
|    clip_fraction            | 0.851      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.15070553 |
|    ent_clip_fraction        | 0.485      |
|    ent_entropy_loss         | 0.237      |
|    ent_loss                 | -0.0165    |
|    ent_policy_gradient_loss | -0.0184    |
|    ent_std                  | 0.235      |
|    ent_value_loss           | 0.0359     |
|    entropy_loss             | -0.168     |
|    explained_variance       | 0.91       |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0449     |
|    n_updates                | 2260       |
|    policy_gradient_loss     | 0.0995     |
|    std                      | 0.246      |
|    value_loss               | 0.0366     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 622        |
|    ep_rew_mean              | 649        |
| time/                       |            |
|    fps                      | 156        |
|    iterations               | 228        |
|    time_elapsed             | 2991       |
|    total_timesteps          | 466944     |
| train/                      |            |
|    approx_kl                | 0.8283503  |
|    clip_fraction            | 0.888      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.04918339 |
|    ent_clip_fraction        | 0.393      |
|    ent_entropy_loss         | 0.277      |
|    ent_loss                 | -0.054     |
|    ent_policy_gradient_loss | -0.0459    |
|    ent_std                  | 0.234      |
|    ent_value_loss           | 0.0259     |
|    entropy_loss             | -0.112     |
|    explained_variance       | 0.879      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.148      |
|    n_updates                | 2270       |
|    policy_gradient_loss     | 0.123      |
|    std                      | 0.246      |
|    value_loss               | 0.0268     |
--------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 630         |
|    ep_rew_mean              | 655         |
| time/                       |             |
|    fps                      | 156         |
|    iterations               | 229         |
|    time_elapsed             | 3001        |
|    total_timesteps          | 468992      |
| train/                      |             |
|    approx_kl                | 0.7615539   |
|    clip_fraction            | 0.87        |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.108855665 |
|    ent_clip_fraction        | 0.452       |
|    ent_entropy_loss         | 0.291       |
|    ent_loss                 | -0.0507     |
|    ent_policy_gradient_loss | -0.0163     |
|    ent_std                  | 0.234       |
|    ent_value_loss           | 0.0122      |
|    entropy_loss             | -0.134      |
|    explained_variance       | 0.938       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.119       |
|    n_updates                | 2280        |
|    policy_gradient_loss     | 0.0861      |
|    std                      | 0.247       |
|    value_loss               | 0.0122      |
---------------------------------------------
Eval num_timesteps=470000, episode_reward=1428.82 +/- 124.07
Episode length: 990.60 +/- 46.05
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 991        |
|    mean_reward              | 1.43e+03   |
| time/                       |            |
|    total_timesteps          | 470000     |
| train/                      |            |
|    approx_kl                | 0.7377911  |
|    clip_fraction            | 0.832      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.28627032 |
|    ent_clip_fraction        | 0.528      |
|    ent_entropy_loss         | 0.277      |
|    ent_loss                 | -0.0181    |
|    ent_policy_gradient_loss | -0.0205    |
|    ent_std                  | 0.235      |
|    ent_value_loss           | 0.025      |
|    entropy_loss             | -0.128     |
|    explained_variance       | 0.9        |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0377     |
|    n_updates                | 2290       |
|    policy_gradient_loss     | 0.0824     |
|    std                      | 0.246      |
|    value_loss               | 0.0258     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 636      |
|    ep_rew_mean     | 658      |
| time/              |          |
|    fps             | 155      |
|    iterations      | 230      |
|    time_elapsed    | 3029     |
|    total_timesteps | 471040   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 635        |
|    ep_rew_mean              | 668        |
| time/                       |            |
|    fps                      | 155        |
|    iterations               | 231        |
|    time_elapsed             | 3039       |
|    total_timesteps          | 473088     |
| train/                      |            |
|    approx_kl                | 0.86386085 |
|    clip_fraction            | 0.866      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.10152696 |
|    ent_clip_fraction        | 0.444      |
|    ent_entropy_loss         | 0.279      |
|    ent_loss                 | -0.0679    |
|    ent_policy_gradient_loss | -0.0464    |
|    ent_std                  | 0.234      |
|    ent_value_loss           | 0.0229     |
|    entropy_loss             | -0.127     |
|    explained_variance       | 0.877      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0856     |
|    n_updates                | 2300       |
|    policy_gradient_loss     | 0.125      |
|    std                      | 0.246      |
|    value_loss               | 0.0228     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 649       |
|    ep_rew_mean              | 689       |
| time/                       |           |
|    fps                      | 155       |
|    iterations               | 232       |
|    time_elapsed             | 3049      |
|    total_timesteps          | 475136    |
| train/                      |           |
|    approx_kl                | 0.6779489 |
|    clip_fraction            | 0.808     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.4708636 |
|    ent_clip_fraction        | 0.602     |
|    ent_entropy_loss         | 0.316     |
|    ent_loss                 | 0.00375   |
|    ent_policy_gradient_loss | 0.0272    |
|    ent_std                  | 0.233     |
|    ent_value_loss           | 0.0203    |
|    entropy_loss             | -0.0966   |
|    explained_variance       | 0.257     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0362    |
|    n_updates                | 2310      |
|    policy_gradient_loss     | 0.113     |
|    std                      | 0.245     |
|    value_loss               | 0.0206    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 602        |
|    ep_rew_mean              | 648        |
| time/                       |            |
|    fps                      | 155        |
|    iterations               | 233        |
|    time_elapsed             | 3059       |
|    total_timesteps          | 477184     |
| train/                      |            |
|    approx_kl                | 0.53421676 |
|    clip_fraction            | 0.744      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.4272257  |
|    ent_clip_fraction        | 0.682      |
|    ent_entropy_loss         | 0.296      |
|    ent_loss                 | -0.062     |
|    ent_policy_gradient_loss | 0.0494     |
|    ent_std                  | 0.234      |
|    ent_value_loss           | 0.0255     |
|    entropy_loss             | -0.0594    |
|    explained_variance       | 0.297      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.134      |
|    n_updates                | 2320       |
|    policy_gradient_loss     | 0.0742     |
|    std                      | 0.244      |
|    value_loss               | 0.027      |
--------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 609         |
|    ep_rew_mean              | 663         |
| time/                       |             |
|    fps                      | 156         |
|    iterations               | 234         |
|    time_elapsed             | 3069        |
|    total_timesteps          | 479232      |
| train/                      |             |
|    approx_kl                | 0.8092607   |
|    clip_fraction            | 0.884       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.044051893 |
|    ent_clip_fraction        | 0.397       |
|    ent_entropy_loss         | 0.29        |
|    ent_loss                 | -0.0297     |
|    ent_policy_gradient_loss | -0.0493     |
|    ent_std                  | 0.234       |
|    ent_value_loss           | 0.111       |
|    entropy_loss             | -0.0786     |
|    explained_variance       | 0.303       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0949      |
|    n_updates                | 2330        |
|    policy_gradient_loss     | 0.12        |
|    std                      | 0.245       |
|    value_loss               | 0.11        |
---------------------------------------------
Eval num_timesteps=480000, episode_reward=1123.79 +/- 178.88
Episode length: 1000.00 +/- 0.00
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 1e+03      |
|    mean_reward              | 1.12e+03   |
| time/                       |            |
|    total_timesteps          | 480000     |
| train/                      |            |
|    approx_kl                | 1.009316   |
|    clip_fraction            | 0.888      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.07589888 |
|    ent_clip_fraction        | 0.444      |
|    ent_entropy_loss         | 0.342      |
|    ent_loss                 | -0.077     |
|    ent_policy_gradient_loss | -0.0506    |
|    ent_std                  | 0.232      |
|    ent_value_loss           | 0.0401     |
|    entropy_loss             | -0.045     |
|    explained_variance       | 0.564      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.101      |
|    n_updates                | 2340       |
|    policy_gradient_loss     | 0.187      |
|    std                      | 0.243      |
|    value_loss               | 0.0396     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 622      |
|    ep_rew_mean     | 675      |
| time/              |          |
|    fps             | 155      |
|    iterations      | 235      |
|    time_elapsed    | 3097     |
|    total_timesteps | 481280   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 631        |
|    ep_rew_mean              | 688        |
| time/                       |            |
|    fps                      | 155        |
|    iterations               | 236        |
|    time_elapsed             | 3107       |
|    total_timesteps          | 483328     |
| train/                      |            |
|    approx_kl                | 0.86399376 |
|    clip_fraction            | 0.855      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.24388784 |
|    ent_clip_fraction        | 0.519      |
|    ent_entropy_loss         | 0.373      |
|    ent_loss                 | -0.0891    |
|    ent_policy_gradient_loss | 0.0314     |
|    ent_std                  | 0.231      |
|    ent_value_loss           | 0.0177     |
|    entropy_loss             | -0.0275    |
|    explained_variance       | 0.914      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0572     |
|    n_updates                | 2350       |
|    policy_gradient_loss     | 0.124      |
|    std                      | 0.244      |
|    value_loss               | 0.0182     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 613        |
|    ep_rew_mean              | 675        |
| time/                       |            |
|    fps                      | 155        |
|    iterations               | 237        |
|    time_elapsed             | 3117       |
|    total_timesteps          | 485376     |
| train/                      |            |
|    approx_kl                | 1.0689662  |
|    clip_fraction            | 0.864      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.21618816 |
|    ent_clip_fraction        | 0.489      |
|    ent_entropy_loss         | 0.393      |
|    ent_loss                 | -0.0572    |
|    ent_policy_gradient_loss | -0.0124    |
|    ent_std                  | 0.231      |
|    ent_value_loss           | 0.0244     |
|    entropy_loss             | -0.0756    |
|    explained_variance       | 0.841      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0977     |
|    n_updates                | 2360       |
|    policy_gradient_loss     | 0.124      |
|    std                      | 0.245      |
|    value_loss               | 0.025      |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 617        |
|    ep_rew_mean              | 686        |
| time/                       |            |
|    fps                      | 155        |
|    iterations               | 238        |
|    time_elapsed             | 3128       |
|    total_timesteps          | 487424     |
| train/                      |            |
|    approx_kl                | 0.8941765  |
|    clip_fraction            | 0.889      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.04535662 |
|    ent_clip_fraction        | 0.419      |
|    ent_entropy_loss         | 0.414      |
|    ent_loss                 | -0.0597    |
|    ent_policy_gradient_loss | -0.0459    |
|    ent_std                  | 0.23       |
|    ent_value_loss           | 0.0587     |
|    entropy_loss             | -0.102     |
|    explained_variance       | 0.302      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0863     |
|    n_updates                | 2370       |
|    policy_gradient_loss     | 0.13       |
|    std                      | 0.246      |
|    value_loss               | 0.0595     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 629        |
|    ep_rew_mean              | 703        |
| time/                       |            |
|    fps                      | 155        |
|    iterations               | 239        |
|    time_elapsed             | 3138       |
|    total_timesteps          | 489472     |
| train/                      |            |
|    approx_kl                | 0.79683256 |
|    clip_fraction            | 0.846      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.33787265 |
|    ent_clip_fraction        | 0.577      |
|    ent_entropy_loss         | 0.451      |
|    ent_loss                 | -0.0503    |
|    ent_policy_gradient_loss | -0.00496   |
|    ent_std                  | 0.229      |
|    ent_value_loss           | 0.0254     |
|    entropy_loss             | -0.0991    |
|    explained_variance       | 0.874      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.164      |
|    n_updates                | 2380       |
|    policy_gradient_loss     | 0.108      |
|    std                      | 0.245      |
|    value_loss               | 0.0251     |
--------------------------------------------
Eval num_timesteps=490000, episode_reward=1540.76 +/- 293.07
Episode length: 934.88 +/- 174.54
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 935        |
|    mean_reward              | 1.54e+03   |
| time/                       |            |
|    total_timesteps          | 490000     |
| train/                      |            |
|    approx_kl                | 0.63804483 |
|    clip_fraction            | 0.8        |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.37917006 |
|    ent_clip_fraction        | 0.645      |
|    ent_entropy_loss         | 0.483      |
|    ent_loss                 | 0.0378     |
|    ent_policy_gradient_loss | 0.0239     |
|    ent_std                  | 0.228      |
|    ent_value_loss           | 0.0191     |
|    entropy_loss             | -0.0809    |
|    explained_variance       | 0.244      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.131      |
|    n_updates                | 2390       |
|    policy_gradient_loss     | 0.118      |
|    std                      | 0.245      |
|    value_loss               | 0.02       |
--------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 637      |
|    ep_rew_mean     | 715      |
| time/              |          |
|    fps             | 155      |
|    iterations      | 240      |
|    time_elapsed    | 3166     |
|    total_timesteps | 491520   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 639        |
|    ep_rew_mean              | 718        |
| time/                       |            |
|    fps                      | 155        |
|    iterations               | 241        |
|    time_elapsed             | 3177       |
|    total_timesteps          | 493568     |
| train/                      |            |
|    approx_kl                | 1.0054077  |
|    clip_fraction            | 0.886      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.06616925 |
|    ent_clip_fraction        | 0.434      |
|    ent_entropy_loss         | 0.507      |
|    ent_loss                 | -0.0782    |
|    ent_policy_gradient_loss | -0.046     |
|    ent_std                  | 0.228      |
|    ent_value_loss           | 0.0218     |
|    entropy_loss             | -0.0534    |
|    explained_variance       | 0.287      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0935     |
|    n_updates                | 2400       |
|    policy_gradient_loss     | 0.134      |
|    std                      | 0.244      |
|    value_loss               | 0.0213     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 644       |
|    ep_rew_mean              | 719       |
| time/                       |           |
|    fps                      | 155       |
|    iterations               | 242       |
|    time_elapsed             | 3187      |
|    total_timesteps          | 495616    |
| train/                      |           |
|    approx_kl                | 1.0173202 |
|    clip_fraction            | 0.838     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.3068956 |
|    ent_clip_fraction        | 0.569     |
|    ent_entropy_loss         | 0.517     |
|    ent_loss                 | -0.0105   |
|    ent_policy_gradient_loss | 0.000892  |
|    ent_std                  | 0.228     |
|    ent_value_loss           | 0.038     |
|    entropy_loss             | -0.00456  |
|    explained_variance       | 0.812     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0804    |
|    n_updates                | 2410      |
|    policy_gradient_loss     | 0.106     |
|    std                      | 0.242     |
|    value_loss               | 0.0381    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 635        |
|    ep_rew_mean              | 723        |
| time/                       |            |
|    fps                      | 155        |
|    iterations               | 243        |
|    time_elapsed             | 3197       |
|    total_timesteps          | 497664     |
| train/                      |            |
|    approx_kl                | 1.8645215  |
|    clip_fraction            | 0.887      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.14783564 |
|    ent_clip_fraction        | 0.448      |
|    ent_entropy_loss         | 0.537      |
|    ent_loss                 | 0.0451     |
|    ent_policy_gradient_loss | -0.0216    |
|    ent_std                  | 0.226      |
|    ent_value_loss           | 0.0219     |
|    entropy_loss             | 0.0467     |
|    explained_variance       | 0.918      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0811     |
|    n_updates                | 2420       |
|    policy_gradient_loss     | 0.123      |
|    std                      | 0.24       |
|    value_loss               | 0.0221     |
--------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 631         |
|    ep_rew_mean              | 729         |
| time/                       |             |
|    fps                      | 155         |
|    iterations               | 244         |
|    time_elapsed             | 3207        |
|    total_timesteps          | 499712      |
| train/                      |             |
|    approx_kl                | 0.7693892   |
|    clip_fraction            | 0.881       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.091273054 |
|    ent_clip_fraction        | 0.445       |
|    ent_entropy_loss         | 0.571       |
|    ent_loss                 | -0.0327     |
|    ent_policy_gradient_loss | -0.0354     |
|    ent_std                  | 0.225       |
|    ent_value_loss           | 0.0622      |
|    entropy_loss             | 0.0869      |
|    explained_variance       | 0.0475      |
|    learning_rate            | 0.0003      |
|    loss                     | 0.11        |
|    n_updates                | 2430        |
|    policy_gradient_loss     | 0.105       |
|    std                      | 0.239       |
|    value_loss               | 0.0621      |
---------------------------------------------
Eval num_timesteps=500000, episode_reward=1449.27 +/- 536.07
Episode length: 852.48 +/- 305.78
---------------------------------------------
| eval/                       |             |
|    mean_ep_length           | 852         |
|    mean_reward              | 1.45e+03    |
| time/                       |             |
|    total_timesteps          | 500000      |
| train/                      |             |
|    approx_kl                | 0.91739625  |
|    clip_fraction            | 0.89        |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.047810707 |
|    ent_clip_fraction        | 0.417       |
|    ent_entropy_loss         | 0.628       |
|    ent_loss                 | -0.0734     |
|    ent_policy_gradient_loss | -0.0453     |
|    ent_std                  | 0.223       |
|    ent_value_loss           | 0.0414      |
|    entropy_loss             | 0.137       |
|    explained_variance       | 0.0696      |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0916      |
|    n_updates                | 2440        |
|    policy_gradient_loss     | 0.127       |
|    std                      | 0.237       |
|    value_loss               | 0.0436      |
---------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 643      |
|    ep_rew_mean     | 751      |
| time/              |          |
|    fps             | 155      |
|    iterations      | 245      |
|    time_elapsed    | 3235     |
|    total_timesteps | 501760   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 630        |
|    ep_rew_mean              | 750        |
| time/                       |            |
|    fps                      | 155        |
|    iterations               | 246        |
|    time_elapsed             | 3245       |
|    total_timesteps          | 503808     |
| train/                      |            |
|    approx_kl                | 1.0193846  |
|    clip_fraction            | 0.857      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.36428994 |
|    ent_clip_fraction        | 0.573      |
|    ent_entropy_loss         | 0.657      |
|    ent_loss                 | 0.0192     |
|    ent_policy_gradient_loss | -0.00465   |
|    ent_std                  | 0.223      |
|    ent_value_loss           | 0.0298     |
|    entropy_loss             | 0.157      |
|    explained_variance       | 0.85       |
|    learning_rate            | 0.0003     |
|    loss                     | 0.123      |
|    n_updates                | 2450       |
|    policy_gradient_loss     | 0.105      |
|    std                      | 0.238      |
|    value_loss               | 0.0286     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 623        |
|    ep_rew_mean              | 744        |
| time/                       |            |
|    fps                      | 155        |
|    iterations               | 247        |
|    time_elapsed             | 3256       |
|    total_timesteps          | 505856     |
| train/                      |            |
|    approx_kl                | 1.0639582  |
|    clip_fraction            | 0.885      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.15697676 |
|    ent_clip_fraction        | 0.492      |
|    ent_entropy_loss         | 0.691      |
|    ent_loss                 | -0.0116    |
|    ent_policy_gradient_loss | -0.0149    |
|    ent_std                  | 0.222      |
|    ent_value_loss           | 0.049      |
|    entropy_loss             | 0.165      |
|    explained_variance       | 0.812      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.115      |
|    n_updates                | 2460       |
|    policy_gradient_loss     | 0.0904     |
|    std                      | 0.237      |
|    value_loss               | 0.0505     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 630        |
|    ep_rew_mean              | 757        |
| time/                       |            |
|    fps                      | 155        |
|    iterations               | 248        |
|    time_elapsed             | 3266       |
|    total_timesteps          | 507904     |
| train/                      |            |
|    approx_kl                | 0.7814666  |
|    clip_fraction            | 0.866      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.19966628 |
|    ent_clip_fraction        | 0.524      |
|    ent_entropy_loss         | 0.736      |
|    ent_loss                 | -0.0831    |
|    ent_policy_gradient_loss | 0.00286    |
|    ent_std                  | 0.22       |
|    ent_value_loss           | 0.0454     |
|    entropy_loss             | 0.208      |
|    explained_variance       | 0.258      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.172      |
|    n_updates                | 2470       |
|    policy_gradient_loss     | 0.142      |
|    std                      | 0.236      |
|    value_loss               | 0.0454     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 620        |
|    ep_rew_mean              | 745        |
| time/                       |            |
|    fps                      | 155        |
|    iterations               | 249        |
|    time_elapsed             | 3276       |
|    total_timesteps          | 509952     |
| train/                      |            |
|    approx_kl                | 0.9813764  |
|    clip_fraction            | 0.891      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.09933044 |
|    ent_clip_fraction        | 0.448      |
|    ent_entropy_loss         | 0.804      |
|    ent_loss                 | -0.00804   |
|    ent_policy_gradient_loss | -0.0405    |
|    ent_std                  | 0.219      |
|    ent_value_loss           | 0.0633     |
|    entropy_loss             | 0.266      |
|    explained_variance       | 0.284      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0881     |
|    n_updates                | 2480       |
|    policy_gradient_loss     | 0.135      |
|    std                      | 0.233      |
|    value_loss               | 0.0641     |
--------------------------------------------
Eval num_timesteps=510000, episode_reward=1559.13 +/- 404.36
Episode length: 919.08 +/- 209.36
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 919        |
|    mean_reward              | 1.56e+03   |
| time/                       |            |
|    total_timesteps          | 510000     |
| train/                      |            |
|    approx_kl                | 1.265137   |
|    clip_fraction            | 0.907      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.15820847 |
|    ent_clip_fraction        | 0.465      |
|    ent_entropy_loss         | 0.852      |
|    ent_loss                 | -0.0203    |
|    ent_policy_gradient_loss | -0.0228    |
|    ent_std                  | 0.217      |
|    ent_value_loss           | 0.0175     |
|    entropy_loss             | 0.316      |
|    explained_variance       | 0.863      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0887     |
|    n_updates                | 2490       |
|    policy_gradient_loss     | 0.134      |
|    std                      | 0.232      |
|    value_loss               | 0.0187     |
--------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 627      |
|    ep_rew_mean     | 751      |
| time/              |          |
|    fps             | 154      |
|    iterations      | 250      |
|    time_elapsed    | 3304     |
|    total_timesteps | 512000   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 634        |
|    ep_rew_mean              | 765        |
| time/                       |            |
|    fps                      | 155        |
|    iterations               | 251        |
|    time_elapsed             | 3314       |
|    total_timesteps          | 514048     |
| train/                      |            |
|    approx_kl                | 1.7836211  |
|    clip_fraction            | 0.855      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.39624357 |
|    ent_clip_fraction        | 0.591      |
|    ent_entropy_loss         | 0.883      |
|    ent_loss                 | -0.0183    |
|    ent_policy_gradient_loss | 0.00916    |
|    ent_std                  | 0.217      |
|    ent_value_loss           | 0.0201     |
|    entropy_loss             | 0.358      |
|    explained_variance       | 0.888      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0781     |
|    n_updates                | 2500       |
|    policy_gradient_loss     | 0.122      |
|    std                      | 0.231      |
|    value_loss               | 0.0209     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 634        |
|    ep_rew_mean              | 765        |
| time/                       |            |
|    fps                      | 155        |
|    iterations               | 252        |
|    time_elapsed             | 3324       |
|    total_timesteps          | 516096     |
| train/                      |            |
|    approx_kl                | 1.1917146  |
|    clip_fraction            | 0.9        |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.12194084 |
|    ent_clip_fraction        | 0.478      |
|    ent_entropy_loss         | 0.908      |
|    ent_loss                 | -0.0653    |
|    ent_policy_gradient_loss | -0.0439    |
|    ent_std                  | 0.216      |
|    ent_value_loss           | 0.0316     |
|    entropy_loss             | 0.374      |
|    explained_variance       | 0.662      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0853     |
|    n_updates                | 2510       |
|    policy_gradient_loss     | 0.137      |
|    std                      | 0.231      |
|    value_loss               | 0.0309     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 612       |
|    ep_rew_mean              | 751       |
| time/                       |           |
|    fps                      | 155       |
|    iterations               | 253       |
|    time_elapsed             | 3335      |
|    total_timesteps          | 518144    |
| train/                      |           |
|    approx_kl                | 3.0339017 |
|    clip_fraction            | 0.802     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.6325318 |
|    ent_clip_fraction        | 0.67      |
|    ent_entropy_loss         | 0.928     |
|    ent_loss                 | 0.0221    |
|    ent_policy_gradient_loss | 0.0444    |
|    ent_std                  | 0.216     |
|    ent_value_loss           | 0.0124    |
|    entropy_loss             | 0.383     |
|    explained_variance       | 0.934     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.106     |
|    n_updates                | 2520      |
|    policy_gradient_loss     | 0.0444    |
|    std                      | 0.231     |
|    value_loss               | 0.0133    |
-------------------------------------------
Eval num_timesteps=520000, episode_reward=1865.03 +/- 214.83
Episode length: 971.16 +/- 104.63
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 971        |
|    mean_reward              | 1.87e+03   |
| time/                       |            |
|    total_timesteps          | 520000     |
| train/                      |            |
|    approx_kl                | 0.91298187 |
|    clip_fraction            | 0.902      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.06367006 |
|    ent_clip_fraction        | 0.428      |
|    ent_entropy_loss         | 0.927      |
|    ent_loss                 | -0.0107    |
|    ent_policy_gradient_loss | -0.0426    |
|    ent_std                  | 0.216      |
|    ent_value_loss           | 0.0537     |
|    entropy_loss             | 0.354      |
|    explained_variance       | 0.253      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.101      |
|    n_updates                | 2530       |
|    policy_gradient_loss     | 0.123      |
|    std                      | 0.232      |
|    value_loss               | 0.0517     |
--------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 629      |
|    ep_rew_mean     | 779      |
| time/              |          |
|    fps             | 154      |
|    iterations      | 254      |
|    time_elapsed    | 3363     |
|    total_timesteps | 520192   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 624        |
|    ep_rew_mean              | 778        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 255        |
|    time_elapsed             | 3373       |
|    total_timesteps          | 522240     |
| train/                      |            |
|    approx_kl                | 1.0444454  |
|    clip_fraction            | 0.886      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.12884521 |
|    ent_clip_fraction        | 0.475      |
|    ent_entropy_loss         | 0.961      |
|    ent_loss                 | -0.0321    |
|    ent_policy_gradient_loss | -0.0393    |
|    ent_std                  | 0.215      |
|    ent_value_loss           | 0.0252     |
|    entropy_loss             | 0.363      |
|    explained_variance       | 0.224      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.125      |
|    n_updates                | 2540       |
|    policy_gradient_loss     | 0.148      |
|    std                      | 0.231      |
|    value_loss               | 0.026      |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 617       |
|    ep_rew_mean              | 782       |
| time/                       |           |
|    fps                      | 154       |
|    iterations               | 256       |
|    time_elapsed             | 3383      |
|    total_timesteps          | 524288    |
| train/                      |           |
|    approx_kl                | 2.5012426 |
|    clip_fraction            | 0.786     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.5950478 |
|    ent_clip_fraction        | 0.675     |
|    ent_entropy_loss         | 0.944     |
|    ent_loss                 | -0.00248  |
|    ent_policy_gradient_loss | 0.0523    |
|    ent_std                  | 0.216     |
|    ent_value_loss           | 0.0292    |
|    entropy_loss             | 0.387     |
|    explained_variance       | 0.874     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0613    |
|    n_updates                | 2550      |
|    policy_gradient_loss     | 0.0512    |
|    std                      | 0.231     |
|    value_loss               | 0.0298    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 630        |
|    ep_rew_mean              | 800        |
| time/                       |            |
|    fps                      | 155        |
|    iterations               | 257        |
|    time_elapsed             | 3393       |
|    total_timesteps          | 526336     |
| train/                      |            |
|    approx_kl                | 0.9774257  |
|    clip_fraction            | 0.876      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.18406203 |
|    ent_clip_fraction        | 0.475      |
|    ent_entropy_loss         | 0.944      |
|    ent_loss                 | -0.00693   |
|    ent_policy_gradient_loss | -0.0216    |
|    ent_std                  | 0.215      |
|    ent_value_loss           | 0.0511     |
|    entropy_loss             | 0.433      |
|    explained_variance       | 0.165      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.125      |
|    n_updates                | 2560       |
|    policy_gradient_loss     | 0.11       |
|    std                      | 0.228      |
|    value_loss               | 0.0508     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 634        |
|    ep_rew_mean              | 811        |
| time/                       |            |
|    fps                      | 155        |
|    iterations               | 258        |
|    time_elapsed             | 3403       |
|    total_timesteps          | 528384     |
| train/                      |            |
|    approx_kl                | 1.6901809  |
|    clip_fraction            | 0.866      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.34025162 |
|    ent_clip_fraction        | 0.58       |
|    ent_entropy_loss         | 1          |
|    ent_loss                 | -0.03      |
|    ent_policy_gradient_loss | 0.00396    |
|    ent_std                  | 0.213      |
|    ent_value_loss           | 0.0137     |
|    entropy_loss             | 0.492      |
|    explained_variance       | 0.937      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.117      |
|    n_updates                | 2570       |
|    policy_gradient_loss     | 0.134      |
|    std                      | 0.227      |
|    value_loss               | 0.0149     |
--------------------------------------------
Eval num_timesteps=530000, episode_reward=1695.71 +/- 414.42
Episode length: 999.68 +/- 1.57
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 1e+03      |
|    mean_reward              | 1.7e+03    |
| time/                       |            |
|    total_timesteps          | 530000     |
| train/                      |            |
|    approx_kl                | 1.133369   |
|    clip_fraction            | 0.899      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.05624431 |
|    ent_clip_fraction        | 0.43       |
|    ent_entropy_loss         | 1.07       |
|    ent_loss                 | -0.0261    |
|    ent_policy_gradient_loss | -0.045     |
|    ent_std                  | 0.212      |
|    ent_value_loss           | 0.0373     |
|    entropy_loss             | 0.52       |
|    explained_variance       | 0.483      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.102      |
|    n_updates                | 2580       |
|    policy_gradient_loss     | 0.152      |
|    std                      | 0.226      |
|    value_loss               | 0.0368     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 626      |
|    ep_rew_mean     | 818      |
| time/              |          |
|    fps             | 154      |
|    iterations      | 259      |
|    time_elapsed    | 3430     |
|    total_timesteps | 530432   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 604        |
|    ep_rew_mean              | 810        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 260        |
|    time_elapsed             | 3441       |
|    total_timesteps          | 532480     |
| train/                      |            |
|    approx_kl                | 1.1479611  |
|    clip_fraction            | 0.896      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.19716036 |
|    ent_clip_fraction        | 0.508      |
|    ent_entropy_loss         | 1.11       |
|    ent_loss                 | 0.0172     |
|    ent_policy_gradient_loss | -0.0258    |
|    ent_std                  | 0.211      |
|    ent_value_loss           | 0.0377     |
|    entropy_loss             | 0.579      |
|    explained_variance       | 0.655      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0275     |
|    n_updates                | 2590       |
|    policy_gradient_loss     | 0.129      |
|    std                      | 0.224      |
|    value_loss               | 0.0351     |
--------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 592         |
|    ep_rew_mean              | 789         |
| time/                       |             |
|    fps                      | 154         |
|    iterations               | 261         |
|    time_elapsed             | 3451        |
|    total_timesteps          | 534528      |
| train/                      |             |
|    approx_kl                | 1.0083442   |
|    clip_fraction            | 0.894       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.071067795 |
|    ent_clip_fraction        | 0.459       |
|    ent_entropy_loss         | 1.16        |
|    ent_loss                 | -0.019      |
|    ent_policy_gradient_loss | -0.0396     |
|    ent_std                  | 0.209       |
|    ent_value_loss           | 0.0646      |
|    entropy_loss             | 0.653       |
|    explained_variance       | 0.243       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0569      |
|    n_updates                | 2600        |
|    policy_gradient_loss     | 0.134       |
|    std                      | 0.222       |
|    value_loss               | 0.0619      |
---------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 593        |
|    ep_rew_mean              | 795        |
| time/                       |            |
|    fps                      | 155        |
|    iterations               | 262        |
|    time_elapsed             | 3461       |
|    total_timesteps          | 536576     |
| train/                      |            |
|    approx_kl                | 1.0860025  |
|    clip_fraction            | 0.917      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.04735478 |
|    ent_clip_fraction        | 0.419      |
|    ent_entropy_loss         | 1.19       |
|    ent_loss                 | -0.00965   |
|    ent_policy_gradient_loss | -0.0503    |
|    ent_std                  | 0.209      |
|    ent_value_loss           | 0.0519     |
|    entropy_loss             | 0.686      |
|    explained_variance       | 0.81       |
|    learning_rate            | 0.0003     |
|    loss                     | 0.107      |
|    n_updates                | 2610       |
|    policy_gradient_loss     | 0.121      |
|    std                      | 0.222      |
|    value_loss               | 0.0514     |
--------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 615         |
|    ep_rew_mean              | 831         |
| time/                       |             |
|    fps                      | 155         |
|    iterations               | 263         |
|    time_elapsed             | 3471        |
|    total_timesteps          | 538624      |
| train/                      |             |
|    approx_kl                | 1.0874829   |
|    clip_fraction            | 0.904       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.054418128 |
|    ent_clip_fraction        | 0.449       |
|    ent_entropy_loss         | 1.23        |
|    ent_loss                 | -0.0153     |
|    ent_policy_gradient_loss | -0.0469     |
|    ent_std                  | 0.207       |
|    ent_value_loss           | 0.0784      |
|    entropy_loss             | 0.714       |
|    explained_variance       | 0.352       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.134       |
|    n_updates                | 2620        |
|    policy_gradient_loss     | 0.139       |
|    std                      | 0.221       |
|    value_loss               | 0.0774      |
---------------------------------------------
Eval num_timesteps=540000, episode_reward=1563.95 +/- 683.69
Episode length: 856.92 +/- 321.03
---------------------------------------------
| eval/                       |             |
|    mean_ep_length           | 857         |
|    mean_reward              | 1.56e+03    |
| time/                       |             |
|    total_timesteps          | 540000      |
| train/                      |             |
|    approx_kl                | 1.0888333   |
|    clip_fraction            | 0.909       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.054055303 |
|    ent_clip_fraction        | 0.44        |
|    ent_entropy_loss         | 1.29        |
|    ent_loss                 | -0.0459     |
|    ent_policy_gradient_loss | -0.0459     |
|    ent_std                  | 0.206       |
|    ent_value_loss           | 0.075       |
|    entropy_loss             | 0.763       |
|    explained_variance       | 0.174       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.131       |
|    n_updates                | 2630        |
|    policy_gradient_loss     | 0.137       |
|    std                      | 0.22        |
|    value_loss               | 0.0741      |
---------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 604      |
|    ep_rew_mean     | 829      |
| time/              |          |
|    fps             | 154      |
|    iterations      | 264      |
|    time_elapsed    | 3499     |
|    total_timesteps | 540672   |
---------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 594         |
|    ep_rew_mean              | 828         |
| time/                       |             |
|    fps                      | 154         |
|    iterations               | 265         |
|    time_elapsed             | 3510        |
|    total_timesteps          | 542720      |
| train/                      |             |
|    approx_kl                | 0.99102324  |
|    clip_fraction            | 0.903       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.050407007 |
|    ent_clip_fraction        | 0.454       |
|    ent_entropy_loss         | 1.33        |
|    ent_loss                 | -0.0138     |
|    ent_policy_gradient_loss | -0.047      |
|    ent_std                  | 0.204       |
|    ent_value_loss           | 0.0637      |
|    entropy_loss             | 0.776       |
|    explained_variance       | 0.361       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.09        |
|    n_updates                | 2640        |
|    policy_gradient_loss     | 0.119       |
|    std                      | 0.22        |
|    value_loss               | 0.0615      |
---------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 589        |
|    ep_rew_mean              | 819        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 266        |
|    time_elapsed             | 3520       |
|    total_timesteps          | 544768     |
| train/                      |            |
|    approx_kl                | 1.0465128  |
|    clip_fraction            | 0.892      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.21290591 |
|    ent_clip_fraction        | 0.516      |
|    ent_entropy_loss         | 1.38       |
|    ent_loss                 | -0.0337    |
|    ent_policy_gradient_loss | -0.0197    |
|    ent_std                  | 0.204      |
|    ent_value_loss           | 0.0637     |
|    entropy_loss             | 0.804      |
|    explained_variance       | 0.534      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.113      |
|    n_updates                | 2650       |
|    policy_gradient_loss     | 0.122      |
|    std                      | 0.219      |
|    value_loss               | 0.0626     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 587        |
|    ep_rew_mean              | 827        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 267        |
|    time_elapsed             | 3530       |
|    total_timesteps          | 546816     |
| train/                      |            |
|    approx_kl                | 0.960153   |
|    clip_fraction            | 0.894      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.16059892 |
|    ent_clip_fraction        | 0.46       |
|    ent_entropy_loss         | 1.4        |
|    ent_loss                 | -0.0336    |
|    ent_policy_gradient_loss | -0.0262    |
|    ent_std                  | 0.203      |
|    ent_value_loss           | 0.0594     |
|    entropy_loss             | 0.817      |
|    explained_variance       | 0.783      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0611     |
|    n_updates                | 2660       |
|    policy_gradient_loss     | 0.115      |
|    std                      | 0.219      |
|    value_loss               | 0.0588     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 586        |
|    ep_rew_mean              | 831        |
| time/                       |            |
|    fps                      | 155        |
|    iterations               | 268        |
|    time_elapsed             | 3540       |
|    total_timesteps          | 548864     |
| train/                      |            |
|    approx_kl                | 1.0567465  |
|    clip_fraction            | 0.881      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.27327132 |
|    ent_clip_fraction        | 0.555      |
|    ent_entropy_loss         | 1.43       |
|    ent_loss                 | -0.0417    |
|    ent_policy_gradient_loss | -0.0127    |
|    ent_std                  | 0.202      |
|    ent_value_loss           | 0.0319     |
|    entropy_loss             | 0.836      |
|    explained_variance       | 0.822      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.145      |
|    n_updates                | 2670       |
|    policy_gradient_loss     | 0.141      |
|    std                      | 0.218      |
|    value_loss               | 0.033      |
--------------------------------------------
Eval num_timesteps=550000, episode_reward=1751.71 +/- 286.34
Episode length: 1000.00 +/- 0.00
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 1e+03     |
|    mean_reward              | 1.75e+03  |
| time/                       |           |
|    total_timesteps          | 550000    |
| train/                      |           |
|    approx_kl                | 1.123658  |
|    clip_fraction            | 0.908     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.1319915 |
|    ent_clip_fraction        | 0.496     |
|    ent_entropy_loss         | 1.46      |
|    ent_loss                 | -0.0364   |
|    ent_policy_gradient_loss | -0.0228   |
|    ent_std                  | 0.202     |
|    ent_value_loss           | 0.041     |
|    entropy_loss             | 0.855     |
|    explained_variance       | 0.167     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.135     |
|    n_updates                | 2680      |
|    policy_gradient_loss     | 0.141     |
|    std                      | 0.217     |
|    value_loss               | 0.0391    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 578      |
|    ep_rew_mean     | 822      |
| time/              |          |
|    fps             | 154      |
|    iterations      | 269      |
|    time_elapsed    | 3569     |
|    total_timesteps | 550912   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 581        |
|    ep_rew_mean              | 837        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 270        |
|    time_elapsed             | 3579       |
|    total_timesteps          | 552960     |
| train/                      |            |
|    approx_kl                | 1.6668141  |
|    clip_fraction            | 0.922      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.05559012 |
|    ent_clip_fraction        | 0.417      |
|    ent_entropy_loss         | 1.48       |
|    ent_loss                 | -0.0382    |
|    ent_policy_gradient_loss | -0.0434    |
|    ent_std                  | 0.201      |
|    ent_value_loss           | 0.0366     |
|    entropy_loss             | 0.886      |
|    explained_variance       | 0.837      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.137      |
|    n_updates                | 2690       |
|    policy_gradient_loss     | 0.122      |
|    std                      | 0.217      |
|    value_loss               | 0.0344     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 587        |
|    ep_rew_mean              | 849        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 271        |
|    time_elapsed             | 3589       |
|    total_timesteps          | 555008     |
| train/                      |            |
|    approx_kl                | 1.1552238  |
|    clip_fraction            | 0.903      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.13102406 |
|    ent_clip_fraction        | 0.496      |
|    ent_entropy_loss         | 1.53       |
|    ent_loss                 | -0.00673   |
|    ent_policy_gradient_loss | -0.0322    |
|    ent_std                  | 0.2        |
|    ent_value_loss           | 0.0286     |
|    entropy_loss             | 0.936      |
|    explained_variance       | 0.254      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.114      |
|    n_updates                | 2700       |
|    policy_gradient_loss     | 0.157      |
|    std                      | 0.215      |
|    value_loss               | 0.029      |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 597       |
|    ep_rew_mean              | 863       |
| time/                       |           |
|    fps                      | 154       |
|    iterations               | 272       |
|    time_elapsed             | 3600      |
|    total_timesteps          | 557056    |
| train/                      |           |
|    approx_kl                | 1.1474967 |
|    clip_fraction            | 0.9       |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.1584804 |
|    ent_clip_fraction        | 0.484     |
|    ent_entropy_loss         | 1.58      |
|    ent_loss                 | -0.0414   |
|    ent_policy_gradient_loss | -0.0337   |
|    ent_std                  | 0.198     |
|    ent_value_loss           | 0.0236    |
|    entropy_loss             | 0.965     |
|    explained_variance       | 0.862     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0994    |
|    n_updates                | 2710      |
|    policy_gradient_loss     | 0.129     |
|    std                      | 0.215     |
|    value_loss               | 0.0226    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 607        |
|    ep_rew_mean              | 885        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 273        |
|    time_elapsed             | 3610       |
|    total_timesteps          | 559104     |
| train/                      |            |
|    approx_kl                | 1.2273256  |
|    clip_fraction            | 0.901      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.15728766 |
|    ent_clip_fraction        | 0.489      |
|    ent_entropy_loss         | 1.62       |
|    ent_loss                 | -0.036     |
|    ent_policy_gradient_loss | -0.0288    |
|    ent_std                  | 0.197      |
|    ent_value_loss           | 0.0286     |
|    entropy_loss             | 0.962      |
|    explained_variance       | 0.819      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.113      |
|    n_updates                | 2720       |
|    policy_gradient_loss     | 0.122      |
|    std                      | 0.215      |
|    value_loss               | 0.0277     |
--------------------------------------------
Eval num_timesteps=560000, episode_reward=1707.37 +/- 653.89
Episode length: 819.64 +/- 301.67
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 820        |
|    mean_reward              | 1.71e+03   |
| time/                       |            |
|    total_timesteps          | 560000     |
| train/                      |            |
|    approx_kl                | 1.066855   |
|    clip_fraction            | 0.905      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.09473105 |
|    ent_clip_fraction        | 0.492      |
|    ent_entropy_loss         | 1.67       |
|    ent_loss                 | -0.0861    |
|    ent_policy_gradient_loss | -0.0455    |
|    ent_std                  | 0.196      |
|    ent_value_loss           | 0.0234     |
|    entropy_loss             | 0.942      |
|    explained_variance       | 0.34       |
|    learning_rate            | 0.0003     |
|    loss                     | 0.111      |
|    n_updates                | 2730       |
|    policy_gradient_loss     | 0.156      |
|    std                      | 0.216      |
|    value_loss               | 0.0237     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 596      |
|    ep_rew_mean     | 865      |
| time/              |          |
|    fps             | 154      |
|    iterations      | 274      |
|    time_elapsed    | 3637     |
|    total_timesteps | 561152   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 604        |
|    ep_rew_mean              | 887        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 275        |
|    time_elapsed             | 3647       |
|    total_timesteps          | 563200     |
| train/                      |            |
|    approx_kl                | 1.3270547  |
|    clip_fraction            | 0.892      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.25547338 |
|    ent_clip_fraction        | 0.521      |
|    ent_entropy_loss         | 1.73       |
|    ent_loss                 | -0.033     |
|    ent_policy_gradient_loss | -0.0227    |
|    ent_std                  | 0.194      |
|    ent_value_loss           | 0.054      |
|    entropy_loss             | 0.973      |
|    explained_variance       | 0.843      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.127      |
|    n_updates                | 2740       |
|    policy_gradient_loss     | 0.179      |
|    std                      | 0.213      |
|    value_loss               | 0.055      |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 612        |
|    ep_rew_mean              | 904        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 276        |
|    time_elapsed             | 3658       |
|    total_timesteps          | 565248     |
| train/                      |            |
|    approx_kl                | 1.2065928  |
|    clip_fraction            | 0.913      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.06953433 |
|    ent_clip_fraction        | 0.476      |
|    ent_entropy_loss         | 1.78       |
|    ent_loss                 | -0.0701    |
|    ent_policy_gradient_loss | -0.0471    |
|    ent_std                  | 0.194      |
|    ent_value_loss           | 0.0457     |
|    entropy_loss             | 1.04       |
|    explained_variance       | 0.61       |
|    learning_rate            | 0.0003     |
|    loss                     | 0.22       |
|    n_updates                | 2750       |
|    policy_gradient_loss     | 0.169      |
|    std                      | 0.212      |
|    value_loss               | 0.0438     |
--------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 610         |
|    ep_rew_mean              | 907         |
| time/                       |             |
|    fps                      | 154         |
|    iterations               | 277         |
|    time_elapsed             | 3668        |
|    total_timesteps          | 567296      |
| train/                      |             |
|    approx_kl                | 1.1854339   |
|    clip_fraction            | 0.912       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.104681455 |
|    ent_clip_fraction        | 0.49        |
|    ent_entropy_loss         | 1.84        |
|    ent_loss                 | -0.0562     |
|    ent_policy_gradient_loss | -0.0338     |
|    ent_std                  | 0.192       |
|    ent_value_loss           | 0.0241      |
|    entropy_loss             | 1.1         |
|    explained_variance       | 0.142       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.209       |
|    n_updates                | 2760        |
|    policy_gradient_loss     | 0.129       |
|    std                      | 0.211       |
|    value_loss               | 0.0243      |
---------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 585        |
|    ep_rew_mean              | 893        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 278        |
|    time_elapsed             | 3678       |
|    total_timesteps          | 569344     |
| train/                      |            |
|    approx_kl                | 1.2584767  |
|    clip_fraction            | 0.916      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.05571983 |
|    ent_clip_fraction        | 0.453      |
|    ent_entropy_loss         | 1.86       |
|    ent_loss                 | -0.0384    |
|    ent_policy_gradient_loss | -0.0424    |
|    ent_std                  | 0.192      |
|    ent_value_loss           | 0.0841     |
|    entropy_loss             | 1.13       |
|    explained_variance       | 0.401      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0685     |
|    n_updates                | 2770       |
|    policy_gradient_loss     | 0.114      |
|    std                      | 0.209      |
|    value_loss               | 0.084      |
--------------------------------------------
Eval num_timesteps=570000, episode_reward=1980.05 +/- 45.50
Episode length: 1000.00 +/- 0.00
---------------------------------------------
| eval/                       |             |
|    mean_ep_length           | 1e+03       |
|    mean_reward              | 1.98e+03    |
| time/                       |             |
|    total_timesteps          | 570000      |
| train/                      |             |
|    approx_kl                | 1.1635034   |
|    clip_fraction            | 0.909       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.054748654 |
|    ent_clip_fraction        | 0.452       |
|    ent_entropy_loss         | 1.91        |
|    ent_loss                 | -0.0328     |
|    ent_policy_gradient_loss | -0.0431     |
|    ent_std                  | 0.19        |
|    ent_value_loss           | 0.102       |
|    entropy_loss             | 1.21        |
|    explained_variance       | 0.248       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.129       |
|    n_updates                | 2780        |
|    policy_gradient_loss     | 0.107       |
|    std                      | 0.207       |
|    value_loss               | 0.0986      |
---------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 568      |
|    ep_rew_mean     | 875      |
| time/              |          |
|    fps             | 154      |
|    iterations      | 279      |
|    time_elapsed    | 3707     |
|    total_timesteps | 571392   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 559        |
|    ep_rew_mean              | 865        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 280        |
|    time_elapsed             | 3717       |
|    total_timesteps          | 573440     |
| train/                      |            |
|    approx_kl                | 1.1127998  |
|    clip_fraction            | 0.89       |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.22591718 |
|    ent_clip_fraction        | 0.544      |
|    ent_entropy_loss         | 1.95       |
|    ent_loss                 | -0.0622    |
|    ent_policy_gradient_loss | -0.0288    |
|    ent_std                  | 0.19       |
|    ent_value_loss           | 0.0479     |
|    entropy_loss             | 1.3        |
|    explained_variance       | 0.424      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.125      |
|    n_updates                | 2790       |
|    policy_gradient_loss     | 0.131      |
|    std                      | 0.205      |
|    value_loss               | 0.048      |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 560        |
|    ep_rew_mean              | 874        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 281        |
|    time_elapsed             | 3728       |
|    total_timesteps          | 575488     |
| train/                      |            |
|    approx_kl                | 2.7500029  |
|    clip_fraction            | 0.912      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.29615718 |
|    ent_clip_fraction        | 0.549      |
|    ent_entropy_loss         | 1.99       |
|    ent_loss                 | -0.0502    |
|    ent_policy_gradient_loss | -0.0151    |
|    ent_std                  | 0.188      |
|    ent_value_loss           | 0.0394     |
|    entropy_loss             | 1.35       |
|    explained_variance       | 0.818      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.142      |
|    n_updates                | 2800       |
|    policy_gradient_loss     | 0.112      |
|    std                      | 0.204      |
|    value_loss               | 0.0407     |
--------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 557         |
|    ep_rew_mean              | 863         |
| time/                       |             |
|    fps                      | 154         |
|    iterations               | 282         |
|    time_elapsed             | 3738        |
|    total_timesteps          | 577536      |
| train/                      |             |
|    approx_kl                | 1.3172603   |
|    clip_fraction            | 0.917       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.074612126 |
|    ent_clip_fraction        | 0.47        |
|    ent_entropy_loss         | 2.03        |
|    ent_loss                 | -0.0509     |
|    ent_policy_gradient_loss | -0.0439     |
|    ent_std                  | 0.188       |
|    ent_value_loss           | 0.0542      |
|    entropy_loss             | 1.38        |
|    explained_variance       | 0.29        |
|    learning_rate            | 0.0003      |
|    loss                     | 0.152       |
|    n_updates                | 2810        |
|    policy_gradient_loss     | 0.137       |
|    std                      | 0.203       |
|    value_loss               | 0.0553      |
---------------------------------------------
---------------------------------------------
| rollout/                    |             |
|    ep_len_mean              | 559         |
|    ep_rew_mean              | 862         |
| time/                       |             |
|    fps                      | 154         |
|    iterations               | 283         |
|    time_elapsed             | 3748        |
|    total_timesteps          | 579584      |
| train/                      |             |
|    approx_kl                | 2.7293434   |
|    clip_fraction            | 0.945       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.095026866 |
|    ent_clip_fraction        | 0.466       |
|    ent_entropy_loss         | 2.08        |
|    ent_loss                 | -0.0169     |
|    ent_policy_gradient_loss | -0.0381     |
|    ent_std                  | 0.186       |
|    ent_value_loss           | 0.0161      |
|    entropy_loss             | 1.41        |
|    explained_variance       | 0.912       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.121       |
|    n_updates                | 2820        |
|    policy_gradient_loss     | 0.13        |
|    std                      | 0.203       |
|    value_loss               | 0.0163      |
---------------------------------------------
Eval num_timesteps=580000, episode_reward=1957.92 +/- 496.46
Episode length: 961.04 +/- 190.86
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 961       |
|    mean_reward              | 1.96e+03  |
| time/                       |           |
|    total_timesteps          | 580000    |
| train/                      |           |
|    approx_kl                | 4.0920315 |
|    clip_fraction            | 0.842     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.7135662 |
|    ent_clip_fraction        | 0.666     |
|    ent_entropy_loss         | 2.09      |
|    ent_loss                 | 0.0606    |
|    ent_policy_gradient_loss | 0.0648    |
|    ent_std                  | 0.187     |
|    ent_value_loss           | 0.0312    |
|    entropy_loss             | 1.47      |
|    explained_variance       | 0.867     |
|    learning_rate            | 0.0003    |
|    loss                     | -0.0061   |
|    n_updates                | 2830      |
|    policy_gradient_loss     | 0.0976    |
|    std                      | 0.201     |
|    value_loss               | 0.0321    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 560      |
|    ep_rew_mean     | 869      |
| time/              |          |
|    fps             | 154      |
|    iterations      | 284      |
|    time_elapsed    | 3776     |
|    total_timesteps | 581632   |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 558       |
|    ep_rew_mean              | 878       |
| time/                       |           |
|    fps                      | 154       |
|    iterations               | 285       |
|    time_elapsed             | 3786      |
|    total_timesteps          | 583680    |
| train/                      |           |
|    approx_kl                | 1.0585463 |
|    clip_fraction            | 0.844     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.5005946 |
|    ent_clip_fraction        | 0.673     |
|    ent_entropy_loss         | 2.04      |
|    ent_loss                 | -0.0507   |
|    ent_policy_gradient_loss | 0.0279    |
|    ent_std                  | 0.189     |
|    ent_value_loss           | 0.0123    |
|    entropy_loss             | 1.5       |
|    explained_variance       | -0.878    |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0912    |
|    n_updates                | 2840      |
|    policy_gradient_loss     | 0.114     |
|    std                      | 0.201     |
|    value_loss               | 0.0128    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 544        |
|    ep_rew_mean              | 859        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 286        |
|    time_elapsed             | 3796       |
|    total_timesteps          | 585728     |
| train/                      |            |
|    approx_kl                | 1.2787676  |
|    clip_fraction            | 0.898      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.25150758 |
|    ent_clip_fraction        | 0.548      |
|    ent_entropy_loss         | 2.05       |
|    ent_loss                 | -0.047     |
|    ent_policy_gradient_loss | -0.0263    |
|    ent_std                  | 0.187      |
|    ent_value_loss           | 0.0276     |
|    entropy_loss             | 1.49       |
|    explained_variance       | 0.303      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.112      |
|    n_updates                | 2850       |
|    policy_gradient_loss     | 0.168      |
|    std                      | 0.201      |
|    value_loss               | 0.0285     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 560        |
|    ep_rew_mean              | 880        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 287        |
|    time_elapsed             | 3806       |
|    total_timesteps          | 587776     |
| train/                      |            |
|    approx_kl                | 1.6103745  |
|    clip_fraction            | 0.891      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.36352533 |
|    ent_clip_fraction        | 0.55       |
|    ent_entropy_loss         | 2.09       |
|    ent_loss                 | 0.0105     |
|    ent_policy_gradient_loss | -0.0106    |
|    ent_std                  | 0.186      |
|    ent_value_loss           | 0.0674     |
|    entropy_loss             | 1.49       |
|    explained_variance       | 0.623      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.118      |
|    n_updates                | 2860       |
|    policy_gradient_loss     | 0.116      |
|    std                      | 0.201      |
|    value_loss               | 0.0658     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 555        |
|    ep_rew_mean              | 884        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 288        |
|    time_elapsed             | 3816       |
|    total_timesteps          | 589824     |
| train/                      |            |
|    approx_kl                | 3.0454583  |
|    clip_fraction            | 0.838      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.58196986 |
|    ent_clip_fraction        | 0.659      |
|    ent_entropy_loss         | 2.13       |
|    ent_loss                 | 0.0107     |
|    ent_policy_gradient_loss | 0.0356     |
|    ent_std                  | 0.186      |
|    ent_value_loss           | 0.0349     |
|    entropy_loss             | 1.51       |
|    explained_variance       | 0.859      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.096      |
|    n_updates                | 2870       |
|    policy_gradient_loss     | 0.119      |
|    std                      | 0.2        |
|    value_loss               | 0.0353     |
--------------------------------------------
Eval num_timesteps=590000, episode_reward=1368.58 +/- 698.59
Episode length: 777.44 +/- 346.70
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 777       |
|    mean_reward              | 1.37e+03  |
| time/                       |           |
|    total_timesteps          | 590000    |
| train/                      |           |
|    approx_kl                | 1.3309805 |
|    clip_fraction            | 0.918     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.1812279 |
|    ent_clip_fraction        | 0.492     |
|    ent_entropy_loss         | 2.14      |
|    ent_loss                 | -0.0725   |
|    ent_policy_gradient_loss | -0.0343   |
|    ent_std                  | 0.185     |
|    ent_value_loss           | 0.0453    |
|    entropy_loss             | 1.52      |
|    explained_variance       | 0.399     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.117     |
|    n_updates                | 2880      |
|    policy_gradient_loss     | 0.179     |
|    std                      | 0.201     |
|    value_loss               | 0.0447    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 569      |
|    ep_rew_mean     | 910      |
| time/              |          |
|    fps             | 154      |
|    iterations      | 289      |
|    time_elapsed    | 3841     |
|    total_timesteps | 591872   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 567        |
|    ep_rew_mean              | 912        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 290        |
|    time_elapsed             | 3851       |
|    total_timesteps          | 593920     |
| train/                      |            |
|    approx_kl                | 0.9304702  |
|    clip_fraction            | 0.8        |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.83236694 |
|    ent_clip_fraction        | 0.74       |
|    ent_entropy_loss         | 2.16       |
|    ent_loss                 | 0.027      |
|    ent_policy_gradient_loss | 0.0569     |
|    ent_std                  | 0.185      |
|    ent_value_loss           | 0.044      |
|    entropy_loss             | 1.51       |
|    explained_variance       | -0.0104    |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0177     |
|    n_updates                | 2890       |
|    policy_gradient_loss     | 0.052      |
|    std                      | 0.201      |
|    value_loss               | 0.0461     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 568        |
|    ep_rew_mean              | 914        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 291        |
|    time_elapsed             | 3861       |
|    total_timesteps          | 595968     |
| train/                      |            |
|    approx_kl                | 1.3547577  |
|    clip_fraction            | 0.925      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.06579186 |
|    ent_clip_fraction        | 0.478      |
|    ent_entropy_loss         | 2.19       |
|    ent_loss                 | -0.0307    |
|    ent_policy_gradient_loss | -0.0383    |
|    ent_std                  | 0.184      |
|    ent_value_loss           | 0.0581     |
|    entropy_loss             | 1.51       |
|    explained_variance       | 0.0981     |
|    learning_rate            | 0.0003     |
|    loss                     | 0.121      |
|    n_updates                | 2900       |
|    policy_gradient_loss     | 0.667      |
|    std                      | 0.2        |
|    value_loss               | 0.0543     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 568        |
|    ep_rew_mean              | 913        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 292        |
|    time_elapsed             | 3871       |
|    total_timesteps          | 598016     |
| train/                      |            |
|    approx_kl                | 2.6153128  |
|    clip_fraction            | 0.905      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.43169558 |
|    ent_clip_fraction        | 0.599      |
|    ent_entropy_loss         | 2.22       |
|    ent_loss                 | -0.039     |
|    ent_policy_gradient_loss | 0.000357   |
|    ent_std                  | 0.184      |
|    ent_value_loss           | 0.0409     |
|    entropy_loss             | 1.55       |
|    explained_variance       | 0.864      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0644     |
|    n_updates                | 2910       |
|    policy_gradient_loss     | 0.116      |
|    std                      | 0.2        |
|    value_loss               | 0.0409     |
--------------------------------------------
Eval num_timesteps=600000, episode_reward=1426.50 +/- 769.54
Episode length: 706.44 +/- 373.25
---------------------------------------------
| eval/                       |             |
|    mean_ep_length           | 706         |
|    mean_reward              | 1.43e+03    |
| time/                       |             |
|    total_timesteps          | 600000      |
| train/                      |             |
|    approx_kl                | 1.85356     |
|    clip_fraction            | 0.919       |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.087829635 |
|    ent_clip_fraction        | 0.487       |
|    ent_entropy_loss         | 2.23        |
|    ent_loss                 | -0.0437     |
|    ent_policy_gradient_loss | -0.0423     |
|    ent_std                  | 0.183       |
|    ent_value_loss           | 0.0639      |
|    entropy_loss             | 1.6         |
|    explained_variance       | 0.524       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.0933      |
|    n_updates                | 2920        |
|    policy_gradient_loss     | 0.128       |
|    std                      | 0.197       |
|    value_loss               | 0.0637      |
---------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 564      |
|    ep_rew_mean     | 920      |
| time/              |          |
|    fps             | 153      |
|    iterations      | 293      |
|    time_elapsed    | 3899     |
|    total_timesteps | 600064   |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 572       |
|    ep_rew_mean              | 928       |
| time/                       |           |
|    fps                      | 154       |
|    iterations               | 294       |
|    time_elapsed             | 3909      |
|    total_timesteps          | 602112    |
| train/                      |           |
|    approx_kl                | 1.2945807 |
|    clip_fraction            | 0.921     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.0571731 |
|    ent_clip_fraction        | 0.454     |
|    ent_entropy_loss         | 2.29      |
|    ent_loss                 | -0.0373   |
|    ent_policy_gradient_loss | -0.0408   |
|    ent_std                  | 0.182     |
|    ent_value_loss           | 0.081     |
|    entropy_loss             | 1.68      |
|    explained_variance       | 0.313     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0752    |
|    n_updates                | 2930      |
|    policy_gradient_loss     | 0.144     |
|    std                      | 0.196     |
|    value_loss               | 0.0799    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 563        |
|    ep_rew_mean              | 920        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 295        |
|    time_elapsed             | 3919       |
|    total_timesteps          | 604160     |
| train/                      |            |
|    approx_kl                | 2.819188   |
|    clip_fraction            | 0.921      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.17170337 |
|    ent_clip_fraction        | 0.501      |
|    ent_entropy_loss         | 2.35       |
|    ent_loss                 | -0.0455    |
|    ent_policy_gradient_loss | -0.0193    |
|    ent_std                  | 0.18       |
|    ent_value_loss           | 0.0366     |
|    entropy_loss             | 1.73       |
|    explained_variance       | 0.835      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0547     |
|    n_updates                | 2940       |
|    policy_gradient_loss     | 0.138      |
|    std                      | 0.195      |
|    value_loss               | 0.0388     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 558        |
|    ep_rew_mean              | 912        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 296        |
|    time_elapsed             | 3929       |
|    total_timesteps          | 606208     |
| train/                      |            |
|    approx_kl                | 1.4635553  |
|    clip_fraction            | 0.92       |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.14731634 |
|    ent_clip_fraction        | 0.496      |
|    ent_entropy_loss         | 2.4        |
|    ent_loss                 | 0.0147     |
|    ent_policy_gradient_loss | -0.0408    |
|    ent_std                  | 0.179      |
|    ent_value_loss           | 0.0689     |
|    entropy_loss             | 1.74       |
|    explained_variance       | 0.42       |
|    learning_rate            | 0.0003     |
|    loss                     | 0.201      |
|    n_updates                | 2950       |
|    policy_gradient_loss     | 0.141      |
|    std                      | 0.195      |
|    value_loss               | 0.0675     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 543       |
|    ep_rew_mean              | 891       |
| time/                       |           |
|    fps                      | 154       |
|    iterations               | 297       |
|    time_elapsed             | 3939      |
|    total_timesteps          | 608256    |
| train/                      |           |
|    approx_kl                | 1.5022516 |
|    clip_fraction            | 0.888     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.3573047 |
|    ent_clip_fraction        | 0.599     |
|    ent_entropy_loss         | 2.4       |
|    ent_loss                 | 0.00201   |
|    ent_policy_gradient_loss | 0.00287   |
|    ent_std                  | 0.18      |
|    ent_value_loss           | 0.0739    |
|    entropy_loss             | 1.74      |
|    explained_variance       | 0.782     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.134     |
|    n_updates                | 2960      |
|    policy_gradient_loss     | 0.111     |
|    std                      | 0.195     |
|    value_loss               | 0.0756    |
-------------------------------------------
Eval num_timesteps=610000, episode_reward=1329.48 +/- 691.86
Episode length: 701.52 +/- 343.87
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 702        |
|    mean_reward              | 1.33e+03   |
| time/                       |            |
|    total_timesteps          | 610000     |
| train/                      |            |
|    approx_kl                | 1.6023136  |
|    clip_fraction            | 0.918      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.19773108 |
|    ent_clip_fraction        | 0.517      |
|    ent_entropy_loss         | 2.39       |
|    ent_loss                 | 0.0204     |
|    ent_policy_gradient_loss | -0.0264    |
|    ent_std                  | 0.179      |
|    ent_value_loss           | 0.0569     |
|    entropy_loss             | 1.72       |
|    explained_variance       | 0.785      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.151      |
|    n_updates                | 2970       |
|    policy_gradient_loss     | 0.137      |
|    std                      | 0.196      |
|    value_loss               | 0.0562     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 505      |
|    ep_rew_mean     | 837      |
| time/              |          |
|    fps             | 153      |
|    iterations      | 298      |
|    time_elapsed    | 3964     |
|    total_timesteps | 610304   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 497        |
|    ep_rew_mean              | 835        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 299        |
|    time_elapsed             | 3974       |
|    total_timesteps          | 612352     |
| train/                      |            |
|    approx_kl                | 1.5026954  |
|    clip_fraction            | 0.919      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.06399216 |
|    ent_clip_fraction        | 0.488      |
|    ent_entropy_loss         | 2.43       |
|    ent_loss                 | -0.0589    |
|    ent_policy_gradient_loss | -0.0469    |
|    ent_std                  | 0.178      |
|    ent_value_loss           | 0.102      |
|    entropy_loss             | 1.72       |
|    explained_variance       | 0.372      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.168      |
|    n_updates                | 2980       |
|    policy_gradient_loss     | 0.154      |
|    std                      | 0.195      |
|    value_loss               | 0.103      |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 494       |
|    ep_rew_mean              | 822       |
| time/                       |           |
|    fps                      | 154       |
|    iterations               | 300       |
|    time_elapsed             | 3983      |
|    total_timesteps          | 614400    |
| train/                      |           |
|    approx_kl                | 1.8489436 |
|    clip_fraction            | 0.84      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.7739437 |
|    ent_clip_fraction        | 0.726     |
|    ent_entropy_loss         | 2.45      |
|    ent_loss                 | 0.0374    |
|    ent_policy_gradient_loss | 0.0612    |
|    ent_std                  | 0.179     |
|    ent_value_loss           | 0.0759    |
|    entropy_loss             | 1.73      |
|    explained_variance       | 0.694     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0299    |
|    n_updates                | 2990      |
|    policy_gradient_loss     | 0.0818    |
|    std                      | 0.195     |
|    value_loss               | 0.0811    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 498        |
|    ep_rew_mean              | 825        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 301        |
|    time_elapsed             | 3993       |
|    total_timesteps          | 616448     |
| train/                      |            |
|    approx_kl                | 2.9090316  |
|    clip_fraction            | 0.951      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.10889942 |
|    ent_clip_fraction        | 0.476      |
|    ent_entropy_loss         | 2.46       |
|    ent_loss                 | -0.0723    |
|    ent_policy_gradient_loss | -0.0401    |
|    ent_std                  | 0.178      |
|    ent_value_loss           | 0.0553     |
|    entropy_loss             | 1.75       |
|    explained_variance       | 0.823      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.164      |
|    n_updates                | 3000       |
|    policy_gradient_loss     | 0.161      |
|    std                      | 0.194      |
|    value_loss               | 0.0532     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 496        |
|    ep_rew_mean              | 819        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 302        |
|    time_elapsed             | 4003       |
|    total_timesteps          | 618496     |
| train/                      |            |
|    approx_kl                | 6.1899137  |
|    clip_fraction            | 0.958      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.07096067 |
|    ent_clip_fraction        | 0.463      |
|    ent_entropy_loss         | 2.54       |
|    ent_loss                 | -0.0433    |
|    ent_policy_gradient_loss | -0.0428    |
|    ent_std                  | 0.175      |
|    ent_value_loss           | 0.0355     |
|    entropy_loss             | 1.85       |
|    explained_variance       | 0.884      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0966     |
|    n_updates                | 3010       |
|    policy_gradient_loss     | 0.12       |
|    std                      | 0.191      |
|    value_loss               | 0.033      |
--------------------------------------------
Eval num_timesteps=620000, episode_reward=1251.58 +/- 690.13
Episode length: 743.96 +/- 370.37
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 744        |
|    mean_reward              | 1.25e+03   |
| time/                       |            |
|    total_timesteps          | 620000     |
| train/                      |            |
|    approx_kl                | 2.5181086  |
|    clip_fraction            | 0.917      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.31980556 |
|    ent_clip_fraction        | 0.571      |
|    ent_entropy_loss         | 2.59       |
|    ent_loss                 | 0.0347     |
|    ent_policy_gradient_loss | -0.0142    |
|    ent_std                  | 0.175      |
|    ent_value_loss           | 0.0665     |
|    entropy_loss             | 1.89       |
|    explained_variance       | 0.751      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.214      |
|    n_updates                | 3020       |
|    policy_gradient_loss     | 0.125      |
|    std                      | 0.192      |
|    value_loss               | 0.0674     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 499      |
|    ep_rew_mean     | 826      |
| time/              |          |
|    fps             | 154      |
|    iterations      | 303      |
|    time_elapsed    | 4028     |
|    total_timesteps | 620544   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 500        |
|    ep_rew_mean              | 826        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 304        |
|    time_elapsed             | 4038       |
|    total_timesteps          | 622592     |
| train/                      |            |
|    approx_kl                | 1.4689399  |
|    clip_fraction            | 0.932      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.06453995 |
|    ent_clip_fraction        | 0.489      |
|    ent_entropy_loss         | 2.6        |
|    ent_loss                 | -0.0515    |
|    ent_policy_gradient_loss | -0.045     |
|    ent_std                  | 0.175      |
|    ent_value_loss           | 0.0978     |
|    entropy_loss             | 1.87       |
|    explained_variance       | 0.285      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.143      |
|    n_updates                | 3030       |
|    policy_gradient_loss     | 0.175      |
|    std                      | 0.191      |
|    value_loss               | 0.0981     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 504       |
|    ep_rew_mean              | 832       |
| time/                       |           |
|    fps                      | 154       |
|    iterations               | 305       |
|    time_elapsed             | 4048      |
|    total_timesteps          | 624640    |
| train/                      |           |
|    approx_kl                | 3.1470213 |
|    clip_fraction            | 0.92      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.4618102 |
|    ent_clip_fraction        | 0.564     |
|    ent_entropy_loss         | 2.64      |
|    ent_loss                 | -0.0276   |
|    ent_policy_gradient_loss | -0.0133   |
|    ent_std                  | 0.174     |
|    ent_value_loss           | 0.0417    |
|    entropy_loss             | 1.9       |
|    explained_variance       | 0.838     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0894    |
|    n_updates                | 3040      |
|    policy_gradient_loss     | 0.151     |
|    std                      | 0.191     |
|    value_loss               | 0.0424    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 509        |
|    ep_rew_mean              | 826        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 306        |
|    time_elapsed             | 4058       |
|    total_timesteps          | 626688     |
| train/                      |            |
|    approx_kl                | 4.87786    |
|    clip_fraction            | 0.944      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.13895392 |
|    ent_clip_fraction        | 0.5        |
|    ent_entropy_loss         | 2.68       |
|    ent_loss                 | -0.021     |
|    ent_policy_gradient_loss | -0.0311    |
|    ent_std                  | 0.173      |
|    ent_value_loss           | 0.0524     |
|    entropy_loss             | 1.9        |
|    explained_variance       | 0.806      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.15       |
|    n_updates                | 3050       |
|    policy_gradient_loss     | 0.141      |
|    std                      | 0.191      |
|    value_loss               | 0.0517     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 504       |
|    ep_rew_mean              | 833       |
| time/                       |           |
|    fps                      | 154       |
|    iterations               | 307       |
|    time_elapsed             | 4068      |
|    total_timesteps          | 628736    |
| train/                      |           |
|    approx_kl                | 8.795546  |
|    clip_fraction            | 0.944     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.3674426 |
|    ent_clip_fraction        | 0.566     |
|    ent_entropy_loss         | 2.67      |
|    ent_loss                 | 0.0196    |
|    ent_policy_gradient_loss | 0.0271    |
|    ent_std                  | 0.174     |
|    ent_value_loss           | 0.0178    |
|    entropy_loss             | 1.96      |
|    explained_variance       | 0.941     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.133     |
|    n_updates                | 3060      |
|    policy_gradient_loss     | 0.0678    |
|    std                      | 0.189     |
|    value_loss               | 0.0173    |
-------------------------------------------
Eval num_timesteps=630000, episode_reward=2051.20 +/- 454.23
Episode length: 962.04 +/- 167.97
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 962       |
|    mean_reward              | 2.05e+03  |
| time/                       |           |
|    total_timesteps          | 630000    |
| train/                      |           |
|    approx_kl                | 2.2077336 |
|    clip_fraction            | 0.896     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.7043394 |
|    ent_clip_fraction        | 0.552     |
|    ent_entropy_loss         | 2.67      |
|    ent_loss                 | -0.0606   |
|    ent_policy_gradient_loss | -0.0347   |
|    ent_std                  | 0.173     |
|    ent_value_loss           | 0.0492    |
|    entropy_loss             | 2.01      |
|    explained_variance       | 0.785     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0684    |
|    n_updates                | 3070      |
|    policy_gradient_loss     | 0.157     |
|    std                      | 0.188     |
|    value_loss               | 0.0492    |
-------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 814      |
| time/              |          |
|    fps             | 153      |
|    iterations      | 308      |
|    time_elapsed    | 4096     |
|    total_timesteps | 630784   |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 488       |
|    ep_rew_mean              | 803       |
| time/                       |           |
|    fps                      | 154       |
|    iterations               | 309       |
|    time_elapsed             | 4106      |
|    total_timesteps          | 632832    |
| train/                      |           |
|    approx_kl                | 4.774338  |
|    clip_fraction            | 0.923     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.4201392 |
|    ent_clip_fraction        | 0.592     |
|    ent_entropy_loss         | 2.73      |
|    ent_loss                 | -0.0931   |
|    ent_policy_gradient_loss | 0.0333    |
|    ent_std                  | 0.172     |
|    ent_value_loss           | 0.0273    |
|    entropy_loss             | 2.07      |
|    explained_variance       | 0.904     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0667    |
|    n_updates                | 3080      |
|    policy_gradient_loss     | 0.0865    |
|    std                      | 0.186     |
|    value_loss               | 0.0274    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 489        |
|    ep_rew_mean              | 810        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 310        |
|    time_elapsed             | 4117       |
|    total_timesteps          | 634880     |
| train/                      |            |
|    approx_kl                | 1.4897792  |
|    clip_fraction            | 0.881      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.49198905 |
|    ent_clip_fraction        | 0.625      |
|    ent_entropy_loss         | 2.75       |
|    ent_loss                 | -0.0212    |
|    ent_policy_gradient_loss | 0.00919    |
|    ent_std                  | 0.172      |
|    ent_value_loss           | 0.0473     |
|    entropy_loss             | 2.1        |
|    explained_variance       | 0.47       |
|    learning_rate            | 0.0003     |
|    loss                     | 0.102      |
|    n_updates                | 3090       |
|    policy_gradient_loss     | 0.14       |
|    std                      | 0.186      |
|    value_loss               | 0.0469     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 494       |
|    ep_rew_mean              | 817       |
| time/                       |           |
|    fps                      | 154       |
|    iterations               | 311       |
|    time_elapsed             | 4127      |
|    total_timesteps          | 636928    |
| train/                      |           |
|    approx_kl                | 1.7366929 |
|    clip_fraction            | 0.901     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.3590616 |
|    ent_clip_fraction        | 0.567     |
|    ent_entropy_loss         | 2.74      |
|    ent_loss                 | 0.000323  |
|    ent_policy_gradient_loss | -0.00014  |
|    ent_std                  | 0.172     |
|    ent_value_loss           | 0.0528    |
|    entropy_loss             | 2.09      |
|    explained_variance       | 0.682     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.124     |
|    n_updates                | 3100      |
|    policy_gradient_loss     | 0.111     |
|    std                      | 0.187     |
|    value_loss               | 0.0541    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 501        |
|    ep_rew_mean              | 826        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 312        |
|    time_elapsed             | 4137       |
|    total_timesteps          | 638976     |
| train/                      |            |
|    approx_kl                | 4.8423533  |
|    clip_fraction            | 0.936      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.21694931 |
|    ent_clip_fraction        | 0.54       |
|    ent_entropy_loss         | 2.75       |
|    ent_loss                 | -0.0312    |
|    ent_policy_gradient_loss | -0.021     |
|    ent_std                  | 0.171      |
|    ent_value_loss           | 0.0269     |
|    entropy_loss             | 2.12       |
|    explained_variance       | 0.926      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0843     |
|    n_updates                | 3110       |
|    policy_gradient_loss     | 0.123      |
|    std                      | 0.185      |
|    value_loss               | 0.0255     |
--------------------------------------------
Eval num_timesteps=640000, episode_reward=1707.04 +/- 705.03
Episode length: 841.88 +/- 280.47
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 842       |
|    mean_reward              | 1.71e+03  |
| time/                       |           |
|    total_timesteps          | 640000    |
| train/                      |           |
|    approx_kl                | 3.7325087 |
|    clip_fraction            | 0.824     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.337232  |
|    ent_clip_fraction        | 0.726     |
|    ent_entropy_loss         | 2.75      |
|    ent_loss                 | -0.0182   |
|    ent_policy_gradient_loss | 0.0714    |
|    ent_std                  | 0.172     |
|    ent_value_loss           | 0.0332    |
|    entropy_loss             | 2.18      |
|    explained_variance       | 0.879     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0692    |
|    n_updates                | 3120      |
|    policy_gradient_loss     | 7.36      |
|    std                      | 0.184     |
|    value_loss               | 0.0356    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 498      |
|    ep_rew_mean     | 817      |
| time/              |          |
|    fps             | 153      |
|    iterations      | 313      |
|    time_elapsed    | 4164     |
|    total_timesteps | 641024   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 507        |
|    ep_rew_mean              | 831        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 314        |
|    time_elapsed             | 4174       |
|    total_timesteps          | 643072     |
| train/                      |            |
|    approx_kl                | 3.8438363  |
|    clip_fraction            | 0.942      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.21552703 |
|    ent_clip_fraction        | 0.511      |
|    ent_entropy_loss         | 2.76       |
|    ent_loss                 | -0.0468    |
|    ent_policy_gradient_loss | -0.0268    |
|    ent_std                  | 0.171      |
|    ent_value_loss           | 0.0388     |
|    entropy_loss             | 2.18       |
|    explained_variance       | 0.879      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.158      |
|    n_updates                | 3130       |
|    policy_gradient_loss     | 0.131      |
|    std                      | 0.184      |
|    value_loss               | 0.0369     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 513       |
|    ep_rew_mean              | 832       |
| time/                       |           |
|    fps                      | 154       |
|    iterations               | 315       |
|    time_elapsed             | 4185      |
|    total_timesteps          | 645120    |
| train/                      |           |
|    approx_kl                | 4.7893753 |
|    clip_fraction            | 0.95      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.0861673 |
|    ent_clip_fraction        | 0.473     |
|    ent_entropy_loss         | 2.81      |
|    ent_loss                 | -0.0461   |
|    ent_policy_gradient_loss | -0.0412   |
|    ent_std                  | 0.17      |
|    ent_value_loss           | 0.0335    |
|    entropy_loss             | 2.22      |
|    explained_variance       | 0.906     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0799    |
|    n_updates                | 3140      |
|    policy_gradient_loss     | 0.129     |
|    std                      | 0.183     |
|    value_loss               | 0.0323    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 508        |
|    ep_rew_mean              | 824        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 316        |
|    time_elapsed             | 4195       |
|    total_timesteps          | 647168     |
| train/                      |            |
|    approx_kl                | 3.5877347  |
|    clip_fraction            | 0.938      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.16076253 |
|    ent_clip_fraction        | 0.522      |
|    ent_entropy_loss         | 2.86       |
|    ent_loss                 | -0.0318    |
|    ent_policy_gradient_loss | -0.0229    |
|    ent_std                  | 0.169      |
|    ent_value_loss           | 0.06       |
|    entropy_loss             | 2.25       |
|    explained_variance       | 0.779      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.11       |
|    n_updates                | 3150       |
|    policy_gradient_loss     | 0.174      |
|    std                      | 0.182      |
|    value_loss               | 0.0626     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 521        |
|    ep_rew_mean              | 851        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 317        |
|    time_elapsed             | 4205       |
|    total_timesteps          | 649216     |
| train/                      |            |
|    approx_kl                | 3.5915103  |
|    clip_fraction            | 0.935      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.25871977 |
|    ent_clip_fraction        | 0.52       |
|    ent_entropy_loss         | 2.86       |
|    ent_loss                 | -0.052     |
|    ent_policy_gradient_loss | -0.0189    |
|    ent_std                  | 0.169      |
|    ent_value_loss           | 0.031      |
|    entropy_loss             | 2.28       |
|    explained_variance       | 0.89       |
|    learning_rate            | 0.0003     |
|    loss                     | 0.102      |
|    n_updates                | 3160       |
|    policy_gradient_loss     | 0.196      |
|    std                      | 0.182      |
|    value_loss               | 0.0291     |
--------------------------------------------
Eval num_timesteps=650000, episode_reward=1643.24 +/- 659.47
Episode length: 875.72 +/- 263.12
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 876       |
|    mean_reward              | 1.64e+03  |
| time/                       |           |
|    total_timesteps          | 650000    |
| train/                      |           |
|    approx_kl                | 1.2847611 |
|    clip_fraction            | 0.86      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.6531207 |
|    ent_clip_fraction        | 0.671     |
|    ent_entropy_loss         | 2.87      |
|    ent_loss                 | 0.0576    |
|    ent_policy_gradient_loss | 0.0392    |
|    ent_std                  | 0.169     |
|    ent_value_loss           | 0.0141    |
|    entropy_loss             | 2.32      |
|    explained_variance       | 0.228     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.201     |
|    n_updates                | 3170      |
|    policy_gradient_loss     | 0.17      |
|    std                      | 0.181     |
|    value_loss               | 0.0152    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 527      |
|    ep_rew_mean     | 865      |
| time/              |          |
|    fps             | 153      |
|    iterations      | 318      |
|    time_elapsed    | 4234     |
|    total_timesteps | 651264   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 523        |
|    ep_rew_mean              | 860        |
| time/                       |            |
|    fps                      | 153        |
|    iterations               | 319        |
|    time_elapsed             | 4244       |
|    total_timesteps          | 653312     |
| train/                      |            |
|    approx_kl                | 1.7891908  |
|    clip_fraction            | 0.916      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.26869023 |
|    ent_clip_fraction        | 0.553      |
|    ent_entropy_loss         | 2.86       |
|    ent_loss                 | -0.0431    |
|    ent_policy_gradient_loss | -0.0239    |
|    ent_std                  | 0.169      |
|    ent_value_loss           | 0.0579     |
|    entropy_loss             | 2.33       |
|    explained_variance       | 0.296      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.14       |
|    n_updates                | 3180       |
|    policy_gradient_loss     | 0.133      |
|    std                      | 0.181      |
|    value_loss               | 0.0569     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 515        |
|    ep_rew_mean              | 859        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 320        |
|    time_elapsed             | 4254       |
|    total_timesteps          | 655360     |
| train/                      |            |
|    approx_kl                | 1.7134386  |
|    clip_fraction            | 0.928      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.06467569 |
|    ent_clip_fraction        | 0.49       |
|    ent_entropy_loss         | 2.89       |
|    ent_loss                 | -0.0425    |
|    ent_policy_gradient_loss | -0.0453    |
|    ent_std                  | 0.168      |
|    ent_value_loss           | 0.0826     |
|    entropy_loss             | 2.33       |
|    explained_variance       | 0.318      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0952     |
|    n_updates                | 3190       |
|    policy_gradient_loss     | 0.144      |
|    std                      | 0.181      |
|    value_loss               | 0.0786     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 531        |
|    ep_rew_mean              | 889        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 321        |
|    time_elapsed             | 4264       |
|    total_timesteps          | 657408     |
| train/                      |            |
|    approx_kl                | 1.7811128  |
|    clip_fraction            | 0.928      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.06877844 |
|    ent_clip_fraction        | 0.514      |
|    ent_entropy_loss         | 2.9        |
|    ent_loss                 | -0.0195    |
|    ent_policy_gradient_loss | -0.045     |
|    ent_std                  | 0.168      |
|    ent_value_loss           | 0.0644     |
|    entropy_loss             | 2.3        |
|    explained_variance       | 0.312      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.114      |
|    n_updates                | 3200       |
|    policy_gradient_loss     | 0.155      |
|    std                      | 0.182      |
|    value_loss               | 0.0653     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 538       |
|    ep_rew_mean              | 909       |
| time/                       |           |
|    fps                      | 154       |
|    iterations               | 322       |
|    time_elapsed             | 4274      |
|    total_timesteps          | 659456    |
| train/                      |           |
|    approx_kl                | 1.508385  |
|    clip_fraction            | 0.888     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.6005382 |
|    ent_clip_fraction        | 0.638     |
|    ent_entropy_loss         | 2.93      |
|    ent_loss                 | -0.0537   |
|    ent_policy_gradient_loss | 0.0235    |
|    ent_std                  | 0.168     |
|    ent_value_loss           | 0.0305    |
|    entropy_loss             | 2.28      |
|    explained_variance       | 0.588     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.149     |
|    n_updates                | 3210      |
|    policy_gradient_loss     | 0.162     |
|    std                      | 0.182     |
|    value_loss               | 0.0323    |
-------------------------------------------
Eval num_timesteps=660000, episode_reward=1391.02 +/- 729.80
Episode length: 727.88 +/- 351.19
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 728       |
|    mean_reward              | 1.39e+03  |
| time/                       |           |
|    total_timesteps          | 660000    |
| train/                      |           |
|    approx_kl                | 1.6110256 |
|    clip_fraction            | 0.914     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.2613647 |
|    ent_clip_fraction        | 0.544     |
|    ent_entropy_loss         | 2.98      |
|    ent_loss                 | -0.0433   |
|    ent_policy_gradient_loss | -0.0257   |
|    ent_std                  | 0.166     |
|    ent_value_loss           | 0.0273    |
|    entropy_loss             | 2.29      |
|    explained_variance       | 0.474     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.165     |
|    n_updates                | 3220      |
|    policy_gradient_loss     | 0.155     |
|    std                      | 0.181     |
|    value_loss               | 0.0283    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 545      |
|    ep_rew_mean     | 932      |
| time/              |          |
|    fps             | 153      |
|    iterations      | 323      |
|    time_elapsed    | 4302     |
|    total_timesteps | 661504   |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 551       |
|    ep_rew_mean              | 940       |
| time/                       |           |
|    fps                      | 153       |
|    iterations               | 324       |
|    time_elapsed             | 4312      |
|    total_timesteps          | 663552    |
| train/                      |           |
|    approx_kl                | 2.3294225 |
|    clip_fraction            | 0.832     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.8331642 |
|    ent_clip_fraction        | 0.692     |
|    ent_entropy_loss         | 2.98      |
|    ent_loss                 | 0.0503    |
|    ent_policy_gradient_loss | 0.055     |
|    ent_std                  | 0.167     |
|    ent_value_loss           | 0.0395    |
|    entropy_loss             | 2.32      |
|    explained_variance       | 0.858     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0821    |
|    n_updates                | 3230      |
|    policy_gradient_loss     | 0.0904    |
|    std                      | 0.181     |
|    value_loss               | 0.0382    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 558        |
|    ep_rew_mean              | 943        |
| time/                       |            |
|    fps                      | 153        |
|    iterations               | 325        |
|    time_elapsed             | 4323       |
|    total_timesteps          | 665600     |
| train/                      |            |
|    approx_kl                | 2.1295006  |
|    clip_fraction            | 0.947      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.19352642 |
|    ent_clip_fraction        | 0.519      |
|    ent_entropy_loss         | 2.97       |
|    ent_loss                 | -0.0235    |
|    ent_policy_gradient_loss | -0.0227    |
|    ent_std                  | 0.166      |
|    ent_value_loss           | 0.0415     |
|    entropy_loss             | 2.34       |
|    explained_variance       | 0.913      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.147      |
|    n_updates                | 3240       |
|    policy_gradient_loss     | 0.143      |
|    std                      | 0.181      |
|    value_loss               | 0.0409     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 575        |
|    ep_rew_mean              | 965        |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 326        |
|    time_elapsed             | 4333       |
|    total_timesteps          | 667648     |
| train/                      |            |
|    approx_kl                | 1.829531   |
|    clip_fraction            | 0.935      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.12672874 |
|    ent_clip_fraction        | 0.484      |
|    ent_entropy_loss         | 3.03       |
|    ent_loss                 | -0.0404    |
|    ent_policy_gradient_loss | -0.0252    |
|    ent_std                  | 0.165      |
|    ent_value_loss           | 0.0366     |
|    entropy_loss             | 2.32       |
|    explained_variance       | 0.881      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0977     |
|    n_updates                | 3250       |
|    policy_gradient_loss     | 0.133      |
|    std                      | 0.181      |
|    value_loss               | 0.0352     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 578       |
|    ep_rew_mean              | 975       |
| time/                       |           |
|    fps                      | 154       |
|    iterations               | 327       |
|    time_elapsed             | 4343      |
|    total_timesteps          | 669696    |
| train/                      |           |
|    approx_kl                | 1.2564056 |
|    clip_fraction            | 0.848     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.9010389 |
|    ent_clip_fraction        | 0.706     |
|    ent_entropy_loss         | 3.04      |
|    ent_loss                 | -0.0243   |
|    ent_policy_gradient_loss | 0.0308    |
|    ent_std                  | 0.166     |
|    ent_value_loss           | 0.0469    |
|    entropy_loss             | 2.34      |
|    explained_variance       | 0.518     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0923    |
|    n_updates                | 3260      |
|    policy_gradient_loss     | 0.0783    |
|    std                      | 0.181     |
|    value_loss               | 0.0487    |
-------------------------------------------
Eval num_timesteps=670000, episode_reward=1629.68 +/- 810.28
Episode length: 791.32 +/- 338.56
---------------------------------------------
| eval/                       |             |
|    mean_ep_length           | 791         |
|    mean_reward              | 1.63e+03    |
| time/                       |             |
|    total_timesteps          | 670000      |
| train/                      |             |
|    approx_kl                | 2.0578725   |
|    clip_fraction            | 0.94        |
|    clip_range               | 0.2         |
|    ent_approx_kl            | 0.086164325 |
|    ent_clip_fraction        | 0.506       |
|    ent_entropy_loss         | 3.08        |
|    ent_loss                 | -0.0249     |
|    ent_policy_gradient_loss | -0.0427     |
|    ent_std                  | 0.164       |
|    ent_value_loss           | 0.0698      |
|    entropy_loss             | 2.36        |
|    explained_variance       | 0.478       |
|    learning_rate            | 0.0003      |
|    loss                     | 0.191       |
|    n_updates                | 3270        |
|    policy_gradient_loss     | 0.176       |
|    std                      | 0.18        |
|    value_loss               | 0.0687      |
---------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 586      |
|    ep_rew_mean     | 992      |
| time/              |          |
|    fps             | 153      |
|    iterations      | 328      |
|    time_elapsed    | 4372     |
|    total_timesteps | 671744   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 586        |
|    ep_rew_mean              | 993        |
| time/                       |            |
|    fps                      | 153        |
|    iterations               | 329        |
|    time_elapsed             | 4382       |
|    total_timesteps          | 673792     |
| train/                      |            |
|    approx_kl                | 1.8405745  |
|    clip_fraction            | 0.942      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.07468323 |
|    ent_clip_fraction        | 0.479      |
|    ent_entropy_loss         | 3.11       |
|    ent_loss                 | -0.0371    |
|    ent_policy_gradient_loss | -0.0413    |
|    ent_std                  | 0.164      |
|    ent_value_loss           | 0.0705     |
|    entropy_loss             | 2.37       |
|    explained_variance       | 0.778      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.137      |
|    n_updates                | 3280       |
|    policy_gradient_loss     | 0.158      |
|    std                      | 0.18       |
|    value_loss               | 0.0687     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 582       |
|    ep_rew_mean              | 1e+03     |
| time/                       |           |
|    fps                      | 153       |
|    iterations               | 330       |
|    time_elapsed             | 4392      |
|    total_timesteps          | 675840    |
| train/                      |           |
|    approx_kl                | 1.6798713 |
|    clip_fraction            | 0.898     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.5547304 |
|    ent_clip_fraction        | 0.606     |
|    ent_entropy_loss         | 3.16      |
|    ent_loss                 | -0.0117   |
|    ent_policy_gradient_loss | 0.0195    |
|    ent_std                  | 0.163     |
|    ent_value_loss           | 0.0412    |
|    entropy_loss             | 2.35      |
|    explained_variance       | 0.895     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.102     |
|    n_updates                | 3290      |
|    policy_gradient_loss     | 0.123     |
|    std                      | 0.181     |
|    value_loss               | 0.0427    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 596        |
|    ep_rew_mean              | 1.02e+03   |
| time/                       |            |
|    fps                      | 153        |
|    iterations               | 331        |
|    time_elapsed             | 4402       |
|    total_timesteps          | 677888     |
| train/                      |            |
|    approx_kl                | 1.5939426  |
|    clip_fraction            | 0.923      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.31489193 |
|    ent_clip_fraction        | 0.579      |
|    ent_entropy_loss         | 3.23       |
|    ent_loss                 | -0.0504    |
|    ent_policy_gradient_loss | -0.0162    |
|    ent_std                  | 0.161      |
|    ent_value_loss           | 0.0346     |
|    entropy_loss             | 2.35       |
|    explained_variance       | 0.425      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.202      |
|    n_updates                | 3300       |
|    policy_gradient_loss     | 0.169      |
|    std                      | 0.18       |
|    value_loss               | 0.0342     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 611        |
|    ep_rew_mean              | 1.04e+03   |
| time/                       |            |
|    fps                      | 154        |
|    iterations               | 332        |
|    time_elapsed             | 4412       |
|    total_timesteps          | 679936     |
| train/                      |            |
|    approx_kl                | 1.8526328  |
|    clip_fraction            | 0.928      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.38661397 |
|    ent_clip_fraction        | 0.555      |
|    ent_entropy_loss         | 3.28       |
|    ent_loss                 | -0.0418    |
|    ent_policy_gradient_loss | -0.0208    |
|    ent_std                  | 0.16       |
|    ent_value_loss           | 0.0136     |
|    entropy_loss             | 2.38       |
|    explained_variance       | 0.939      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0345     |
|    n_updates                | 3310       |
|    policy_gradient_loss     | 0.198      |
|    std                      | 0.18       |
|    value_loss               | 0.0136     |
--------------------------------------------
Eval num_timesteps=680000, episode_reward=2071.94 +/- 555.56
Episode length: 941.56 +/- 164.66
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 942       |
|    mean_reward              | 2.07e+03  |
| time/                       |           |
|    total_timesteps          | 680000    |
| train/                      |           |
|    approx_kl                | 2.0727253 |
|    clip_fraction            | 0.867     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.8649899 |
|    ent_clip_fraction        | 0.709     |
|    ent_entropy_loss         | 3.3       |
|    ent_loss                 | -0.00246  |
|    ent_policy_gradient_loss | 0.0269    |
|    ent_std                  | 0.16      |
|    ent_value_loss           | 0.0366    |
|    entropy_loss             | 2.37      |
|    explained_variance       | 0.78      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0472    |
|    n_updates                | 3320      |
|    policy_gradient_loss     | 0.132     |
|    std                      | 0.18      |
|    value_loss               | 0.0375    |
-------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 612      |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 333      |
|    time_elapsed    | 4444     |
|    total_timesteps | 681984   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 625        |
|    ep_rew_mean              | 1.07e+03   |
| time/                       |            |
|    fps                      | 153        |
|    iterations               | 334        |
|    time_elapsed             | 4455       |
|    total_timesteps          | 684032     |
| train/                      |            |
|    approx_kl                | 1.9453133  |
|    clip_fraction            | 0.942      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.06638459 |
|    ent_clip_fraction        | 0.503      |
|    ent_entropy_loss         | 3.31       |
|    ent_loss                 | -0.0322    |
|    ent_policy_gradient_loss | -0.0386    |
|    ent_std                  | 0.16       |
|    ent_value_loss           | 0.0547     |
|    entropy_loss             | 2.37       |
|    explained_variance       | 0.661      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0767     |
|    n_updates                | 3330       |
|    policy_gradient_loss     | 0.159      |
|    std                      | 0.179      |
|    value_loss               | 0.0516     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 627        |
|    ep_rew_mean              | 1.08e+03   |
| time/                       |            |
|    fps                      | 153        |
|    iterations               | 335        |
|    time_elapsed             | 4465       |
|    total_timesteps          | 686080     |
| train/                      |            |
|    approx_kl                | 2.0975518  |
|    clip_fraction            | 0.925      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.31753594 |
|    ent_clip_fraction        | 0.588      |
|    ent_entropy_loss         | 3.33       |
|    ent_loss                 | -0.0515    |
|    ent_policy_gradient_loss | -0.0143    |
|    ent_std                  | 0.159      |
|    ent_value_loss           | 0.0115     |
|    entropy_loss             | 2.43       |
|    explained_variance       | 0.95       |
|    learning_rate            | 0.0003     |
|    loss                     | 0.211      |
|    n_updates                | 3340       |
|    policy_gradient_loss     | 0.207      |
|    std                      | 0.178      |
|    value_loss               | 0.0111     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 637        |
|    ep_rew_mean              | 1.1e+03    |
| time/                       |            |
|    fps                      | 153        |
|    iterations               | 336        |
|    time_elapsed             | 4475       |
|    total_timesteps          | 688128     |
| train/                      |            |
|    approx_kl                | 1.959464   |
|    clip_fraction            | 0.912      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.55022526 |
|    ent_clip_fraction        | 0.624      |
|    ent_entropy_loss         | 3.37       |
|    ent_loss                 | -0.0825    |
|    ent_policy_gradient_loss | -0.0112    |
|    ent_std                  | 0.158      |
|    ent_value_loss           | 0.0208     |
|    entropy_loss             | 2.5        |
|    explained_variance       | 0.963      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0808     |
|    n_updates                | 3350       |
|    policy_gradient_loss     | 0.159      |
|    std                      | 0.177      |
|    value_loss               | 0.0231     |
--------------------------------------------
Eval num_timesteps=690000, episode_reward=1310.74 +/- 822.74
Episode length: 695.72 +/- 384.86
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 696       |
|    mean_reward              | 1.31e+03  |
| time/                       |           |
|    total_timesteps          | 690000    |
| train/                      |           |
|    approx_kl                | 3.556592  |
|    clip_fraction            | 0.878     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.0961368 |
|    ent_clip_fraction        | 0.678     |
|    ent_entropy_loss         | 3.41      |
|    ent_loss                 | 0.00772   |
|    ent_policy_gradient_loss | 0.03      |
|    ent_std                  | 0.158     |
|    ent_value_loss           | 0.0212    |
|    entropy_loss             | 2.52      |
|    explained_variance       | 0.943     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0873    |
|    n_updates                | 3360      |
|    policy_gradient_loss     | 0.127     |
|    std                      | 0.176     |
|    value_loss               | 0.0221    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 633      |
|    ep_rew_mean     | 1.1e+03  |
| time/              |          |
|    fps             | 153      |
|    iterations      | 337      |
|    time_elapsed    | 4501     |
|    total_timesteps | 690176   |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 642       |
|    ep_rew_mean              | 1.12e+03  |
| time/                       |           |
|    fps                      | 153       |
|    iterations               | 338       |
|    time_elapsed             | 4511      |
|    total_timesteps          | 692224    |
| train/                      |           |
|    approx_kl                | 2.8742018 |
|    clip_fraction            | 0.91      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.7165307 |
|    ent_clip_fraction        | 0.628     |
|    ent_entropy_loss         | 3.47      |
|    ent_loss                 | -0.029    |
|    ent_policy_gradient_loss | 0.00161   |
|    ent_std                  | 0.156     |
|    ent_value_loss           | 0.0407    |
|    entropy_loss             | 2.55      |
|    explained_variance       | 0.878     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0717    |
|    n_updates                | 3370      |
|    policy_gradient_loss     | 0.158     |
|    std                      | 0.176     |
|    value_loss               | 0.0408    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 633        |
|    ep_rew_mean              | 1.1e+03    |
| time/                       |            |
|    fps                      | 153        |
|    iterations               | 339        |
|    time_elapsed             | 4522       |
|    total_timesteps          | 694272     |
| train/                      |            |
|    approx_kl                | 2.3899152  |
|    clip_fraction            | 0.951      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.16155417 |
|    ent_clip_fraction        | 0.541      |
|    ent_entropy_loss         | 3.51       |
|    ent_loss                 | -0.0442    |
|    ent_policy_gradient_loss | -0.0326    |
|    ent_std                  | 0.156      |
|    ent_value_loss           | 0.0461     |
|    entropy_loss             | 2.56       |
|    explained_variance       | 0.815      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.146      |
|    n_updates                | 3380       |
|    policy_gradient_loss     | 0.185      |
|    std                      | 0.175      |
|    value_loss               | 0.0437     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 639       |
|    ep_rew_mean              | 1.11e+03  |
| time/                       |           |
|    fps                      | 153       |
|    iterations               | 340       |
|    time_elapsed             | 4532      |
|    total_timesteps          | 696320    |
| train/                      |           |
|    approx_kl                | 2.2439687 |
|    clip_fraction            | 0.923     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.5983435 |
|    ent_clip_fraction        | 0.588     |
|    ent_entropy_loss         | 3.51      |
|    ent_loss                 | -0.00972  |
|    ent_policy_gradient_loss | 0.00767   |
|    ent_std                  | 0.156     |
|    ent_value_loss           | 0.0234    |
|    entropy_loss             | 2.59      |
|    explained_variance       | 0.916     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0514    |
|    n_updates                | 3390      |
|    policy_gradient_loss     | 0.0922    |
|    std                      | 0.175     |
|    value_loss               | 0.0253    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 637       |
|    ep_rew_mean              | 1.1e+03   |
| time/                       |           |
|    fps                      | 153       |
|    iterations               | 341       |
|    time_elapsed             | 4542      |
|    total_timesteps          | 698368    |
| train/                      |           |
|    approx_kl                | 3.0816255 |
|    clip_fraction            | 0.896     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.9241415 |
|    ent_clip_fraction        | 0.689     |
|    ent_entropy_loss         | 3.55      |
|    ent_loss                 | 0.0128    |
|    ent_policy_gradient_loss | 0.0182    |
|    ent_std                  | 0.155     |
|    ent_value_loss           | 0.0313    |
|    entropy_loss             | 2.6       |
|    explained_variance       | 0.912     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0581    |
|    n_updates                | 3400      |
|    policy_gradient_loss     | 0.144     |
|    std                      | 0.175     |
|    value_loss               | 0.0318    |
-------------------------------------------
Eval num_timesteps=700000, episode_reward=2093.81 +/- 652.66
Episode length: 890.28 +/- 252.70
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 890       |
|    mean_reward              | 2.09e+03  |
| time/                       |           |
|    total_timesteps          | 700000    |
| train/                      |           |
|    approx_kl                | 1.7992983 |
|    clip_fraction            | 0.914     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.5932939 |
|    ent_clip_fraction        | 0.614     |
|    ent_entropy_loss         | 3.6       |
|    ent_loss                 | -0.015    |
|    ent_policy_gradient_loss | -0.0162   |
|    ent_std                  | 0.154     |
|    ent_value_loss           | 0.0627    |
|    entropy_loss             | 2.63      |
|    explained_variance       | 0.87      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.096     |
|    n_updates                | 3410      |
|    policy_gradient_loss     | 0.165     |
|    std                      | 0.173     |
|    value_loss               | 0.0626    |
-------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 637      |
|    ep_rew_mean     | 1.11e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 342      |
|    time_elapsed    | 4570     |
|    total_timesteps | 700416   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 634        |
|    ep_rew_mean              | 1.11e+03   |
| time/                       |            |
|    fps                      | 153        |
|    iterations               | 343        |
|    time_elapsed             | 4580       |
|    total_timesteps          | 702464     |
| train/                      |            |
|    approx_kl                | 1.9519346  |
|    clip_fraction            | 0.917      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.52471787 |
|    ent_clip_fraction        | 0.594      |
|    ent_entropy_loss         | 3.64       |
|    ent_loss                 | -0.0511    |
|    ent_policy_gradient_loss | -0.00085   |
|    ent_std                  | 0.153      |
|    ent_value_loss           | 0.0224     |
|    entropy_loss             | 2.69       |
|    explained_variance       | 0.925      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0996     |
|    n_updates                | 3420       |
|    policy_gradient_loss     | 0.131      |
|    std                      | 0.173      |
|    value_loss               | 0.0223     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 636       |
|    ep_rew_mean              | 1.13e+03  |
| time/                       |           |
|    fps                      | 153       |
|    iterations               | 344       |
|    time_elapsed             | 4590      |
|    total_timesteps          | 704512    |
| train/                      |           |
|    approx_kl                | 2.5375726 |
|    clip_fraction            | 0.927     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.4337018 |
|    ent_clip_fraction        | 0.599     |
|    ent_entropy_loss         | 3.68      |
|    ent_loss                 | -0.037    |
|    ent_policy_gradient_loss | -0.00914  |
|    ent_std                  | 0.153     |
|    ent_value_loss           | 0.0474    |
|    entropy_loss             | 2.7       |
|    explained_variance       | 0.291     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.138     |
|    n_updates                | 3430      |
|    policy_gradient_loss     | 0.145     |
|    std                      | 0.173     |
|    value_loss               | 0.0458    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 641       |
|    ep_rew_mean              | 1.14e+03  |
| time/                       |           |
|    fps                      | 153       |
|    iterations               | 345       |
|    time_elapsed             | 4600      |
|    total_timesteps          | 706560    |
| train/                      |           |
|    approx_kl                | 1.8960048 |
|    clip_fraction            | 0.906     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.7599481 |
|    ent_clip_fraction        | 0.659     |
|    ent_entropy_loss         | 3.7       |
|    ent_loss                 | -0.0308   |
|    ent_policy_gradient_loss | 0.036     |
|    ent_std                  | 0.152     |
|    ent_value_loss           | 0.0103    |
|    entropy_loss             | 2.72      |
|    explained_variance       | 0.313     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.116     |
|    n_updates                | 3440      |
|    policy_gradient_loss     | 0.185     |
|    std                      | 0.172     |
|    value_loss               | 0.0104    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 638        |
|    ep_rew_mean              | 1.15e+03   |
| time/                       |            |
|    fps                      | 153        |
|    iterations               | 346        |
|    time_elapsed             | 4610       |
|    total_timesteps          | 708608     |
| train/                      |            |
|    approx_kl                | 2.1990325  |
|    clip_fraction            | 0.947      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.22668555 |
|    ent_clip_fraction        | 0.551      |
|    ent_entropy_loss         | 3.69       |
|    ent_loss                 | -0.0197    |
|    ent_policy_gradient_loss | -0.025     |
|    ent_std                  | 0.153      |
|    ent_value_loss           | 0.0483     |
|    entropy_loss             | 2.73       |
|    explained_variance       | 0.315      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.179      |
|    n_updates                | 3450       |
|    policy_gradient_loss     | 0.166      |
|    std                      | 0.172      |
|    value_loss               | 0.0482     |
--------------------------------------------
Eval num_timesteps=710000, episode_reward=1746.63 +/- 671.71
Episode length: 844.92 +/- 292.47
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 845       |
|    mean_reward              | 1.75e+03  |
| time/                       |           |
|    total_timesteps          | 710000    |
| train/                      |           |
|    approx_kl                | 1.9572582 |
|    clip_fraction            | 0.916     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.5585525 |
|    ent_clip_fraction        | 0.61      |
|    ent_entropy_loss         | 3.69      |
|    ent_loss                 | -0.00303  |
|    ent_policy_gradient_loss | 0.00816   |
|    ent_std                  | 0.153     |
|    ent_value_loss           | 0.0302    |
|    entropy_loss             | 2.72      |
|    explained_variance       | 0.287     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.129     |
|    n_updates                | 3460      |
|    policy_gradient_loss     | 0.18      |
|    std                      | 0.173     |
|    value_loss               | 0.0328    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 642      |
|    ep_rew_mean     | 1.16e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 347      |
|    time_elapsed    | 4638     |
|    total_timesteps | 710656   |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 629       |
|    ep_rew_mean              | 1.15e+03  |
| time/                       |           |
|    fps                      | 153       |
|    iterations               | 348       |
|    time_elapsed             | 4648      |
|    total_timesteps          | 712704    |
| train/                      |           |
|    approx_kl                | 1.845274  |
|    clip_fraction            | 0.883     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.9089674 |
|    ent_clip_fraction        | 0.666     |
|    ent_entropy_loss         | 3.71      |
|    ent_loss                 | -0.00823  |
|    ent_policy_gradient_loss | 0.00494   |
|    ent_std                  | 0.152     |
|    ent_value_loss           | 0.0537    |
|    entropy_loss             | 2.72      |
|    explained_variance       | 0.34      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0471    |
|    n_updates                | 3470      |
|    policy_gradient_loss     | 0.136     |
|    std                      | 0.172     |
|    value_loss               | 0.0523    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 637        |
|    ep_rew_mean              | 1.16e+03   |
| time/                       |            |
|    fps                      | 153        |
|    iterations               | 349        |
|    time_elapsed             | 4658       |
|    total_timesteps          | 714752     |
| train/                      |            |
|    approx_kl                | 2.1551373  |
|    clip_fraction            | 0.935      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.38109255 |
|    ent_clip_fraction        | 0.584      |
|    ent_entropy_loss         | 3.72       |
|    ent_loss                 | -0.0202    |
|    ent_policy_gradient_loss | -0.0104    |
|    ent_std                  | 0.152      |
|    ent_value_loss           | 0.0403     |
|    entropy_loss             | 2.73       |
|    explained_variance       | 0.497      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.12       |
|    n_updates                | 3480       |
|    policy_gradient_loss     | 0.153      |
|    std                      | 0.172      |
|    value_loss               | 0.0376     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 638       |
|    ep_rew_mean              | 1.16e+03  |
| time/                       |           |
|    fps                      | 153       |
|    iterations               | 350       |
|    time_elapsed             | 4668      |
|    total_timesteps          | 716800    |
| train/                      |           |
|    approx_kl                | 2.2824078 |
|    clip_fraction            | 0.849     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.1437479 |
|    ent_clip_fraction        | 0.724     |
|    ent_entropy_loss         | 3.74      |
|    ent_loss                 | 0.133     |
|    ent_policy_gradient_loss | 0.0523    |
|    ent_std                  | 0.152     |
|    ent_value_loss           | 0.0407    |
|    entropy_loss             | 2.77      |
|    explained_variance       | 0.905     |
|    learning_rate            | 0.0003    |
|    loss                     | -0.00271  |
|    n_updates                | 3490      |
|    policy_gradient_loss     | 0.1       |
|    std                      | 0.171     |
|    value_loss               | 0.0443    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 650        |
|    ep_rew_mean              | 1.17e+03   |
| time/                       |            |
|    fps                      | 153        |
|    iterations               | 351        |
|    time_elapsed             | 4679       |
|    total_timesteps          | 718848     |
| train/                      |            |
|    approx_kl                | 1.8720069  |
|    clip_fraction            | 0.939      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.13507418 |
|    ent_clip_fraction        | 0.5        |
|    ent_entropy_loss         | 3.79       |
|    ent_loss                 | -0.0436    |
|    ent_policy_gradient_loss | -0.0379    |
|    ent_std                  | 0.15       |
|    ent_value_loss           | 0.0282     |
|    entropy_loss             | 2.82       |
|    explained_variance       | 0.949      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.112      |
|    n_updates                | 3500       |
|    policy_gradient_loss     | 0.16       |
|    std                      | 0.169      |
|    value_loss               | 0.027      |
--------------------------------------------
Eval num_timesteps=720000, episode_reward=2147.48 +/- 492.27
Episode length: 959.40 +/- 137.87
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 959       |
|    mean_reward              | 2.15e+03  |
| time/                       |           |
|    total_timesteps          | 720000    |
| train/                      |           |
|    approx_kl                | 1.3868139 |
|    clip_fraction            | 0.849     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.0270721 |
|    ent_clip_fraction        | 0.736     |
|    ent_entropy_loss         | 3.8       |
|    ent_loss                 | -0.0175   |
|    ent_policy_gradient_loss | 0.0647    |
|    ent_std                  | 0.151     |
|    ent_value_loss           | 0.00876   |
|    entropy_loss             | 2.89      |
|    explained_variance       | 0.92      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.19      |
|    n_updates                | 3510      |
|    policy_gradient_loss     | 0.156     |
|    std                      | 0.169     |
|    value_loss               | 0.00905   |
-------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 666      |
|    ep_rew_mean     | 1.2e+03  |
| time/              |          |
|    fps             | 153      |
|    iterations      | 352      |
|    time_elapsed    | 4707     |
|    total_timesteps | 720896   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 671        |
|    ep_rew_mean              | 1.19e+03   |
| time/                       |            |
|    fps                      | 153        |
|    iterations               | 353        |
|    time_elapsed             | 4717       |
|    total_timesteps          | 722944     |
| train/                      |            |
|    approx_kl                | 2.1395054  |
|    clip_fraction            | 0.921      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.34462708 |
|    ent_clip_fraction        | 0.555      |
|    ent_entropy_loss         | 3.8        |
|    ent_loss                 | 0.00292    |
|    ent_policy_gradient_loss | -0.0139    |
|    ent_std                  | 0.15       |
|    ent_value_loss           | 0.0236     |
|    entropy_loss             | 2.92       |
|    explained_variance       | 0.954      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.158      |
|    n_updates                | 3520       |
|    policy_gradient_loss     | 0.135      |
|    std                      | 0.168      |
|    value_loss               | 0.024      |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 657        |
|    ep_rew_mean              | 1.16e+03   |
| time/                       |            |
|    fps                      | 153        |
|    iterations               | 354        |
|    time_elapsed             | 4727       |
|    total_timesteps          | 724992     |
| train/                      |            |
|    approx_kl                | 1.7813118  |
|    clip_fraction            | 0.891      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.59544396 |
|    ent_clip_fraction        | 0.606      |
|    ent_entropy_loss         | 3.83       |
|    ent_loss                 | -0.0106    |
|    ent_policy_gradient_loss | 0.0197     |
|    ent_std                  | 0.15       |
|    ent_value_loss           | 0.0295     |
|    entropy_loss             | 2.98       |
|    explained_variance       | 0.921      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0774     |
|    n_updates                | 3530       |
|    policy_gradient_loss     | 0.0997     |
|    std                      | 0.166      |
|    value_loss               | 0.0302     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 662       |
|    ep_rew_mean              | 1.15e+03  |
| time/                       |           |
|    fps                      | 153       |
|    iterations               | 355       |
|    time_elapsed             | 4737      |
|    total_timesteps          | 727040    |
| train/                      |           |
|    approx_kl                | 1.7429302 |
|    clip_fraction            | 0.914     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.5088084 |
|    ent_clip_fraction        | 0.562     |
|    ent_entropy_loss         | 3.87      |
|    ent_loss                 | -0.022    |
|    ent_policy_gradient_loss | -0.0224   |
|    ent_std                  | 0.149     |
|    ent_value_loss           | 0.0526    |
|    entropy_loss             | 3.03      |
|    explained_variance       | 0.858     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.106     |
|    n_updates                | 3540      |
|    policy_gradient_loss     | 0.164     |
|    std                      | 0.165     |
|    value_loss               | 0.0499    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 659       |
|    ep_rew_mean              | 1.14e+03  |
| time/                       |           |
|    fps                      | 153       |
|    iterations               | 356       |
|    time_elapsed             | 4748      |
|    total_timesteps          | 729088    |
| train/                      |           |
|    approx_kl                | 1.9130666 |
|    clip_fraction            | 0.905     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.780993  |
|    ent_clip_fraction        | 0.608     |
|    ent_entropy_loss         | 3.9       |
|    ent_loss                 | -0.0416   |
|    ent_policy_gradient_loss | 0.0491    |
|    ent_std                  | 0.149     |
|    ent_value_loss           | 0.00813   |
|    entropy_loss             | 3.06      |
|    explained_variance       | 0.967     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0366    |
|    n_updates                | 3550      |
|    policy_gradient_loss     | 0.1       |
|    std                      | 0.165     |
|    value_loss               | 0.00927   |
-------------------------------------------
Eval num_timesteps=730000, episode_reward=1563.20 +/- 786.79
Episode length: 757.60 +/- 346.24
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 758        |
|    mean_reward              | 1.56e+03   |
| time/                       |            |
|    total_timesteps          | 730000     |
| train/                      |            |
|    approx_kl                | 2.3725476  |
|    clip_fraction            | 0.945      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.33325368 |
|    ent_clip_fraction        | 0.566      |
|    ent_entropy_loss         | 3.91       |
|    ent_loss                 | -0.0448    |
|    ent_policy_gradient_loss | -0.0307    |
|    ent_std                  | 0.149      |
|    ent_value_loss           | 0.0257     |
|    entropy_loss             | 3.06       |
|    explained_variance       | 0.943      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.157      |
|    n_updates                | 3560       |
|    policy_gradient_loss     | 0.184      |
|    std                      | 0.165      |
|    value_loss               | 0.0246     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 662      |
|    ep_rew_mean     | 1.15e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 357      |
|    time_elapsed    | 4773     |
|    total_timesteps | 731136   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 669        |
|    ep_rew_mean              | 1.16e+03   |
| time/                       |            |
|    fps                      | 153        |
|    iterations               | 358        |
|    time_elapsed             | 4783       |
|    total_timesteps          | 733184     |
| train/                      |            |
|    approx_kl                | 2.8279653  |
|    clip_fraction            | 0.934      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.49668914 |
|    ent_clip_fraction        | 0.581      |
|    ent_entropy_loss         | 3.93       |
|    ent_loss                 | -0.0529    |
|    ent_policy_gradient_loss | -0.0185    |
|    ent_std                  | 0.148      |
|    ent_value_loss           | 0.0234     |
|    entropy_loss             | 3.07       |
|    explained_variance       | 0.923      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.118      |
|    n_updates                | 3570       |
|    policy_gradient_loss     | 0.169      |
|    std                      | 0.165      |
|    value_loss               | 0.0254     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 668       |
|    ep_rew_mean              | 1.16e+03  |
| time/                       |           |
|    fps                      | 153       |
|    iterations               | 359       |
|    time_elapsed             | 4794      |
|    total_timesteps          | 735232    |
| train/                      |           |
|    approx_kl                | 2.0316992 |
|    clip_fraction            | 0.881     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.0857801 |
|    ent_clip_fraction        | 0.702     |
|    ent_entropy_loss         | 3.95      |
|    ent_loss                 | -0.00266  |
|    ent_policy_gradient_loss | 0.0543    |
|    ent_std                  | 0.148     |
|    ent_value_loss           | 0.0306    |
|    entropy_loss             | 3.05      |
|    explained_variance       | 0.553     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0467    |
|    n_updates                | 3580      |
|    policy_gradient_loss     | 0.162     |
|    std                      | 0.166     |
|    value_loss               | 0.0304    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 673        |
|    ep_rew_mean              | 1.17e+03   |
| time/                       |            |
|    fps                      | 153        |
|    iterations               | 360        |
|    time_elapsed             | 4804       |
|    total_timesteps          | 737280     |
| train/                      |            |
|    approx_kl                | 1.9514315  |
|    clip_fraction            | 0.941      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.26870617 |
|    ent_clip_fraction        | 0.544      |
|    ent_entropy_loss         | 3.96       |
|    ent_loss                 | -0.05      |
|    ent_policy_gradient_loss | -0.0338    |
|    ent_std                  | 0.148      |
|    ent_value_loss           | 0.0434     |
|    entropy_loss             | 3.02       |
|    explained_variance       | 0.907      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.147      |
|    n_updates                | 3590       |
|    policy_gradient_loss     | 0.136      |
|    std                      | 0.166      |
|    value_loss               | 0.0417     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 677        |
|    ep_rew_mean              | 1.18e+03   |
| time/                       |            |
|    fps                      | 153        |
|    iterations               | 361        |
|    time_elapsed             | 4814       |
|    total_timesteps          | 739328     |
| train/                      |            |
|    approx_kl                | 2.548512   |
|    clip_fraction            | 0.955      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.08354528 |
|    ent_clip_fraction        | 0.552      |
|    ent_entropy_loss         | 3.99       |
|    ent_loss                 | -0.0364    |
|    ent_policy_gradient_loss | -0.0434    |
|    ent_std                  | 0.147      |
|    ent_value_loss           | 0.0549     |
|    entropy_loss             | 3.04       |
|    explained_variance       | 0.301      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.183      |
|    n_updates                | 3600       |
|    policy_gradient_loss     | 0.175      |
|    std                      | 0.165      |
|    value_loss               | 0.0539     |
--------------------------------------------
Eval num_timesteps=740000, episode_reward=2284.13 +/- 560.69
Episode length: 936.36 +/- 217.20
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 936       |
|    mean_reward              | 2.28e+03  |
| time/                       |           |
|    total_timesteps          | 740000    |
| train/                      |           |
|    approx_kl                | 2.3633735 |
|    clip_fraction            | 0.938     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.6017856 |
|    ent_clip_fraction        | 0.621     |
|    ent_entropy_loss         | 4.01      |
|    ent_loss                 | -0.0317   |
|    ent_policy_gradient_loss | -0.0193   |
|    ent_std                  | 0.147     |
|    ent_value_loss           | 0.0341    |
|    entropy_loss             | 3.08      |
|    explained_variance       | 0.288     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.157     |
|    n_updates                | 3610      |
|    policy_gradient_loss     | 0.179     |
|    std                      | 0.165     |
|    value_loss               | 0.0341    |
-------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 685      |
|    ep_rew_mean     | 1.2e+03  |
| time/              |          |
|    fps             | 153      |
|    iterations      | 362      |
|    time_elapsed    | 4842     |
|    total_timesteps | 741376   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 694        |
|    ep_rew_mean              | 1.23e+03   |
| time/                       |            |
|    fps                      | 153        |
|    iterations               | 363        |
|    time_elapsed             | 4852       |
|    total_timesteps          | 743424     |
| train/                      |            |
|    approx_kl                | 2.7634273  |
|    clip_fraction            | 0.947      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.30105487 |
|    ent_clip_fraction        | 0.591      |
|    ent_entropy_loss         | 4.05       |
|    ent_loss                 | -0.0482    |
|    ent_policy_gradient_loss | -0.00891   |
|    ent_std                  | 0.145      |
|    ent_value_loss           | 0.0167     |
|    entropy_loss             | 3.1        |
|    explained_variance       | 0.843      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.165      |
|    n_updates                | 3620       |
|    policy_gradient_loss     | 0.2        |
|    std                      | 0.164      |
|    value_loss               | 0.0176     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 711       |
|    ep_rew_mean              | 1.26e+03  |
| time/                       |           |
|    fps                      | 153       |
|    iterations               | 364       |
|    time_elapsed             | 4862      |
|    total_timesteps          | 745472    |
| train/                      |           |
|    approx_kl                | 2.3237317 |
|    clip_fraction            | 0.94      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.2322352 |
|    ent_clip_fraction        | 0.532     |
|    ent_entropy_loss         | 4.1       |
|    ent_loss                 | -0.0488   |
|    ent_policy_gradient_loss | -0.0281   |
|    ent_std                  | 0.145     |
|    ent_value_loss           | 0.0178    |
|    entropy_loss             | 3.13      |
|    explained_variance       | 0.951     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.11      |
|    n_updates                | 3630      |
|    policy_gradient_loss     | 0.167     |
|    std                      | 0.164     |
|    value_loss               | 0.017     |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 688       |
|    ep_rew_mean              | 1.24e+03  |
| time/                       |           |
|    fps                      | 153       |
|    iterations               | 365       |
|    time_elapsed             | 4873      |
|    total_timesteps          | 747520    |
| train/                      |           |
|    approx_kl                | 2.2186875 |
|    clip_fraction            | 0.918     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.9118904 |
|    ent_clip_fraction        | 0.65      |
|    ent_entropy_loss         | 4.14      |
|    ent_loss                 | 0.00373   |
|    ent_policy_gradient_loss | -0.00724  |
|    ent_std                  | 0.144     |
|    ent_value_loss           | 0.0304    |
|    entropy_loss             | 3.17      |
|    explained_variance       | 0.848     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.161     |
|    n_updates                | 3640      |
|    policy_gradient_loss     | 0.185     |
|    std                      | 0.163     |
|    value_loss               | 0.0299    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 693       |
|    ep_rew_mean              | 1.25e+03  |
| time/                       |           |
|    fps                      | 153       |
|    iterations               | 366       |
|    time_elapsed             | 4883      |
|    total_timesteps          | 749568    |
| train/                      |           |
|    approx_kl                | 2.6740456 |
|    clip_fraction            | 0.901     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.9356522 |
|    ent_clip_fraction        | 0.657     |
|    ent_entropy_loss         | 4.16      |
|    ent_loss                 | -0.0366   |
|    ent_policy_gradient_loss | 0.0188    |
|    ent_std                  | 0.144     |
|    ent_value_loss           | 0.0491    |
|    entropy_loss             | 3.2       |
|    explained_variance       | 0.526     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.119     |
|    n_updates                | 3650      |
|    policy_gradient_loss     | 0.148     |
|    std                      | 0.162     |
|    value_loss               | 0.051     |
-------------------------------------------
Eval num_timesteps=750000, episode_reward=1360.26 +/- 757.50
Episode length: 746.92 +/- 354.17
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 747        |
|    mean_reward              | 1.36e+03   |
| time/                       |            |
|    total_timesteps          | 750000     |
| train/                      |            |
|    approx_kl                | 2.5941992  |
|    clip_fraction            | 0.954      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.19497888 |
|    ent_clip_fraction        | 0.557      |
|    ent_entropy_loss         | 4.18       |
|    ent_loss                 | -0.0736    |
|    ent_policy_gradient_loss | -0.0407    |
|    ent_std                  | 0.143      |
|    ent_value_loss           | 0.0451     |
|    entropy_loss             | 3.19       |
|    explained_variance       | 0.457      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.191      |
|    n_updates                | 3660       |
|    policy_gradient_loss     | 0.187      |
|    std                      | 0.162      |
|    value_loss               | 0.0422     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 689      |
|    ep_rew_mean     | 1.25e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 367      |
|    time_elapsed    | 4911     |
|    total_timesteps | 751616   |
---------------------------------
------------------------------------------
| rollout/                    |          |
|    ep_len_mean              | 678      |
|    ep_rew_mean              | 1.23e+03 |
| time/                       |          |
|    fps                      | 153      |
|    iterations               | 368      |
|    time_elapsed             | 4921     |
|    total_timesteps          | 753664   |
| train/                      |          |
|    approx_kl                | 1.944463 |
|    clip_fraction            | 0.878    |
|    clip_range               | 0.2      |
|    ent_approx_kl            | 1.228473 |
|    ent_clip_fraction        | 0.718    |
|    ent_entropy_loss         | 4.21     |
|    ent_loss                 | 0.00142  |
|    ent_policy_gradient_loss | 0.156    |
|    ent_std                  | 0.143    |
|    ent_value_loss           | 0.0326   |
|    entropy_loss             | 3.24     |
|    explained_variance       | 0.447    |
|    learning_rate            | 0.0003   |
|    loss                     | 0.117    |
|    n_updates                | 3670     |
|    policy_gradient_loss     | 0.188    |
|    std                      | 0.162    |
|    value_loss               | 0.034    |
------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 655       |
|    ep_rew_mean              | 1.19e+03  |
| time/                       |           |
|    fps                      | 153       |
|    iterations               | 369       |
|    time_elapsed             | 4931      |
|    total_timesteps          | 755712    |
| train/                      |           |
|    approx_kl                | 1.7958928 |
|    clip_fraction            | 0.9       |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.8020059 |
|    ent_clip_fraction        | 0.653     |
|    ent_entropy_loss         | 4.22      |
|    ent_loss                 | 0.0356    |
|    ent_policy_gradient_loss | 0.00843   |
|    ent_std                  | 0.143     |
|    ent_value_loss           | 0.0444    |
|    entropy_loss             | 3.25      |
|    explained_variance       | 0.907     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0884    |
|    n_updates                | 3680      |
|    policy_gradient_loss     | 0.116     |
|    std                      | 0.162     |
|    value_loss               | 0.0459    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 667        |
|    ep_rew_mean              | 1.2e+03    |
| time/                       |            |
|    fps                      | 153        |
|    iterations               | 370        |
|    time_elapsed             | 4942       |
|    total_timesteps          | 757760     |
| train/                      |            |
|    approx_kl                | 1.6766155  |
|    clip_fraction            | 0.911      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.41991243 |
|    ent_clip_fraction        | 0.548      |
|    ent_entropy_loss         | 4.21       |
|    ent_loss                 | 0.0122     |
|    ent_policy_gradient_loss | -0.0157    |
|    ent_std                  | 0.143      |
|    ent_value_loss           | 0.0615     |
|    entropy_loss             | 3.3        |
|    explained_variance       | 0.861      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.083      |
|    n_updates                | 3690       |
|    policy_gradient_loss     | 0.142      |
|    std                      | 0.159      |
|    value_loss               | 0.0599     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 658       |
|    ep_rew_mean              | 1.19e+03  |
| time/                       |           |
|    fps                      | 153       |
|    iterations               | 371       |
|    time_elapsed             | 4952      |
|    total_timesteps          | 759808    |
| train/                      |           |
|    approx_kl                | 1.6359019 |
|    clip_fraction            | 0.861     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.0362042 |
|    ent_clip_fraction        | 0.648     |
|    ent_entropy_loss         | 4.2       |
|    ent_loss                 | 0.0198    |
|    ent_policy_gradient_loss | 0.0476    |
|    ent_std                  | 0.144     |
|    ent_value_loss           | 0.0217    |
|    entropy_loss             | 3.4       |
|    explained_variance       | 0.947     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.048     |
|    n_updates                | 3700      |
|    policy_gradient_loss     | 0.121     |
|    std                      | 0.158     |
|    value_loss               | 0.0221    |
-------------------------------------------
Eval num_timesteps=760000, episode_reward=1027.87 +/- 614.20
Episode length: 700.76 +/- 390.78
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 701        |
|    mean_reward              | 1.03e+03   |
| time/                       |            |
|    total_timesteps          | 760000     |
| train/                      |            |
|    approx_kl                | 2.116897   |
|    clip_fraction            | 0.906      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.39379096 |
|    ent_clip_fraction        | 0.551      |
|    ent_entropy_loss         | 4.21       |
|    ent_loss                 | -0.0156    |
|    ent_policy_gradient_loss | -0.0201    |
|    ent_std                  | 0.143      |
|    ent_value_loss           | 0.0493     |
|    entropy_loss             | 3.49       |
|    explained_variance       | 0.87       |
|    learning_rate            | 0.0003     |
|    loss                     | 0.122      |
|    n_updates                | 3710       |
|    policy_gradient_loss     | 0.129      |
|    std                      | 0.156      |
|    value_loss               | 0.0489     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 643      |
|    ep_rew_mean     | 1.16e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 372      |
|    time_elapsed    | 4978     |
|    total_timesteps | 761856   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 668        |
|    ep_rew_mean              | 1.22e+03   |
| time/                       |            |
|    fps                      | 153        |
|    iterations               | 373        |
|    time_elapsed             | 4988       |
|    total_timesteps          | 763904     |
| train/                      |            |
|    approx_kl                | 3.1117904  |
|    clip_fraction            | 0.921      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.49880096 |
|    ent_clip_fraction        | 0.583      |
|    ent_entropy_loss         | 4.22       |
|    ent_loss                 | -0.0249    |
|    ent_policy_gradient_loss | -0.00278   |
|    ent_std                  | 0.144      |
|    ent_value_loss           | 0.053      |
|    entropy_loss             | 3.54       |
|    explained_variance       | 0.883      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.166      |
|    n_updates                | 3720       |
|    policy_gradient_loss     | 0.157      |
|    std                      | 0.156      |
|    value_loss               | 0.0502     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 657        |
|    ep_rew_mean              | 1.2e+03    |
| time/                       |            |
|    fps                      | 153        |
|    iterations               | 374        |
|    time_elapsed             | 4998       |
|    total_timesteps          | 765952     |
| train/                      |            |
|    approx_kl                | 2.9915857  |
|    clip_fraction            | 0.949      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.32119042 |
|    ent_clip_fraction        | 0.573      |
|    ent_entropy_loss         | 4.21       |
|    ent_loss                 | -0.0627    |
|    ent_policy_gradient_loss | -0.0282    |
|    ent_std                  | 0.143      |
|    ent_value_loss           | 0.0292     |
|    entropy_loss             | 3.53       |
|    explained_variance       | -0.0141    |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0274     |
|    n_updates                | 3730       |
|    policy_gradient_loss     | 0.171      |
|    std                      | 0.156      |
|    value_loss               | 0.0277     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 671        |
|    ep_rew_mean              | 1.22e+03   |
| time/                       |            |
|    fps                      | 153        |
|    iterations               | 375        |
|    time_elapsed             | 5008       |
|    total_timesteps          | 768000     |
| train/                      |            |
|    approx_kl                | 1.8415365  |
|    clip_fraction            | 0.912      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.64973897 |
|    ent_clip_fraction        | 0.587      |
|    ent_entropy_loss         | 4.25       |
|    ent_loss                 | -0.0297    |
|    ent_policy_gradient_loss | -0.018     |
|    ent_std                  | 0.142      |
|    ent_value_loss           | 0.0362     |
|    entropy_loss             | 3.51       |
|    explained_variance       | 0.899      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.112      |
|    n_updates                | 3740       |
|    policy_gradient_loss     | 0.139      |
|    std                      | 0.157      |
|    value_loss               | 0.0348     |
--------------------------------------------
Eval num_timesteps=770000, episode_reward=2250.99 +/- 624.13
Episode length: 918.52 +/- 240.89
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 919       |
|    mean_reward              | 2.25e+03  |
| time/                       |           |
|    total_timesteps          | 770000    |
| train/                      |           |
|    approx_kl                | 3.2304888 |
|    clip_fraction            | 0.908     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.8597081 |
|    ent_clip_fraction        | 0.644     |
|    ent_entropy_loss         | 4.3       |
|    ent_loss                 | 0.0223    |
|    ent_policy_gradient_loss | 0.0138    |
|    ent_std                  | 0.142     |
|    ent_value_loss           | 0.0349    |
|    entropy_loss             | 3.48      |
|    explained_variance       | 0.9       |
|    learning_rate            | 0.0003    |
|    loss                     | 0.137     |
|    n_updates                | 3750      |
|    policy_gradient_loss     | 0.155     |
|    std                      | 0.157     |
|    value_loss               | 0.0369    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 661      |
|    ep_rew_mean     | 1.19e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 376      |
|    time_elapsed    | 5036     |
|    total_timesteps | 770048   |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 658       |
|    ep_rew_mean              | 1.18e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 377       |
|    time_elapsed             | 5046      |
|    total_timesteps          | 772096    |
| train/                      |           |
|    approx_kl                | 3.1716285 |
|    clip_fraction            | 0.799     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.6246593 |
|    ent_clip_fraction        | 0.772     |
|    ent_entropy_loss         | 4.28      |
|    ent_loss                 | 0.0437    |
|    ent_policy_gradient_loss | 0.114     |
|    ent_std                  | 0.143     |
|    ent_value_loss           | 0.0187    |
|    entropy_loss             | 3.51      |
|    explained_variance       | 0.94      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0634    |
|    n_updates                | 3760      |
|    policy_gradient_loss     | 0.0263    |
|    std                      | 0.156     |
|    value_loss               | 0.0227    |
-------------------------------------------
------------------------------------------
| rollout/                    |          |
|    ep_len_mean              | 667      |
|    ep_rew_mean              | 1.19e+03 |
| time/                       |          |
|    fps                      | 153      |
|    iterations               | 378      |
|    time_elapsed             | 5056     |
|    total_timesteps          | 774144   |
| train/                      |          |
|    approx_kl                | 3.045221 |
|    clip_fraction            | 0.9      |
|    clip_range               | 0.2      |
|    ent_approx_kl            | 1.162564 |
|    ent_clip_fraction        | 0.697    |
|    ent_entropy_loss         | 4.27     |
|    ent_loss                 | -0.0452  |
|    ent_policy_gradient_loss | 0.0127   |
|    ent_std                  | 0.142    |
|    ent_value_loss           | 0.0324   |
|    entropy_loss             | 3.54     |
|    explained_variance       | 0.844    |
|    learning_rate            | 0.0003   |
|    loss                     | 0.135    |
|    n_updates                | 3770     |
|    policy_gradient_loss     | 0.164    |
|    std                      | 0.155    |
|    value_loss               | 0.0341   |
------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 662       |
|    ep_rew_mean              | 1.18e+03  |
| time/                       |           |
|    fps                      | 153       |
|    iterations               | 379       |
|    time_elapsed             | 5067      |
|    total_timesteps          | 776192    |
| train/                      |           |
|    approx_kl                | 3.8478947 |
|    clip_fraction            | 0.889     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.1060817 |
|    ent_clip_fraction        | 0.682     |
|    ent_entropy_loss         | 4.32      |
|    ent_loss                 | -0.00854  |
|    ent_policy_gradient_loss | 0.0415    |
|    ent_std                  | 0.142     |
|    ent_value_loss           | 0.0245    |
|    entropy_loss             | 3.58      |
|    explained_variance       | 0.945     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0926    |
|    n_updates                | 3780      |
|    policy_gradient_loss     | 0.106     |
|    std                      | 0.155     |
|    value_loss               | 0.0249    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 671        |
|    ep_rew_mean              | 1.19e+03   |
| time/                       |            |
|    fps                      | 153        |
|    iterations               | 380        |
|    time_elapsed             | 5077       |
|    total_timesteps          | 778240     |
| train/                      |            |
|    approx_kl                | 2.5890899  |
|    clip_fraction            | 0.943      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.46453014 |
|    ent_clip_fraction        | 0.562      |
|    ent_entropy_loss         | 4.31       |
|    ent_loss                 | -0.0378    |
|    ent_policy_gradient_loss | -0.0245    |
|    ent_std                  | 0.141      |
|    ent_value_loss           | 0.0532     |
|    entropy_loss             | 3.54       |
|    explained_variance       | 0.855      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.147      |
|    n_updates                | 3790       |
|    policy_gradient_loss     | 0.153      |
|    std                      | 0.157      |
|    value_loss               | 0.0533     |
--------------------------------------------
Eval num_timesteps=780000, episode_reward=2383.12 +/- 420.61
Episode length: 997.88 +/- 10.39
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 998       |
|    mean_reward              | 2.38e+03  |
| time/                       |           |
|    total_timesteps          | 780000    |
| train/                      |           |
|    approx_kl                | 3.4531436 |
|    clip_fraction            | 0.933     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.6019965 |
|    ent_clip_fraction        | 0.624     |
|    ent_entropy_loss         | 4.33      |
|    ent_loss                 | -0.0551   |
|    ent_policy_gradient_loss | 0.00235   |
|    ent_std                  | 0.141     |
|    ent_value_loss           | 0.0183    |
|    entropy_loss             | 3.52      |
|    explained_variance       | 0.949     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.232     |
|    n_updates                | 3800      |
|    policy_gradient_loss     | 0.165     |
|    std                      | 0.156     |
|    value_loss               | 0.018     |
-------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 676      |
|    ep_rew_mean     | 1.21e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 381      |
|    time_elapsed    | 5105     |
|    total_timesteps | 780288   |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 681       |
|    ep_rew_mean              | 1.23e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 382       |
|    time_elapsed             | 5115      |
|    total_timesteps          | 782336    |
| train/                      |           |
|    approx_kl                | 2.1104233 |
|    clip_fraction            | 0.908     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.8560125 |
|    ent_clip_fraction        | 0.708     |
|    ent_entropy_loss         | 4.31      |
|    ent_loss                 | -0.0306   |
|    ent_policy_gradient_loss | 0.0609    |
|    ent_std                  | 0.142     |
|    ent_value_loss           | 0.0198    |
|    entropy_loss             | 3.56      |
|    explained_variance       | 0.472     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.126     |
|    n_updates                | 3810      |
|    policy_gradient_loss     | 0.122     |
|    std                      | 0.156     |
|    value_loss               | 0.0202    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 683       |
|    ep_rew_mean              | 1.23e+03  |
| time/                       |           |
|    fps                      | 153       |
|    iterations               | 383       |
|    time_elapsed             | 5126      |
|    total_timesteps          | 784384    |
| train/                      |           |
|    approx_kl                | 1.5765784 |
|    clip_fraction            | 0.807     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.6449893 |
|    ent_clip_fraction        | 0.778     |
|    ent_entropy_loss         | 4.27      |
|    ent_loss                 | 0.0329    |
|    ent_policy_gradient_loss | 0.0723    |
|    ent_std                  | 0.143     |
|    ent_value_loss           | 0.0467    |
|    entropy_loss             | 3.56      |
|    explained_variance       | 0.418     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0825    |
|    n_updates                | 3820      |
|    policy_gradient_loss     | 0.0865    |
|    std                      | 0.156     |
|    value_loss               | 0.0483    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 683       |
|    ep_rew_mean              | 1.25e+03  |
| time/                       |           |
|    fps                      | 153       |
|    iterations               | 384       |
|    time_elapsed             | 5136      |
|    total_timesteps          | 786432    |
| train/                      |           |
|    approx_kl                | 1.7633852 |
|    clip_fraction            | 0.845     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.4859449 |
|    ent_clip_fraction        | 0.755     |
|    ent_entropy_loss         | 4.22      |
|    ent_loss                 | 0.0179    |
|    ent_policy_gradient_loss | 0.043     |
|    ent_std                  | 0.143     |
|    ent_value_loss           | 0.0333    |
|    entropy_loss             | 3.53      |
|    explained_variance       | 0.234     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.113     |
|    n_updates                | 3830      |
|    policy_gradient_loss     | 0.127     |
|    std                      | 0.157     |
|    value_loss               | 0.0339    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 683        |
|    ep_rew_mean              | 1.26e+03   |
| time/                       |            |
|    fps                      | 153        |
|    iterations               | 385        |
|    time_elapsed             | 5146       |
|    total_timesteps          | 788480     |
| train/                      |            |
|    approx_kl                | 4.0953474  |
|    clip_fraction            | 0.935      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.49092305 |
|    ent_clip_fraction        | 0.607      |
|    ent_entropy_loss         | 4.22       |
|    ent_loss                 | -0.0392    |
|    ent_policy_gradient_loss | -0.00491   |
|    ent_std                  | 0.143      |
|    ent_value_loss           | 0.00804    |
|    entropy_loss             | 3.49       |
|    explained_variance       | 0.963      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.12       |
|    n_updates                | 3840       |
|    policy_gradient_loss     | 0.175      |
|    std                      | 0.157      |
|    value_loss               | 0.00746    |
--------------------------------------------
Eval num_timesteps=790000, episode_reward=2123.87 +/- 725.12
Episode length: 931.92 +/- 231.51
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 932        |
|    mean_reward              | 2.12e+03   |
| time/                       |            |
|    total_timesteps          | 790000     |
| train/                      |            |
|    approx_kl                | 2.7359161  |
|    clip_fraction            | 0.943      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.35682917 |
|    ent_clip_fraction        | 0.582      |
|    ent_entropy_loss         | 4.22       |
|    ent_loss                 | -0.0174    |
|    ent_policy_gradient_loss | -0.0104    |
|    ent_std                  | 0.143      |
|    ent_value_loss           | 0.00944    |
|    entropy_loss             | 3.49       |
|    explained_variance       | 0.843      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.124      |
|    n_updates                | 3850       |
|    policy_gradient_loss     | 0.196      |
|    std                      | 0.157      |
|    value_loss               | 0.00872    |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 690      |
|    ep_rew_mean     | 1.27e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 386      |
|    time_elapsed    | 5174     |
|    total_timesteps | 790528   |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 681       |
|    ep_rew_mean              | 1.26e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 387       |
|    time_elapsed             | 5184      |
|    total_timesteps          | 792576    |
| train/                      |           |
|    approx_kl                | 4.123193  |
|    clip_fraction            | 0.923     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.7587974 |
|    ent_clip_fraction        | 0.633     |
|    ent_entropy_loss         | 4.2       |
|    ent_loss                 | 0.0188    |
|    ent_policy_gradient_loss | 0.0441    |
|    ent_std                  | 0.143     |
|    ent_value_loss           | 0.00958   |
|    entropy_loss             | 3.5       |
|    explained_variance       | 0.972     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.178     |
|    n_updates                | 3860      |
|    policy_gradient_loss     | 0.155     |
|    std                      | 0.156     |
|    value_loss               | 0.00949   |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 696        |
|    ep_rew_mean              | 1.28e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 388        |
|    time_elapsed             | 5195       |
|    total_timesteps          | 794624     |
| train/                      |            |
|    approx_kl                | 3.035581   |
|    clip_fraction            | 0.962      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.14651613 |
|    ent_clip_fraction        | 0.545      |
|    ent_entropy_loss         | 4.2        |
|    ent_loss                 | -0.0418    |
|    ent_policy_gradient_loss | -0.034     |
|    ent_std                  | 0.143      |
|    ent_value_loss           | 0.0354     |
|    entropy_loss             | 3.52       |
|    explained_variance       | 0.897      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.12       |
|    n_updates                | 3870       |
|    policy_gradient_loss     | 0.149      |
|    std                      | 0.157      |
|    value_loss               | 0.0319     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 691        |
|    ep_rew_mean              | 1.3e+03    |
| time/                       |            |
|    fps                      | 153        |
|    iterations               | 389        |
|    time_elapsed             | 5205       |
|    total_timesteps          | 796672     |
| train/                      |            |
|    approx_kl                | 2.8854904  |
|    clip_fraction            | 0.914      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.81672484 |
|    ent_clip_fraction        | 0.672      |
|    ent_entropy_loss         | 4.22       |
|    ent_loss                 | 0.0299     |
|    ent_policy_gradient_loss | 0.0257     |
|    ent_std                  | 0.143      |
|    ent_value_loss           | 0.0276     |
|    entropy_loss             | 3.53       |
|    explained_variance       | 0.929      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.101      |
|    n_updates                | 3880       |
|    policy_gradient_loss     | 0.112      |
|    std                      | 0.156      |
|    value_loss               | 0.0274     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 697       |
|    ep_rew_mean              | 1.32e+03  |
| time/                       |           |
|    fps                      | 153       |
|    iterations               | 390       |
|    time_elapsed             | 5215      |
|    total_timesteps          | 798720    |
| train/                      |           |
|    approx_kl                | 2.8718796 |
|    clip_fraction            | 0.947     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.3368104 |
|    ent_clip_fraction        | 0.594     |
|    ent_entropy_loss         | 4.23      |
|    ent_loss                 | -0.0597   |
|    ent_policy_gradient_loss | -0.0123   |
|    ent_std                  | 0.143     |
|    ent_value_loss           | 0.0257    |
|    entropy_loss             | 3.54      |
|    explained_variance       | 0.241     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.243     |
|    n_updates                | 3890      |
|    policy_gradient_loss     | 0.174     |
|    std                      | 0.156     |
|    value_loss               | 0.0266    |
-------------------------------------------
Eval num_timesteps=800000, episode_reward=2101.29 +/- 624.40
Episode length: 962.36 +/- 138.22
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 962       |
|    mean_reward              | 2.1e+03   |
| time/                       |           |
|    total_timesteps          | 800000    |
| train/                      |           |
|    approx_kl                | 2.6870322 |
|    clip_fraction            | 0.925     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.9856715 |
|    ent_clip_fraction        | 0.646     |
|    ent_entropy_loss         | 4.24      |
|    ent_loss                 | -0.0431   |
|    ent_policy_gradient_loss | 0.00956   |
|    ent_std                  | 0.143     |
|    ent_value_loss           | 0.0144    |
|    entropy_loss             | 3.53      |
|    explained_variance       | 0.8       |
|    learning_rate            | 0.0003    |
|    loss                     | 0.138     |
|    n_updates                | 3900      |
|    policy_gradient_loss     | 0.186     |
|    std                      | 0.156     |
|    value_loss               | 0.0169    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 702      |
|    ep_rew_mean     | 1.33e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 391      |
|    time_elapsed    | 5243     |
|    total_timesteps | 800768   |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 700       |
|    ep_rew_mean              | 1.33e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 392       |
|    time_elapsed             | 5253      |
|    total_timesteps          | 802816    |
| train/                      |           |
|    approx_kl                | 5.5897517 |
|    clip_fraction            | 0.956     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.3431967 |
|    ent_clip_fraction        | 0.595     |
|    ent_entropy_loss         | 4.28      |
|    ent_loss                 | -0.0539   |
|    ent_policy_gradient_loss | -0.00841  |
|    ent_std                  | 0.142     |
|    ent_value_loss           | 0.0264    |
|    entropy_loss             | 3.52      |
|    explained_variance       | 0.934     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.136     |
|    n_updates                | 3910      |
|    policy_gradient_loss     | 0.136     |
|    std                      | 0.156     |
|    value_loss               | 0.0254    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 708       |
|    ep_rew_mean              | 1.33e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 393       |
|    time_elapsed             | 5263      |
|    total_timesteps          | 804864    |
| train/                      |           |
|    approx_kl                | 6.1025286 |
|    clip_fraction            | 0.944     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.6015665 |
|    ent_clip_fraction        | 0.607     |
|    ent_entropy_loss         | 4.31      |
|    ent_loss                 | -0.0208   |
|    ent_policy_gradient_loss | -0.00311  |
|    ent_std                  | 0.141     |
|    ent_value_loss           | 0.0367    |
|    entropy_loss             | 3.53      |
|    explained_variance       | 0.901     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.148     |
|    n_updates                | 3920      |
|    policy_gradient_loss     | 0.154     |
|    std                      | 0.156     |
|    value_loss               | 0.0368    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 712       |
|    ep_rew_mean              | 1.33e+03  |
| time/                       |           |
|    fps                      | 153       |
|    iterations               | 394       |
|    time_elapsed             | 5273      |
|    total_timesteps          | 806912    |
| train/                      |           |
|    approx_kl                | 2.5273347 |
|    clip_fraction            | 0.953     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.4139992 |
|    ent_clip_fraction        | 0.537     |
|    ent_entropy_loss         | 4.34      |
|    ent_loss                 | -0.0745   |
|    ent_policy_gradient_loss | -0.0257   |
|    ent_std                  | 0.14      |
|    ent_value_loss           | 0.0132    |
|    entropy_loss             | 3.49      |
|    explained_variance       | 0.832     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.202     |
|    n_updates                | 3930      |
|    policy_gradient_loss     | 0.151     |
|    std                      | 0.157     |
|    value_loss               | 0.0139    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 713       |
|    ep_rew_mean              | 1.33e+03  |
| time/                       |           |
|    fps                      | 153       |
|    iterations               | 395       |
|    time_elapsed             | 5283      |
|    total_timesteps          | 808960    |
| train/                      |           |
|    approx_kl                | 5.334771  |
|    clip_fraction            | 0.951     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.5801273 |
|    ent_clip_fraction        | 0.603     |
|    ent_entropy_loss         | 4.41      |
|    ent_loss                 | -0.0646   |
|    ent_policy_gradient_loss | -0.00788  |
|    ent_std                  | 0.139     |
|    ent_value_loss           | 0.0152    |
|    entropy_loss             | 3.51      |
|    explained_variance       | 0.899     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.215     |
|    n_updates                | 3940      |
|    policy_gradient_loss     | 0.169     |
|    std                      | 0.156     |
|    value_loss               | 0.0159    |
-------------------------------------------
Eval num_timesteps=810000, episode_reward=2281.79 +/- 660.83
Episode length: 898.56 +/- 242.51
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 899       |
|    mean_reward              | 2.28e+03  |
| time/                       |           |
|    total_timesteps          | 810000    |
| train/                      |           |
|    approx_kl                | 4.9064646 |
|    clip_fraction            | 0.965     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.1631152 |
|    ent_clip_fraction        | 0.555     |
|    ent_entropy_loss         | 4.45      |
|    ent_loss                 | -0.0325   |
|    ent_policy_gradient_loss | -0.0348   |
|    ent_std                  | 0.139     |
|    ent_value_loss           | 0.0316    |
|    entropy_loss             | 3.54      |
|    explained_variance       | 0.869     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.118     |
|    n_updates                | 3950      |
|    policy_gradient_loss     | 0.253     |
|    std                      | 0.156     |
|    value_loss               | 0.0308    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 717      |
|    ep_rew_mean     | 1.34e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 396      |
|    time_elapsed    | 5311     |
|    total_timesteps | 811008   |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 716       |
|    ep_rew_mean              | 1.34e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 397       |
|    time_elapsed             | 5321      |
|    total_timesteps          | 813056    |
| train/                      |           |
|    approx_kl                | 2.112299  |
|    clip_fraction            | 0.801     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.8734944 |
|    ent_clip_fraction        | 0.801     |
|    ent_entropy_loss         | 4.47      |
|    ent_loss                 | 0.182     |
|    ent_policy_gradient_loss | 0.118     |
|    ent_std                  | 0.139     |
|    ent_value_loss           | 0.0123    |
|    entropy_loss             | 3.56      |
|    explained_variance       | 0.933     |
|    learning_rate            | 0.0003    |
|    loss                     | -0.0037   |
|    n_updates                | 3960      |
|    policy_gradient_loss     | 0.108     |
|    std                      | 0.155     |
|    value_loss               | 0.0127    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 716        |
|    ep_rew_mean              | 1.33e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 398        |
|    time_elapsed             | 5331       |
|    total_timesteps          | 815104     |
| train/                      |            |
|    approx_kl                | 3.3567352  |
|    clip_fraction            | 0.956      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.31443816 |
|    ent_clip_fraction        | 0.584      |
|    ent_entropy_loss         | 4.48       |
|    ent_loss                 | -0.0207    |
|    ent_policy_gradient_loss | -0.0264    |
|    ent_std                  | 0.138      |
|    ent_value_loss           | 0.0199     |
|    entropy_loss             | 3.58       |
|    explained_variance       | 0.381      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0787     |
|    n_updates                | 3970       |
|    policy_gradient_loss     | 0.201      |
|    std                      | 0.155      |
|    value_loss               | 0.0212     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 721       |
|    ep_rew_mean              | 1.35e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 399       |
|    time_elapsed             | 5341      |
|    total_timesteps          | 817152    |
| train/                      |           |
|    approx_kl                | 6.292434  |
|    clip_fraction            | 0.952     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.5098369 |
|    ent_clip_fraction        | 0.6       |
|    ent_entropy_loss         | 4.49      |
|    ent_loss                 | -0.0637   |
|    ent_policy_gradient_loss | 0.00754   |
|    ent_std                  | 0.138     |
|    ent_value_loss           | 0.0155    |
|    entropy_loss             | 3.62      |
|    explained_variance       | 0.959     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.178     |
|    n_updates                | 3980      |
|    policy_gradient_loss     | 0.161     |
|    std                      | 0.154     |
|    value_loss               | 0.0161    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 721       |
|    ep_rew_mean              | 1.34e+03  |
| time/                       |           |
|    fps                      | 153       |
|    iterations               | 400       |
|    time_elapsed             | 5352      |
|    total_timesteps          | 819200    |
| train/                      |           |
|    approx_kl                | 3.6863708 |
|    clip_fraction            | 0.846     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.4949679 |
|    ent_clip_fraction        | 0.784     |
|    ent_entropy_loss         | 4.47      |
|    ent_loss                 | 0.0288    |
|    ent_policy_gradient_loss | 0.092     |
|    ent_std                  | 0.139     |
|    ent_value_loss           | 0.0108    |
|    entropy_loss             | 3.65      |
|    explained_variance       | 0.965     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0644    |
|    n_updates                | 3990      |
|    policy_gradient_loss     | 0.615     |
|    std                      | 0.153     |
|    value_loss               | 0.0126    |
-------------------------------------------
Eval num_timesteps=820000, episode_reward=1748.57 +/- 757.43
Episode length: 840.48 +/- 288.23
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 840        |
|    mean_reward              | 1.75e+03   |
| time/                       |            |
|    total_timesteps          | 820000     |
| train/                      |            |
|    approx_kl                | 2.9700096  |
|    clip_fraction            | 0.953      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.37752303 |
|    ent_clip_fraction        | 0.573      |
|    ent_entropy_loss         | 4.45       |
|    ent_loss                 | -0.0937    |
|    ent_policy_gradient_loss | -0.0251    |
|    ent_std                  | 0.139      |
|    ent_value_loss           | 0.015      |
|    entropy_loss             | 3.63       |
|    explained_variance       | 0.831      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.194      |
|    n_updates                | 4000       |
|    policy_gradient_loss     | 0.186      |
|    std                      | 0.154      |
|    value_loss               | 0.0151     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 740      |
|    ep_rew_mean     | 1.39e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 401      |
|    time_elapsed    | 5380     |
|    total_timesteps | 821248   |
---------------------------------
------------------------------------------
| rollout/                    |          |
|    ep_len_mean              | 736      |
|    ep_rew_mean              | 1.38e+03 |
| time/                       |          |
|    fps                      | 152      |
|    iterations               | 402      |
|    time_elapsed             | 5390     |
|    total_timesteps          | 823296   |
| train/                      |          |
|    approx_kl                | 2.343122 |
|    clip_fraction            | 0.88     |
|    clip_range               | 0.2      |
|    ent_approx_kl            | 1.213867 |
|    ent_clip_fraction        | 0.734    |
|    ent_entropy_loss         | 4.46     |
|    ent_loss                 | 0.0263   |
|    ent_policy_gradient_loss | 0.0517   |
|    ent_std                  | 0.139    |
|    ent_value_loss           | 0.0254   |
|    entropy_loss             | 3.62     |
|    explained_variance       | 0.519    |
|    learning_rate            | 0.0003   |
|    loss                     | 0.204    |
|    n_updates                | 4010     |
|    policy_gradient_loss     | 0.14     |
|    std                      | 0.154    |
|    value_loss               | 0.0261   |
------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 743        |
|    ep_rew_mean              | 1.4e+03    |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 403        |
|    time_elapsed             | 5400       |
|    total_timesteps          | 825344     |
| train/                      |            |
|    approx_kl                | 2.8783793  |
|    clip_fraction            | 0.961      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.20727229 |
|    ent_clip_fraction        | 0.56       |
|    ent_entropy_loss         | 4.47       |
|    ent_loss                 | -0.0298    |
|    ent_policy_gradient_loss | -0.0313    |
|    ent_std                  | 0.138      |
|    ent_value_loss           | 0.0527     |
|    entropy_loss             | 3.62       |
|    explained_variance       | 0.455      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.156      |
|    n_updates                | 4020       |
|    policy_gradient_loss     | 0.181      |
|    std                      | 0.154      |
|    value_loss               | 0.0543     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 751       |
|    ep_rew_mean              | 1.4e+03   |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 404       |
|    time_elapsed             | 5410      |
|    total_timesteps          | 827392    |
| train/                      |           |
|    approx_kl                | 2.405256  |
|    clip_fraction            | 0.914     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.0312892 |
|    ent_clip_fraction        | 0.69      |
|    ent_entropy_loss         | 4.51      |
|    ent_loss                 | -0.000252 |
|    ent_policy_gradient_loss | 0.00503   |
|    ent_std                  | 0.137     |
|    ent_value_loss           | 0.0144    |
|    entropy_loss             | 3.6       |
|    explained_variance       | 0.454     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.131     |
|    n_updates                | 4030      |
|    policy_gradient_loss     | 0.188     |
|    std                      | 0.154     |
|    value_loss               | 0.0142    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 762       |
|    ep_rew_mean              | 1.43e+03  |
| time/                       |           |
|    fps                      | 153       |
|    iterations               | 405       |
|    time_elapsed             | 5420      |
|    total_timesteps          | 829440    |
| train/                      |           |
|    approx_kl                | 4.7677402 |
|    clip_fraction            | 0.894     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.2170222 |
|    ent_clip_fraction        | 0.703     |
|    ent_entropy_loss         | 4.55      |
|    ent_loss                 | 0.029     |
|    ent_policy_gradient_loss | 0.0537    |
|    ent_std                  | 0.137     |
|    ent_value_loss           | 0.0102    |
|    entropy_loss             | 3.62      |
|    explained_variance       | 0.974     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.107     |
|    n_updates                | 4040      |
|    policy_gradient_loss     | 0.132     |
|    std                      | 0.154     |
|    value_loss               | 0.0105    |
-------------------------------------------
Eval num_timesteps=830000, episode_reward=2062.80 +/- 948.26
Episode length: 885.76 +/- 293.86
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 886       |
|    mean_reward              | 2.06e+03  |
| time/                       |           |
|    total_timesteps          | 830000    |
| train/                      |           |
|    approx_kl                | 4.7059827 |
|    clip_fraction            | 0.97      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.095531  |
|    ent_clip_fraction        | 0.544     |
|    ent_entropy_loss         | 4.6       |
|    ent_loss                 | -0.0257   |
|    ent_policy_gradient_loss | -0.0372   |
|    ent_std                  | 0.136     |
|    ent_value_loss           | 0.0472    |
|    entropy_loss             | 3.59      |
|    explained_variance       | 0.876     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.148     |
|    n_updates                | 4050      |
|    policy_gradient_loss     | 0.158     |
|    std                      | 0.155     |
|    value_loss               | 0.0465    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 758      |
|    ep_rew_mean     | 1.43e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 406      |
|    time_elapsed    | 5448     |
|    total_timesteps | 831488   |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 750       |
|    ep_rew_mean              | 1.43e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 407       |
|    time_elapsed             | 5458      |
|    total_timesteps          | 833536    |
| train/                      |           |
|    approx_kl                | 6.593172  |
|    clip_fraction            | 0.927     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.7907437 |
|    ent_clip_fraction        | 0.653     |
|    ent_entropy_loss         | 4.59      |
|    ent_loss                 | 0.0194    |
|    ent_policy_gradient_loss | 0.0438    |
|    ent_std                  | 0.137     |
|    ent_value_loss           | 0.0345    |
|    entropy_loss             | 3.63      |
|    explained_variance       | 0.909     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0873    |
|    n_updates                | 4060      |
|    policy_gradient_loss     | 0.165     |
|    std                      | 0.153     |
|    value_loss               | 0.038     |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 759        |
|    ep_rew_mean              | 1.45e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 408        |
|    time_elapsed             | 5468       |
|    total_timesteps          | 835584     |
| train/                      |            |
|    approx_kl                | 2.8356817  |
|    clip_fraction            | 0.953      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.54196906 |
|    ent_clip_fraction        | 0.585      |
|    ent_entropy_loss         | 4.61       |
|    ent_loss                 | -0.00795   |
|    ent_policy_gradient_loss | -0.0273    |
|    ent_std                  | 0.136      |
|    ent_value_loss           | 0.0742     |
|    entropy_loss             | 3.66       |
|    explained_variance       | 0.817      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.122      |
|    n_updates                | 4070       |
|    policy_gradient_loss     | 0.167      |
|    std                      | 0.154      |
|    value_loss               | 0.0743     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 773        |
|    ep_rew_mean              | 1.46e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 409        |
|    time_elapsed             | 5478       |
|    total_timesteps          | 837632     |
| train/                      |            |
|    approx_kl                | 3.1601243  |
|    clip_fraction            | 0.942      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.51430166 |
|    ent_clip_fraction        | 0.627      |
|    ent_entropy_loss         | 4.63       |
|    ent_loss                 | -0.0656    |
|    ent_policy_gradient_loss | -0.00421   |
|    ent_std                  | 0.136      |
|    ent_value_loss           | 0.0241     |
|    entropy_loss             | 3.61       |
|    explained_variance       | 0.866      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0885     |
|    n_updates                | 4080       |
|    policy_gradient_loss     | 0.188      |
|    std                      | 0.154      |
|    value_loss               | 0.0256     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 781       |
|    ep_rew_mean              | 1.47e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 410       |
|    time_elapsed             | 5488      |
|    total_timesteps          | 839680    |
| train/                      |           |
|    approx_kl                | 2.5777225 |
|    clip_fraction            | 0.844     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.4963121 |
|    ent_clip_fraction        | 0.726     |
|    ent_entropy_loss         | 4.63      |
|    ent_loss                 | 0.0127    |
|    ent_policy_gradient_loss | 0.0659    |
|    ent_std                  | 0.136     |
|    ent_value_loss           | 0.00309   |
|    entropy_loss             | 3.62      |
|    explained_variance       | 0.449     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.049     |
|    n_updates                | 4090      |
|    policy_gradient_loss     | 0.0902    |
|    std                      | 0.154     |
|    value_loss               | 0.00479   |
-------------------------------------------
Eval num_timesteps=840000, episode_reward=2480.12 +/- 481.65
Episode length: 1000.00 +/- 0.00
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 1e+03     |
|    mean_reward              | 2.48e+03  |
| time/                       |           |
|    total_timesteps          | 840000    |
| train/                      |           |
|    approx_kl                | 2.752759  |
|    clip_fraction            | 0.818     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.0608954 |
|    ent_clip_fraction        | 0.802     |
|    ent_entropy_loss         | 4.62      |
|    ent_loss                 | 0.111     |
|    ent_policy_gradient_loss | 0.0913    |
|    ent_std                  | 0.137     |
|    ent_value_loss           | 0.0355    |
|    entropy_loss             | 3.64      |
|    explained_variance       | 0.85      |
|    learning_rate            | 0.0003    |
|    loss                     | -0.00515  |
|    n_updates                | 4100      |
|    policy_gradient_loss     | 0.167     |
|    std                      | 0.153     |
|    value_loss               | 0.036     |
-------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 781      |
|    ep_rew_mean     | 1.46e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 411      |
|    time_elapsed    | 5517     |
|    total_timesteps | 841728   |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 781       |
|    ep_rew_mean              | 1.47e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 412       |
|    time_elapsed             | 5527      |
|    total_timesteps          | 843776    |
| train/                      |           |
|    approx_kl                | 5.4386873 |
|    clip_fraction            | 0.922     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.5173378 |
|    ent_clip_fraction        | 0.68      |
|    ent_entropy_loss         | 4.6       |
|    ent_loss                 | 0.02      |
|    ent_policy_gradient_loss | 0.0171    |
|    ent_std                  | 0.136     |
|    ent_value_loss           | 0.0105    |
|    entropy_loss             | 3.67      |
|    explained_variance       | 0.95      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.105     |
|    n_updates                | 4110      |
|    policy_gradient_loss     | 0.219     |
|    std                      | 0.153     |
|    value_loss               | 0.0108    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 776       |
|    ep_rew_mean              | 1.47e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 413       |
|    time_elapsed             | 5537      |
|    total_timesteps          | 845824    |
| train/                      |           |
|    approx_kl                | 3.862925  |
|    clip_fraction            | 0.955     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.4194646 |
|    ent_clip_fraction        | 0.613     |
|    ent_entropy_loss         | 4.61      |
|    ent_loss                 | -0.0738   |
|    ent_policy_gradient_loss | -0.0245   |
|    ent_std                  | 0.136     |
|    ent_value_loss           | 0.024     |
|    entropy_loss             | 3.7       |
|    explained_variance       | 0.863     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.171     |
|    n_updates                | 4120      |
|    policy_gradient_loss     | 0.174     |
|    std                      | 0.152     |
|    value_loss               | 0.0231    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 776        |
|    ep_rew_mean              | 1.46e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 414        |
|    time_elapsed             | 5547       |
|    total_timesteps          | 847872     |
| train/                      |            |
|    approx_kl                | 4.7839546  |
|    clip_fraction            | 0.951      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.41320264 |
|    ent_clip_fraction        | 0.573      |
|    ent_entropy_loss         | 4.62       |
|    ent_loss                 | 0.0103     |
|    ent_policy_gradient_loss | -0.00918   |
|    ent_std                  | 0.136      |
|    ent_value_loss           | 0.0497     |
|    entropy_loss             | 3.74       |
|    explained_variance       | 0.839      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.133      |
|    n_updates                | 4130       |
|    policy_gradient_loss     | 0.166      |
|    std                      | 0.152      |
|    value_loss               | 0.0471     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 757       |
|    ep_rew_mean              | 1.42e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 415       |
|    time_elapsed             | 5558      |
|    total_timesteps          | 849920    |
| train/                      |           |
|    approx_kl                | 10.016389 |
|    clip_fraction            | 0.964     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.5948155 |
|    ent_clip_fraction        | 0.561     |
|    ent_entropy_loss         | 4.66      |
|    ent_loss                 | -0.0442   |
|    ent_policy_gradient_loss | -0.00694  |
|    ent_std                  | 0.135     |
|    ent_value_loss           | 0.0213    |
|    entropy_loss             | 3.77      |
|    explained_variance       | 0.935     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0732    |
|    n_updates                | 4140      |
|    policy_gradient_loss     | 0.129     |
|    std                      | 0.151     |
|    value_loss               | 0.0211    |
-------------------------------------------
Eval num_timesteps=850000, episode_reward=978.01 +/- 532.49
Episode length: 526.88 +/- 367.45
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 527       |
|    mean_reward              | 978       |
| time/                       |           |
|    total_timesteps          | 850000    |
| train/                      |           |
|    approx_kl                | 5.6039867 |
|    clip_fraction            | 0.886     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.4248627 |
|    ent_clip_fraction        | 0.696     |
|    ent_entropy_loss         | 4.69      |
|    ent_loss                 | 0.106     |
|    ent_policy_gradient_loss | 0.0496    |
|    ent_std                  | 0.135     |
|    ent_value_loss           | 0.0618    |
|    entropy_loss             | 3.8       |
|    explained_variance       | 0.832     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.19      |
|    n_updates                | 4150      |
|    policy_gradient_loss     | 0.108     |
|    std                      | 0.15      |
|    value_loss               | 0.0643    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 764      |
|    ep_rew_mean     | 1.43e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 416      |
|    time_elapsed    | 5583     |
|    total_timesteps | 851968   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 770        |
|    ep_rew_mean              | 1.44e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 417        |
|    time_elapsed             | 5593       |
|    total_timesteps          | 854016     |
| train/                      |            |
|    approx_kl                | 7.7373495  |
|    clip_fraction            | 0.956      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.46938226 |
|    ent_clip_fraction        | 0.589      |
|    ent_entropy_loss         | 4.71       |
|    ent_loss                 | -0.0422    |
|    ent_policy_gradient_loss | -0.0247    |
|    ent_std                  | 0.134      |
|    ent_value_loss           | 0.0252     |
|    entropy_loss             | 3.81       |
|    explained_variance       | 0.918      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.121      |
|    n_updates                | 4160       |
|    policy_gradient_loss     | 0.177      |
|    std                      | 0.15       |
|    value_loss               | 0.0238     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 765        |
|    ep_rew_mean              | 1.42e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 418        |
|    time_elapsed             | 5603       |
|    total_timesteps          | 856064     |
| train/                      |            |
|    approx_kl                | 5.0307984  |
|    clip_fraction            | 0.953      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.80594903 |
|    ent_clip_fraction        | 0.581      |
|    ent_entropy_loss         | 4.7        |
|    ent_loss                 | 0.0314     |
|    ent_policy_gradient_loss | 0.0261     |
|    ent_std                  | 0.135      |
|    ent_value_loss           | 0.0176     |
|    entropy_loss             | 3.84       |
|    explained_variance       | 0.922      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0873     |
|    n_updates                | 4170       |
|    policy_gradient_loss     | 0.0771     |
|    std                      | 0.149      |
|    value_loss               | 0.0163     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 771       |
|    ep_rew_mean              | 1.43e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 419       |
|    time_elapsed             | 5613      |
|    total_timesteps          | 858112    |
| train/                      |           |
|    approx_kl                | 1.5493449 |
|    clip_fraction            | 0.714     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.408814  |
|    ent_clip_fraction        | 0.898     |
|    ent_entropy_loss         | 4.69      |
|    ent_loss                 | 0.0569    |
|    ent_policy_gradient_loss | 0.124     |
|    ent_std                  | 0.135     |
|    ent_value_loss           | 0.0248    |
|    entropy_loss             | 3.85      |
|    explained_variance       | 0.804     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0132    |
|    n_updates                | 4180      |
|    policy_gradient_loss     | 0.0473    |
|    std                      | 0.15      |
|    value_loss               | 0.0319    |
-------------------------------------------
Eval num_timesteps=860000, episode_reward=2077.18 +/- 831.92
Episode length: 817.92 +/- 291.47
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 818       |
|    mean_reward              | 2.08e+03  |
| time/                       |           |
|    total_timesteps          | 860000    |
| train/                      |           |
|    approx_kl                | 4.464744  |
|    clip_fraction            | 0.916     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.0419118 |
|    ent_clip_fraction        | 0.664     |
|    ent_entropy_loss         | 4.66      |
|    ent_loss                 | 0.00967   |
|    ent_policy_gradient_loss | 0.0371    |
|    ent_std                  | 0.135     |
|    ent_value_loss           | 0.0104    |
|    entropy_loss             | 3.84      |
|    explained_variance       | 0.962     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.104     |
|    n_updates                | 4190      |
|    policy_gradient_loss     | 0.162     |
|    std                      | 0.15      |
|    value_loss               | 0.0105    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 764      |
|    ep_rew_mean     | 1.41e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 420      |
|    time_elapsed    | 5637     |
|    total_timesteps | 860160   |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 760       |
|    ep_rew_mean              | 1.41e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 421       |
|    time_elapsed             | 5647      |
|    total_timesteps          | 862208    |
| train/                      |           |
|    approx_kl                | 2.4608884 |
|    clip_fraction            | 0.93      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.9617224 |
|    ent_clip_fraction        | 0.644     |
|    ent_entropy_loss         | 4.7       |
|    ent_loss                 | -0.0139   |
|    ent_policy_gradient_loss | 0.00227   |
|    ent_std                  | 0.134     |
|    ent_value_loss           | 0.0437    |
|    entropy_loss             | 3.82      |
|    explained_variance       | 0.31      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.136     |
|    n_updates                | 4200      |
|    policy_gradient_loss     | 0.173     |
|    std                      | 0.15      |
|    value_loss               | 0.0428    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 747        |
|    ep_rew_mean              | 1.38e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 422        |
|    time_elapsed             | 5657       |
|    total_timesteps          | 864256     |
| train/                      |            |
|    approx_kl                | 2.7326283  |
|    clip_fraction            | 0.948      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.37014568 |
|    ent_clip_fraction        | 0.587      |
|    ent_entropy_loss         | 4.75       |
|    ent_loss                 | -0.00276   |
|    ent_policy_gradient_loss | -0.0166    |
|    ent_std                  | 0.133      |
|    ent_value_loss           | 0.0434     |
|    entropy_loss             | 3.81       |
|    explained_variance       | 0.343      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.172      |
|    n_updates                | 4210       |
|    policy_gradient_loss     | 0.161      |
|    std                      | 0.15       |
|    value_loss               | 0.0424     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 750       |
|    ep_rew_mean              | 1.38e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 423       |
|    time_elapsed             | 5667      |
|    total_timesteps          | 866304    |
| train/                      |           |
|    approx_kl                | 3.7274556 |
|    clip_fraction            | 0.96      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.1269157 |
|    ent_clip_fraction        | 0.53      |
|    ent_entropy_loss         | 4.79      |
|    ent_loss                 | -0.0396   |
|    ent_policy_gradient_loss | -0.0347   |
|    ent_std                  | 0.133     |
|    ent_value_loss           | 0.0409    |
|    entropy_loss             | 3.83      |
|    explained_variance       | 0.909     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.108     |
|    n_updates                | 4220      |
|    policy_gradient_loss     | 0.15      |
|    std                      | 0.15      |
|    value_loss               | 0.0384    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 738        |
|    ep_rew_mean              | 1.37e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 424        |
|    time_elapsed             | 5677       |
|    total_timesteps          | 868352     |
| train/                      |            |
|    approx_kl                | 2.5020485  |
|    clip_fraction            | 0.929      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.26320928 |
|    ent_clip_fraction        | 0.518      |
|    ent_entropy_loss         | 4.85       |
|    ent_loss                 | 0.00584    |
|    ent_policy_gradient_loss | -0.0128    |
|    ent_std                  | 0.132      |
|    ent_value_loss           | 0.0243     |
|    entropy_loss             | 3.93       |
|    explained_variance       | 0.916      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.126      |
|    n_updates                | 4230       |
|    policy_gradient_loss     | 0.124      |
|    std                      | 0.147      |
|    value_loss               | 0.0232     |
--------------------------------------------
Eval num_timesteps=870000, episode_reward=1597.10 +/- 933.79
Episode length: 716.60 +/- 372.33
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 717        |
|    mean_reward              | 1.6e+03    |
| time/                       |            |
|    total_timesteps          | 870000     |
| train/                      |            |
|    approx_kl                | 3.8115163  |
|    clip_fraction            | 0.965      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.14362088 |
|    ent_clip_fraction        | 0.571      |
|    ent_entropy_loss         | 4.92       |
|    ent_loss                 | -0.0595    |
|    ent_policy_gradient_loss | -0.0387    |
|    ent_std                  | 0.131      |
|    ent_value_loss           | 0.0508     |
|    entropy_loss             | 4          |
|    explained_variance       | 0.761      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.145      |
|    n_updates                | 4240       |
|    policy_gradient_loss     | 0.176      |
|    std                      | 0.147      |
|    value_loss               | 0.0516     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 721      |
|    ep_rew_mean     | 1.32e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 425      |
|    time_elapsed    | 5706     |
|    total_timesteps | 870400   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 712        |
|    ep_rew_mean              | 1.31e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 426        |
|    time_elapsed             | 5715       |
|    total_timesteps          | 872448     |
| train/                      |            |
|    approx_kl                | 3.299313   |
|    clip_fraction            | 0.965      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.09854153 |
|    ent_clip_fraction        | 0.562      |
|    ent_entropy_loss         | 4.95       |
|    ent_loss                 | -0.0164    |
|    ent_policy_gradient_loss | -0.0376    |
|    ent_std                  | 0.13       |
|    ent_value_loss           | 0.0768     |
|    entropy_loss             | 3.99       |
|    explained_variance       | 0.603      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.238      |
|    n_updates                | 4250       |
|    policy_gradient_loss     | 0.17       |
|    std                      | 0.147      |
|    value_loss               | 0.0784     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 696        |
|    ep_rew_mean              | 1.3e+03    |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 427        |
|    time_elapsed             | 5725       |
|    total_timesteps          | 874496     |
| train/                      |            |
|    approx_kl                | 3.0718474  |
|    clip_fraction            | 0.949      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.34498858 |
|    ent_clip_fraction        | 0.6        |
|    ent_entropy_loss         | 4.98       |
|    ent_loss                 | -0.035     |
|    ent_policy_gradient_loss | -0.0266    |
|    ent_std                  | 0.13       |
|    ent_value_loss           | 0.0457     |
|    entropy_loss             | 4.04       |
|    explained_variance       | 0.769      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.14       |
|    n_updates                | 4260       |
|    policy_gradient_loss     | 0.238      |
|    std                      | 0.146      |
|    value_loss               | 0.0471     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 687        |
|    ep_rew_mean              | 1.29e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 428        |
|    time_elapsed             | 5735       |
|    total_timesteps          | 876544     |
| train/                      |            |
|    approx_kl                | 4.6732683  |
|    clip_fraction            | 0.962      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.11422193 |
|    ent_clip_fraction        | 0.549      |
|    ent_entropy_loss         | 5.01       |
|    ent_loss                 | -0.0166    |
|    ent_policy_gradient_loss | -0.0409    |
|    ent_std                  | 0.129      |
|    ent_value_loss           | 0.0461     |
|    entropy_loss             | 4.06       |
|    explained_variance       | 0.877      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.209      |
|    n_updates                | 4270       |
|    policy_gradient_loss     | 1.05       |
|    std                      | 0.145      |
|    value_loss               | 0.0486     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 678        |
|    ep_rew_mean              | 1.29e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 429        |
|    time_elapsed             | 5745       |
|    total_timesteps          | 878592     |
| train/                      |            |
|    approx_kl                | 2.862992   |
|    clip_fraction            | 0.959      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.09493211 |
|    ent_clip_fraction        | 0.556      |
|    ent_entropy_loss         | 5.04       |
|    ent_loss                 | -0.0519    |
|    ent_policy_gradient_loss | -0.0421    |
|    ent_std                  | 0.129      |
|    ent_value_loss           | 0.0592     |
|    entropy_loss             | 4.11       |
|    explained_variance       | 0.451      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.153      |
|    n_updates                | 4280       |
|    policy_gradient_loss     | 0.199      |
|    std                      | 0.145      |
|    value_loss               | 0.0603     |
--------------------------------------------
Eval num_timesteps=880000, episode_reward=2747.15 +/- 210.27
Episode length: 1000.00 +/- 0.00
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 1e+03     |
|    mean_reward              | 2.75e+03  |
| time/                       |           |
|    total_timesteps          | 880000    |
| train/                      |           |
|    approx_kl                | 2.0485754 |
|    clip_fraction            | 0.777     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.055622  |
|    ent_clip_fraction        | 0.822     |
|    ent_entropy_loss         | 5         |
|    ent_loss                 | 0.101     |
|    ent_policy_gradient_loss | 0.105     |
|    ent_std                  | 0.13      |
|    ent_value_loss           | 0.0421    |
|    entropy_loss             | 4.15      |
|    explained_variance       | 0.881     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0383    |
|    n_updates                | 4290      |
|    policy_gradient_loss     | 0.0324    |
|    std                      | 0.144     |
|    value_loss               | 0.0476    |
-------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 678      |
|    ep_rew_mean     | 1.28e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 430      |
|    time_elapsed    | 5772     |
|    total_timesteps | 880640   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 678        |
|    ep_rew_mean              | 1.29e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 431        |
|    time_elapsed             | 5781       |
|    total_timesteps          | 882688     |
| train/                      |            |
|    approx_kl                | 3.9783041  |
|    clip_fraction            | 0.95       |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.44724116 |
|    ent_clip_fraction        | 0.623      |
|    ent_entropy_loss         | 4.96       |
|    ent_loss                 | -0.0685    |
|    ent_policy_gradient_loss | -0.0212    |
|    ent_std                  | 0.13       |
|    ent_value_loss           | 0.0217     |
|    entropy_loss             | 4.16       |
|    explained_variance       | 0.931      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.144      |
|    n_updates                | 4300       |
|    policy_gradient_loss     | 0.183      |
|    std                      | 0.144      |
|    value_loss               | 0.022      |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 667       |
|    ep_rew_mean              | 1.28e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 432       |
|    time_elapsed             | 5791      |
|    total_timesteps          | 884736    |
| train/                      |           |
|    approx_kl                | 2.0971713 |
|    clip_fraction            | 0.893     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.4978129 |
|    ent_clip_fraction        | 0.738     |
|    ent_entropy_loss         | 5         |
|    ent_loss                 | -0.066    |
|    ent_policy_gradient_loss | -0.000857 |
|    ent_std                  | 0.129     |
|    ent_value_loss           | 0.0122    |
|    entropy_loss             | 4.14      |
|    explained_variance       | 0.211     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.145     |
|    n_updates                | 4310      |
|    policy_gradient_loss     | 0.2       |
|    std                      | 0.145     |
|    value_loss               | 0.0124    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 658       |
|    ep_rew_mean              | 1.24e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 433       |
|    time_elapsed             | 5802      |
|    total_timesteps          | 886784    |
| train/                      |           |
|    approx_kl                | 2.8689234 |
|    clip_fraction            | 0.911     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.0207466 |
|    ent_clip_fraction        | 0.687     |
|    ent_entropy_loss         | 5.02      |
|    ent_loss                 | 0.0173    |
|    ent_policy_gradient_loss | 0.0142    |
|    ent_std                  | 0.129     |
|    ent_value_loss           | 0.0342    |
|    entropy_loss             | 4.11      |
|    explained_variance       | 0.795     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.158     |
|    n_updates                | 4320      |
|    policy_gradient_loss     | 0.146     |
|    std                      | 0.145     |
|    value_loss               | 0.0333    |
-------------------------------------------
------------------------------------------
| rollout/                    |          |
|    ep_len_mean              | 661      |
|    ep_rew_mean              | 1.25e+03 |
| time/                       |          |
|    fps                      | 152      |
|    iterations               | 434      |
|    time_elapsed             | 5812     |
|    total_timesteps          | 888832   |
| train/                      |          |
|    approx_kl                | 4.372595 |
|    clip_fraction            | 0.961    |
|    clip_range               | 0.2      |
|    ent_approx_kl            | 0.545879 |
|    ent_clip_fraction        | 0.579    |
|    ent_entropy_loss         | 5.05     |
|    ent_loss                 | 0.0308   |
|    ent_policy_gradient_loss | -0.0123  |
|    ent_std                  | 0.128    |
|    ent_value_loss           | 0.0379   |
|    entropy_loss             | 4.1      |
|    explained_variance       | 0.907    |
|    learning_rate            | 0.0003   |
|    loss                     | 0.078    |
|    n_updates                | 4330     |
|    policy_gradient_loss     | 0.145    |
|    std                      | 0.145    |
|    value_loss               | 0.0383   |
------------------------------------------
Eval num_timesteps=890000, episode_reward=2276.84 +/- 561.71
Episode length: 942.36 +/- 175.12
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 942        |
|    mean_reward              | 2.28e+03   |
| time/                       |            |
|    total_timesteps          | 890000     |
| train/                      |            |
|    approx_kl                | 3.0570922  |
|    clip_fraction            | 0.951      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.40809208 |
|    ent_clip_fraction        | 0.615      |
|    ent_entropy_loss         | 5.12       |
|    ent_loss                 | -0.0613    |
|    ent_policy_gradient_loss | -0.0317    |
|    ent_std                  | 0.127      |
|    ent_value_loss           | 0.0577     |
|    entropy_loss             | 4.1        |
|    explained_variance       | 0.716      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.232      |
|    n_updates                | 4340       |
|    policy_gradient_loss     | 0.185      |
|    std                      | 0.145      |
|    value_loss               | 0.0592     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 661      |
|    ep_rew_mean     | 1.25e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 435      |
|    time_elapsed    | 5839     |
|    total_timesteps | 890880   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 643        |
|    ep_rew_mean              | 1.22e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 436        |
|    time_elapsed             | 5849       |
|    total_timesteps          | 892928     |
| train/                      |            |
|    approx_kl                | 2.9234643  |
|    clip_fraction            | 0.96       |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.15404968 |
|    ent_clip_fraction        | 0.581      |
|    ent_entropy_loss         | 5.13       |
|    ent_loss                 | -0.0927    |
|    ent_policy_gradient_loss | -0.044     |
|    ent_std                  | 0.127      |
|    ent_value_loss           | 0.0335     |
|    entropy_loss             | 4.1        |
|    explained_variance       | 0.286      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.184      |
|    n_updates                | 4350       |
|    policy_gradient_loss     | 0.197      |
|    std                      | 0.145      |
|    value_loss               | 0.0341     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 630       |
|    ep_rew_mean              | 1.22e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 437       |
|    time_elapsed             | 5859      |
|    total_timesteps          | 894976    |
| train/                      |           |
|    approx_kl                | 3.1028478 |
|    clip_fraction            | 0.933     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.7970594 |
|    ent_clip_fraction        | 0.651     |
|    ent_entropy_loss         | 5.15      |
|    ent_loss                 | 0.0195    |
|    ent_policy_gradient_loss | -0.00528  |
|    ent_std                  | 0.127     |
|    ent_value_loss           | 0.0412    |
|    entropy_loss             | 4.12      |
|    explained_variance       | 0.506     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.191     |
|    n_updates                | 4360      |
|    policy_gradient_loss     | 0.195     |
|    std                      | 0.144     |
|    value_loss               | 0.0402    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 645       |
|    ep_rew_mean              | 1.26e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 438       |
|    time_elapsed             | 5869      |
|    total_timesteps          | 897024    |
| train/                      |           |
|    approx_kl                | 2.0130877 |
|    clip_fraction            | 0.868     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.6867211 |
|    ent_clip_fraction        | 0.772     |
|    ent_entropy_loss         | 5.18      |
|    ent_loss                 | 0.0401    |
|    ent_policy_gradient_loss | 0.0463    |
|    ent_std                  | 0.127     |
|    ent_value_loss           | 0.0531    |
|    entropy_loss             | 4.17      |
|    explained_variance       | 0.466     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.125     |
|    n_updates                | 4370      |
|    policy_gradient_loss     | 0.162     |
|    std                      | 0.143     |
|    value_loss               | 0.056     |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 650        |
|    ep_rew_mean              | 1.29e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 439        |
|    time_elapsed             | 5879       |
|    total_timesteps          | 899072     |
| train/                      |            |
|    approx_kl                | 5.2770033  |
|    clip_fraction            | 0.961      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.36470902 |
|    ent_clip_fraction        | 0.617      |
|    ent_entropy_loss         | 5.2        |
|    ent_loss                 | -0.037     |
|    ent_policy_gradient_loss | -0.0329    |
|    ent_std                  | 0.126      |
|    ent_value_loss           | 0.0417     |
|    entropy_loss             | 4.2        |
|    explained_variance       | 0.912      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.149      |
|    n_updates                | 4380       |
|    policy_gradient_loss     | 0.19       |
|    std                      | 0.143      |
|    value_loss               | 0.0413     |
--------------------------------------------
Eval num_timesteps=900000, episode_reward=2192.84 +/- 887.11
Episode length: 856.44 +/- 276.05
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 856        |
|    mean_reward              | 2.19e+03   |
| time/                       |            |
|    total_timesteps          | 900000     |
| train/                      |            |
|    approx_kl                | 3.1317906  |
|    clip_fraction            | 0.966      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.21828718 |
|    ent_clip_fraction        | 0.596      |
|    ent_entropy_loss         | 5.25       |
|    ent_loss                 | -0.0397    |
|    ent_policy_gradient_loss | -0.0253    |
|    ent_std                  | 0.125      |
|    ent_value_loss           | 0.0552     |
|    entropy_loss             | 4.24       |
|    explained_variance       | 0.148      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0465     |
|    n_updates                | 4390       |
|    policy_gradient_loss     | 0.181      |
|    std                      | 0.142      |
|    value_loss               | 0.0552     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 643      |
|    ep_rew_mean     | 1.29e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 440      |
|    time_elapsed    | 5907     |
|    total_timesteps | 901120   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 640        |
|    ep_rew_mean              | 1.32e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 441        |
|    time_elapsed             | 5917       |
|    total_timesteps          | 903168     |
| train/                      |            |
|    approx_kl                | 2.867935   |
|    clip_fraction            | 0.959      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.16310088 |
|    ent_clip_fraction        | 0.582      |
|    ent_entropy_loss         | 5.3        |
|    ent_loss                 | -0.0645    |
|    ent_policy_gradient_loss | -0.0332    |
|    ent_std                  | 0.124      |
|    ent_value_loss           | 0.0482     |
|    entropy_loss             | 4.29       |
|    explained_variance       | 0.237      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.192      |
|    n_updates                | 4400       |
|    policy_gradient_loss     | 0.169      |
|    std                      | 0.141      |
|    value_loss               | 0.0497     |
--------------------------------------------
------------------------------------------
| rollout/                    |          |
|    ep_len_mean              | 649      |
|    ep_rew_mean              | 1.34e+03 |
| time/                       |          |
|    fps                      | 152      |
|    iterations               | 442      |
|    time_elapsed             | 5927     |
|    total_timesteps          | 905216   |
| train/                      |          |
|    approx_kl                | 2.568051 |
|    clip_fraction            | 0.946    |
|    clip_range               | 0.2      |
|    ent_approx_kl            | 0.405215 |
|    ent_clip_fraction        | 0.612    |
|    ent_entropy_loss         | 5.33     |
|    ent_loss                 | -0.0392  |
|    ent_policy_gradient_loss | -0.0164  |
|    ent_std                  | 0.124    |
|    ent_value_loss           | 0.0472   |
|    entropy_loss             | 4.3      |
|    explained_variance       | 0.309    |
|    learning_rate            | 0.0003   |
|    loss                     | 0.104    |
|    n_updates                | 4410     |
|    policy_gradient_loss     | 0.159    |
|    std                      | 0.142    |
|    value_loss               | 0.0481   |
------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 642        |
|    ep_rew_mean              | 1.33e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 443        |
|    time_elapsed             | 5937       |
|    total_timesteps          | 907264     |
| train/                      |            |
|    approx_kl                | 2.7907028  |
|    clip_fraction            | 0.961      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.11571284 |
|    ent_clip_fraction        | 0.575      |
|    ent_entropy_loss         | 5.36       |
|    ent_loss                 | -0.0597    |
|    ent_policy_gradient_loss | -0.0362    |
|    ent_std                  | 0.124      |
|    ent_value_loss           | 0.0347     |
|    entropy_loss             | 4.29       |
|    explained_variance       | 0.455      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.159      |
|    n_updates                | 4420       |
|    policy_gradient_loss     | 0.299      |
|    std                      | 0.141      |
|    value_loss               | 0.0355     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 649        |
|    ep_rew_mean              | 1.35e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 444        |
|    time_elapsed             | 5947       |
|    total_timesteps          | 909312     |
| train/                      |            |
|    approx_kl                | 4.261366   |
|    clip_fraction            | 0.965      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.17318681 |
|    ent_clip_fraction        | 0.595      |
|    ent_entropy_loss         | 5.4        |
|    ent_loss                 | -0.037     |
|    ent_policy_gradient_loss | -0.0389    |
|    ent_std                  | 0.123      |
|    ent_value_loss           | 0.0479     |
|    entropy_loss             | 4.35       |
|    explained_variance       | 0.88       |
|    learning_rate            | 0.0003     |
|    loss                     | 0.169      |
|    n_updates                | 4430       |
|    policy_gradient_loss     | 0.179      |
|    std                      | 0.14       |
|    value_loss               | 0.0484     |
--------------------------------------------
Eval num_timesteps=910000, episode_reward=2528.86 +/- 532.51
Episode length: 955.28 +/- 134.84
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 955       |
|    mean_reward              | 2.53e+03  |
| time/                       |           |
|    total_timesteps          | 910000    |
| train/                      |           |
|    approx_kl                | 2.215744  |
|    clip_fraction            | 0.913     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.7985346 |
|    ent_clip_fraction        | 0.749     |
|    ent_entropy_loss         | 5.46      |
|    ent_loss                 | -0.0227   |
|    ent_policy_gradient_loss | 0.0152    |
|    ent_std                  | 0.122     |
|    ent_value_loss           | 0.0211    |
|    entropy_loss             | 4.39      |
|    explained_variance       | 0.763     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0454    |
|    n_updates                | 4440      |
|    policy_gradient_loss     | 0.192     |
|    std                      | 0.14      |
|    value_loss               | 0.0239    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 652      |
|    ep_rew_mean     | 1.35e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 445      |
|    time_elapsed    | 5976     |
|    total_timesteps | 911360   |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 661       |
|    ep_rew_mean              | 1.39e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 446       |
|    time_elapsed             | 5987      |
|    total_timesteps          | 913408    |
| train/                      |           |
|    approx_kl                | 5.3459206 |
|    clip_fraction            | 0.806     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.2474818 |
|    ent_clip_fraction        | 0.774     |
|    ent_entropy_loss         | 5.44      |
|    ent_loss                 | 0.049     |
|    ent_policy_gradient_loss | 0.0615    |
|    ent_std                  | 0.123     |
|    ent_value_loss           | 0.0532    |
|    entropy_loss             | 4.39      |
|    explained_variance       | 0.884     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.126     |
|    n_updates                | 4450      |
|    policy_gradient_loss     | 0.0735    |
|    std                      | 0.14      |
|    value_loss               | 0.0593    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 655       |
|    ep_rew_mean              | 1.39e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 447       |
|    time_elapsed             | 5997      |
|    total_timesteps          | 915456    |
| train/                      |           |
|    approx_kl                | 3.218606  |
|    clip_fraction            | 0.956     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.4479196 |
|    ent_clip_fraction        | 0.627     |
|    ent_entropy_loss         | 5.44      |
|    ent_loss                 | -0.0421   |
|    ent_policy_gradient_loss | -0.0192   |
|    ent_std                  | 0.123     |
|    ent_value_loss           | 0.0218    |
|    entropy_loss             | 4.39      |
|    explained_variance       | 0.692     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.218     |
|    n_updates                | 4460      |
|    policy_gradient_loss     | 0.213     |
|    std                      | 0.139     |
|    value_loss               | 0.0215    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 674        |
|    ep_rew_mean              | 1.45e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 448        |
|    time_elapsed             | 6006       |
|    total_timesteps          | 917504     |
| train/                      |            |
|    approx_kl                | 2.969838   |
|    clip_fraction            | 0.965      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.09426708 |
|    ent_clip_fraction        | 0.574      |
|    ent_entropy_loss         | 5.45       |
|    ent_loss                 | -0.0457    |
|    ent_policy_gradient_loss | -0.0382    |
|    ent_std                  | 0.122      |
|    ent_value_loss           | 0.0618     |
|    entropy_loss             | 4.41       |
|    explained_variance       | 0.488      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.19       |
|    n_updates                | 4470       |
|    policy_gradient_loss     | 0.173      |
|    std                      | 0.139      |
|    value_loss               | 0.0591     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 678       |
|    ep_rew_mean              | 1.47e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 449       |
|    time_elapsed             | 6016      |
|    total_timesteps          | 919552    |
| train/                      |           |
|    approx_kl                | 2.8559248 |
|    clip_fraction            | 0.956     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.2524283 |
|    ent_clip_fraction        | 0.597     |
|    ent_entropy_loss         | 5.44      |
|    ent_loss                 | -0.0512   |
|    ent_policy_gradient_loss | -0.0184   |
|    ent_std                  | 0.123     |
|    ent_value_loss           | 0.0376    |
|    entropy_loss             | 4.43      |
|    explained_variance       | 0.567     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.129     |
|    n_updates                | 4480      |
|    policy_gradient_loss     | 0.211     |
|    std                      | 0.139     |
|    value_loss               | 0.036     |
-------------------------------------------
Eval num_timesteps=920000, episode_reward=2447.78 +/- 890.34
Episode length: 877.24 +/- 269.09
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 877       |
|    mean_reward              | 2.45e+03  |
| time/                       |           |
|    total_timesteps          | 920000    |
| train/                      |           |
|    approx_kl                | 4.708662  |
|    clip_fraction            | 0.945     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.6577972 |
|    ent_clip_fraction        | 0.653     |
|    ent_entropy_loss         | 5.44      |
|    ent_loss                 | -0.0236   |
|    ent_policy_gradient_loss | 0.00807   |
|    ent_std                  | 0.123     |
|    ent_value_loss           | 0.0315    |
|    entropy_loss             | 4.45      |
|    explained_variance       | 0.927     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.125     |
|    n_updates                | 4490      |
|    policy_gradient_loss     | 0.169     |
|    std                      | 0.139     |
|    value_loss               | 0.032     |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 682      |
|    ep_rew_mean     | 1.49e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 450      |
|    time_elapsed    | 6044     |
|    total_timesteps | 921600   |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 687       |
|    ep_rew_mean              | 1.52e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 451       |
|    time_elapsed             | 6053      |
|    total_timesteps          | 923648    |
| train/                      |           |
|    approx_kl                | 2.1392727 |
|    clip_fraction            | 0.895     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.2956502 |
|    ent_clip_fraction        | 0.746     |
|    ent_entropy_loss         | 5.42      |
|    ent_loss                 | 0.18      |
|    ent_policy_gradient_loss | 0.0518    |
|    ent_std                  | 0.123     |
|    ent_value_loss           | 0.0128    |
|    entropy_loss             | 4.46      |
|    explained_variance       | 0.452     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.151     |
|    n_updates                | 4500      |
|    policy_gradient_loss     | 0.232     |
|    std                      | 0.138     |
|    value_loss               | 0.0134    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 687       |
|    ep_rew_mean              | 1.53e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 452       |
|    time_elapsed             | 6063      |
|    total_timesteps          | 925696    |
| train/                      |           |
|    approx_kl                | 2.4539757 |
|    clip_fraction            | 0.91      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.1588571 |
|    ent_clip_fraction        | 0.714     |
|    ent_entropy_loss         | 5.42      |
|    ent_loss                 | -0.00628  |
|    ent_policy_gradient_loss | 0.0462    |
|    ent_std                  | 0.123     |
|    ent_value_loss           | 0.0166    |
|    entropy_loss             | 4.5       |
|    explained_variance       | 0.626     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.267     |
|    n_updates                | 4510      |
|    policy_gradient_loss     | 0.18      |
|    std                      | 0.138     |
|    value_loss               | 0.0173    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 687       |
|    ep_rew_mean              | 1.54e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 453       |
|    time_elapsed             | 6073      |
|    total_timesteps          | 927744    |
| train/                      |           |
|    approx_kl                | 3.4828517 |
|    clip_fraction            | 0.961     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.2509388 |
|    ent_clip_fraction        | 0.594     |
|    ent_entropy_loss         | 5.44      |
|    ent_loss                 | -0.0466   |
|    ent_policy_gradient_loss | -0.0285   |
|    ent_std                  | 0.122     |
|    ent_value_loss           | 0.0139    |
|    entropy_loss             | 4.48      |
|    explained_variance       | 0.663     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.207     |
|    n_updates                | 4520      |
|    policy_gradient_loss     | 0.277     |
|    std                      | 0.139     |
|    value_loss               | 0.014     |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 694        |
|    ep_rew_mean              | 1.57e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 454        |
|    time_elapsed             | 6083       |
|    total_timesteps          | 929792     |
| train/                      |            |
|    approx_kl                | 2.7142162  |
|    clip_fraction            | 0.941      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.87336355 |
|    ent_clip_fraction        | 0.673      |
|    ent_entropy_loss         | 5.49       |
|    ent_loss                 | -0.0418    |
|    ent_policy_gradient_loss | 0.00271    |
|    ent_std                  | 0.122      |
|    ent_value_loss           | 0.0146     |
|    entropy_loss             | 4.44       |
|    explained_variance       | 0.432      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.257      |
|    n_updates                | 4530       |
|    policy_gradient_loss     | 0.227      |
|    std                      | 0.139      |
|    value_loss               | 0.0144     |
--------------------------------------------
Eval num_timesteps=930000, episode_reward=2203.06 +/- 875.34
Episode length: 872.20 +/- 235.69
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 872       |
|    mean_reward              | 2.2e+03   |
| time/                       |           |
|    total_timesteps          | 930000    |
| train/                      |           |
|    approx_kl                | 3.7067418 |
|    clip_fraction            | 0.915     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.5571331 |
|    ent_clip_fraction        | 0.724     |
|    ent_entropy_loss         | 5.53      |
|    ent_loss                 | 0.0309    |
|    ent_policy_gradient_loss | 0.0555    |
|    ent_std                  | 0.121     |
|    ent_value_loss           | 0.012     |
|    entropy_loss             | 4.45      |
|    explained_variance       | 0.542     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.103     |
|    n_updates                | 4540      |
|    policy_gradient_loss     | 0.181     |
|    std                      | 0.139     |
|    value_loss               | 0.0126    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 694      |
|    ep_rew_mean     | 1.58e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 455      |
|    time_elapsed    | 6111     |
|    total_timesteps | 931840   |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 702       |
|    ep_rew_mean              | 1.62e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 456       |
|    time_elapsed             | 6122      |
|    total_timesteps          | 933888    |
| train/                      |           |
|    approx_kl                | 7.389917  |
|    clip_fraction            | 0.96      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.2256235 |
|    ent_clip_fraction        | 0.602     |
|    ent_entropy_loss         | 5.55      |
|    ent_loss                 | -0.0492   |
|    ent_policy_gradient_loss | -0.0115   |
|    ent_std                  | 0.121     |
|    ent_value_loss           | 0.0572    |
|    entropy_loss             | 4.45      |
|    explained_variance       | 0.328     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.279     |
|    n_updates                | 4550      |
|    policy_gradient_loss     | 0.188     |
|    std                      | 0.139     |
|    value_loss               | 0.0565    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 695        |
|    ep_rew_mean              | 1.61e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 457        |
|    time_elapsed             | 6131       |
|    total_timesteps          | 935936     |
| train/                      |            |
|    approx_kl                | 3.2584052  |
|    clip_fraction            | 0.955      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.61037004 |
|    ent_clip_fraction        | 0.635      |
|    ent_entropy_loss         | 5.59       |
|    ent_loss                 | -0.054     |
|    ent_policy_gradient_loss | -0.02      |
|    ent_std                  | 0.12       |
|    ent_value_loss           | 0.00963    |
|    entropy_loss             | 4.45       |
|    explained_variance       | 0.318      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.154      |
|    n_updates                | 4560       |
|    policy_gradient_loss     | 0.248      |
|    std                      | 0.139      |
|    value_loss               | 0.00979    |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 703        |
|    ep_rew_mean              | 1.63e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 458        |
|    time_elapsed             | 6141       |
|    total_timesteps          | 937984     |
| train/                      |            |
|    approx_kl                | 3.964015   |
|    clip_fraction            | 0.951      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.61383533 |
|    ent_clip_fraction        | 0.598      |
|    ent_entropy_loss         | 5.64       |
|    ent_loss                 | -0.0197    |
|    ent_policy_gradient_loss | -0.00844   |
|    ent_std                  | 0.119      |
|    ent_value_loss           | 0.0365     |
|    entropy_loss             | 4.45       |
|    explained_variance       | 0.931      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.107      |
|    n_updates                | 4570       |
|    policy_gradient_loss     | 0.164      |
|    std                      | 0.139      |
|    value_loss               | 0.0373     |
--------------------------------------------
Eval num_timesteps=940000, episode_reward=2527.37 +/- 742.23
Episode length: 939.84 +/- 202.65
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 940       |
|    mean_reward              | 2.53e+03  |
| time/                       |           |
|    total_timesteps          | 940000    |
| train/                      |           |
|    approx_kl                | 4.6791015 |
|    clip_fraction            | 0.798     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 4.469593  |
|    ent_clip_fraction        | 0.872     |
|    ent_entropy_loss         | 5.64      |
|    ent_loss                 | 0.107     |
|    ent_policy_gradient_loss | 0.158     |
|    ent_std                  | 0.12      |
|    ent_value_loss           | 0.0308    |
|    entropy_loss             | 4.51      |
|    explained_variance       | 0.913     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.00656   |
|    n_updates                | 4580      |
|    policy_gradient_loss     | 0.111     |
|    std                      | 0.137     |
|    value_loss               | 0.0375    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 709      |
|    ep_rew_mean     | 1.64e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 459      |
|    time_elapsed    | 6168     |
|    total_timesteps | 940032   |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 720       |
|    ep_rew_mean              | 1.68e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 460       |
|    time_elapsed             | 6178      |
|    total_timesteps          | 942080    |
| train/                      |           |
|    approx_kl                | 3.8892198 |
|    clip_fraction            | 0.961     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.5085468 |
|    ent_clip_fraction        | 0.606     |
|    ent_entropy_loss         | 5.62      |
|    ent_loss                 | -0.0326   |
|    ent_policy_gradient_loss | -0.0388   |
|    ent_std                  | 0.12      |
|    ent_value_loss           | 0.0319    |
|    entropy_loss             | 4.53      |
|    explained_variance       | 0.553     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.201     |
|    n_updates                | 4590      |
|    policy_gradient_loss     | 0.197     |
|    std                      | 0.138     |
|    value_loss               | 0.0305    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 720       |
|    ep_rew_mean              | 1.69e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 461       |
|    time_elapsed             | 6188      |
|    total_timesteps          | 944128    |
| train/                      |           |
|    approx_kl                | 3.171312  |
|    clip_fraction            | 0.955     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.5879754 |
|    ent_clip_fraction        | 0.616     |
|    ent_entropy_loss         | 5.66      |
|    ent_loss                 | -0.0137   |
|    ent_policy_gradient_loss | -0.0268   |
|    ent_std                  | 0.119     |
|    ent_value_loss           | 0.0503    |
|    entropy_loss             | 4.51      |
|    explained_variance       | 0.539     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.174     |
|    n_updates                | 4600      |
|    policy_gradient_loss     | 0.167     |
|    std                      | 0.138     |
|    value_loss               | 0.0466    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 730        |
|    ep_rew_mean              | 1.71e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 462        |
|    time_elapsed             | 6198       |
|    total_timesteps          | 946176     |
| train/                      |            |
|    approx_kl                | 3.2123013  |
|    clip_fraction            | 0.961      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.44767606 |
|    ent_clip_fraction        | 0.609      |
|    ent_entropy_loss         | 5.73       |
|    ent_loss                 | -0.0374    |
|    ent_policy_gradient_loss | -0.0342    |
|    ent_std                  | 0.118      |
|    ent_value_loss           | 0.0653     |
|    entropy_loss             | 4.53       |
|    explained_variance       | 0.708      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.173      |
|    n_updates                | 4610       |
|    policy_gradient_loss     | 0.205      |
|    std                      | 0.137      |
|    value_loss               | 0.0635     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 737        |
|    ep_rew_mean              | 1.75e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 463        |
|    time_elapsed             | 6208       |
|    total_timesteps          | 948224     |
| train/                      |            |
|    approx_kl                | 2.1939094  |
|    clip_fraction            | 0.931      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.28890097 |
|    ent_clip_fraction        | 0.574      |
|    ent_entropy_loss         | 5.78       |
|    ent_loss                 | -0.041     |
|    ent_policy_gradient_loss | -0.0214    |
|    ent_std                  | 0.118      |
|    ent_value_loss           | 0.0237     |
|    entropy_loss             | 4.58       |
|    explained_variance       | 0.969      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.135      |
|    n_updates                | 4620       |
|    policy_gradient_loss     | 0.134      |
|    std                      | 0.136      |
|    value_loss               | 0.0233     |
--------------------------------------------
Eval num_timesteps=950000, episode_reward=2963.54 +/- 555.26
Episode length: 989.80 +/- 49.97
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 990       |
|    mean_reward              | 2.96e+03  |
| time/                       |           |
|    total_timesteps          | 950000    |
| train/                      |           |
|    approx_kl                | 2.090191  |
|    clip_fraction            | 0.815     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.7190347 |
|    ent_clip_fraction        | 0.831     |
|    ent_entropy_loss         | 5.77      |
|    ent_loss                 | 0.0595    |
|    ent_policy_gradient_loss | 0.158     |
|    ent_std                  | 0.118     |
|    ent_value_loss           | 0.0142    |
|    entropy_loss             | 4.64      |
|    explained_variance       | 0.194     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.133     |
|    n_updates                | 4630      |
|    policy_gradient_loss     | 0.11      |
|    std                      | 0.136     |
|    value_loss               | 0.0158    |
-------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 740      |
|    ep_rew_mean     | 1.76e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 464      |
|    time_elapsed    | 6239     |
|    total_timesteps | 950272   |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 746       |
|    ep_rew_mean              | 1.78e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 465       |
|    time_elapsed             | 6249      |
|    total_timesteps          | 952320    |
| train/                      |           |
|    approx_kl                | 2.5623012 |
|    clip_fraction            | 0.909     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.4764707 |
|    ent_clip_fraction        | 0.722     |
|    ent_entropy_loss         | 5.77      |
|    ent_loss                 | -0.024    |
|    ent_policy_gradient_loss | -0.00618  |
|    ent_std                  | 0.118     |
|    ent_value_loss           | 0.0417    |
|    entropy_loss             | 4.61      |
|    explained_variance       | 0.416     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.108     |
|    n_updates                | 4640      |
|    policy_gradient_loss     | 0.178     |
|    std                      | 0.136     |
|    value_loss               | 0.046     |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 744       |
|    ep_rew_mean              | 1.8e+03   |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 466       |
|    time_elapsed             | 6259      |
|    total_timesteps          | 954368    |
| train/                      |           |
|    approx_kl                | 2.852973  |
|    clip_fraction            | 0.925     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.3779492 |
|    ent_clip_fraction        | 0.722     |
|    ent_entropy_loss         | 5.79      |
|    ent_loss                 | 0.0462    |
|    ent_policy_gradient_loss | 0.0443    |
|    ent_std                  | 0.117     |
|    ent_value_loss           | 0.0374    |
|    entropy_loss             | 4.58      |
|    explained_variance       | 0.364     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0852    |
|    n_updates                | 4650      |
|    policy_gradient_loss     | 0.17      |
|    std                      | 0.137     |
|    value_loss               | 0.0383    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 735        |
|    ep_rew_mean              | 1.78e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 467        |
|    time_elapsed             | 6269       |
|    total_timesteps          | 956416     |
| train/                      |            |
|    approx_kl                | 3.7850914  |
|    clip_fraction            | 0.961      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.37978226 |
|    ent_clip_fraction        | 0.618      |
|    ent_entropy_loss         | 5.8        |
|    ent_loss                 | -0.0645    |
|    ent_policy_gradient_loss | -0.0293    |
|    ent_std                  | 0.117      |
|    ent_value_loss           | 0.0377     |
|    entropy_loss             | 4.57       |
|    explained_variance       | 0.733      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.213      |
|    n_updates                | 4660       |
|    policy_gradient_loss     | 0.189      |
|    std                      | 0.137      |
|    value_loss               | 0.0351     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 737       |
|    ep_rew_mean              | 1.8e+03   |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 468       |
|    time_elapsed             | 6279      |
|    total_timesteps          | 958464    |
| train/                      |           |
|    approx_kl                | 2.4103017 |
|    clip_fraction            | 0.882     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.8366807 |
|    ent_clip_fraction        | 0.745     |
|    ent_entropy_loss         | 5.82      |
|    ent_loss                 | 0.0472    |
|    ent_policy_gradient_loss | 0.0527    |
|    ent_std                  | 0.117     |
|    ent_value_loss           | 0.0357    |
|    entropy_loss             | 4.61      |
|    explained_variance       | 0.741     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.135     |
|    n_updates                | 4670      |
|    policy_gradient_loss     | 0.131     |
|    std                      | 0.136     |
|    value_loss               | 0.0404    |
-------------------------------------------
Eval num_timesteps=960000, episode_reward=2947.23 +/- 580.88
Episode length: 955.44 +/- 121.68
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 955        |
|    mean_reward              | 2.95e+03   |
| time/                       |            |
|    total_timesteps          | 960000     |
| train/                      |            |
|    approx_kl                | 3.7241502  |
|    clip_fraction            | 0.959      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.71278864 |
|    ent_clip_fraction        | 0.636      |
|    ent_entropy_loss         | 5.84       |
|    ent_loss                 | -0.0795    |
|    ent_policy_gradient_loss | -0.0273    |
|    ent_std                  | 0.117      |
|    ent_value_loss           | 0.0188     |
|    entropy_loss             | 4.62       |
|    explained_variance       | 0.966      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.172      |
|    n_updates                | 4680       |
|    policy_gradient_loss     | 0.218      |
|    std                      | 0.136      |
|    value_loss               | 0.0178     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 750      |
|    ep_rew_mean     | 1.83e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 469      |
|    time_elapsed    | 6308     |
|    total_timesteps | 960512   |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 759       |
|    ep_rew_mean              | 1.87e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 470       |
|    time_elapsed             | 6318      |
|    total_timesteps          | 962560    |
| train/                      |           |
|    approx_kl                | 3.618524  |
|    clip_fraction            | 0.92      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.4368292 |
|    ent_clip_fraction        | 0.717     |
|    ent_entropy_loss         | 5.86      |
|    ent_loss                 | 0.00591   |
|    ent_policy_gradient_loss | 0.0321    |
|    ent_std                  | 0.117     |
|    ent_value_loss           | 0.021     |
|    entropy_loss             | 4.64      |
|    explained_variance       | 0.927     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.12      |
|    n_updates                | 4690      |
|    policy_gradient_loss     | 0.154     |
|    std                      | 0.135     |
|    value_loss               | 0.0211    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 768        |
|    ep_rew_mean              | 1.89e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 471        |
|    time_elapsed             | 6328       |
|    total_timesteps          | 964608     |
| train/                      |            |
|    approx_kl                | 3.2244291  |
|    clip_fraction            | 0.951      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.88309443 |
|    ent_clip_fraction        | 0.691      |
|    ent_entropy_loss         | 5.86       |
|    ent_loss                 | 0.0267     |
|    ent_policy_gradient_loss | 0.015      |
|    ent_std                  | 0.117      |
|    ent_value_loss           | 0.0117     |
|    entropy_loss             | 4.68       |
|    explained_variance       | 0.361      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.215      |
|    n_updates                | 4700       |
|    policy_gradient_loss     | 0.222      |
|    std                      | 0.134      |
|    value_loss               | 0.0121     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 765       |
|    ep_rew_mean              | 1.89e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 472       |
|    time_elapsed             | 6338      |
|    total_timesteps          | 966656    |
| train/                      |           |
|    approx_kl                | 2.3732123 |
|    clip_fraction            | 0.848     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.574737  |
|    ent_clip_fraction        | 0.774     |
|    ent_entropy_loss         | 5.88      |
|    ent_loss                 | 0.0414    |
|    ent_policy_gradient_loss | 0.0491    |
|    ent_std                  | 0.116     |
|    ent_value_loss           | 0.0163    |
|    entropy_loss             | 4.68      |
|    explained_variance       | 0.963     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.133     |
|    n_updates                | 4710      |
|    policy_gradient_loss     | 0.209     |
|    std                      | 0.135     |
|    value_loss               | 0.0161    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 763        |
|    ep_rew_mean              | 1.88e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 473        |
|    time_elapsed             | 6348       |
|    total_timesteps          | 968704     |
| train/                      |            |
|    approx_kl                | 3.6569889  |
|    clip_fraction            | 0.956      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.80989367 |
|    ent_clip_fraction        | 0.633      |
|    ent_entropy_loss         | 5.93       |
|    ent_loss                 | -0.024     |
|    ent_policy_gradient_loss | -0.0156    |
|    ent_std                  | 0.115      |
|    ent_value_loss           | 0.0325     |
|    entropy_loss             | 4.67       |
|    explained_variance       | 0.718      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.18       |
|    n_updates                | 4720       |
|    policy_gradient_loss     | 0.244      |
|    std                      | 0.135      |
|    value_loss               | 0.0341     |
--------------------------------------------
Eval num_timesteps=970000, episode_reward=2714.96 +/- 904.62
Episode length: 868.00 +/- 278.20
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 868       |
|    mean_reward              | 2.71e+03  |
| time/                       |           |
|    total_timesteps          | 970000    |
| train/                      |           |
|    approx_kl                | 3.2099483 |
|    clip_fraction            | 0.923     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.6249745 |
|    ent_clip_fraction        | 0.711     |
|    ent_entropy_loss         | 5.99      |
|    ent_loss                 | 0.0379    |
|    ent_policy_gradient_loss | 0.0282    |
|    ent_std                  | 0.114     |
|    ent_value_loss           | 0.0457    |
|    entropy_loss             | 4.68      |
|    explained_variance       | 0.93      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0635    |
|    n_updates                | 4730      |
|    policy_gradient_loss     | 0.171     |
|    std                      | 0.135     |
|    value_loss               | 0.0462    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 777      |
|    ep_rew_mean     | 1.92e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 474      |
|    time_elapsed    | 6376     |
|    total_timesteps | 970752   |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 794       |
|    ep_rew_mean              | 1.98e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 475       |
|    time_elapsed             | 6386      |
|    total_timesteps          | 972800    |
| train/                      |           |
|    approx_kl                | 4.886138  |
|    clip_fraction            | 0.959     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.7407907 |
|    ent_clip_fraction        | 0.665     |
|    ent_entropy_loss         | 6         |
|    ent_loss                 | -0.0321   |
|    ent_policy_gradient_loss | 0.00541   |
|    ent_std                  | 0.115     |
|    ent_value_loss           | 0.0161    |
|    entropy_loss             | 4.69      |
|    explained_variance       | 0.959     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.11      |
|    n_updates                | 4740      |
|    policy_gradient_loss     | 0.199     |
|    std                      | 0.134     |
|    value_loss               | 0.018     |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 804       |
|    ep_rew_mean              | 1.99e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 476       |
|    time_elapsed             | 6397      |
|    total_timesteps          | 974848    |
| train/                      |           |
|    approx_kl                | 5.4537086 |
|    clip_fraction            | 0.923     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.357599  |
|    ent_clip_fraction        | 0.704     |
|    ent_entropy_loss         | 6         |
|    ent_loss                 | 0.0356    |
|    ent_policy_gradient_loss | 0.036     |
|    ent_std                  | 0.114     |
|    ent_value_loss           | 0.0237    |
|    entropy_loss             | 4.71      |
|    explained_variance       | 0.893     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.121     |
|    n_updates                | 4750      |
|    policy_gradient_loss     | 0.195     |
|    std                      | 0.135     |
|    value_loss               | 0.0247    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 803       |
|    ep_rew_mean              | 2e+03     |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 477       |
|    time_elapsed             | 6407      |
|    total_timesteps          | 976896    |
| train/                      |           |
|    approx_kl                | 5.631591  |
|    clip_fraction            | 0.933     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.3462502 |
|    ent_clip_fraction        | 0.715     |
|    ent_entropy_loss         | 5.99      |
|    ent_loss                 | 0.112     |
|    ent_policy_gradient_loss | 0.114     |
|    ent_std                  | 0.115     |
|    ent_value_loss           | 0.00743   |
|    entropy_loss             | 4.72      |
|    explained_variance       | 0.991     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0215    |
|    n_updates                | 4760      |
|    policy_gradient_loss     | 0.167     |
|    std                      | 0.134     |
|    value_loss               | 0.00784   |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 812        |
|    ep_rew_mean              | 2.04e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 478        |
|    time_elapsed             | 6417       |
|    total_timesteps          | 978944     |
| train/                      |            |
|    approx_kl                | 3.344967   |
|    clip_fraction            | 0.965      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.46069163 |
|    ent_clip_fraction        | 0.603      |
|    ent_entropy_loss         | 6.01       |
|    ent_loss                 | -0.0815    |
|    ent_policy_gradient_loss | -0.016     |
|    ent_std                  | 0.114      |
|    ent_value_loss           | 0.037      |
|    entropy_loss             | 4.73       |
|    explained_variance       | 0.389      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.155      |
|    n_updates                | 4770       |
|    policy_gradient_loss     | 0.212      |
|    std                      | 0.134      |
|    value_loss               | 0.0368     |
--------------------------------------------
Eval num_timesteps=980000, episode_reward=2838.23 +/- 941.62
Episode length: 935.16 +/- 220.86
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 935        |
|    mean_reward              | 2.84e+03   |
| time/                       |            |
|    total_timesteps          | 980000     |
| train/                      |            |
|    approx_kl                | 3.3351836  |
|    clip_fraction            | 0.964      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.32180762 |
|    ent_clip_fraction        | 0.612      |
|    ent_entropy_loss         | 6.03       |
|    ent_loss                 | -0.0582    |
|    ent_policy_gradient_loss | -0.0366    |
|    ent_std                  | 0.114      |
|    ent_value_loss           | 0.0107     |
|    entropy_loss             | 4.75       |
|    explained_variance       | 0.598      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.195      |
|    n_updates                | 4780       |
|    policy_gradient_loss     | 0.232      |
|    std                      | 0.133      |
|    value_loss               | 0.0116     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 817      |
|    ep_rew_mean     | 2.05e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 479      |
|    time_elapsed    | 6445     |
|    total_timesteps | 980992   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 819        |
|    ep_rew_mean              | 2.07e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 480        |
|    time_elapsed             | 6455       |
|    total_timesteps          | 983040     |
| train/                      |            |
|    approx_kl                | 3.396468   |
|    clip_fraction            | 0.97       |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.10306412 |
|    ent_clip_fraction        | 0.59       |
|    ent_entropy_loss         | 6.07       |
|    ent_loss                 | -0.0539    |
|    ent_policy_gradient_loss | -0.0269    |
|    ent_std                  | 0.113      |
|    ent_value_loss           | 0.053      |
|    entropy_loss             | 4.81       |
|    explained_variance       | 0.424      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.198      |
|    n_updates                | 4790       |
|    policy_gradient_loss     | 0.187      |
|    std                      | 0.132      |
|    value_loss               | 0.0525     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 827       |
|    ep_rew_mean              | 2.1e+03   |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 481       |
|    time_elapsed             | 6465      |
|    total_timesteps          | 985088    |
| train/                      |           |
|    approx_kl                | 2.9364638 |
|    clip_fraction            | 0.934     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.8611263 |
|    ent_clip_fraction        | 0.686     |
|    ent_entropy_loss         | 6.1       |
|    ent_loss                 | -0.0266   |
|    ent_policy_gradient_loss | -0.00161  |
|    ent_std                  | 0.113     |
|    ent_value_loss           | 0.033     |
|    entropy_loss             | 4.86      |
|    explained_variance       | 0.474     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0862    |
|    n_updates                | 4800      |
|    policy_gradient_loss     | 0.173     |
|    std                      | 0.132     |
|    value_loss               | 0.0345    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 828       |
|    ep_rew_mean              | 2.11e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 482       |
|    time_elapsed             | 6476      |
|    total_timesteps          | 987136    |
| train/                      |           |
|    approx_kl                | 2.9211473 |
|    clip_fraction            | 0.934     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.143402  |
|    ent_clip_fraction        | 0.727     |
|    ent_entropy_loss         | 6.1       |
|    ent_loss                 | -0.0641   |
|    ent_policy_gradient_loss | 0.0233    |
|    ent_std                  | 0.113     |
|    ent_value_loss           | 0.0163    |
|    entropy_loss             | 4.9       |
|    explained_variance       | 0.58      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.219     |
|    n_updates                | 4810      |
|    policy_gradient_loss     | 0.206     |
|    std                      | 0.131     |
|    value_loss               | 0.0169    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 822       |
|    ep_rew_mean              | 2.11e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 483       |
|    time_elapsed             | 6486      |
|    total_timesteps          | 989184    |
| train/                      |           |
|    approx_kl                | 3.4131732 |
|    clip_fraction            | 0.949     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.9055005 |
|    ent_clip_fraction        | 0.675     |
|    ent_entropy_loss         | 6.11      |
|    ent_loss                 | -0.0214   |
|    ent_policy_gradient_loss | 0.0158    |
|    ent_std                  | 0.113     |
|    ent_value_loss           | 0.0115    |
|    entropy_loss             | 4.91      |
|    explained_variance       | 0.466     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.239     |
|    n_updates                | 4820      |
|    policy_gradient_loss     | 0.214     |
|    std                      | 0.131     |
|    value_loss               | 0.0117    |
-------------------------------------------
Eval num_timesteps=990000, episode_reward=2902.55 +/- 975.76
Episode length: 906.36 +/- 246.12
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 906       |
|    mean_reward              | 2.9e+03   |
| time/                       |           |
|    total_timesteps          | 990000    |
| train/                      |           |
|    approx_kl                | 3.7695255 |
|    clip_fraction            | 0.969     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.2929755 |
|    ent_clip_fraction        | 0.627     |
|    ent_entropy_loss         | 6.12      |
|    ent_loss                 | -0.0351   |
|    ent_policy_gradient_loss | -0.0227   |
|    ent_std                  | 0.113     |
|    ent_value_loss           | 0.0381    |
|    entropy_loss             | 4.91      |
|    explained_variance       | 0.585     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.158     |
|    n_updates                | 4830      |
|    policy_gradient_loss     | 0.178     |
|    std                      | 0.131     |
|    value_loss               | 0.0373    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 830      |
|    ep_rew_mean     | 2.14e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 484      |
|    time_elapsed    | 6514     |
|    total_timesteps | 991232   |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 836        |
|    ep_rew_mean              | 2.16e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 485        |
|    time_elapsed             | 6524       |
|    total_timesteps          | 993280     |
| train/                      |            |
|    approx_kl                | 3.3621454  |
|    clip_fraction            | 0.959      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.72657704 |
|    ent_clip_fraction        | 0.662      |
|    ent_entropy_loss         | 6.13       |
|    ent_loss                 | 0.0119     |
|    ent_policy_gradient_loss | -0.0129    |
|    ent_std                  | 0.113      |
|    ent_value_loss           | 0.0089     |
|    entropy_loss             | 4.93       |
|    explained_variance       | 0.237      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.215      |
|    n_updates                | 4840       |
|    policy_gradient_loss     | 0.208      |
|    std                      | 0.131      |
|    value_loss               | 0.00951    |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 844       |
|    ep_rew_mean              | 2.19e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 486       |
|    time_elapsed             | 6534      |
|    total_timesteps          | 995328    |
| train/                      |           |
|    approx_kl                | 9.429932  |
|    clip_fraction            | 0.944     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.3177574 |
|    ent_clip_fraction        | 0.718     |
|    ent_entropy_loss         | 6.15      |
|    ent_loss                 | -0.00917  |
|    ent_policy_gradient_loss | 0.0162    |
|    ent_std                  | 0.112     |
|    ent_value_loss           | 0.0136    |
|    entropy_loss             | 4.98      |
|    explained_variance       | 0.976     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.173     |
|    n_updates                | 4850      |
|    policy_gradient_loss     | 0.187     |
|    std                      | 0.129     |
|    value_loss               | 0.014     |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 844        |
|    ep_rew_mean              | 2.2e+03    |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 487        |
|    time_elapsed             | 6544       |
|    total_timesteps          | 997376     |
| train/                      |            |
|    approx_kl                | 6.3543186  |
|    clip_fraction            | 0.95       |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.99175715 |
|    ent_clip_fraction        | 0.673      |
|    ent_entropy_loss         | 6.17       |
|    ent_loss                 | 0.00622    |
|    ent_policy_gradient_loss | 0.0154     |
|    ent_std                  | 0.112      |
|    ent_value_loss           | 0.0153     |
|    entropy_loss             | 5.01       |
|    explained_variance       | 0.979      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.144      |
|    n_updates                | 4860       |
|    policy_gradient_loss     | 0.152      |
|    std                      | 0.13       |
|    value_loss               | 0.0152     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 854       |
|    ep_rew_mean              | 2.24e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 488       |
|    time_elapsed             | 6555      |
|    total_timesteps          | 999424    |
| train/                      |           |
|    approx_kl                | 3.1518345 |
|    clip_fraction            | 0.949     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.8420458 |
|    ent_clip_fraction        | 0.668     |
|    ent_entropy_loss         | 6.17      |
|    ent_loss                 | -0.0169   |
|    ent_policy_gradient_loss | -0.0188   |
|    ent_std                  | 0.112     |
|    ent_value_loss           | 0.00893   |
|    entropy_loss             | 4.97      |
|    explained_variance       | 0.515     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.244     |
|    n_updates                | 4870      |
|    policy_gradient_loss     | 0.252     |
|    std                      | 0.131     |
|    value_loss               | 0.00979   |
-------------------------------------------
Eval num_timesteps=1000000, episode_reward=3081.18 +/- 880.65
Episode length: 892.28 +/- 252.06
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 892       |
|    mean_reward              | 3.08e+03  |
| time/                       |           |
|    total_timesteps          | 1000000   |
| train/                      |           |
|    approx_kl                | 2.93362   |
|    clip_fraction            | 0.909     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.7035925 |
|    ent_clip_fraction        | 0.741     |
|    ent_entropy_loss         | 6.21      |
|    ent_loss                 | -0.00606  |
|    ent_policy_gradient_loss | 0.0331    |
|    ent_std                  | 0.111     |
|    ent_value_loss           | 0.00845   |
|    entropy_loss             | 4.92      |
|    explained_variance       | 0.616     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.168     |
|    n_updates                | 4880      |
|    policy_gradient_loss     | 0.221     |
|    std                      | 0.131     |
|    value_loss               | 0.00867   |
-------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 843      |
|    ep_rew_mean     | 2.22e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 489      |
|    time_elapsed    | 6583     |
|    total_timesteps | 1001472  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 842       |
|    ep_rew_mean              | 2.25e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 490       |
|    time_elapsed             | 6592      |
|    total_timesteps          | 1003520   |
| train/                      |           |
|    approx_kl                | 3.49585   |
|    clip_fraction            | 0.967     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.3094255 |
|    ent_clip_fraction        | 0.6       |
|    ent_entropy_loss         | 6.26      |
|    ent_loss                 | -0.0622   |
|    ent_policy_gradient_loss | -0.032    |
|    ent_std                  | 0.111     |
|    ent_value_loss           | 0.0283    |
|    entropy_loss             | 4.93      |
|    explained_variance       | 0.687     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.171     |
|    n_updates                | 4890      |
|    policy_gradient_loss     | 0.183     |
|    std                      | 0.131     |
|    value_loss               | 0.0285    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 834       |
|    ep_rew_mean              | 2.23e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 491       |
|    time_elapsed             | 6602      |
|    total_timesteps          | 1005568   |
| train/                      |           |
|    approx_kl                | 2.9928195 |
|    clip_fraction            | 0.941     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.0787205 |
|    ent_clip_fraction        | 0.71      |
|    ent_entropy_loss         | 6.29      |
|    ent_loss                 | -0.00936  |
|    ent_policy_gradient_loss | -0.013    |
|    ent_std                  | 0.11      |
|    ent_value_loss           | 0.0404    |
|    entropy_loss             | 4.96      |
|    explained_variance       | 0.169     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.162     |
|    n_updates                | 4900      |
|    policy_gradient_loss     | 0.175     |
|    std                      | 0.131     |
|    value_loss               | 0.0405    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 834       |
|    ep_rew_mean              | 2.25e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 492       |
|    time_elapsed             | 6612      |
|    total_timesteps          | 1007616   |
| train/                      |           |
|    approx_kl                | 3.2543    |
|    clip_fraction            | 0.962     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.5143107 |
|    ent_clip_fraction        | 0.644     |
|    ent_entropy_loss         | 6.3       |
|    ent_loss                 | -0.0454   |
|    ent_policy_gradient_loss | -0.0162   |
|    ent_std                  | 0.11      |
|    ent_value_loss           | 0.0566    |
|    entropy_loss             | 4.95      |
|    explained_variance       | 0.315     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.141     |
|    n_updates                | 4910      |
|    policy_gradient_loss     | 0.167     |
|    std                      | 0.13      |
|    value_loss               | 0.0547    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 834       |
|    ep_rew_mean              | 2.26e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 493       |
|    time_elapsed             | 6622      |
|    total_timesteps          | 1009664   |
| train/                      |           |
|    approx_kl                | 3.2911506 |
|    clip_fraction            | 0.951     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.7731023 |
|    ent_clip_fraction        | 0.686     |
|    ent_entropy_loss         | 6.31      |
|    ent_loss                 | 0.0202    |
|    ent_policy_gradient_loss | -0.0149   |
|    ent_std                  | 0.11      |
|    ent_value_loss           | 0.0102    |
|    entropy_loss             | 4.95      |
|    explained_variance       | 0.679     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.229     |
|    n_updates                | 4920      |
|    policy_gradient_loss     | 0.234     |
|    std                      | 0.131     |
|    value_loss               | 0.0108    |
-------------------------------------------
Eval num_timesteps=1010000, episode_reward=3121.74 +/- 702.14
Episode length: 922.12 +/- 187.83
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 922       |
|    mean_reward              | 3.12e+03  |
| time/                       |           |
|    total_timesteps          | 1010000   |
| train/                      |           |
|    approx_kl                | 3.3348646 |
|    clip_fraction            | 0.961     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.7961737 |
|    ent_clip_fraction        | 0.654     |
|    ent_entropy_loss         | 6.33      |
|    ent_loss                 | -0.0606   |
|    ent_policy_gradient_loss | -0.0143   |
|    ent_std                  | 0.11      |
|    ent_value_loss           | 0.00863   |
|    entropy_loss             | 4.97      |
|    explained_variance       | 0.466     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.207     |
|    n_updates                | 4930      |
|    policy_gradient_loss     | 0.225     |
|    std                      | 0.13      |
|    value_loss               | 0.00878   |
-------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 834      |
|    ep_rew_mean     | 2.27e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 494      |
|    time_elapsed    | 6650     |
|    total_timesteps | 1011712  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 830       |
|    ep_rew_mean              | 2.27e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 495       |
|    time_elapsed             | 6660      |
|    total_timesteps          | 1013760   |
| train/                      |           |
|    approx_kl                | 3.3330045 |
|    clip_fraction            | 0.954     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.2071141 |
|    ent_clip_fraction        | 0.674     |
|    ent_entropy_loss         | 6.35      |
|    ent_loss                 | -0.0808   |
|    ent_policy_gradient_loss | -0.0152   |
|    ent_std                  | 0.109     |
|    ent_value_loss           | 0.00958   |
|    entropy_loss             | 5.01      |
|    explained_variance       | 0.651     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.232     |
|    n_updates                | 4940      |
|    policy_gradient_loss     | 0.234     |
|    std                      | 0.13      |
|    value_loss               | 0.00955   |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 843        |
|    ep_rew_mean              | 2.32e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 496        |
|    time_elapsed             | 6670       |
|    total_timesteps          | 1015808    |
| train/                      |            |
|    approx_kl                | 3.1992805  |
|    clip_fraction            | 0.956      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.58330226 |
|    ent_clip_fraction        | 0.628      |
|    ent_entropy_loss         | 6.37       |
|    ent_loss                 | 0.00733    |
|    ent_policy_gradient_loss | -0.0135    |
|    ent_std                  | 0.109      |
|    ent_value_loss           | 0.0328     |
|    entropy_loss             | 4.99       |
|    explained_variance       | 0.36       |
|    learning_rate            | 0.0003     |
|    loss                     | 0.118      |
|    n_updates                | 4950       |
|    policy_gradient_loss     | 0.197      |
|    std                      | 0.13       |
|    value_loss               | 0.0325     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 846        |
|    ep_rew_mean              | 2.34e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 497        |
|    time_elapsed             | 6680       |
|    total_timesteps          | 1017856    |
| train/                      |            |
|    approx_kl                | 3.0639522  |
|    clip_fraction            | 0.957      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.50102127 |
|    ent_clip_fraction        | 0.655      |
|    ent_entropy_loss         | 6.37       |
|    ent_loss                 | -0.0156    |
|    ent_policy_gradient_loss | -0.0118    |
|    ent_std                  | 0.109      |
|    ent_value_loss           | 0.0359     |
|    entropy_loss             | 5          |
|    explained_variance       | 0.482      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.202      |
|    n_updates                | 4960       |
|    policy_gradient_loss     | 0.204      |
|    std                      | 0.13       |
|    value_loss               | 0.0364     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 853       |
|    ep_rew_mean              | 2.37e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 498       |
|    time_elapsed             | 6690      |
|    total_timesteps          | 1019904   |
| train/                      |           |
|    approx_kl                | 2.5653644 |
|    clip_fraction            | 0.902     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.9358925 |
|    ent_clip_fraction        | 0.769     |
|    ent_entropy_loss         | 6.37      |
|    ent_loss                 | 0.0817    |
|    ent_policy_gradient_loss | 0.0611    |
|    ent_std                  | 0.109     |
|    ent_value_loss           | 0.0131    |
|    entropy_loss             | 5.02      |
|    explained_variance       | 0.485     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0478    |
|    n_updates                | 4970      |
|    policy_gradient_loss     | 0.175     |
|    std                      | 0.129     |
|    value_loss               | 0.0141    |
-------------------------------------------
Eval num_timesteps=1020000, episode_reward=3625.62 +/- 374.15
Episode length: 1000.00 +/- 0.00
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 1e+03      |
|    mean_reward              | 3.63e+03   |
| time/                       |            |
|    total_timesteps          | 1020000    |
| train/                      |            |
|    approx_kl                | 3.4933696  |
|    clip_fraction            | 0.967      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.28763175 |
|    ent_clip_fraction        | 0.609      |
|    ent_entropy_loss         | 6.37       |
|    ent_loss                 | -0.0473    |
|    ent_policy_gradient_loss | -0.036     |
|    ent_std                  | 0.11       |
|    ent_value_loss           | 0.0147     |
|    entropy_loss             | 5.01       |
|    explained_variance       | 0.48       |
|    learning_rate            | 0.0003     |
|    loss                     | 0.19       |
|    n_updates                | 4980       |
|    policy_gradient_loss     | 0.369      |
|    std                      | 0.13       |
|    value_loss               | 0.0147     |
--------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 861      |
|    ep_rew_mean     | 2.42e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 499      |
|    time_elapsed    | 6718     |
|    total_timesteps | 1021952  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 859       |
|    ep_rew_mean              | 2.44e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 500       |
|    time_elapsed             | 6729      |
|    total_timesteps          | 1024000   |
| train/                      |           |
|    approx_kl                | 3.1110551 |
|    clip_fraction            | 0.957     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.9528331 |
|    ent_clip_fraction        | 0.654     |
|    ent_entropy_loss         | 6.36      |
|    ent_loss                 | -0.0121   |
|    ent_policy_gradient_loss | 0.0128    |
|    ent_std                  | 0.11      |
|    ent_value_loss           | 0.0124    |
|    entropy_loss             | 5         |
|    explained_variance       | 0.438     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.184     |
|    n_updates                | 4990      |
|    policy_gradient_loss     | 0.239     |
|    std                      | 0.13      |
|    value_loss               | 0.0128    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 870       |
|    ep_rew_mean              | 2.49e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 501       |
|    time_elapsed             | 6739      |
|    total_timesteps          | 1026048   |
| train/                      |           |
|    approx_kl                | 3.5522013 |
|    clip_fraction            | 0.964     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.4651866 |
|    ent_clip_fraction        | 0.629     |
|    ent_entropy_loss         | 6.36      |
|    ent_loss                 | -0.0642   |
|    ent_policy_gradient_loss | -0.0229   |
|    ent_std                  | 0.109     |
|    ent_value_loss           | 0.0369    |
|    entropy_loss             | 5.02      |
|    explained_variance       | 0.461     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.214     |
|    n_updates                | 5000      |
|    policy_gradient_loss     | 0.197     |
|    std                      | 0.129     |
|    value_loss               | 0.0352    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 871       |
|    ep_rew_mean              | 2.51e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 502       |
|    time_elapsed             | 6749      |
|    total_timesteps          | 1028096   |
| train/                      |           |
|    approx_kl                | 2.854157  |
|    clip_fraction            | 0.935     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.1601572 |
|    ent_clip_fraction        | 0.689     |
|    ent_entropy_loss         | 6.38      |
|    ent_loss                 | 0.0107    |
|    ent_policy_gradient_loss | 0.0332    |
|    ent_std                  | 0.109     |
|    ent_value_loss           | 0.00873   |
|    entropy_loss             | 5.04      |
|    explained_variance       | 0.559     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.136     |
|    n_updates                | 5010      |
|    policy_gradient_loss     | 0.203     |
|    std                      | 0.129     |
|    value_loss               | 0.00878   |
-------------------------------------------
Eval num_timesteps=1030000, episode_reward=3832.34 +/- 148.26
Episode length: 993.92 +/- 29.79
------------------------------------------
| eval/                       |          |
|    mean_ep_length           | 994      |
|    mean_reward              | 3.83e+03 |
| time/                       |          |
|    total_timesteps          | 1030000  |
| train/                      |          |
|    approx_kl                | 3.205558 |
|    clip_fraction            | 0.92     |
|    clip_range               | 0.2      |
|    ent_approx_kl            | 1.154252 |
|    ent_clip_fraction        | 0.714    |
|    ent_entropy_loss         | 6.37     |
|    ent_loss                 | 0.0296   |
|    ent_policy_gradient_loss | 0.025    |
|    ent_std                  | 0.11     |
|    ent_value_loss           | 0.0641   |
|    entropy_loss             | 5.06     |
|    explained_variance       | 0.364    |
|    learning_rate            | 0.0003   |
|    loss                     | 0.116    |
|    n_updates                | 5020     |
|    policy_gradient_loss     | 0.136    |
|    std                      | 0.129    |
|    value_loss               | 0.0631   |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 872      |
|    ep_rew_mean     | 2.51e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 503      |
|    time_elapsed    | 6777     |
|    total_timesteps | 1030144  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 881       |
|    ep_rew_mean              | 2.54e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 504       |
|    time_elapsed             | 6787      |
|    total_timesteps          | 1032192   |
| train/                      |           |
|    approx_kl                | 6.155529  |
|    clip_fraction            | 0.964     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.5672405 |
|    ent_clip_fraction        | 0.679     |
|    ent_entropy_loss         | 6.36      |
|    ent_loss                 | -0.013    |
|    ent_policy_gradient_loss | -0.000737 |
|    ent_std                  | 0.11      |
|    ent_value_loss           | 0.0204    |
|    entropy_loss             | 5.08      |
|    explained_variance       | 0.959     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.159     |
|    n_updates                | 5030      |
|    policy_gradient_loss     | 0.214     |
|    std                      | 0.128     |
|    value_loss               | 0.0188    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 885       |
|    ep_rew_mean              | 2.58e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 505       |
|    time_elapsed             | 6798      |
|    total_timesteps          | 1034240   |
| train/                      |           |
|    approx_kl                | 3.281999  |
|    clip_fraction            | 0.958     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.7536024 |
|    ent_clip_fraction        | 0.659     |
|    ent_entropy_loss         | 6.39      |
|    ent_loss                 | -0.0903   |
|    ent_policy_gradient_loss | 0.0084    |
|    ent_std                  | 0.109     |
|    ent_value_loss           | 0.0134    |
|    entropy_loss             | 5.09      |
|    explained_variance       | 0.419     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.124     |
|    n_updates                | 5040      |
|    policy_gradient_loss     | 0.211     |
|    std                      | 0.128     |
|    value_loss               | 0.0138    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 885       |
|    ep_rew_mean              | 2.6e+03   |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 506       |
|    time_elapsed             | 6808      |
|    total_timesteps          | 1036288   |
| train/                      |           |
|    approx_kl                | 3.2133358 |
|    clip_fraction            | 0.947     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.027096  |
|    ent_clip_fraction        | 0.692     |
|    ent_entropy_loss         | 6.41      |
|    ent_loss                 | 0.0249    |
|    ent_policy_gradient_loss | 0.00183   |
|    ent_std                  | 0.109     |
|    ent_value_loss           | 0.00921   |
|    entropy_loss             | 5.12      |
|    explained_variance       | 0.607     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.176     |
|    n_updates                | 5050      |
|    policy_gradient_loss     | 0.229     |
|    std                      | 0.128     |
|    value_loss               | 0.0094    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 885        |
|    ep_rew_mean              | 2.61e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 507        |
|    time_elapsed             | 6818       |
|    total_timesteps          | 1038336    |
| train/                      |            |
|    approx_kl                | 3.497486   |
|    clip_fraction            | 0.958      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.97306395 |
|    ent_clip_fraction        | 0.695      |
|    ent_entropy_loss         | 6.43       |
|    ent_loss                 | 0.0213     |
|    ent_policy_gradient_loss | 0.0499     |
|    ent_std                  | 0.108      |
|    ent_value_loss           | 0.00823    |
|    entropy_loss             | 5.14       |
|    explained_variance       | 0.466      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.164      |
|    n_updates                | 5060       |
|    policy_gradient_loss     | 0.242      |
|    std                      | 0.127      |
|    value_loss               | 0.00855    |
--------------------------------------------
Eval num_timesteps=1040000, episode_reward=3200.57 +/- 966.72
Episode length: 899.28 +/- 231.47
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 899       |
|    mean_reward              | 3.2e+03   |
| time/                       |           |
|    total_timesteps          | 1040000   |
| train/                      |           |
|    approx_kl                | 2.854639  |
|    clip_fraction            | 0.898     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.2435832 |
|    ent_clip_fraction        | 0.787     |
|    ent_entropy_loss         | 6.43      |
|    ent_loss                 | 0.0165    |
|    ent_policy_gradient_loss | 0.152     |
|    ent_std                  | 0.109     |
|    ent_value_loss           | 0.00799   |
|    entropy_loss             | 5.18      |
|    explained_variance       | 0.631     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.166     |
|    n_updates                | 5070      |
|    policy_gradient_loss     | 0.181     |
|    std                      | 0.127     |
|    value_loss               | 0.00815   |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 900      |
|    ep_rew_mean     | 2.66e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 508      |
|    time_elapsed    | 6846     |
|    total_timesteps | 1040384  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 905       |
|    ep_rew_mean              | 2.69e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 509       |
|    time_elapsed             | 6857      |
|    total_timesteps          | 1042432   |
| train/                      |           |
|    approx_kl                | 2.9317186 |
|    clip_fraction            | 0.901     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.9278601 |
|    ent_clip_fraction        | 0.769     |
|    ent_entropy_loss         | 6.38      |
|    ent_loss                 | 0.0627    |
|    ent_policy_gradient_loss | 0.065     |
|    ent_std                  | 0.11      |
|    ent_value_loss           | 0.0304    |
|    entropy_loss             | 5.17      |
|    explained_variance       | 0.378     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.16      |
|    n_updates                | 5080      |
|    policy_gradient_loss     | 0.137     |
|    std                      | 0.127     |
|    value_loss               | 0.032     |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 905       |
|    ep_rew_mean              | 2.7e+03   |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 510       |
|    time_elapsed             | 6867      |
|    total_timesteps          | 1044480   |
| train/                      |           |
|    approx_kl                | 3.9116526 |
|    clip_fraction            | 0.964     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.0179881 |
|    ent_clip_fraction        | 0.681     |
|    ent_entropy_loss         | 6.35      |
|    ent_loss                 | -0.0484   |
|    ent_policy_gradient_loss | -0.00502  |
|    ent_std                  | 0.11      |
|    ent_value_loss           | 0.0125    |
|    entropy_loss             | 5.15      |
|    explained_variance       | 0.105     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0573    |
|    n_updates                | 5090      |
|    policy_gradient_loss     | 0.202     |
|    std                      | 0.127     |
|    value_loss               | 0.0125    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 905       |
|    ep_rew_mean              | 2.72e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 511       |
|    time_elapsed             | 6877      |
|    total_timesteps          | 1046528   |
| train/                      |           |
|    approx_kl                | 3.4425235 |
|    clip_fraction            | 0.957     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.2429454 |
|    ent_clip_fraction        | 0.665     |
|    ent_entropy_loss         | 6.38      |
|    ent_loss                 | 0.0114    |
|    ent_policy_gradient_loss | -0.00755  |
|    ent_std                  | 0.109     |
|    ent_value_loss           | 0.0289    |
|    entropy_loss             | 5.17      |
|    explained_variance       | 0.579     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.178     |
|    n_updates                | 5100      |
|    policy_gradient_loss     | 0.184     |
|    std                      | 0.127     |
|    value_loss               | 0.0292    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 907        |
|    ep_rew_mean              | 2.74e+03   |
| time/                       |            |
|    fps                      | 152        |
|    iterations               | 512        |
|    time_elapsed             | 6887       |
|    total_timesteps          | 1048576    |
| train/                      |            |
|    approx_kl                | 3.9795713  |
|    clip_fraction            | 0.958      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.89648926 |
|    ent_clip_fraction        | 0.682      |
|    ent_entropy_loss         | 6.44       |
|    ent_loss                 | -0.068     |
|    ent_policy_gradient_loss | -0.0217    |
|    ent_std                  | 0.108      |
|    ent_value_loss           | 0.0138     |
|    entropy_loss             | 5.19       |
|    explained_variance       | 0.503      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.116      |
|    n_updates                | 5110       |
|    policy_gradient_loss     | 0.246      |
|    std                      | 0.127      |
|    value_loss               | 0.014      |
--------------------------------------------
Eval num_timesteps=1050000, episode_reward=3437.76 +/- 1005.24
Episode length: 894.56 +/- 258.00
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 895        |
|    mean_reward              | 3.44e+03   |
| time/                       |            |
|    total_timesteps          | 1050000    |
| train/                      |            |
|    approx_kl                | 3.7449923  |
|    clip_fraction            | 0.951      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.93105936 |
|    ent_clip_fraction        | 0.664      |
|    ent_entropy_loss         | 6.47       |
|    ent_loss                 | -0.0352    |
|    ent_policy_gradient_loss | -0.00246   |
|    ent_std                  | 0.108      |
|    ent_value_loss           | 0.0263     |
|    entropy_loss             | 5.16       |
|    explained_variance       | 0.541      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.25       |
|    n_updates                | 5120       |
|    policy_gradient_loss     | 0.164      |
|    std                      | 0.127      |
|    value_loss               | 0.0258     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 907      |
|    ep_rew_mean     | 2.76e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 513      |
|    time_elapsed    | 6915     |
|    total_timesteps | 1050624  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 907       |
|    ep_rew_mean              | 2.78e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 514       |
|    time_elapsed             | 6925      |
|    total_timesteps          | 1052672   |
| train/                      |           |
|    approx_kl                | 3.4106944 |
|    clip_fraction            | 0.958     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.6311852 |
|    ent_clip_fraction        | 0.671     |
|    ent_entropy_loss         | 6.5       |
|    ent_loss                 | -0.0149   |
|    ent_policy_gradient_loss | -0.0193   |
|    ent_std                  | 0.108     |
|    ent_value_loss           | 0.0141    |
|    entropy_loss             | 5.18      |
|    explained_variance       | 0.145     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.144     |
|    n_updates                | 5130      |
|    policy_gradient_loss     | 0.212     |
|    std                      | 0.126     |
|    value_loss               | 0.0145    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 907       |
|    ep_rew_mean              | 2.8e+03   |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 515       |
|    time_elapsed             | 6936      |
|    total_timesteps          | 1054720   |
| train/                      |           |
|    approx_kl                | 3.0987961 |
|    clip_fraction            | 0.93      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.4210603 |
|    ent_clip_fraction        | 0.754     |
|    ent_entropy_loss         | 6.52      |
|    ent_loss                 | 0.0147    |
|    ent_policy_gradient_loss | 0.0764    |
|    ent_std                  | 0.108     |
|    ent_value_loss           | 0.01      |
|    entropy_loss             | 5.2       |
|    explained_variance       | 0.384     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.145     |
|    n_updates                | 5140      |
|    policy_gradient_loss     | 0.186     |
|    std                      | 0.127     |
|    value_loss               | 0.0102    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 909       |
|    ep_rew_mean              | 2.82e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 516       |
|    time_elapsed             | 6946      |
|    total_timesteps          | 1056768   |
| train/                      |           |
|    approx_kl                | 3.0343242 |
|    clip_fraction            | 0.921     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.4873161 |
|    ent_clip_fraction        | 0.755     |
|    ent_entropy_loss         | 6.49      |
|    ent_loss                 | 0.063     |
|    ent_policy_gradient_loss | 0.0608    |
|    ent_std                  | 0.108     |
|    ent_value_loss           | 0.00844   |
|    entropy_loss             | 5.2       |
|    explained_variance       | 0.621     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0977    |
|    n_updates                | 5150      |
|    policy_gradient_loss     | 0.187     |
|    std                      | 0.127     |
|    value_loss               | 0.00899   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 912       |
|    ep_rew_mean              | 2.84e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 517       |
|    time_elapsed             | 6956      |
|    total_timesteps          | 1058816   |
| train/                      |           |
|    approx_kl                | 3.474873  |
|    clip_fraction            | 0.949     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.1032479 |
|    ent_clip_fraction        | 0.686     |
|    ent_entropy_loss         | 6.49      |
|    ent_loss                 | -0.0154   |
|    ent_policy_gradient_loss | 0.00582   |
|    ent_std                  | 0.108     |
|    ent_value_loss           | 0.0273    |
|    entropy_loss             | 5.22      |
|    explained_variance       | 0.599     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0768    |
|    n_updates                | 5160      |
|    policy_gradient_loss     | 0.272     |
|    std                      | 0.126     |
|    value_loss               | 0.0284    |
-------------------------------------------
Eval num_timesteps=1060000, episode_reward=3727.03 +/- 943.73
Episode length: 933.60 +/- 228.02
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 934       |
|    mean_reward              | 3.73e+03  |
| time/                       |           |
|    total_timesteps          | 1060000   |
| train/                      |           |
|    approx_kl                | 3.3911438 |
|    clip_fraction            | 0.95      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.0171084 |
|    ent_clip_fraction        | 0.681     |
|    ent_entropy_loss         | 6.5       |
|    ent_loss                 | -0.049    |
|    ent_policy_gradient_loss | -0.00151  |
|    ent_std                  | 0.108     |
|    ent_value_loss           | 0.0123    |
|    entropy_loss             | 5.21      |
|    explained_variance       | 0.678     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.136     |
|    n_updates                | 5170      |
|    policy_gradient_loss     | 0.235     |
|    std                      | 0.127     |
|    value_loss               | 0.0124    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 912      |
|    ep_rew_mean     | 2.86e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 518      |
|    time_elapsed    | 6983     |
|    total_timesteps | 1060864  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 912       |
|    ep_rew_mean              | 2.87e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 519       |
|    time_elapsed             | 6993      |
|    total_timesteps          | 1062912   |
| train/                      |           |
|    approx_kl                | 3.1424594 |
|    clip_fraction            | 0.927     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.7155039 |
|    ent_clip_fraction        | 0.735     |
|    ent_entropy_loss         | 6.52      |
|    ent_loss                 | 0.0434    |
|    ent_policy_gradient_loss | 0.0514    |
|    ent_std                  | 0.107     |
|    ent_value_loss           | 0.0105    |
|    entropy_loss             | 5.2       |
|    explained_variance       | 0.672     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.137     |
|    n_updates                | 5180      |
|    policy_gradient_loss     | 0.241     |
|    std                      | 0.127     |
|    value_loss               | 0.0103    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 912       |
|    ep_rew_mean              | 2.87e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 520       |
|    time_elapsed             | 7003      |
|    total_timesteps          | 1064960   |
| train/                      |           |
|    approx_kl                | 3.1944933 |
|    clip_fraction            | 0.933     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.6828465 |
|    ent_clip_fraction        | 0.736     |
|    ent_entropy_loss         | 6.54      |
|    ent_loss                 | -0.000181 |
|    ent_policy_gradient_loss | 0.0792    |
|    ent_std                  | 0.107     |
|    ent_value_loss           | 0.00805   |
|    entropy_loss             | 5.19      |
|    explained_variance       | 0.531     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.209     |
|    n_updates                | 5190      |
|    policy_gradient_loss     | 0.208     |
|    std                      | 0.127     |
|    value_loss               | 0.00823   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 909       |
|    ep_rew_mean              | 2.87e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 521       |
|    time_elapsed             | 7013      |
|    total_timesteps          | 1067008   |
| train/                      |           |
|    approx_kl                | 1.3493612 |
|    clip_fraction            | 0.769     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 9.472298  |
|    ent_clip_fraction        | 0.891     |
|    ent_entropy_loss         | 6.58      |
|    ent_loss                 | -0.0166   |
|    ent_policy_gradient_loss | 0.0257    |
|    ent_std                  | 0.106     |
|    ent_value_loss           | 0.0128    |
|    entropy_loss             | 5.16      |
|    explained_variance       | 0.981     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.218     |
|    n_updates                | 5200      |
|    policy_gradient_loss     | 0.184     |
|    std                      | 0.127     |
|    value_loss               | 0.0137    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 909       |
|    ep_rew_mean              | 2.89e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 522       |
|    time_elapsed             | 7023      |
|    total_timesteps          | 1069056   |
| train/                      |           |
|    approx_kl                | 3.7923996 |
|    clip_fraction            | 0.951     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.0498337 |
|    ent_clip_fraction        | 0.698     |
|    ent_entropy_loss         | 6.63      |
|    ent_loss                 | -0.0175   |
|    ent_policy_gradient_loss | 0.00114   |
|    ent_std                  | 0.106     |
|    ent_value_loss           | 0.0394    |
|    entropy_loss             | 5.11      |
|    explained_variance       | 0.131     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.12      |
|    n_updates                | 5210      |
|    policy_gradient_loss     | 0.202     |
|    std                      | 0.128     |
|    value_loss               | 0.0385    |
-------------------------------------------
Eval num_timesteps=1070000, episode_reward=4002.41 +/- 169.17
Episode length: 996.12 +/- 19.01
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 996       |
|    mean_reward              | 4e+03     |
| time/                       |           |
|    total_timesteps          | 1070000   |
| train/                      |           |
|    approx_kl                | 4.0652757 |
|    clip_fraction            | 0.953     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.0250602 |
|    ent_clip_fraction        | 0.704     |
|    ent_entropy_loss         | 6.63      |
|    ent_loss                 | 0.0302    |
|    ent_policy_gradient_loss | 0.0376    |
|    ent_std                  | 0.106     |
|    ent_value_loss           | 0.00681   |
|    entropy_loss             | 5.12      |
|    explained_variance       | 0.576     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.17      |
|    n_updates                | 5220      |
|    policy_gradient_loss     | 0.228     |
|    std                      | 0.127     |
|    value_loss               | 0.00709   |
-------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 910      |
|    ep_rew_mean     | 2.9e+03  |
| time/              |          |
|    fps             | 151      |
|    iterations      | 523      |
|    time_elapsed    | 7051     |
|    total_timesteps | 1071104  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 910       |
|    ep_rew_mean              | 2.91e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 524       |
|    time_elapsed             | 7061      |
|    total_timesteps          | 1073152   |
| train/                      |           |
|    approx_kl                | 3.4535418 |
|    clip_fraction            | 0.966     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.5374469 |
|    ent_clip_fraction        | 0.654     |
|    ent_entropy_loss         | 6.64      |
|    ent_loss                 | 0.0762    |
|    ent_policy_gradient_loss | 0.00447   |
|    ent_std                  | 0.106     |
|    ent_value_loss           | 0.0336    |
|    entropy_loss             | 5.19      |
|    explained_variance       | 0.414     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.224     |
|    n_updates                | 5230      |
|    policy_gradient_loss     | 0.205     |
|    std                      | 0.126     |
|    value_loss               | 0.0337    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 917       |
|    ep_rew_mean              | 2.94e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 525       |
|    time_elapsed             | 7071      |
|    total_timesteps          | 1075200   |
| train/                      |           |
|    approx_kl                | 3.0701928 |
|    clip_fraction            | 0.943     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.126257  |
|    ent_clip_fraction        | 0.699     |
|    ent_entropy_loss         | 6.67      |
|    ent_loss                 | -0.004    |
|    ent_policy_gradient_loss | 0.0132    |
|    ent_std                  | 0.105     |
|    ent_value_loss           | 0.00734   |
|    entropy_loss             | 5.22      |
|    explained_variance       | 0.618     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.131     |
|    n_updates                | 5240      |
|    policy_gradient_loss     | 0.223     |
|    std                      | 0.126     |
|    value_loss               | 0.00809   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 917       |
|    ep_rew_mean              | 2.95e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 526       |
|    time_elapsed             | 7081      |
|    total_timesteps          | 1077248   |
| train/                      |           |
|    approx_kl                | 3.2846494 |
|    clip_fraction            | 0.96      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.8017564 |
|    ent_clip_fraction        | 0.651     |
|    ent_entropy_loss         | 6.67      |
|    ent_loss                 | -0.0624   |
|    ent_policy_gradient_loss | -0.00153  |
|    ent_std                  | 0.105     |
|    ent_value_loss           | 0.00594   |
|    entropy_loss             | 5.25      |
|    explained_variance       | 0.562     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.107     |
|    n_updates                | 5250      |
|    policy_gradient_loss     | 0.216     |
|    std                      | 0.126     |
|    value_loss               | 0.00597   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 917       |
|    ep_rew_mean              | 2.96e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 527       |
|    time_elapsed             | 7091      |
|    total_timesteps          | 1079296   |
| train/                      |           |
|    approx_kl                | 4.3035345 |
|    clip_fraction            | 0.969     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.642684  |
|    ent_clip_fraction        | 0.642     |
|    ent_entropy_loss         | 6.68      |
|    ent_loss                 | -0.0305   |
|    ent_policy_gradient_loss | -4.36e-05 |
|    ent_std                  | 0.106     |
|    ent_value_loss           | 0.00936   |
|    entropy_loss             | 5.28      |
|    explained_variance       | 0.638     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.215     |
|    n_updates                | 5260      |
|    policy_gradient_loss     | 0.246     |
|    std                      | 0.125     |
|    value_loss               | 0.00992   |
-------------------------------------------
Eval num_timesteps=1080000, episode_reward=3734.27 +/- 1027.70
Episode length: 922.20 +/- 245.24
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 922       |
|    mean_reward              | 3.73e+03  |
| time/                       |           |
|    total_timesteps          | 1080000   |
| train/                      |           |
|    approx_kl                | 3.2657115 |
|    clip_fraction            | 0.954     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.9260999 |
|    ent_clip_fraction        | 0.672     |
|    ent_entropy_loss         | 6.67      |
|    ent_loss                 | 0.006     |
|    ent_policy_gradient_loss | 0.00208   |
|    ent_std                  | 0.105     |
|    ent_value_loss           | 0.00752   |
|    entropy_loss             | 5.34      |
|    explained_variance       | 0.736     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.147     |
|    n_updates                | 5270      |
|    policy_gradient_loss     | 0.265     |
|    std                      | 0.124     |
|    value_loss               | 0.00743   |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 924      |
|    ep_rew_mean     | 2.99e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 528      |
|    time_elapsed    | 7118     |
|    total_timesteps | 1081344  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 924       |
|    ep_rew_mean              | 3.01e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 529       |
|    time_elapsed             | 7128      |
|    total_timesteps          | 1083392   |
| train/                      |           |
|    approx_kl                | 2.9597607 |
|    clip_fraction            | 0.918     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.4947975 |
|    ent_clip_fraction        | 0.745     |
|    ent_entropy_loss         | 6.69      |
|    ent_loss                 | 0.0286    |
|    ent_policy_gradient_loss | 0.0657    |
|    ent_std                  | 0.105     |
|    ent_value_loss           | 0.0101    |
|    entropy_loss             | 5.39      |
|    explained_variance       | 0.672     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.115     |
|    n_updates                | 5280      |
|    policy_gradient_loss     | 0.191     |
|    std                      | 0.123     |
|    value_loss               | 0.00987   |
-------------------------------------------
------------------------------------------
| rollout/                    |          |
|    ep_len_mean              | 924      |
|    ep_rew_mean              | 3.01e+03 |
| time/                       |          |
|    fps                      | 152      |
|    iterations               | 530      |
|    time_elapsed             | 7138     |
|    total_timesteps          | 1085440  |
| train/                      |          |
|    approx_kl                | 6.057633 |
|    clip_fraction            | 0.967    |
|    clip_range               | 0.2      |
|    ent_approx_kl            | 0.638076 |
|    ent_clip_fraction        | 0.641    |
|    ent_entropy_loss         | 6.69     |
|    ent_loss                 | -0.0665  |
|    ent_policy_gradient_loss | -0.02    |
|    ent_std                  | 0.105    |
|    ent_value_loss           | 0.00986  |
|    entropy_loss             | 5.39     |
|    explained_variance       | 0.572    |
|    learning_rate            | 0.0003   |
|    loss                     | 0.201    |
|    n_updates                | 5290     |
|    policy_gradient_loss     | 0.256    |
|    std                      | 0.124    |
|    value_loss               | 0.01     |
------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 924       |
|    ep_rew_mean              | 3.04e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 531       |
|    time_elapsed             | 7149      |
|    total_timesteps          | 1087488   |
| train/                      |           |
|    approx_kl                | 1.9546036 |
|    clip_fraction            | 0.816     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.1694045 |
|    ent_clip_fraction        | 0.86      |
|    ent_entropy_loss         | 6.65      |
|    ent_loss                 | 0.0785    |
|    ent_policy_gradient_loss | 0.145     |
|    ent_std                  | 0.106     |
|    ent_value_loss           | 0.00669   |
|    entropy_loss             | 5.41      |
|    explained_variance       | 0.516     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0853    |
|    n_updates                | 5300      |
|    policy_gradient_loss     | 0.104     |
|    std                      | 0.123     |
|    value_loss               | 0.00705   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 924       |
|    ep_rew_mean              | 3.06e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 532       |
|    time_elapsed             | 7159      |
|    total_timesteps          | 1089536   |
| train/                      |           |
|    approx_kl                | 2.2110083 |
|    clip_fraction            | 0.844     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.665482  |
|    ent_clip_fraction        | 0.833     |
|    ent_entropy_loss         | 6.58      |
|    ent_loss                 | 0.112     |
|    ent_policy_gradient_loss | 0.174     |
|    ent_std                  | 0.107     |
|    ent_value_loss           | 0.00694   |
|    entropy_loss             | 5.43      |
|    explained_variance       | 0.679     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0132    |
|    n_updates                | 5310      |
|    policy_gradient_loss     | 0.112     |
|    std                      | 0.123     |
|    value_loss               | 0.00721   |
-------------------------------------------
Eval num_timesteps=1090000, episode_reward=4055.35 +/- 105.62
Episode length: 1000.00 +/- 0.00
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 1e+03      |
|    mean_reward              | 4.06e+03   |
| time/                       |            |
|    total_timesteps          | 1090000    |
| train/                      |            |
|    approx_kl                | 3.8517022  |
|    clip_fraction            | 0.971      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.34839708 |
|    ent_clip_fraction        | 0.611      |
|    ent_entropy_loss         | 6.53       |
|    ent_loss                 | -0.0452    |
|    ent_policy_gradient_loss | -0.0265    |
|    ent_std                  | 0.107      |
|    ent_value_loss           | 0.00623    |
|    entropy_loss             | 5.41       |
|    explained_variance       | 0.541      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.0882     |
|    n_updates                | 5320       |
|    policy_gradient_loss     | 0.32       |
|    std                      | 0.123      |
|    value_loss               | 0.00611    |
--------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 924      |
|    ep_rew_mean     | 3.08e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 533      |
|    time_elapsed    | 7187     |
|    total_timesteps | 1091584  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 933       |
|    ep_rew_mean              | 3.12e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 534       |
|    time_elapsed             | 7197      |
|    total_timesteps          | 1093632   |
| train/                      |           |
|    approx_kl                | 3.5693972 |
|    clip_fraction            | 0.961     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.8326614 |
|    ent_clip_fraction        | 0.65      |
|    ent_entropy_loss         | 6.54      |
|    ent_loss                 | 0.0842    |
|    ent_policy_gradient_loss | -0.00908  |
|    ent_std                  | 0.107     |
|    ent_value_loss           | 0.00583   |
|    entropy_loss             | 5.41      |
|    explained_variance       | 0.658     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0744    |
|    n_updates                | 5330      |
|    policy_gradient_loss     | 0.257     |
|    std                      | 0.123     |
|    value_loss               | 0.00591   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 937       |
|    ep_rew_mean              | 3.14e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 535       |
|    time_elapsed             | 7207      |
|    total_timesteps          | 1095680   |
| train/                      |           |
|    approx_kl                | 3.0836978 |
|    clip_fraction            | 0.915     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.6203747 |
|    ent_clip_fraction        | 0.744     |
|    ent_entropy_loss         | 6.54      |
|    ent_loss                 | 0.0268    |
|    ent_policy_gradient_loss | 0.0761    |
|    ent_std                  | 0.107     |
|    ent_value_loss           | 0.00577   |
|    entropy_loss             | 5.43      |
|    explained_variance       | 0.619     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.2       |
|    n_updates                | 5340      |
|    policy_gradient_loss     | 0.226     |
|    std                      | 0.123     |
|    value_loss               | 0.00594   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 941       |
|    ep_rew_mean              | 3.14e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 536       |
|    time_elapsed             | 7218      |
|    total_timesteps          | 1097728   |
| train/                      |           |
|    approx_kl                | 3.651083  |
|    clip_fraction            | 0.966     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.5910593 |
|    ent_clip_fraction        | 0.649     |
|    ent_entropy_loss         | 6.56      |
|    ent_loss                 | -0.0427   |
|    ent_policy_gradient_loss | -0.0155   |
|    ent_std                  | 0.106     |
|    ent_value_loss           | 0.00682   |
|    entropy_loss             | 5.43      |
|    explained_variance       | 0.61      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.256     |
|    n_updates                | 5350      |
|    policy_gradient_loss     | 0.261     |
|    std                      | 0.123     |
|    value_loss               | 0.00656   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 947       |
|    ep_rew_mean              | 3.17e+03  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 537       |
|    time_elapsed             | 7228      |
|    total_timesteps          | 1099776   |
| train/                      |           |
|    approx_kl                | 5.5219955 |
|    clip_fraction            | 0.873     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 7.9297867 |
|    ent_clip_fraction        | 0.841     |
|    ent_entropy_loss         | 6.6       |
|    ent_loss                 | -0.0264   |
|    ent_policy_gradient_loss | 0.0553    |
|    ent_std                  | 0.106     |
|    ent_value_loss           | 0.0105    |
|    entropy_loss             | 5.41      |
|    explained_variance       | 0.983     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0787    |
|    n_updates                | 5360      |
|    policy_gradient_loss     | 0.16      |
|    std                      | 0.123     |
|    value_loss               | 0.0126    |
-------------------------------------------
Eval num_timesteps=1100000, episode_reward=4219.63 +/- 100.98
Episode length: 1000.00 +/- 0.00
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 1e+03      |
|    mean_reward              | 4.22e+03   |
| time/                       |            |
|    total_timesteps          | 1100000    |
| train/                      |            |
|    approx_kl                | 3.5763006  |
|    clip_fraction            | 0.966      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.44948652 |
|    ent_clip_fraction        | 0.621      |
|    ent_entropy_loss         | 6.63       |
|    ent_loss                 | -0.0215    |
|    ent_policy_gradient_loss | -0.015     |
|    ent_std                  | 0.106      |
|    ent_value_loss           | 0.0282     |
|    entropy_loss             | 5.41       |
|    explained_variance       | 0.353      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.152      |
|    n_updates                | 5370       |
|    policy_gradient_loss     | 0.185      |
|    std                      | 0.123      |
|    value_loss               | 0.0256     |
--------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 947      |
|    ep_rew_mean     | 3.18e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 538      |
|    time_elapsed    | 7255     |
|    total_timesteps | 1101824  |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 947        |
|    ep_rew_mean              | 3.19e+03   |
| time/                       |            |
|    fps                      | 151        |
|    iterations               | 539        |
|    time_elapsed             | 7269       |
|    total_timesteps          | 1103872    |
| train/                      |            |
|    approx_kl                | 3.406096   |
|    clip_fraction            | 0.964      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.43014005 |
|    ent_clip_fraction        | 0.652      |
|    ent_entropy_loss         | 6.64       |
|    ent_loss                 | -0.0395    |
|    ent_policy_gradient_loss | -0.0221    |
|    ent_std                  | 0.106      |
|    ent_value_loss           | 0.0103     |
|    entropy_loss             | 5.39       |
|    explained_variance       | 0.422      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.166      |
|    n_updates                | 5380       |
|    policy_gradient_loss     | 0.219      |
|    std                      | 0.123      |
|    value_loss               | 0.0101     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 947       |
|    ep_rew_mean              | 3.18e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 540       |
|    time_elapsed             | 7280      |
|    total_timesteps          | 1105920   |
| train/                      |           |
|    approx_kl                | 3.006669  |
|    clip_fraction            | 0.946     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.1299971 |
|    ent_clip_fraction        | 0.716     |
|    ent_entropy_loss         | 6.66      |
|    ent_loss                 | 0.066     |
|    ent_policy_gradient_loss | 0.0251    |
|    ent_std                  | 0.105     |
|    ent_value_loss           | 0.00849   |
|    entropy_loss             | 5.41      |
|    explained_variance       | 0.619     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0495    |
|    n_updates                | 5390      |
|    policy_gradient_loss     | 0.212     |
|    std                      | 0.123     |
|    value_loss               | 0.00872   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 948       |
|    ep_rew_mean              | 3.19e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 541       |
|    time_elapsed             | 7290      |
|    total_timesteps          | 1107968   |
| train/                      |           |
|    approx_kl                | 7.3959455 |
|    clip_fraction            | 0.952     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.5091921 |
|    ent_clip_fraction        | 0.715     |
|    ent_entropy_loss         | 6.67      |
|    ent_loss                 | 0.0879    |
|    ent_policy_gradient_loss | 0.0566    |
|    ent_std                  | 0.105     |
|    ent_value_loss           | 0.00834   |
|    entropy_loss             | 5.43      |
|    explained_variance       | 0.987     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.12      |
|    n_updates                | 5400      |
|    policy_gradient_loss     | 0.136     |
|    std                      | 0.123     |
|    value_loss               | 0.01      |
-------------------------------------------
Eval num_timesteps=1110000, episode_reward=3533.74 +/- 1220.36
Episode length: 847.28 +/- 278.15
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 847       |
|    mean_reward              | 3.53e+03  |
| time/                       |           |
|    total_timesteps          | 1110000   |
| train/                      |           |
|    approx_kl                | 2.6375184 |
|    clip_fraction            | 0.9       |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.1059337 |
|    ent_clip_fraction        | 0.76      |
|    ent_entropy_loss         | 6.68      |
|    ent_loss                 | 0.11      |
|    ent_policy_gradient_loss | 0.0678    |
|    ent_std                  | 0.105     |
|    ent_value_loss           | 0.0301    |
|    entropy_loss             | 5.43      |
|    explained_variance       | 0.524     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0611    |
|    n_updates                | 5410      |
|    policy_gradient_loss     | 0.151     |
|    std                      | 0.123     |
|    value_loss               | 0.0326    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 941      |
|    ep_rew_mean     | 3.17e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 542      |
|    time_elapsed    | 7317     |
|    total_timesteps | 1110016  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 941       |
|    ep_rew_mean              | 3.18e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 543       |
|    time_elapsed             | 7327      |
|    total_timesteps          | 1112064   |
| train/                      |           |
|    approx_kl                | 2.8040414 |
|    clip_fraction            | 0.916     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.111329  |
|    ent_clip_fraction        | 0.752     |
|    ent_entropy_loss         | 6.69      |
|    ent_loss                 | 0.0287    |
|    ent_policy_gradient_loss | 0.0727    |
|    ent_std                  | 0.105     |
|    ent_value_loss           | 0.0307    |
|    entropy_loss             | 5.44      |
|    explained_variance       | 0.625     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.104     |
|    n_updates                | 5420      |
|    policy_gradient_loss     | 0.159     |
|    std                      | 0.123     |
|    value_loss               | 0.0313    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 941       |
|    ep_rew_mean              | 3.18e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 544       |
|    time_elapsed             | 7337      |
|    total_timesteps          | 1114112   |
| train/                      |           |
|    approx_kl                | 1.8392498 |
|    clip_fraction            | 0.799     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.8449721 |
|    ent_clip_fraction        | 0.883     |
|    ent_entropy_loss         | 6.66      |
|    ent_loss                 | 0.0885    |
|    ent_policy_gradient_loss | 0.14      |
|    ent_std                  | 0.106     |
|    ent_value_loss           | 0.0103    |
|    entropy_loss             | 5.43      |
|    explained_variance       | 0.142     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0539    |
|    n_updates                | 5430      |
|    policy_gradient_loss     | 0.0825    |
|    std                      | 0.123     |
|    value_loss               | 0.0114    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 941       |
|    ep_rew_mean              | 3.19e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 545       |
|    time_elapsed             | 7348      |
|    total_timesteps          | 1116160   |
| train/                      |           |
|    approx_kl                | 3.276501  |
|    clip_fraction            | 0.885     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.0020537 |
|    ent_clip_fraction        | 0.784     |
|    ent_entropy_loss         | 6.62      |
|    ent_loss                 | -0.0546   |
|    ent_policy_gradient_loss | 0.0767    |
|    ent_std                  | 0.106     |
|    ent_value_loss           | 0.00874   |
|    entropy_loss             | 5.46      |
|    explained_variance       | 0.509     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.224     |
|    n_updates                | 5440      |
|    policy_gradient_loss     | 0.171     |
|    std                      | 0.122     |
|    value_loss               | 0.00898   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 943       |
|    ep_rew_mean              | 3.2e+03   |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 546       |
|    time_elapsed             | 7358      |
|    total_timesteps          | 1118208   |
| train/                      |           |
|    approx_kl                | 3.7734823 |
|    clip_fraction            | 0.969     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.5809316 |
|    ent_clip_fraction        | 0.622     |
|    ent_entropy_loss         | 6.6       |
|    ent_loss                 | -0.0519   |
|    ent_policy_gradient_loss | -0.0252   |
|    ent_std                  | 0.106     |
|    ent_value_loss           | 0.00876   |
|    entropy_loss             | 5.46      |
|    explained_variance       | 0.583     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.156     |
|    n_updates                | 5450      |
|    policy_gradient_loss     | 0.292     |
|    std                      | 0.123     |
|    value_loss               | 0.00862   |
-------------------------------------------
Eval num_timesteps=1120000, episode_reward=3973.58 +/- 575.14
Episode length: 965.28 +/- 134.79
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 965       |
|    mean_reward              | 3.97e+03  |
| time/                       |           |
|    total_timesteps          | 1120000   |
| train/                      |           |
|    approx_kl                | 3.7983217 |
|    clip_fraction            | 0.954     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.5553687 |
|    ent_clip_fraction        | 0.693     |
|    ent_entropy_loss         | 6.63      |
|    ent_loss                 | -0.0502   |
|    ent_policy_gradient_loss | 0.0138    |
|    ent_std                  | 0.106     |
|    ent_value_loss           | 0.00722   |
|    entropy_loss             | 5.42      |
|    explained_variance       | 0.643     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.252     |
|    n_updates                | 5460      |
|    policy_gradient_loss     | 0.319     |
|    std                      | 0.123     |
|    value_loss               | 0.00717   |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 943      |
|    ep_rew_mean     | 3.21e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 547      |
|    time_elapsed    | 7386     |
|    total_timesteps | 1120256  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 944       |
|    ep_rew_mean              | 3.22e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 548       |
|    time_elapsed             | 7396      |
|    total_timesteps          | 1122304   |
| train/                      |           |
|    approx_kl                | 3.4092386 |
|    clip_fraction            | 0.959     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.2215738 |
|    ent_clip_fraction        | 0.686     |
|    ent_entropy_loss         | 6.65      |
|    ent_loss                 | 0.00517   |
|    ent_policy_gradient_loss | -0.00042  |
|    ent_std                  | 0.105     |
|    ent_value_loss           | 0.00924   |
|    entropy_loss             | 5.38      |
|    explained_variance       | 0.663     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.188     |
|    n_updates                | 5470      |
|    policy_gradient_loss     | 0.246     |
|    std                      | 0.124     |
|    value_loss               | 0.00886   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 952       |
|    ep_rew_mean              | 3.26e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 549       |
|    time_elapsed             | 7406      |
|    total_timesteps          | 1124352   |
| train/                      |           |
|    approx_kl                | 2.7115598 |
|    clip_fraction            | 0.893     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.9750947 |
|    ent_clip_fraction        | 0.736     |
|    ent_entropy_loss         | 6.65      |
|    ent_loss                 | -0.0262   |
|    ent_policy_gradient_loss | 0.0404    |
|    ent_std                  | 0.106     |
|    ent_value_loss           | 0.0101    |
|    entropy_loss             | 5.36      |
|    explained_variance       | 0.582     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.169     |
|    n_updates                | 5480      |
|    policy_gradient_loss     | 0.181     |
|    std                      | 0.124     |
|    value_loss               | 0.0101    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 952       |
|    ep_rew_mean              | 3.28e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 550       |
|    time_elapsed             | 7416      |
|    total_timesteps          | 1126400   |
| train/                      |           |
|    approx_kl                | 2.444881  |
|    clip_fraction            | 0.872     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.5789967 |
|    ent_clip_fraction        | 0.803     |
|    ent_entropy_loss         | 6.66      |
|    ent_loss                 | 0.0491    |
|    ent_policy_gradient_loss | 0.0612    |
|    ent_std                  | 0.105     |
|    ent_value_loss           | 0.0086    |
|    entropy_loss             | 5.36      |
|    explained_variance       | 0.522     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0934    |
|    n_updates                | 5490      |
|    policy_gradient_loss     | 0.187     |
|    std                      | 0.124     |
|    value_loss               | 0.0083    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 952       |
|    ep_rew_mean              | 3.29e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 551       |
|    time_elapsed             | 7426      |
|    total_timesteps          | 1128448   |
| train/                      |           |
|    approx_kl                | 3.4043295 |
|    clip_fraction            | 0.892     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.2860892 |
|    ent_clip_fraction        | 0.791     |
|    ent_entropy_loss         | 6.66      |
|    ent_loss                 | 0.0694    |
|    ent_policy_gradient_loss | 0.0958    |
|    ent_std                  | 0.105     |
|    ent_value_loss           | 0.00686   |
|    entropy_loss             | 5.37      |
|    explained_variance       | 0.565     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.211     |
|    n_updates                | 5500      |
|    policy_gradient_loss     | 0.228     |
|    std                      | 0.124     |
|    value_loss               | 0.0068    |
-------------------------------------------
Eval num_timesteps=1130000, episode_reward=3041.01 +/- 1274.59
Episode length: 798.28 +/- 295.46
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 798       |
|    mean_reward              | 3.04e+03  |
| time/                       |           |
|    total_timesteps          | 1130000   |
| train/                      |           |
|    approx_kl                | 2.5487592 |
|    clip_fraction            | 0.859     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.814189  |
|    ent_clip_fraction        | 0.796     |
|    ent_entropy_loss         | 6.65      |
|    ent_loss                 | 0.0545    |
|    ent_policy_gradient_loss | 0.0576    |
|    ent_std                  | 0.106     |
|    ent_value_loss           | 0.00622   |
|    entropy_loss             | 5.4       |
|    explained_variance       | 0.655     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.129     |
|    n_updates                | 5510      |
|    policy_gradient_loss     | 0.16      |
|    std                      | 0.124     |
|    value_loss               | 0.00592   |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 952      |
|    ep_rew_mean     | 3.29e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 552      |
|    time_elapsed    | 7453     |
|    total_timesteps | 1130496  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 944       |
|    ep_rew_mean              | 3.25e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 553       |
|    time_elapsed             | 7463      |
|    total_timesteps          | 1132544   |
| train/                      |           |
|    approx_kl                | 3.0534782 |
|    clip_fraction            | 0.917     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.237104  |
|    ent_clip_fraction        | 0.745     |
|    ent_entropy_loss         | 6.63      |
|    ent_loss                 | -0.0204   |
|    ent_policy_gradient_loss | 0.0331    |
|    ent_std                  | 0.106     |
|    ent_value_loss           | 0.0129    |
|    entropy_loss             | 5.36      |
|    explained_variance       | 0.871     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.155     |
|    n_updates                | 5520      |
|    policy_gradient_loss     | 0.188     |
|    std                      | 0.124     |
|    value_loss               | 0.013     |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 942       |
|    ep_rew_mean              | 3.25e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 554       |
|    time_elapsed             | 7473      |
|    total_timesteps          | 1134592   |
| train/                      |           |
|    approx_kl                | 6.972913  |
|    clip_fraction            | 0.973     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.7361211 |
|    ent_clip_fraction        | 0.652     |
|    ent_entropy_loss         | 6.66      |
|    ent_loss                 | -0.0607   |
|    ent_policy_gradient_loss | -0.0134   |
|    ent_std                  | 0.105     |
|    ent_value_loss           | 0.0272    |
|    entropy_loss             | 5.36      |
|    explained_variance       | 0.967     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.221     |
|    n_updates                | 5530      |
|    policy_gradient_loss     | 0.217     |
|    std                      | 0.124     |
|    value_loss               | 0.026     |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 942       |
|    ep_rew_mean              | 3.25e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 555       |
|    time_elapsed             | 7483      |
|    total_timesteps          | 1136640   |
| train/                      |           |
|    approx_kl                | 1.9450727 |
|    clip_fraction            | 0.821     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.4903364 |
|    ent_clip_fraction        | 0.831     |
|    ent_entropy_loss         | 6.71      |
|    ent_loss                 | 0.127     |
|    ent_policy_gradient_loss | 0.0867    |
|    ent_std                  | 0.105     |
|    ent_value_loss           | 0.0433    |
|    entropy_loss             | 5.41      |
|    explained_variance       | 0.447     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.111     |
|    n_updates                | 5540      |
|    policy_gradient_loss     | 0.0976    |
|    std                      | 0.123     |
|    value_loss               | 0.0466    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 949        |
|    ep_rew_mean              | 3.29e+03   |
| time/                       |            |
|    fps                      | 151        |
|    iterations               | 556        |
|    time_elapsed             | 7492       |
|    total_timesteps          | 1138688    |
| train/                      |            |
|    approx_kl                | 3.7538967  |
|    clip_fraction            | 0.963      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.58034503 |
|    ent_clip_fraction        | 0.645      |
|    ent_entropy_loss         | 6.72       |
|    ent_loss                 | -0.0392    |
|    ent_policy_gradient_loss | -0.0141    |
|    ent_std                  | 0.105      |
|    ent_value_loss           | 0.0152     |
|    entropy_loss             | 5.43       |
|    explained_variance       | 0.518      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.184      |
|    n_updates                | 5550       |
|    policy_gradient_loss     | 0.212      |
|    std                      | 0.123      |
|    value_loss               | 0.0139     |
--------------------------------------------
Eval num_timesteps=1140000, episode_reward=4286.09 +/- 521.44
Episode length: 978.00 +/- 107.78
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 978       |
|    mean_reward              | 4.29e+03  |
| time/                       |           |
|    total_timesteps          | 1140000   |
| train/                      |           |
|    approx_kl                | 3.4472697 |
|    clip_fraction            | 0.955     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.7963978 |
|    ent_clip_fraction        | 0.686     |
|    ent_entropy_loss         | 6.75      |
|    ent_loss                 | -0.0539   |
|    ent_policy_gradient_loss | -0.00707  |
|    ent_std                  | 0.104     |
|    ent_value_loss           | 0.0311    |
|    entropy_loss             | 5.46      |
|    explained_variance       | 0.491     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.161     |
|    n_updates                | 5560      |
|    policy_gradient_loss     | 0.187     |
|    std                      | 0.122     |
|    value_loss               | 0.0292    |
-------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 941      |
|    ep_rew_mean     | 3.27e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 557      |
|    time_elapsed    | 7521     |
|    total_timesteps | 1140736  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 941       |
|    ep_rew_mean              | 3.27e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 558       |
|    time_elapsed             | 7531      |
|    total_timesteps          | 1142784   |
| train/                      |           |
|    approx_kl                | 4.2846255 |
|    clip_fraction            | 0.956     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.7787628 |
|    ent_clip_fraction        | 0.662     |
|    ent_entropy_loss         | 6.77      |
|    ent_loss                 | -0.0165   |
|    ent_policy_gradient_loss | -0.00242  |
|    ent_std                  | 0.104     |
|    ent_value_loss           | 0.0361    |
|    entropy_loss             | 5.46      |
|    explained_variance       | 0.407     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.141     |
|    n_updates                | 5570      |
|    policy_gradient_loss     | 0.262     |
|    std                      | 0.123     |
|    value_loss               | 0.0344    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 950       |
|    ep_rew_mean              | 3.31e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 559       |
|    time_elapsed             | 7541      |
|    total_timesteps          | 1144832   |
| train/                      |           |
|    approx_kl                | 3.8903089 |
|    clip_fraction            | 0.96      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.8650623 |
|    ent_clip_fraction        | 0.673     |
|    ent_entropy_loss         | 6.77      |
|    ent_loss                 | -0.0151   |
|    ent_policy_gradient_loss | 0.00677   |
|    ent_std                  | 0.104     |
|    ent_value_loss           | 0.00956   |
|    entropy_loss             | 5.43      |
|    explained_variance       | 0.281     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.261     |
|    n_updates                | 5580      |
|    policy_gradient_loss     | 0.233     |
|    std                      | 0.123     |
|    value_loss               | 0.00937   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 943       |
|    ep_rew_mean              | 3.3e+03   |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 560       |
|    time_elapsed             | 7551      |
|    total_timesteps          | 1146880   |
| train/                      |           |
|    approx_kl                | 3.09917   |
|    clip_fraction            | 0.927     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.8429846 |
|    ent_clip_fraction        | 0.754     |
|    ent_entropy_loss         | 6.77      |
|    ent_loss                 | -0.00434  |
|    ent_policy_gradient_loss | 0.0406    |
|    ent_std                  | 0.104     |
|    ent_value_loss           | 0.00662   |
|    entropy_loss             | 5.4       |
|    explained_variance       | 0.56      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.195     |
|    n_updates                | 5590      |
|    policy_gradient_loss     | 0.225     |
|    std                      | 0.124     |
|    value_loss               | 0.00677   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 934       |
|    ep_rew_mean              | 3.28e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 561       |
|    time_elapsed             | 7561      |
|    total_timesteps          | 1148928   |
| train/                      |           |
|    approx_kl                | 3.1546252 |
|    clip_fraction            | 0.914     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.170093  |
|    ent_clip_fraction        | 0.772     |
|    ent_entropy_loss         | 6.77      |
|    ent_loss                 | 0.0228    |
|    ent_policy_gradient_loss | 0.0472    |
|    ent_std                  | 0.104     |
|    ent_value_loss           | 0.0237    |
|    entropy_loss             | 5.38      |
|    explained_variance       | 0.473     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.123     |
|    n_updates                | 5600      |
|    policy_gradient_loss     | 0.228     |
|    std                      | 0.124     |
|    value_loss               | 0.024     |
-------------------------------------------
Eval num_timesteps=1150000, episode_reward=4011.09 +/- 816.86
Episode length: 961.28 +/- 189.69
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 961       |
|    mean_reward              | 4.01e+03  |
| time/                       |           |
|    total_timesteps          | 1150000   |
| train/                      |           |
|    approx_kl                | 3.3463657 |
|    clip_fraction            | 0.941     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.7944102 |
|    ent_clip_fraction        | 0.737     |
|    ent_entropy_loss         | 6.82      |
|    ent_loss                 | 0.0232    |
|    ent_policy_gradient_loss | 0.0149    |
|    ent_std                  | 0.103     |
|    ent_value_loss           | 0.0379    |
|    entropy_loss             | 5.39      |
|    explained_variance       | 0.46      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.205     |
|    n_updates                | 5610      |
|    policy_gradient_loss     | 0.188     |
|    std                      | 0.123     |
|    value_loss               | 0.0394    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 932      |
|    ep_rew_mean     | 3.29e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 562      |
|    time_elapsed    | 7589     |
|    total_timesteps | 1150976  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 928       |
|    ep_rew_mean              | 3.28e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 563       |
|    time_elapsed             | 7600      |
|    total_timesteps          | 1153024   |
| train/                      |           |
|    approx_kl                | 4.007979  |
|    clip_fraction            | 0.954     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.9321756 |
|    ent_clip_fraction        | 0.691     |
|    ent_entropy_loss         | 6.87      |
|    ent_loss                 | 0.0113    |
|    ent_policy_gradient_loss | 0.00056   |
|    ent_std                  | 0.102     |
|    ent_value_loss           | 0.041     |
|    entropy_loss             | 5.42      |
|    explained_variance       | 0.356     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.165     |
|    n_updates                | 5620      |
|    policy_gradient_loss     | 0.183     |
|    std                      | 0.123     |
|    value_loss               | 0.0397    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 924       |
|    ep_rew_mean              | 3.28e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 564       |
|    time_elapsed             | 7610      |
|    total_timesteps          | 1155072   |
| train/                      |           |
|    approx_kl                | 4.6248717 |
|    clip_fraction            | 0.97      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.4352256 |
|    ent_clip_fraction        | 0.646     |
|    ent_entropy_loss         | 6.88      |
|    ent_loss                 | -0.0336   |
|    ent_policy_gradient_loss | -0.011    |
|    ent_std                  | 0.103     |
|    ent_value_loss           | 0.0454    |
|    entropy_loss             | 5.42      |
|    explained_variance       | 0.35      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.191     |
|    n_updates                | 5630      |
|    policy_gradient_loss     | 0.193     |
|    std                      | 0.123     |
|    value_loss               | 0.0439    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 924       |
|    ep_rew_mean              | 3.32e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 565       |
|    time_elapsed             | 7620      |
|    total_timesteps          | 1157120   |
| train/                      |           |
|    approx_kl                | 3.246671  |
|    clip_fraction            | 0.894     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.9371862 |
|    ent_clip_fraction        | 0.789     |
|    ent_entropy_loss         | 6.88      |
|    ent_loss                 | 0.0727    |
|    ent_policy_gradient_loss | 0.0604    |
|    ent_std                  | 0.102     |
|    ent_value_loss           | 0.0371    |
|    entropy_loss             | 5.44      |
|    explained_variance       | 0.396     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.152     |
|    n_updates                | 5640      |
|    policy_gradient_loss     | 0.224     |
|    std                      | 0.123     |
|    value_loss               | 0.0381    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 924        |
|    ep_rew_mean              | 3.33e+03   |
| time/                       |            |
|    fps                      | 151        |
|    iterations               | 566        |
|    time_elapsed             | 7630       |
|    total_timesteps          | 1159168    |
| train/                      |            |
|    approx_kl                | 3.4053254  |
|    clip_fraction            | 0.966      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.67957723 |
|    ent_clip_fraction        | 0.654      |
|    ent_entropy_loss         | 6.88       |
|    ent_loss                 | 0.0718     |
|    ent_policy_gradient_loss | 0.0821     |
|    ent_std                  | 0.103      |
|    ent_value_loss           | 0.0136     |
|    entropy_loss             | 5.44       |
|    explained_variance       | 0.445      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.207      |
|    n_updates                | 5650       |
|    policy_gradient_loss     | 0.204      |
|    std                      | 0.122      |
|    value_loss               | 0.0128     |
--------------------------------------------
Eval num_timesteps=1160000, episode_reward=3691.20 +/- 1111.39
Episode length: 867.12 +/- 257.97
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 867        |
|    mean_reward              | 3.69e+03   |
| time/                       |            |
|    total_timesteps          | 1160000    |
| train/                      |            |
|    approx_kl                | 4.1449833  |
|    clip_fraction            | 0.965      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.77848476 |
|    ent_clip_fraction        | 0.667      |
|    ent_entropy_loss         | 6.87       |
|    ent_loss                 | 0.00453    |
|    ent_policy_gradient_loss | 0.00767    |
|    ent_std                  | 0.102      |
|    ent_value_loss           | 0.0112     |
|    entropy_loss             | 5.49       |
|    explained_variance       | 0.548      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.185      |
|    n_updates                | 5660       |
|    policy_gradient_loss     | 0.225      |
|    std                      | 0.122      |
|    value_loss               | 0.0105     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 929      |
|    ep_rew_mean     | 3.35e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 567      |
|    time_elapsed    | 7658     |
|    total_timesteps | 1161216  |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 929        |
|    ep_rew_mean              | 3.36e+03   |
| time/                       |            |
|    fps                      | 151        |
|    iterations               | 568        |
|    time_elapsed             | 7668       |
|    total_timesteps          | 1163264    |
| train/                      |            |
|    approx_kl                | 3.7753892  |
|    clip_fraction            | 0.969      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.24157293 |
|    ent_clip_fraction        | 0.631      |
|    ent_entropy_loss         | 6.9        |
|    ent_loss                 | -0.0504    |
|    ent_policy_gradient_loss | -0.0296    |
|    ent_std                  | 0.102      |
|    ent_value_loss           | 0.0327     |
|    entropy_loss             | 5.49       |
|    explained_variance       | 0.453      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.205      |
|    n_updates                | 5670       |
|    policy_gradient_loss     | 0.204      |
|    std                      | 0.122      |
|    value_loss               | 0.0323     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 924       |
|    ep_rew_mean              | 3.35e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 569       |
|    time_elapsed             | 7678      |
|    total_timesteps          | 1165312   |
| train/                      |           |
|    approx_kl                | 2.6662672 |
|    clip_fraction            | 0.914     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.2462914 |
|    ent_clip_fraction        | 0.769     |
|    ent_entropy_loss         | 6.88      |
|    ent_loss                 | 0.00442   |
|    ent_policy_gradient_loss | 0.0781    |
|    ent_std                  | 0.103     |
|    ent_value_loss           | 0.0109    |
|    entropy_loss             | 5.49      |
|    explained_variance       | 0.542     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.199     |
|    n_updates                | 5680      |
|    policy_gradient_loss     | 0.259     |
|    std                      | 0.122     |
|    value_loss               | 0.0121    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 924       |
|    ep_rew_mean              | 3.36e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 570       |
|    time_elapsed             | 7689      |
|    total_timesteps          | 1167360   |
| train/                      |           |
|    approx_kl                | 3.086214  |
|    clip_fraction            | 0.925     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.1813946 |
|    ent_clip_fraction        | 0.701     |
|    ent_entropy_loss         | 6.84      |
|    ent_loss                 | 0.0917    |
|    ent_policy_gradient_loss | 0.0209    |
|    ent_std                  | 0.103     |
|    ent_value_loss           | 0.0181    |
|    entropy_loss             | 5.51      |
|    explained_variance       | 0.621     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.168     |
|    n_updates                | 5690      |
|    policy_gradient_loss     | 0.143     |
|    std                      | 0.121     |
|    value_loss               | 0.0179    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 924        |
|    ep_rew_mean              | 3.36e+03   |
| time/                       |            |
|    fps                      | 151        |
|    iterations               | 571        |
|    time_elapsed             | 7699       |
|    total_timesteps          | 1169408    |
| train/                      |            |
|    approx_kl                | 3.840366   |
|    clip_fraction            | 0.963      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.76640743 |
|    ent_clip_fraction        | 0.665      |
|    ent_entropy_loss         | 6.85       |
|    ent_loss                 | -0.0342    |
|    ent_policy_gradient_loss | -0.0208    |
|    ent_std                  | 0.103      |
|    ent_value_loss           | 0.0103     |
|    entropy_loss             | 5.52       |
|    explained_variance       | 0.575      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.221      |
|    n_updates                | 5700       |
|    policy_gradient_loss     | 0.238      |
|    std                      | 0.121      |
|    value_loss               | 0.0104     |
--------------------------------------------
Eval num_timesteps=1170000, episode_reward=3020.34 +/- 1371.87
Episode length: 750.68 +/- 329.29
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 751       |
|    mean_reward              | 3.02e+03  |
| time/                       |           |
|    total_timesteps          | 1170000   |
| train/                      |           |
|    approx_kl                | 3.7832007 |
|    clip_fraction            | 0.962     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.8045062 |
|    ent_clip_fraction        | 0.671     |
|    ent_entropy_loss         | 6.85      |
|    ent_loss                 | -0.0347   |
|    ent_policy_gradient_loss | 0.0134    |
|    ent_std                  | 0.103     |
|    ent_value_loss           | 0.0122    |
|    entropy_loss             | 5.52      |
|    explained_variance       | 0.395     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.176     |
|    n_updates                | 5710      |
|    policy_gradient_loss     | 0.321     |
|    std                      | 0.121     |
|    value_loss               | 0.012     |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 924      |
|    ep_rew_mean     | 3.36e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 572      |
|    time_elapsed    | 7724     |
|    total_timesteps | 1171456  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 924       |
|    ep_rew_mean              | 3.37e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 573       |
|    time_elapsed             | 7734      |
|    total_timesteps          | 1173504   |
| train/                      |           |
|    approx_kl                | 4.0486765 |
|    clip_fraction            | 0.958     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.1661508 |
|    ent_clip_fraction        | 0.688     |
|    ent_entropy_loss         | 6.83      |
|    ent_loss                 | -0.0516   |
|    ent_policy_gradient_loss | 8.87e-05  |
|    ent_std                  | 0.103     |
|    ent_value_loss           | 0.00794   |
|    entropy_loss             | 5.52      |
|    explained_variance       | 0.636     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.279     |
|    n_updates                | 5720      |
|    policy_gradient_loss     | 0.226     |
|    std                      | 0.122     |
|    value_loss               | 0.00808   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 924       |
|    ep_rew_mean              | 3.37e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 574       |
|    time_elapsed             | 7744      |
|    total_timesteps          | 1175552   |
| train/                      |           |
|    approx_kl                | 4.222665  |
|    clip_fraction            | 0.969     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.6353034 |
|    ent_clip_fraction        | 0.632     |
|    ent_entropy_loss         | 6.85      |
|    ent_loss                 | -0.0619   |
|    ent_policy_gradient_loss | -0.0277   |
|    ent_std                  | 0.103     |
|    ent_value_loss           | 0.00538   |
|    entropy_loss             | 5.51      |
|    explained_variance       | 0.638     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.248     |
|    n_updates                | 5730      |
|    policy_gradient_loss     | 0.26      |
|    std                      | 0.122     |
|    value_loss               | 0.00556   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 917       |
|    ep_rew_mean              | 3.36e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 575       |
|    time_elapsed             | 7754      |
|    total_timesteps          | 1177600   |
| train/                      |           |
|    approx_kl                | 3.4865975 |
|    clip_fraction            | 0.941     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.9456019 |
|    ent_clip_fraction        | 0.713     |
|    ent_entropy_loss         | 6.87      |
|    ent_loss                 | -0.0311   |
|    ent_policy_gradient_loss | -0.00364  |
|    ent_std                  | 0.103     |
|    ent_value_loss           | 0.00769   |
|    entropy_loss             | 5.49      |
|    explained_variance       | 0.671     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.265     |
|    n_updates                | 5740      |
|    policy_gradient_loss     | 0.271     |
|    std                      | 0.123     |
|    value_loss               | 0.00775   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 899       |
|    ep_rew_mean              | 3.3e+03   |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 576       |
|    time_elapsed             | 7765      |
|    total_timesteps          | 1179648   |
| train/                      |           |
|    approx_kl                | 3.6275914 |
|    clip_fraction            | 0.957     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.1748106 |
|    ent_clip_fraction        | 0.663     |
|    ent_entropy_loss         | 6.88      |
|    ent_loss                 | -0.0336   |
|    ent_policy_gradient_loss | -0.00758  |
|    ent_std                  | 0.102     |
|    ent_value_loss           | 0.0354    |
|    entropy_loss             | 5.44      |
|    explained_variance       | 0.346     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.114     |
|    n_updates                | 5750      |
|    policy_gradient_loss     | 0.689     |
|    std                      | 0.123     |
|    value_loss               | 0.0343    |
-------------------------------------------
Eval num_timesteps=1180000, episode_reward=3745.26 +/- 1088.70
Episode length: 909.72 +/- 220.61
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 910       |
|    mean_reward              | 3.75e+03  |
| time/                       |           |
|    total_timesteps          | 1180000   |
| train/                      |           |
|    approx_kl                | 2.3497787 |
|    clip_fraction            | 0.858     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.8054183 |
|    ent_clip_fraction        | 0.807     |
|    ent_entropy_loss         | 6.89      |
|    ent_loss                 | -0.00289  |
|    ent_policy_gradient_loss | 0.0872    |
|    ent_std                  | 0.102     |
|    ent_value_loss           | 0.0653    |
|    entropy_loss             | 5.44      |
|    explained_variance       | 0.4       |
|    learning_rate            | 0.0003    |
|    loss                     | 0.116     |
|    n_updates                | 5760      |
|    policy_gradient_loss     | 0.105     |
|    std                      | 0.123     |
|    value_loss               | 0.0671    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 896      |
|    ep_rew_mean     | 3.29e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 577      |
|    time_elapsed    | 7793     |
|    total_timesteps | 1181696  |
---------------------------------
------------------------------------------
| rollout/                    |          |
|    ep_len_mean              | 891      |
|    ep_rew_mean              | 3.28e+03 |
| time/                       |          |
|    fps                      | 151      |
|    iterations               | 578      |
|    time_elapsed             | 7802     |
|    total_timesteps          | 1183744  |
| train/                      |          |
|    approx_kl                | 4.342598 |
|    clip_fraction            | 0.976    |
|    clip_range               | 0.2      |
|    ent_approx_kl            | 0.286128 |
|    ent_clip_fraction        | 0.648    |
|    ent_entropy_loss         | 6.91     |
|    ent_loss                 | -0.0278  |
|    ent_policy_gradient_loss | -0.0262  |
|    ent_std                  | 0.102    |
|    ent_value_loss           | 0.0472   |
|    entropy_loss             | 5.46     |
|    explained_variance       | 0.353    |
|    learning_rate            | 0.0003   |
|    loss                     | 0.191    |
|    n_updates                | 5770     |
|    policy_gradient_loss     | 0.194    |
|    std                      | 0.122    |
|    value_loss               | 0.0471   |
------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 891        |
|    ep_rew_mean              | 3.26e+03   |
| time/                       |            |
|    fps                      | 151        |
|    iterations               | 579        |
|    time_elapsed             | 7813       |
|    total_timesteps          | 1185792    |
| train/                      |            |
|    approx_kl                | 3.9897897  |
|    clip_fraction            | 0.966      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.61279154 |
|    ent_clip_fraction        | 0.666      |
|    ent_entropy_loss         | 6.89       |
|    ent_loss                 | -0.0381    |
|    ent_policy_gradient_loss | -0.00365   |
|    ent_std                  | 0.103      |
|    ent_value_loss           | 0.0402     |
|    entropy_loss             | 5.45       |
|    explained_variance       | 0.377      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.15       |
|    n_updates                | 5780       |
|    policy_gradient_loss     | 0.197      |
|    std                      | 0.123      |
|    value_loss               | 0.0397     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 890       |
|    ep_rew_mean              | 3.28e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 580       |
|    time_elapsed             | 7826      |
|    total_timesteps          | 1187840   |
| train/                      |           |
|    approx_kl                | 8.946583  |
|    clip_fraction            | 0.958     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.2531785 |
|    ent_clip_fraction        | 0.702     |
|    ent_entropy_loss         | 6.89      |
|    ent_loss                 | 0.0485    |
|    ent_policy_gradient_loss | 0.0341    |
|    ent_std                  | 0.102     |
|    ent_value_loss           | 0.016     |
|    entropy_loss             | 5.43      |
|    explained_variance       | 0.977     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0792    |
|    n_updates                | 5790      |
|    policy_gradient_loss     | 0.177     |
|    std                      | 0.123     |
|    value_loss               | 0.0159    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 890       |
|    ep_rew_mean              | 3.28e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 581       |
|    time_elapsed             | 7836      |
|    total_timesteps          | 1189888   |
| train/                      |           |
|    approx_kl                | 3.541606  |
|    clip_fraction            | 0.949     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.9530287 |
|    ent_clip_fraction        | 0.685     |
|    ent_entropy_loss         | 6.89      |
|    ent_loss                 | 0.015     |
|    ent_policy_gradient_loss | 0.0145    |
|    ent_std                  | 0.102     |
|    ent_value_loss           | 0.0379    |
|    entropy_loss             | 5.43      |
|    explained_variance       | 0.472     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.225     |
|    n_updates                | 5800      |
|    policy_gradient_loss     | 0.184     |
|    std                      | 0.123     |
|    value_loss               | 0.0391    |
-------------------------------------------
Eval num_timesteps=1190000, episode_reward=3934.50 +/- 846.23
Episode length: 1000.00 +/- 0.00
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 1e+03     |
|    mean_reward              | 3.93e+03  |
| time/                       |           |
|    total_timesteps          | 1190000   |
| train/                      |           |
|    approx_kl                | 2.606195  |
|    clip_fraction            | 0.907     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.9997327 |
|    ent_clip_fraction        | 0.778     |
|    ent_entropy_loss         | 6.92      |
|    ent_loss                 | 0.078     |
|    ent_policy_gradient_loss | 0.0835    |
|    ent_std                  | 0.102     |
|    ent_value_loss           | 0.00843   |
|    entropy_loss             | 5.46      |
|    explained_variance       | 0.349     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.11      |
|    n_updates                | 5810      |
|    policy_gradient_loss     | 0.173     |
|    std                      | 0.123     |
|    value_loss               | 0.00864   |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 890      |
|    ep_rew_mean     | 3.28e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 582      |
|    time_elapsed    | 7864     |
|    total_timesteps | 1191936  |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 890        |
|    ep_rew_mean              | 3.29e+03   |
| time/                       |            |
|    fps                      | 151        |
|    iterations               | 583        |
|    time_elapsed             | 7874       |
|    total_timesteps          | 1193984    |
| train/                      |            |
|    approx_kl                | 4.580719   |
|    clip_fraction            | 0.974      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.23074618 |
|    ent_clip_fraction        | 0.636      |
|    ent_entropy_loss         | 6.93       |
|    ent_loss                 | -0.0596    |
|    ent_policy_gradient_loss | -0.028     |
|    ent_std                  | 0.102      |
|    ent_value_loss           | 0.0232     |
|    entropy_loss             | 5.51       |
|    explained_variance       | 0.652      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.238      |
|    n_updates                | 5820       |
|    policy_gradient_loss     | 0.2        |
|    std                      | 0.12       |
|    value_loss               | 0.021      |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 890       |
|    ep_rew_mean              | 3.31e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 584       |
|    time_elapsed             | 7884      |
|    total_timesteps          | 1196032   |
| train/                      |           |
|    approx_kl                | 2.3799741 |
|    clip_fraction            | 0.871     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.6441731 |
|    ent_clip_fraction        | 0.814     |
|    ent_entropy_loss         | 6.96      |
|    ent_loss                 | 0.0883    |
|    ent_policy_gradient_loss | 0.0894    |
|    ent_std                  | 0.102     |
|    ent_value_loss           | 0.00924   |
|    entropy_loss             | 5.62      |
|    explained_variance       | 0.705     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0771    |
|    n_updates                | 5830      |
|    policy_gradient_loss     | 0.169     |
|    std                      | 0.12      |
|    value_loss               | 0.00967   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 894       |
|    ep_rew_mean              | 3.33e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 585       |
|    time_elapsed             | 7894      |
|    total_timesteps          | 1198080   |
| train/                      |           |
|    approx_kl                | 3.4559116 |
|    clip_fraction            | 0.951     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.2513978 |
|    ent_clip_fraction        | 0.697     |
|    ent_entropy_loss         | 6.98      |
|    ent_loss                 | -0.0567   |
|    ent_policy_gradient_loss | 0.0239    |
|    ent_std                  | 0.101     |
|    ent_value_loss           | 0.0103    |
|    entropy_loss             | 5.65      |
|    explained_variance       | 0.634     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.193     |
|    n_updates                | 5840      |
|    policy_gradient_loss     | 0.244     |
|    std                      | 0.119     |
|    value_loss               | 0.0105    |
-------------------------------------------
Eval num_timesteps=1200000, episode_reward=4139.88 +/- 580.54
Episode length: 976.00 +/- 85.36
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 976       |
|    mean_reward              | 4.14e+03  |
| time/                       |           |
|    total_timesteps          | 1200000   |
| train/                      |           |
|    approx_kl                | 3.4433331 |
|    clip_fraction            | 0.946     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.1322027 |
|    ent_clip_fraction        | 0.698     |
|    ent_entropy_loss         | 7         |
|    ent_loss                 | -0.0605   |
|    ent_policy_gradient_loss | 0.0214    |
|    ent_std                  | 0.101     |
|    ent_value_loss           | 0.0063    |
|    entropy_loss             | 5.7       |
|    explained_variance       | 0.596     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.199     |
|    n_updates                | 5850      |
|    policy_gradient_loss     | 0.192     |
|    std                      | 0.119     |
|    value_loss               | 0.00651   |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 900      |
|    ep_rew_mean     | 3.36e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 586      |
|    time_elapsed    | 7922     |
|    total_timesteps | 1200128  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 897       |
|    ep_rew_mean              | 3.36e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 587       |
|    time_elapsed             | 7932      |
|    total_timesteps          | 1202176   |
| train/                      |           |
|    approx_kl                | 4.0051365 |
|    clip_fraction            | 0.968     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.567954  |
|    ent_clip_fraction        | 0.647     |
|    ent_entropy_loss         | 7.02      |
|    ent_loss                 | -0.0335   |
|    ent_policy_gradient_loss | -0.0178   |
|    ent_std                  | 0.101     |
|    ent_value_loss           | 0.0172    |
|    entropy_loss             | 5.72      |
|    explained_variance       | 0.611     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.166     |
|    n_updates                | 5860      |
|    policy_gradient_loss     | 0.2       |
|    std                      | 0.118     |
|    value_loss               | 0.0167    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 897       |
|    ep_rew_mean              | 3.36e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 588       |
|    time_elapsed             | 7943      |
|    total_timesteps          | 1204224   |
| train/                      |           |
|    approx_kl                | 3.752469  |
|    clip_fraction            | 0.956     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.8938016 |
|    ent_clip_fraction        | 0.702     |
|    ent_entropy_loss         | 7.06      |
|    ent_loss                 | -0.0133   |
|    ent_policy_gradient_loss | -0.00458  |
|    ent_std                  | 0.1       |
|    ent_value_loss           | 0.0382    |
|    entropy_loss             | 5.74      |
|    explained_variance       | 0.44      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.148     |
|    n_updates                | 5870      |
|    policy_gradient_loss     | 0.163     |
|    std                      | 0.119     |
|    value_loss               | 0.038     |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 897       |
|    ep_rew_mean              | 3.37e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 589       |
|    time_elapsed             | 7953      |
|    total_timesteps          | 1206272   |
| train/                      |           |
|    approx_kl                | 2.2013621 |
|    clip_fraction            | 0.868     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.2577639 |
|    ent_clip_fraction        | 0.851     |
|    ent_entropy_loss         | 7.07      |
|    ent_loss                 | 0.0692    |
|    ent_policy_gradient_loss | 0.137     |
|    ent_std                  | 0.1       |
|    ent_value_loss           | 0.00993   |
|    entropy_loss             | 5.73      |
|    explained_variance       | 0.238     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.136     |
|    n_updates                | 5880      |
|    policy_gradient_loss     | 0.175     |
|    std                      | 0.118     |
|    value_loss               | 0.0112    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 897       |
|    ep_rew_mean              | 3.38e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 590       |
|    time_elapsed             | 7963      |
|    total_timesteps          | 1208320   |
| train/                      |           |
|    approx_kl                | 3.6068447 |
|    clip_fraction            | 0.957     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.3027465 |
|    ent_clip_fraction        | 0.697     |
|    ent_entropy_loss         | 7.07      |
|    ent_loss                 | -0.056    |
|    ent_policy_gradient_loss | -0.0151   |
|    ent_std                  | 0.1       |
|    ent_value_loss           | 0.00689   |
|    entropy_loss             | 5.7       |
|    explained_variance       | 0.557     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.297     |
|    n_updates                | 5890      |
|    policy_gradient_loss     | 0.269     |
|    std                      | 0.119     |
|    value_loss               | 0.00728   |
-------------------------------------------
Eval num_timesteps=1210000, episode_reward=4070.84 +/- 1237.57
Episode length: 929.32 +/- 239.86
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 929       |
|    mean_reward              | 4.07e+03  |
| time/                       |           |
|    total_timesteps          | 1210000   |
| train/                      |           |
|    approx_kl                | 3.6709077 |
|    clip_fraction            | 0.958     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.1710366 |
|    ent_clip_fraction        | 0.7       |
|    ent_entropy_loss         | 7.1       |
|    ent_loss                 | -0.0332   |
|    ent_policy_gradient_loss | 0.0238    |
|    ent_std                  | 0.0997    |
|    ent_value_loss           | 0.00631   |
|    entropy_loss             | 5.68      |
|    explained_variance       | 0.598     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.173     |
|    n_updates                | 5900      |
|    policy_gradient_loss     | 0.229     |
|    std                      | 0.119     |
|    value_loss               | 0.00639   |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 897      |
|    ep_rew_mean     | 3.39e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 591      |
|    time_elapsed    | 7991     |
|    total_timesteps | 1210368  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 897       |
|    ep_rew_mean              | 3.39e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 592       |
|    time_elapsed             | 8002      |
|    total_timesteps          | 1212416   |
| train/                      |           |
|    approx_kl                | 3.615734  |
|    clip_fraction            | 0.952     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.5031714 |
|    ent_clip_fraction        | 0.719     |
|    ent_entropy_loss         | 7.1       |
|    ent_loss                 | -0.00184  |
|    ent_policy_gradient_loss | 0.00692   |
|    ent_std                  | 0.0996    |
|    ent_value_loss           | 0.00634   |
|    entropy_loss             | 5.71      |
|    explained_variance       | 0.59      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.279     |
|    n_updates                | 5910      |
|    policy_gradient_loss     | 0.24      |
|    std                      | 0.119     |
|    value_loss               | 0.00628   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 897       |
|    ep_rew_mean              | 3.4e+03   |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 593       |
|    time_elapsed             | 8012      |
|    total_timesteps          | 1214464   |
| train/                      |           |
|    approx_kl                | 3.7197628 |
|    clip_fraction            | 0.963     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.2208043 |
|    ent_clip_fraction        | 0.673     |
|    ent_entropy_loss         | 7.13      |
|    ent_loss                 | -0.0911   |
|    ent_policy_gradient_loss | -0.0379   |
|    ent_std                  | 0.0993    |
|    ent_value_loss           | 0.00764   |
|    entropy_loss             | 5.7       |
|    explained_variance       | 0.709     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.168     |
|    n_updates                | 5920      |
|    policy_gradient_loss     | 0.254     |
|    std                      | 0.119     |
|    value_loss               | 0.00748   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 897       |
|    ep_rew_mean              | 3.4e+03   |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 594       |
|    time_elapsed             | 8022      |
|    total_timesteps          | 1216512   |
| train/                      |           |
|    approx_kl                | 2.3225062 |
|    clip_fraction            | 0.881     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.0759878 |
|    ent_clip_fraction        | 0.811     |
|    ent_entropy_loss         | 7.15      |
|    ent_loss                 | -0.0305   |
|    ent_policy_gradient_loss | 0.0792    |
|    ent_std                  | 0.0988    |
|    ent_value_loss           | 0.00714   |
|    entropy_loss             | 5.71      |
|    explained_variance       | 0.646     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.161     |
|    n_updates                | 5930      |
|    policy_gradient_loss     | 0.198     |
|    std                      | 0.119     |
|    value_loss               | 0.00726   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 897       |
|    ep_rew_mean              | 3.4e+03   |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 595       |
|    time_elapsed             | 8032      |
|    total_timesteps          | 1218560   |
| train/                      |           |
|    approx_kl                | 2.9899495 |
|    clip_fraction            | 0.909     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.8541176 |
|    ent_clip_fraction        | 0.764     |
|    ent_entropy_loss         | 7.15      |
|    ent_loss                 | 0.017     |
|    ent_policy_gradient_loss | 0.0583    |
|    ent_std                  | 0.0994    |
|    ent_value_loss           | 0.0102    |
|    entropy_loss             | 5.72      |
|    explained_variance       | 0.502     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.101     |
|    n_updates                | 5940      |
|    policy_gradient_loss     | 0.158     |
|    std                      | 0.118     |
|    value_loss               | 0.0102    |
-------------------------------------------
Eval num_timesteps=1220000, episode_reward=4278.56 +/- 364.55
Episode length: 987.36 +/- 61.92
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 987        |
|    mean_reward              | 4.28e+03   |
| time/                       |            |
|    total_timesteps          | 1220000    |
| train/                      |            |
|    approx_kl                | 4.062191   |
|    clip_fraction            | 0.966      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.50817955 |
|    ent_clip_fraction        | 0.655      |
|    ent_entropy_loss         | 7.14       |
|    ent_loss                 | -0.0327    |
|    ent_policy_gradient_loss | -0.00227   |
|    ent_std                  | 0.0994     |
|    ent_value_loss           | 0.00818    |
|    entropy_loss             | 5.74       |
|    explained_variance       | 0.584      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.188      |
|    n_updates                | 5950       |
|    policy_gradient_loss     | 0.245      |
|    std                      | 0.118      |
|    value_loss               | 0.00808    |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 897      |
|    ep_rew_mean     | 3.41e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 596      |
|    time_elapsed    | 8061     |
|    total_timesteps | 1220608  |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 896        |
|    ep_rew_mean              | 3.44e+03   |
| time/                       |            |
|    fps                      | 151        |
|    iterations               | 597        |
|    time_elapsed             | 8072       |
|    total_timesteps          | 1222656    |
| train/                      |            |
|    approx_kl                | 3.7196434  |
|    clip_fraction            | 0.955      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.99176705 |
|    ent_clip_fraction        | 0.683      |
|    ent_entropy_loss         | 7.12       |
|    ent_loss                 | 0.00575    |
|    ent_policy_gradient_loss | 0.0113     |
|    ent_std                  | 0.0998     |
|    ent_value_loss           | 0.00611    |
|    entropy_loss             | 5.75       |
|    explained_variance       | 0.559      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.237      |
|    n_updates                | 5960       |
|    policy_gradient_loss     | 0.229      |
|    std                      | 0.118      |
|    value_loss               | 0.00591    |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 901       |
|    ep_rew_mean              | 3.46e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 598       |
|    time_elapsed             | 8082      |
|    total_timesteps          | 1224704   |
| train/                      |           |
|    approx_kl                | 3.4023924 |
|    clip_fraction            | 0.936     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.221179  |
|    ent_clip_fraction        | 0.734     |
|    ent_entropy_loss         | 7.14      |
|    ent_loss                 | 0.0353    |
|    ent_policy_gradient_loss | 0.0261    |
|    ent_std                  | 0.0991    |
|    ent_value_loss           | 0.0207    |
|    entropy_loss             | 5.75      |
|    explained_variance       | 0.583     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.105     |
|    n_updates                | 5970      |
|    policy_gradient_loss     | 0.2       |
|    std                      | 0.118     |
|    value_loss               | 0.0216    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 901       |
|    ep_rew_mean              | 3.47e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 599       |
|    time_elapsed             | 8092      |
|    total_timesteps          | 1226752   |
| train/                      |           |
|    approx_kl                | 3.9946024 |
|    clip_fraction            | 0.953     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.0022984 |
|    ent_clip_fraction        | 0.715     |
|    ent_entropy_loss         | 7.13      |
|    ent_loss                 | 0.102     |
|    ent_policy_gradient_loss | 0.048     |
|    ent_std                  | 0.0997    |
|    ent_value_loss           | 0.00651   |
|    entropy_loss             | 5.73      |
|    explained_variance       | 0.533     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0797    |
|    n_updates                | 5980      |
|    policy_gradient_loss     | 0.205     |
|    std                      | 0.119     |
|    value_loss               | 0.00621   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 894       |
|    ep_rew_mean              | 3.44e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 600       |
|    time_elapsed             | 8102      |
|    total_timesteps          | 1228800   |
| train/                      |           |
|    approx_kl                | 3.952114  |
|    clip_fraction            | 0.958     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.3942673 |
|    ent_clip_fraction        | 0.718     |
|    ent_entropy_loss         | 7.12      |
|    ent_loss                 | -0.0813   |
|    ent_policy_gradient_loss | 0.00977   |
|    ent_std                  | 0.0998    |
|    ent_value_loss           | 0.00813   |
|    entropy_loss             | 5.73      |
|    explained_variance       | 0.306     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.26      |
|    n_updates                | 5990      |
|    policy_gradient_loss     | 0.243     |
|    std                      | 0.119     |
|    value_loss               | 0.00767   |
-------------------------------------------
Eval num_timesteps=1230000, episode_reward=4187.78 +/- 952.05
Episode length: 939.44 +/- 205.76
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 939       |
|    mean_reward              | 4.19e+03  |
| time/                       |           |
|    total_timesteps          | 1230000   |
| train/                      |           |
|    approx_kl                | 3.620808  |
|    clip_fraction            | 0.956     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.2527832 |
|    ent_clip_fraction        | 0.686     |
|    ent_entropy_loss         | 7.14      |
|    ent_loss                 | 0.0121    |
|    ent_policy_gradient_loss | -0.00408  |
|    ent_std                  | 0.0992    |
|    ent_value_loss           | 0.0312    |
|    entropy_loss             | 5.71      |
|    explained_variance       | 0.378     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.259     |
|    n_updates                | 6000      |
|    policy_gradient_loss     | 0.2       |
|    std                      | 0.119     |
|    value_loss               | 0.0288    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 902      |
|    ep_rew_mean     | 3.47e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 601      |
|    time_elapsed    | 8130     |
|    total_timesteps | 1230848  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 902       |
|    ep_rew_mean              | 3.47e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 602       |
|    time_elapsed             | 8141      |
|    total_timesteps          | 1232896   |
| train/                      |           |
|    approx_kl                | 3.98697   |
|    clip_fraction            | 0.96      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.1789751 |
|    ent_clip_fraction        | 0.705     |
|    ent_entropy_loss         | 7.16      |
|    ent_loss                 | -0.0247   |
|    ent_policy_gradient_loss | -0.0044   |
|    ent_std                  | 0.0992    |
|    ent_value_loss           | 0.00742   |
|    entropy_loss             | 5.73      |
|    explained_variance       | 0.321     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.203     |
|    n_updates                | 6010      |
|    policy_gradient_loss     | 0.282     |
|    std                      | 0.118     |
|    value_loss               | 0.00785   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 902       |
|    ep_rew_mean              | 3.47e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 603       |
|    time_elapsed             | 8151      |
|    total_timesteps          | 1234944   |
| train/                      |           |
|    approx_kl                | 4.271868  |
|    clip_fraction            | 0.958     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.2704042 |
|    ent_clip_fraction        | 0.685     |
|    ent_entropy_loss         | 7.14      |
|    ent_loss                 | -0.0129   |
|    ent_policy_gradient_loss | 0.0306    |
|    ent_std                  | 0.0996    |
|    ent_value_loss           | 0.00662   |
|    entropy_loss             | 5.78      |
|    explained_variance       | 0.645     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.215     |
|    n_updates                | 6020      |
|    policy_gradient_loss     | 0.198     |
|    std                      | 0.117     |
|    value_loss               | 0.007     |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 902       |
|    ep_rew_mean              | 3.47e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 604       |
|    time_elapsed             | 8161      |
|    total_timesteps          | 1236992   |
| train/                      |           |
|    approx_kl                | 3.935565  |
|    clip_fraction            | 0.949     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.6064868 |
|    ent_clip_fraction        | 0.705     |
|    ent_entropy_loss         | 7.12      |
|    ent_loss                 | -0.0332   |
|    ent_policy_gradient_loss | 0.0167    |
|    ent_std                  | 0.0997    |
|    ent_value_loss           | 0.00751   |
|    entropy_loss             | 5.8       |
|    explained_variance       | 0.629     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.205     |
|    n_updates                | 6030      |
|    policy_gradient_loss     | 0.222     |
|    std                      | 0.118     |
|    value_loss               | 0.00747   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 908       |
|    ep_rew_mean              | 3.5e+03   |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 605       |
|    time_elapsed             | 8171      |
|    total_timesteps          | 1239040   |
| train/                      |           |
|    approx_kl                | 3.68499   |
|    clip_fraction            | 0.937     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.7182955 |
|    ent_clip_fraction        | 0.728     |
|    ent_entropy_loss         | 7.11      |
|    ent_loss                 | 0.0369    |
|    ent_policy_gradient_loss | 0.0354    |
|    ent_std                  | 0.0996    |
|    ent_value_loss           | 0.00698   |
|    entropy_loss             | 5.77      |
|    explained_variance       | 0.467     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.151     |
|    n_updates                | 6040      |
|    policy_gradient_loss     | 0.205     |
|    std                      | 0.118     |
|    value_loss               | 0.00714   |
-------------------------------------------
Eval num_timesteps=1240000, episode_reward=4092.80 +/- 834.93
Episode length: 971.84 +/- 95.74
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 972       |
|    mean_reward              | 4.09e+03  |
| time/                       |           |
|    total_timesteps          | 1240000   |
| train/                      |           |
|    approx_kl                | 4.130948  |
|    clip_fraction            | 0.967     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.7942445 |
|    ent_clip_fraction        | 0.657     |
|    ent_entropy_loss         | 7.12      |
|    ent_loss                 | 0.000825  |
|    ent_policy_gradient_loss | -0.00532  |
|    ent_std                  | 0.0996    |
|    ent_value_loss           | 0.00558   |
|    entropy_loss             | 5.74      |
|    explained_variance       | 0.539     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.199     |
|    n_updates                | 6050      |
|    policy_gradient_loss     | 0.266     |
|    std                      | 0.119     |
|    value_loss               | 0.00579   |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 917      |
|    ep_rew_mean     | 3.53e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 606      |
|    time_elapsed    | 8199     |
|    total_timesteps | 1241088  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 925       |
|    ep_rew_mean              | 3.55e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 607       |
|    time_elapsed             | 8209      |
|    total_timesteps          | 1243136   |
| train/                      |           |
|    approx_kl                | 3.9111915 |
|    clip_fraction            | 0.929     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.73447   |
|    ent_clip_fraction        | 0.747     |
|    ent_entropy_loss         | 7.12      |
|    ent_loss                 | -0.00339  |
|    ent_policy_gradient_loss | 0.0887    |
|    ent_std                  | 0.0998    |
|    ent_value_loss           | 0.00603   |
|    entropy_loss             | 5.76      |
|    explained_variance       | 0.588     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.177     |
|    n_updates                | 6060      |
|    policy_gradient_loss     | 0.191     |
|    std                      | 0.118     |
|    value_loss               | 0.00641   |
-------------------------------------------
------------------------------------------
| rollout/                    |          |
|    ep_len_mean              | 925      |
|    ep_rew_mean              | 3.52e+03 |
| time/                       |          |
|    fps                      | 151      |
|    iterations               | 608      |
|    time_elapsed             | 8218     |
|    total_timesteps          | 1245184  |
| train/                      |          |
|    approx_kl                | 2.425626 |
|    clip_fraction            | 0.81     |
|    clip_range               | 0.2      |
|    ent_approx_kl            | 8.251622 |
|    ent_clip_fraction        | 0.857    |
|    ent_entropy_loss         | 7.08     |
|    ent_loss                 | 0.0522   |
|    ent_policy_gradient_loss | 0.128    |
|    ent_std                  | 0.101    |
|    ent_value_loss           | 0.00904  |
|    entropy_loss             | 5.77     |
|    explained_variance       | 0.985    |
|    learning_rate            | 0.0003   |
|    loss                     | 0.0637   |
|    n_updates                | 6070     |
|    policy_gradient_loss     | 0.0746   |
|    std                      | 0.118    |
|    value_loss               | 0.0106   |
------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 929       |
|    ep_rew_mean              | 3.53e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 609       |
|    time_elapsed             | 8228      |
|    total_timesteps          | 1247232   |
| train/                      |           |
|    approx_kl                | 5.848207  |
|    clip_fraction            | 0.966     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.4786682 |
|    ent_clip_fraction        | 0.655     |
|    ent_entropy_loss         | 7.06      |
|    ent_loss                 | 0.00353   |
|    ent_policy_gradient_loss | 0.0244    |
|    ent_std                  | 0.1       |
|    ent_value_loss           | 0.0145    |
|    entropy_loss             | 5.74      |
|    explained_variance       | 0.986     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.131     |
|    n_updates                | 6080      |
|    policy_gradient_loss     | 0.172     |
|    std                      | 0.118     |
|    value_loss               | 0.0144    |
-------------------------------------------
------------------------------------------
| rollout/                    |          |
|    ep_len_mean              | 932      |
|    ep_rew_mean              | 3.53e+03 |
| time/                       |          |
|    fps                      | 151      |
|    iterations               | 610      |
|    time_elapsed             | 8238     |
|    total_timesteps          | 1249280  |
| train/                      |          |
|    approx_kl                | 4.359833 |
|    clip_fraction            | 0.907    |
|    clip_range               | 0.2      |
|    ent_approx_kl            | 4.244908 |
|    ent_clip_fraction        | 0.768    |
|    ent_entropy_loss         | 7.1      |
|    ent_loss                 | 0.0209   |
|    ent_policy_gradient_loss | 0.0317   |
|    ent_std                  | 0.1      |
|    ent_value_loss           | 0.0224   |
|    entropy_loss             | 5.73     |
|    explained_variance       | 0.956    |
|    learning_rate            | 0.0003   |
|    loss                     | 0.211    |
|    n_updates                | 6090     |
|    policy_gradient_loss     | 0.168    |
|    std                      | 0.119    |
|    value_loss               | 0.0247   |
------------------------------------------
Eval num_timesteps=1250000, episode_reward=4029.63 +/- 1234.04
Episode length: 923.96 +/- 244.52
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 924       |
|    mean_reward              | 4.03e+03  |
| time/                       |           |
|    total_timesteps          | 1250000   |
| train/                      |           |
|    approx_kl                | 4.0269704 |
|    clip_fraction            | 0.915     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.4149458 |
|    ent_clip_fraction        | 0.786     |
|    ent_entropy_loss         | 7.11      |
|    ent_loss                 | 0.0392    |
|    ent_policy_gradient_loss | 0.0814    |
|    ent_std                  | 0.0998    |
|    ent_value_loss           | 0.0114    |
|    entropy_loss             | 5.73      |
|    explained_variance       | 0.881     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.142     |
|    n_updates                | 6100      |
|    policy_gradient_loss     | 0.244     |
|    std                      | 0.118     |
|    value_loss               | 0.0111    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 924      |
|    ep_rew_mean     | 3.49e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 611      |
|    time_elapsed    | 8267     |
|    total_timesteps | 1251328  |
---------------------------------
------------------------------------------
| rollout/                    |          |
|    ep_len_mean              | 924      |
|    ep_rew_mean              | 3.47e+03 |
| time/                       |          |
|    fps                      | 151      |
|    iterations               | 612      |
|    time_elapsed             | 8277     |
|    total_timesteps          | 1253376  |
| train/                      |          |
|    approx_kl                | 4.56915  |
|    clip_fraction            | 0.943    |
|    clip_range               | 0.2      |
|    ent_approx_kl            | 2.260902 |
|    ent_clip_fraction        | 0.721    |
|    ent_entropy_loss         | 7.13     |
|    ent_loss                 | 0.0168   |
|    ent_policy_gradient_loss | 0.0323   |
|    ent_std                  | 0.0996   |
|    ent_value_loss           | 0.0305   |
|    entropy_loss             | 5.75     |
|    explained_variance       | 0.397    |
|    learning_rate            | 0.0003   |
|    loss                     | 0.116    |
|    n_updates                | 6110     |
|    policy_gradient_loss     | 0.17     |
|    std                      | 0.119    |
|    value_loss               | 0.0328   |
------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 927       |
|    ep_rew_mean              | 3.49e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 613       |
|    time_elapsed             | 8288      |
|    total_timesteps          | 1255424   |
| train/                      |           |
|    approx_kl                | 7.654709  |
|    clip_fraction            | 0.949     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.5657191 |
|    ent_clip_fraction        | 0.698     |
|    ent_entropy_loss         | 7.13      |
|    ent_loss                 | 0.0708    |
|    ent_policy_gradient_loss | 0.0472    |
|    ent_std                  | 0.0998    |
|    ent_value_loss           | 0.0215    |
|    entropy_loss             | 5.72      |
|    explained_variance       | 0.98      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0991    |
|    n_updates                | 6120      |
|    policy_gradient_loss     | 0.12      |
|    std                      | 0.119     |
|    value_loss               | 0.0234    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 927        |
|    ep_rew_mean              | 3.49e+03   |
| time/                       |            |
|    fps                      | 151        |
|    iterations               | 614        |
|    time_elapsed             | 8298       |
|    total_timesteps          | 1257472    |
| train/                      |            |
|    approx_kl                | 5.190503   |
|    clip_fraction            | 0.974      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.71547604 |
|    ent_clip_fraction        | 0.658      |
|    ent_entropy_loss         | 7.11       |
|    ent_loss                 | -0.0669    |
|    ent_policy_gradient_loss | -0.0229    |
|    ent_std                  | 0.0999     |
|    ent_value_loss           | 0.00741    |
|    entropy_loss             | 5.71       |
|    explained_variance       | 0.298      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.173      |
|    n_updates                | 6130       |
|    policy_gradient_loss     | 0.24       |
|    std                      | 0.119      |
|    value_loss               | 0.00643    |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 934       |
|    ep_rew_mean              | 3.52e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 615       |
|    time_elapsed             | 8308      |
|    total_timesteps          | 1259520   |
| train/                      |           |
|    approx_kl                | 6.4479237 |
|    clip_fraction            | 0.963     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.0568242 |
|    ent_clip_fraction        | 0.695     |
|    ent_entropy_loss         | 7.11      |
|    ent_loss                 | 0.00641   |
|    ent_policy_gradient_loss | -0.00772  |
|    ent_std                  | 0.0998    |
|    ent_value_loss           | 0.00662   |
|    entropy_loss             | 5.71      |
|    explained_variance       | 0.596     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.191     |
|    n_updates                | 6140      |
|    policy_gradient_loss     | 0.25      |
|    std                      | 0.119     |
|    value_loss               | 0.00642   |
-------------------------------------------
Eval num_timesteps=1260000, episode_reward=4147.08 +/- 118.69
Episode length: 1000.00 +/- 0.00
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 1e+03     |
|    mean_reward              | 4.15e+03  |
| time/                       |           |
|    total_timesteps          | 1260000   |
| train/                      |           |
|    approx_kl                | 3.8150172 |
|    clip_fraction            | 0.935     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.0887966 |
|    ent_clip_fraction        | 0.771     |
|    ent_entropy_loss         | 7.13      |
|    ent_loss                 | -0.0352   |
|    ent_policy_gradient_loss | 0.0566    |
|    ent_std                  | 0.0995    |
|    ent_value_loss           | 0.00601   |
|    entropy_loss             | 5.68      |
|    explained_variance       | 0.383     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.23      |
|    n_updates                | 6150      |
|    policy_gradient_loss     | 0.209     |
|    std                      | 0.119     |
|    value_loss               | 0.00614   |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 934      |
|    ep_rew_mean     | 3.5e+03  |
| time/              |          |
|    fps             | 151      |
|    iterations      | 616      |
|    time_elapsed    | 8336     |
|    total_timesteps | 1261568  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 934       |
|    ep_rew_mean              | 3.51e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 617       |
|    time_elapsed             | 8346      |
|    total_timesteps          | 1263616   |
| train/                      |           |
|    approx_kl                | 8.937943  |
|    clip_fraction            | 0.929     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.6094782 |
|    ent_clip_fraction        | 0.76      |
|    ent_entropy_loss         | 7.14      |
|    ent_loss                 | -0.0156   |
|    ent_policy_gradient_loss | 0.0748    |
|    ent_std                  | 0.0996    |
|    ent_value_loss           | 0.0219    |
|    entropy_loss             | 5.68      |
|    explained_variance       | 0.98      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.142     |
|    n_updates                | 6160      |
|    policy_gradient_loss     | 0.172     |
|    std                      | 0.12      |
|    value_loss               | 0.0229    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 927       |
|    ep_rew_mean              | 3.48e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 618       |
|    time_elapsed             | 8355      |
|    total_timesteps          | 1265664   |
| train/                      |           |
|    approx_kl                | 21.300234 |
|    clip_fraction            | 0.969     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.2218773 |
|    ent_clip_fraction        | 0.69      |
|    ent_entropy_loss         | 7.15      |
|    ent_loss                 | -0.0367   |
|    ent_policy_gradient_loss | -0.0272   |
|    ent_std                  | 0.0993    |
|    ent_value_loss           | 0.00466   |
|    entropy_loss             | 5.62      |
|    explained_variance       | 0.438     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.256     |
|    n_updates                | 6170      |
|    policy_gradient_loss     | 0.272     |
|    std                      | 0.121     |
|    value_loss               | 0.00456   |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 927        |
|    ep_rew_mean              | 3.49e+03   |
| time/                       |            |
|    fps                      | 151        |
|    iterations               | 619        |
|    time_elapsed             | 8365       |
|    total_timesteps          | 1267712    |
| train/                      |            |
|    approx_kl                | 4.35411    |
|    clip_fraction            | 0.969      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.61950743 |
|    ent_clip_fraction        | 0.667      |
|    ent_entropy_loss         | 7.15       |
|    ent_loss                 | -0.004     |
|    ent_policy_gradient_loss | -0.00158   |
|    ent_std                  | 0.0993     |
|    ent_value_loss           | 0.0268     |
|    entropy_loss             | 5.61       |
|    explained_variance       | 0.549      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.181      |
|    n_updates                | 6180       |
|    policy_gradient_loss     | 0.209      |
|    std                      | 0.12       |
|    value_loss               | 0.0266     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 927       |
|    ep_rew_mean              | 3.49e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 620       |
|    time_elapsed             | 8375      |
|    total_timesteps          | 1269760   |
| train/                      |           |
|    approx_kl                | 4.055324  |
|    clip_fraction            | 0.941     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.5640914 |
|    ent_clip_fraction        | 0.734     |
|    ent_entropy_loss         | 7.14      |
|    ent_loss                 | 0.00087   |
|    ent_policy_gradient_loss | 0.0183    |
|    ent_std                  | 0.0995    |
|    ent_value_loss           | 0.00618   |
|    entropy_loss             | 5.65      |
|    explained_variance       | 0.536     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.217     |
|    n_updates                | 6190      |
|    policy_gradient_loss     | 0.269     |
|    std                      | 0.12      |
|    value_loss               | 0.00626   |
-------------------------------------------
Eval num_timesteps=1270000, episode_reward=4299.65 +/- 853.77
Episode length: 953.60 +/- 181.67
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 954       |
|    mean_reward              | 4.3e+03   |
| time/                       |           |
|    total_timesteps          | 1270000   |
| train/                      |           |
|    approx_kl                | 3.5291023 |
|    clip_fraction            | 0.916     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.2346454 |
|    ent_clip_fraction        | 0.775     |
|    ent_entropy_loss         | 7.14      |
|    ent_loss                 | 0.0207    |
|    ent_policy_gradient_loss | 0.0714    |
|    ent_std                  | 0.0996    |
|    ent_value_loss           | 0.00818   |
|    entropy_loss             | 5.65      |
|    explained_variance       | 0.565     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.17      |
|    n_updates                | 6200      |
|    policy_gradient_loss     | 0.208     |
|    std                      | 0.12      |
|    value_loss               | 0.00864   |
-------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 941      |
|    ep_rew_mean     | 3.55e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 621      |
|    time_elapsed    | 8402     |
|    total_timesteps | 1271808  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 944       |
|    ep_rew_mean              | 3.57e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 622       |
|    time_elapsed             | 8412      |
|    total_timesteps          | 1273856   |
| train/                      |           |
|    approx_kl                | 4.2420096 |
|    clip_fraction            | 0.967     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.6333637 |
|    ent_clip_fraction        | 0.669     |
|    ent_entropy_loss         | 7.13      |
|    ent_loss                 | -0.0574   |
|    ent_policy_gradient_loss | -0.0171   |
|    ent_std                  | 0.0997    |
|    ent_value_loss           | 0.00543   |
|    entropy_loss             | 5.67      |
|    explained_variance       | 0.585     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.273     |
|    n_updates                | 6210      |
|    policy_gradient_loss     | 0.254     |
|    std                      | 0.119     |
|    value_loss               | 0.00544   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 952       |
|    ep_rew_mean              | 3.6e+03   |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 623       |
|    time_elapsed             | 8422      |
|    total_timesteps          | 1275904   |
| train/                      |           |
|    approx_kl                | 3.6583538 |
|    clip_fraction            | 0.954     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.3854716 |
|    ent_clip_fraction        | 0.711     |
|    ent_entropy_loss         | 7.13      |
|    ent_loss                 | 0.0254    |
|    ent_policy_gradient_loss | 0.0043    |
|    ent_std                  | 0.0996    |
|    ent_value_loss           | 0.00522   |
|    entropy_loss             | 5.67      |
|    explained_variance       | 0.642     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.195     |
|    n_updates                | 6220      |
|    policy_gradient_loss     | 0.243     |
|    std                      | 0.119     |
|    value_loss               | 0.00526   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 956       |
|    ep_rew_mean              | 3.62e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 624       |
|    time_elapsed             | 8432      |
|    total_timesteps          | 1277952   |
| train/                      |           |
|    approx_kl                | 3.6567018 |
|    clip_fraction            | 0.931     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.8544967 |
|    ent_clip_fraction        | 0.759     |
|    ent_entropy_loss         | 7.13      |
|    ent_loss                 | 0.0265    |
|    ent_policy_gradient_loss | 0.0675    |
|    ent_std                  | 0.0998    |
|    ent_value_loss           | 0.00574   |
|    entropy_loss             | 5.72      |
|    explained_variance       | 0.564     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.192     |
|    n_updates                | 6230      |
|    policy_gradient_loss     | 0.28      |
|    std                      | 0.118     |
|    value_loss               | 0.00582   |
-------------------------------------------
Eval num_timesteps=1280000, episode_reward=4427.24 +/- 849.38
Episode length: 963.08 +/- 180.87
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 963       |
|    mean_reward              | 4.43e+03  |
| time/                       |           |
|    total_timesteps          | 1280000   |
| train/                      |           |
|    approx_kl                | 3.1714306 |
|    clip_fraction            | 0.906     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.4416547 |
|    ent_clip_fraction        | 0.784     |
|    ent_entropy_loss         | 7.1       |
|    ent_loss                 | -0.0126   |
|    ent_policy_gradient_loss | 0.0637    |
|    ent_std                  | 0.1       |
|    ent_value_loss           | 0.00512   |
|    entropy_loss             | 5.74      |
|    explained_variance       | 0.552     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.22      |
|    n_updates                | 6240      |
|    policy_gradient_loss     | 0.209     |
|    std                      | 0.119     |
|    value_loss               | 0.00506   |
-------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 960      |
|    ep_rew_mean     | 3.64e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 625      |
|    time_elapsed    | 8459     |
|    total_timesteps | 1280000  |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 960        |
|    ep_rew_mean              | 3.67e+03   |
| time/                       |            |
|    fps                      | 151        |
|    iterations               | 626        |
|    time_elapsed             | 8470       |
|    total_timesteps          | 1282048    |
| train/                      |            |
|    approx_kl                | 3.995226   |
|    clip_fraction            | 0.966      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.75832915 |
|    ent_clip_fraction        | 0.67       |
|    ent_entropy_loss         | 7.12       |
|    ent_loss                 | -0.0334    |
|    ent_policy_gradient_loss | -0.0213    |
|    ent_std                  | 0.0997     |
|    ent_value_loss           | 0.00859    |
|    entropy_loss             | 5.72       |
|    explained_variance       | 0.558      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.251      |
|    n_updates                | 6250       |
|    policy_gradient_loss     | 0.227      |
|    std                      | 0.119      |
|    value_loss               | 0.00843    |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 962       |
|    ep_rew_mean              | 3.67e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 627       |
|    time_elapsed             | 8480      |
|    total_timesteps          | 1284096   |
| train/                      |           |
|    approx_kl                | 3.7651787 |
|    clip_fraction            | 0.95      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.4547828 |
|    ent_clip_fraction        | 0.702     |
|    ent_entropy_loss         | 7.14      |
|    ent_loss                 | 0.00235   |
|    ent_policy_gradient_loss | 0.0105    |
|    ent_std                  | 0.0994    |
|    ent_value_loss           | 0.00587   |
|    entropy_loss             | 5.73      |
|    explained_variance       | 0.547     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.241     |
|    n_updates                | 6260      |
|    policy_gradient_loss     | 0.331     |
|    std                      | 0.118     |
|    value_loss               | 0.00599   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 962       |
|    ep_rew_mean              | 3.68e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 628       |
|    time_elapsed             | 8490      |
|    total_timesteps          | 1286144   |
| train/                      |           |
|    approx_kl                | 8.365487  |
|    clip_fraction            | 0.939     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.7620443 |
|    ent_clip_fraction        | 0.739     |
|    ent_entropy_loss         | 7.15      |
|    ent_loss                 | 0.0451    |
|    ent_policy_gradient_loss | 0.0488    |
|    ent_std                  | 0.0993    |
|    ent_value_loss           | 0.0128    |
|    entropy_loss             | 5.77      |
|    explained_variance       | 0.982     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.116     |
|    n_updates                | 6270      |
|    policy_gradient_loss     | 0.637     |
|    std                      | 0.118     |
|    value_loss               | 0.013     |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 963       |
|    ep_rew_mean              | 3.69e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 629       |
|    time_elapsed             | 8500      |
|    total_timesteps          | 1288192   |
| train/                      |           |
|    approx_kl                | 4.653615  |
|    clip_fraction            | 0.961     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.9387466 |
|    ent_clip_fraction        | 0.68      |
|    ent_entropy_loss         | 7.16      |
|    ent_loss                 | -0.0068   |
|    ent_policy_gradient_loss | 0.0146    |
|    ent_std                  | 0.0991    |
|    ent_value_loss           | 0.00376   |
|    entropy_loss             | 5.82      |
|    explained_variance       | 0.474     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.142     |
|    n_updates                | 6280      |
|    policy_gradient_loss     | 0.234     |
|    std                      | 0.117     |
|    value_loss               | 0.00378   |
-------------------------------------------
Eval num_timesteps=1290000, episode_reward=4275.07 +/- 1090.55
Episode length: 1000.00 +/- 0.00
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 1e+03     |
|    mean_reward              | 4.28e+03  |
| time/                       |           |
|    total_timesteps          | 1290000   |
| train/                      |           |
|    approx_kl                | 4.637092  |
|    clip_fraction            | 0.972     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.8747646 |
|    ent_clip_fraction        | 0.658     |
|    ent_entropy_loss         | 7.17      |
|    ent_loss                 | -0.0652   |
|    ent_policy_gradient_loss | -0.0345   |
|    ent_std                  | 0.099     |
|    ent_value_loss           | 0.0069    |
|    entropy_loss             | 5.84      |
|    explained_variance       | 0.656     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.264     |
|    n_updates                | 6290      |
|    policy_gradient_loss     | 0.255     |
|    std                      | 0.117     |
|    value_loss               | 0.00634   |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 963      |
|    ep_rew_mean     | 3.69e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 630      |
|    time_elapsed    | 8528     |
|    total_timesteps | 1290240  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 963       |
|    ep_rew_mean              | 3.69e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 631       |
|    time_elapsed             | 8538      |
|    total_timesteps          | 1292288   |
| train/                      |           |
|    approx_kl                | 4.2269893 |
|    clip_fraction            | 0.966     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.8822967 |
|    ent_clip_fraction        | 0.689     |
|    ent_entropy_loss         | 7.18      |
|    ent_loss                 | -0.0367   |
|    ent_policy_gradient_loss | 0.00964   |
|    ent_std                  | 0.0989    |
|    ent_value_loss           | 0.00662   |
|    entropy_loss             | 5.89      |
|    explained_variance       | 0.624     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.206     |
|    n_updates                | 6300      |
|    policy_gradient_loss     | 0.242     |
|    std                      | 0.115     |
|    value_loss               | 0.0065    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 963       |
|    ep_rew_mean              | 3.69e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 632       |
|    time_elapsed             | 8549      |
|    total_timesteps          | 1294336   |
| train/                      |           |
|    approx_kl                | 4.1700583 |
|    clip_fraction            | 0.942     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.3164784 |
|    ent_clip_fraction        | 0.695     |
|    ent_entropy_loss         | 7.18      |
|    ent_loss                 | 0.0245    |
|    ent_policy_gradient_loss | 0.0186    |
|    ent_std                  | 0.0991    |
|    ent_value_loss           | 0.00614   |
|    entropy_loss             | 5.96      |
|    explained_variance       | 0.552     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.184     |
|    n_updates                | 6310      |
|    policy_gradient_loss     | 0.213     |
|    std                      | 0.115     |
|    value_loss               | 0.00607   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 964       |
|    ep_rew_mean              | 3.7e+03   |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 633       |
|    time_elapsed             | 8559      |
|    total_timesteps          | 1296384   |
| train/                      |           |
|    approx_kl                | 5.171652  |
|    clip_fraction            | 0.928     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.6038198 |
|    ent_clip_fraction        | 0.753     |
|    ent_entropy_loss         | 7.19      |
|    ent_loss                 | -0.0361   |
|    ent_policy_gradient_loss | 0.0295    |
|    ent_std                  | 0.0987    |
|    ent_value_loss           | 0.00641   |
|    entropy_loss             | 5.92      |
|    explained_variance       | 0.604     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.174     |
|    n_updates                | 6320      |
|    policy_gradient_loss     | 0.213     |
|    std                      | 0.116     |
|    value_loss               | 0.0062    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 964       |
|    ep_rew_mean              | 3.7e+03   |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 634       |
|    time_elapsed             | 8569      |
|    total_timesteps          | 1298432   |
| train/                      |           |
|    approx_kl                | 2.890708  |
|    clip_fraction            | 0.863     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.6067376 |
|    ent_clip_fraction        | 0.826     |
|    ent_entropy_loss         | 7.21      |
|    ent_loss                 | 0.105     |
|    ent_policy_gradient_loss | 0.0861    |
|    ent_std                  | 0.0985    |
|    ent_value_loss           | 0.0064    |
|    entropy_loss             | 5.89      |
|    explained_variance       | 0.551     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.154     |
|    n_updates                | 6330      |
|    policy_gradient_loss     | 0.178     |
|    std                      | 0.116     |
|    value_loss               | 0.00612   |
-------------------------------------------
Eval num_timesteps=1300000, episode_reward=3801.07 +/- 1115.00
Episode length: 1000.00 +/- 0.00
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 1e+03     |
|    mean_reward              | 3.8e+03   |
| time/                       |           |
|    total_timesteps          | 1300000   |
| train/                      |           |
|    approx_kl                | 3.80399   |
|    clip_fraction            | 0.944     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.5535305 |
|    ent_clip_fraction        | 0.747     |
|    ent_entropy_loss         | 7.26      |
|    ent_loss                 | 0.00912   |
|    ent_policy_gradient_loss | 0.0367    |
|    ent_std                  | 0.0975    |
|    ent_value_loss           | 0.00551   |
|    entropy_loss             | 5.85      |
|    explained_variance       | 0.679     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.181     |
|    n_updates                | 6340      |
|    policy_gradient_loss     | 0.258     |
|    std                      | 0.117     |
|    value_loss               | 0.00526   |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 968      |
|    ep_rew_mean     | 3.71e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 635      |
|    time_elapsed    | 8596     |
|    total_timesteps | 1300480  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 965       |
|    ep_rew_mean              | 3.71e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 636       |
|    time_elapsed             | 8607      |
|    total_timesteps          | 1302528   |
| train/                      |           |
|    approx_kl                | 4.758522  |
|    clip_fraction            | 0.968     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.2981625 |
|    ent_clip_fraction        | 0.695     |
|    ent_entropy_loss         | 7.3       |
|    ent_loss                 | -0.0046   |
|    ent_policy_gradient_loss | -0.00298  |
|    ent_std                  | 0.0976    |
|    ent_value_loss           | 0.00736   |
|    entropy_loss             | 5.84      |
|    explained_variance       | 0.621     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.161     |
|    n_updates                | 6350      |
|    policy_gradient_loss     | 0.277     |
|    std                      | 0.117     |
|    value_loss               | 0.00711   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 965       |
|    ep_rew_mean              | 3.72e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 637       |
|    time_elapsed             | 8617      |
|    total_timesteps          | 1304576   |
| train/                      |           |
|    approx_kl                | 3.729587  |
|    clip_fraction            | 0.955     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.2595853 |
|    ent_clip_fraction        | 0.69      |
|    ent_entropy_loss         | 7.27      |
|    ent_loss                 | -0.0549   |
|    ent_policy_gradient_loss | 0.00591   |
|    ent_std                  | 0.098     |
|    ent_value_loss           | 0.0172    |
|    entropy_loss             | 5.82      |
|    explained_variance       | 0.462     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.157     |
|    n_updates                | 6360      |
|    policy_gradient_loss     | 0.191     |
|    std                      | 0.117     |
|    value_loss               | 0.0176    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 965       |
|    ep_rew_mean              | 3.72e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 638       |
|    time_elapsed             | 8627      |
|    total_timesteps          | 1306624   |
| train/                      |           |
|    approx_kl                | 2.2596645 |
|    clip_fraction            | 0.832     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 4.930327  |
|    ent_clip_fraction        | 0.884     |
|    ent_entropy_loss         | 7.26      |
|    ent_loss                 | 0.223     |
|    ent_policy_gradient_loss | 0.178     |
|    ent_std                  | 0.0978    |
|    ent_value_loss           | 0.00824   |
|    entropy_loss             | 5.82      |
|    explained_variance       | 0.545     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.155     |
|    n_updates                | 6370      |
|    policy_gradient_loss     | 0.145     |
|    std                      | 0.117     |
|    value_loss               | 0.00931   |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 965        |
|    ep_rew_mean              | 3.71e+03   |
| time/                       |            |
|    fps                      | 151        |
|    iterations               | 639        |
|    time_elapsed             | 8637       |
|    total_timesteps          | 1308672    |
| train/                      |            |
|    approx_kl                | 5.2433414  |
|    clip_fraction            | 0.973      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.88941044 |
|    ent_clip_fraction        | 0.692      |
|    ent_entropy_loss         | 7.25       |
|    ent_loss                 | -0.0298    |
|    ent_policy_gradient_loss | -0.00844   |
|    ent_std                  | 0.0982     |
|    ent_value_loss           | 0.00735    |
|    entropy_loss             | 5.83       |
|    explained_variance       | 0.479      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.241      |
|    n_updates                | 6380       |
|    policy_gradient_loss     | 0.238      |
|    std                      | 0.117      |
|    value_loss               | 0.00752    |
--------------------------------------------
Eval num_timesteps=1310000, episode_reward=4505.60 +/- 249.15
Episode length: 990.96 +/- 44.29
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 991       |
|    mean_reward              | 4.51e+03  |
| time/                       |           |
|    total_timesteps          | 1310000   |
| train/                      |           |
|    approx_kl                | 5.211362  |
|    clip_fraction            | 0.963     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.0836613 |
|    ent_clip_fraction        | 0.664     |
|    ent_entropy_loss         | 7.25      |
|    ent_loss                 | -0.034    |
|    ent_policy_gradient_loss | -0.00625  |
|    ent_std                  | 0.0978    |
|    ent_value_loss           | 0.0179    |
|    entropy_loss             | 5.88      |
|    explained_variance       | 0.96      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.104     |
|    n_updates                | 6390      |
|    policy_gradient_loss     | 0.18      |
|    std                      | 0.116     |
|    value_loss               | 0.0177    |
-------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 965      |
|    ep_rew_mean     | 3.71e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 640      |
|    time_elapsed    | 8665     |
|    total_timesteps | 1310720  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 965       |
|    ep_rew_mean              | 3.71e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 641       |
|    time_elapsed             | 8675      |
|    total_timesteps          | 1312768   |
| train/                      |           |
|    approx_kl                | 3.1010194 |
|    clip_fraction            | 0.869     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.7975984 |
|    ent_clip_fraction        | 0.849     |
|    ent_entropy_loss         | 7.23      |
|    ent_loss                 | 0.114     |
|    ent_policy_gradient_loss | 0.114     |
|    ent_std                  | 0.0988    |
|    ent_value_loss           | 0.0152    |
|    entropy_loss             | 5.93      |
|    explained_variance       | 0.513     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.108     |
|    n_updates                | 6400      |
|    policy_gradient_loss     | 0.118     |
|    std                      | 0.115     |
|    value_loss               | 0.0168    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 965       |
|    ep_rew_mean              | 3.7e+03   |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 642       |
|    time_elapsed             | 8686      |
|    total_timesteps          | 1314816   |
| train/                      |           |
|    approx_kl                | 4.4862986 |
|    clip_fraction            | 0.962     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.1725767 |
|    ent_clip_fraction        | 0.681     |
|    ent_entropy_loss         | 7.18      |
|    ent_loss                 | -0.00831  |
|    ent_policy_gradient_loss | 0.000296  |
|    ent_std                  | 0.0989    |
|    ent_value_loss           | 0.00653   |
|    entropy_loss             | 5.95      |
|    explained_variance       | 0.603     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.246     |
|    n_updates                | 6410      |
|    policy_gradient_loss     | 0.23      |
|    std                      | 0.115     |
|    value_loss               | 0.00621   |
-------------------------------------------
------------------------------------------
| rollout/                    |          |
|    ep_len_mean              | 957      |
|    ep_rew_mean              | 3.67e+03 |
| time/                       |          |
|    fps                      | 151      |
|    iterations               | 643      |
|    time_elapsed             | 8696     |
|    total_timesteps          | 1316864  |
| train/                      |          |
|    approx_kl                | 9.896229 |
|    clip_fraction            | 0.876    |
|    clip_range               | 0.2      |
|    ent_approx_kl            | 3.491288 |
|    ent_clip_fraction        | 0.829    |
|    ent_entropy_loss         | 7.13     |
|    ent_loss                 | 0.0419   |
|    ent_policy_gradient_loss | 0.125    |
|    ent_std                  | 0.1      |
|    ent_value_loss           | 0.0127   |
|    entropy_loss             | 6        |
|    explained_variance       | 0.986    |
|    learning_rate            | 0.0003   |
|    loss                     | 0.0788   |
|    n_updates                | 6420     |
|    policy_gradient_loss     | 0.0545   |
|    std                      | 0.114    |
|    value_loss               | 0.0129   |
------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 966        |
|    ep_rew_mean              | 3.71e+03   |
| time/                       |            |
|    fps                      | 151        |
|    iterations               | 644        |
|    time_elapsed             | 8706       |
|    total_timesteps          | 1318912    |
| train/                      |            |
|    approx_kl                | 5.0916624  |
|    clip_fraction            | 0.973      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.43110886 |
|    ent_clip_fraction        | 0.658      |
|    ent_entropy_loss         | 7.05       |
|    ent_loss                 | -0.0212    |
|    ent_policy_gradient_loss | -0.0153    |
|    ent_std                  | 0.101      |
|    ent_value_loss           | 0.0524     |
|    entropy_loss             | 6.02       |
|    explained_variance       | 0.514      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.2        |
|    n_updates                | 6430       |
|    policy_gradient_loss     | 0.172      |
|    std                      | 0.115      |
|    value_loss               | 0.051      |
--------------------------------------------
Eval num_timesteps=1320000, episode_reward=3478.01 +/- 1456.01
Episode length: 900.00 +/- 265.68
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 900       |
|    mean_reward              | 3.48e+03  |
| time/                       |           |
|    total_timesteps          | 1320000   |
| train/                      |           |
|    approx_kl                | 5.0677156 |
|    clip_fraction            | 0.956     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.3308697 |
|    ent_clip_fraction        | 0.693     |
|    ent_entropy_loss         | 7.04      |
|    ent_loss                 | -0.0474   |
|    ent_policy_gradient_loss | 0.00749   |
|    ent_std                  | 0.1       |
|    ent_value_loss           | 0.00594   |
|    entropy_loss             | 5.99      |
|    explained_variance       | 0.54      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.208     |
|    n_updates                | 6440      |
|    policy_gradient_loss     | 0.223     |
|    std                      | 0.115     |
|    value_loss               | 0.00571   |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 966      |
|    ep_rew_mean     | 3.65e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 645      |
|    time_elapsed    | 8733     |
|    total_timesteps | 1320960  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 965       |
|    ep_rew_mean              | 3.65e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 646       |
|    time_elapsed             | 8744      |
|    total_timesteps          | 1323008   |
| train/                      |           |
|    approx_kl                | 23.423893 |
|    clip_fraction            | 0.973     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.5684688 |
|    ent_clip_fraction        | 0.616     |
|    ent_entropy_loss         | 7.09      |
|    ent_loss                 | 0.0223    |
|    ent_policy_gradient_loss | 0.0296    |
|    ent_std                  | 0.0998    |
|    ent_value_loss           | 0.0161    |
|    entropy_loss             | 6.01      |
|    explained_variance       | 0.942     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.17      |
|    n_updates                | 6450      |
|    policy_gradient_loss     | 0.101     |
|    std                      | 0.114     |
|    value_loss               | 0.0204    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 973        |
|    ep_rew_mean              | 3.68e+03   |
| time/                       |            |
|    fps                      | 151        |
|    iterations               | 647        |
|    time_elapsed             | 8754       |
|    total_timesteps          | 1325056    |
| train/                      |            |
|    approx_kl                | 5.525543   |
|    clip_fraction            | 0.968      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.98468435 |
|    ent_clip_fraction        | 0.7        |
|    ent_entropy_loss         | 7.1        |
|    ent_loss                 | 0.042      |
|    ent_policy_gradient_loss | 0.0116     |
|    ent_std                  | 0.1        |
|    ent_value_loss           | 0.0373     |
|    entropy_loss             | 6.03       |
|    explained_variance       | -0.0571    |
|    learning_rate            | 0.0003     |
|    loss                     | 0.183      |
|    n_updates                | 6460       |
|    policy_gradient_loss     | 0.183      |
|    std                      | 0.114      |
|    value_loss               | 0.0364     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 973       |
|    ep_rew_mean              | 3.69e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 648       |
|    time_elapsed             | 8764      |
|    total_timesteps          | 1327104   |
| train/                      |           |
|    approx_kl                | 4.7183094 |
|    clip_fraction            | 0.903     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.9456906 |
|    ent_clip_fraction        | 0.784     |
|    ent_entropy_loss         | 7.09      |
|    ent_loss                 | -0.00119  |
|    ent_policy_gradient_loss | 0.0654    |
|    ent_std                  | 0.0999    |
|    ent_value_loss           | 0.00763   |
|    entropy_loss             | 6.04      |
|    explained_variance       | 0.515     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.189     |
|    n_updates                | 6470      |
|    policy_gradient_loss     | 0.224     |
|    std                      | 0.114     |
|    value_loss               | 0.00762   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 973       |
|    ep_rew_mean              | 3.69e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 649       |
|    time_elapsed             | 8774      |
|    total_timesteps          | 1329152   |
| train/                      |           |
|    approx_kl                | 4.784997  |
|    clip_fraction            | 0.969     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.0535667 |
|    ent_clip_fraction        | 0.669     |
|    ent_entropy_loss         | 7.12      |
|    ent_loss                 | -0.0446   |
|    ent_policy_gradient_loss | -0.0141   |
|    ent_std                  | 0.0995    |
|    ent_value_loss           | 0.00701   |
|    entropy_loss             | 6.05      |
|    explained_variance       | 0.469     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.28      |
|    n_updates                | 6480      |
|    policy_gradient_loss     | 0.242     |
|    std                      | 0.114     |
|    value_loss               | 0.00694   |
-------------------------------------------
Eval num_timesteps=1330000, episode_reward=4257.59 +/- 934.21
Episode length: 970.04 +/- 121.33
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 970       |
|    mean_reward              | 4.26e+03  |
| time/                       |           |
|    total_timesteps          | 1330000   |
| train/                      |           |
|    approx_kl                | 4.5485187 |
|    clip_fraction            | 0.958     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.2352083 |
|    ent_clip_fraction        | 0.709     |
|    ent_entropy_loss         | 7.11      |
|    ent_loss                 | -0.021    |
|    ent_policy_gradient_loss | 0.0122    |
|    ent_std                  | 0.0998    |
|    ent_value_loss           | 0.00688   |
|    entropy_loss             | 6.06      |
|    explained_variance       | 0.622     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.2       |
|    n_updates                | 6490      |
|    policy_gradient_loss     | 0.246     |
|    std                      | 0.114     |
|    value_loss               | 0.00697   |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 960      |
|    ep_rew_mean     | 3.64e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 650      |
|    time_elapsed    | 8803     |
|    total_timesteps | 1331200  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 955       |
|    ep_rew_mean              | 3.6e+03   |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 651       |
|    time_elapsed             | 8813      |
|    total_timesteps          | 1333248   |
| train/                      |           |
|    approx_kl                | 5.2429905 |
|    clip_fraction            | 0.965     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.7019789 |
|    ent_clip_fraction        | 0.676     |
|    ent_entropy_loss         | 7.08      |
|    ent_loss                 | -0.0157   |
|    ent_policy_gradient_loss | -0.00865  |
|    ent_std                  | 0.1       |
|    ent_value_loss           | 0.0386    |
|    entropy_loss             | 6.02      |
|    explained_variance       | 0.493     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.147     |
|    n_updates                | 6500      |
|    policy_gradient_loss     | 0.171     |
|    std                      | 0.114     |
|    value_loss               | 0.0371    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 948       |
|    ep_rew_mean              | 3.57e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 652       |
|    time_elapsed             | 8823      |
|    total_timesteps          | 1335296   |
| train/                      |           |
|    approx_kl                | 11.159957 |
|    clip_fraction            | 0.975     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.6987208 |
|    ent_clip_fraction        | 0.663     |
|    ent_entropy_loss         | 7.1       |
|    ent_loss                 | -0.0303   |
|    ent_policy_gradient_loss | -0.00803  |
|    ent_std                  | 0.0995    |
|    ent_value_loss           | 0.0289    |
|    entropy_loss             | 5.98      |
|    explained_variance       | 0.97      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.182     |
|    n_updates                | 6510      |
|    policy_gradient_loss     | 0.163     |
|    std                      | 0.115     |
|    value_loss               | 0.0295    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 936       |
|    ep_rew_mean              | 3.51e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 653       |
|    time_elapsed             | 8833      |
|    total_timesteps          | 1337344   |
| train/                      |           |
|    approx_kl                | 4.633215  |
|    clip_fraction            | 0.934     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.7630154 |
|    ent_clip_fraction        | 0.747     |
|    ent_entropy_loss         | 7.13      |
|    ent_loss                 | 0.0529    |
|    ent_policy_gradient_loss | 0.0253    |
|    ent_std                  | 0.0993    |
|    ent_value_loss           | 0.0268    |
|    entropy_loss             | 5.99      |
|    explained_variance       | 0.508     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.134     |
|    n_updates                | 6520      |
|    policy_gradient_loss     | 0.174     |
|    std                      | 0.114     |
|    value_loss               | 0.0271    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 936       |
|    ep_rew_mean              | 3.52e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 654       |
|    time_elapsed             | 8843      |
|    total_timesteps          | 1339392   |
| train/                      |           |
|    approx_kl                | 5.6077704 |
|    clip_fraction            | 0.918     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.0351709 |
|    ent_clip_fraction        | 0.634     |
|    ent_entropy_loss         | 7.16      |
|    ent_loss                 | -0.0193   |
|    ent_policy_gradient_loss | -0.00862  |
|    ent_std                  | 0.0987    |
|    ent_value_loss           | 0.053     |
|    entropy_loss             | 6.02      |
|    explained_variance       | 0.937     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.147     |
|    n_updates                | 6530      |
|    policy_gradient_loss     | 0.131     |
|    std                      | 0.113     |
|    value_loss               | 0.0525    |
-------------------------------------------
Eval num_timesteps=1340000, episode_reward=3472.21 +/- 1562.24
Episode length: 794.52 +/- 330.55
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 795        |
|    mean_reward              | 3.47e+03   |
| time/                       |            |
|    total_timesteps          | 1340000    |
| train/                      |            |
|    approx_kl                | 6.3213897  |
|    clip_fraction            | 0.976      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.37421474 |
|    ent_clip_fraction        | 0.629      |
|    ent_entropy_loss         | 7.19       |
|    ent_loss                 | 0.00105    |
|    ent_policy_gradient_loss | -0.00454   |
|    ent_std                  | 0.0987     |
|    ent_value_loss           | 0.0406     |
|    entropy_loss             | 6.09       |
|    explained_variance       | 0.941      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.213      |
|    n_updates                | 6540       |
|    policy_gradient_loss     | 0.182      |
|    std                      | 0.113      |
|    value_loss               | 0.0385     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 934      |
|    ep_rew_mean     | 3.53e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 655      |
|    time_elapsed    | 8872     |
|    total_timesteps | 1341440  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 934       |
|    ep_rew_mean              | 3.54e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 656       |
|    time_elapsed             | 8882      |
|    total_timesteps          | 1343488   |
| train/                      |           |
|    approx_kl                | 6.560488  |
|    clip_fraction            | 0.968     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.6741811 |
|    ent_clip_fraction        | 0.66      |
|    ent_entropy_loss         | 7.24      |
|    ent_loss                 | -0.0037   |
|    ent_policy_gradient_loss | -0.0174   |
|    ent_std                  | 0.0975    |
|    ent_value_loss           | 0.0321    |
|    entropy_loss             | 6.14      |
|    explained_variance       | 0.899     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.216     |
|    n_updates                | 6550      |
|    policy_gradient_loss     | 0.177     |
|    std                      | 0.112     |
|    value_loss               | 0.0317    |
-------------------------------------------
------------------------------------------
| rollout/                    |          |
|    ep_len_mean              | 938      |
|    ep_rew_mean              | 3.56e+03 |
| time/                       |          |
|    fps                      | 151      |
|    iterations               | 657      |
|    time_elapsed             | 8892     |
|    total_timesteps          | 1345536  |
| train/                      |          |
|    approx_kl                | 4.62461  |
|    clip_fraction            | 0.907    |
|    clip_range               | 0.2      |
|    ent_approx_kl            | 2.084638 |
|    ent_clip_fraction        | 0.773    |
|    ent_entropy_loss         | 7.28     |
|    ent_loss                 | 0.0372   |
|    ent_policy_gradient_loss | 0.0635   |
|    ent_std                  | 0.0979   |
|    ent_value_loss           | 0.0202   |
|    entropy_loss             | 6.18     |
|    explained_variance       | 0.308    |
|    learning_rate            | 0.0003   |
|    loss                     | 0.118    |
|    n_updates                | 6560     |
|    policy_gradient_loss     | 0.107    |
|    std                      | 0.112    |
|    value_loss               | 0.0193   |
------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 938       |
|    ep_rew_mean              | 3.57e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 658       |
|    time_elapsed             | 8902      |
|    total_timesteps          | 1347584   |
| train/                      |           |
|    approx_kl                | 3.8755884 |
|    clip_fraction            | 0.938     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.6530917 |
|    ent_clip_fraction        | 0.731     |
|    ent_entropy_loss         | 7.26      |
|    ent_loss                 | -0.0267   |
|    ent_policy_gradient_loss | 0.0141    |
|    ent_std                  | 0.0977    |
|    ent_value_loss           | 0.0282    |
|    entropy_loss             | 6.19      |
|    explained_variance       | 0.519     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.208     |
|    n_updates                | 6570      |
|    policy_gradient_loss     | 0.164     |
|    std                      | 0.112     |
|    value_loss               | 0.0279    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 938       |
|    ep_rew_mean              | 3.53e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 659       |
|    time_elapsed             | 8913      |
|    total_timesteps          | 1349632   |
| train/                      |           |
|    approx_kl                | 9.683485  |
|    clip_fraction            | 0.958     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.2378776 |
|    ent_clip_fraction        | 0.717     |
|    ent_entropy_loss         | 7.27      |
|    ent_loss                 | 0.00521   |
|    ent_policy_gradient_loss | 0.0578    |
|    ent_std                  | 0.0977    |
|    ent_value_loss           | 0.0316    |
|    entropy_loss             | 6.21      |
|    explained_variance       | 0.951     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.131     |
|    n_updates                | 6580      |
|    policy_gradient_loss     | 0.161     |
|    std                      | 0.111     |
|    value_loss               | 0.034     |
-------------------------------------------
Eval num_timesteps=1350000, episode_reward=3259.02 +/- 1644.49
Episode length: 832.28 +/- 326.50
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 832        |
|    mean_reward              | 3.26e+03   |
| time/                       |            |
|    total_timesteps          | 1350000    |
| train/                      |            |
|    approx_kl                | 13.216923  |
|    clip_fraction            | 0.987      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.42453387 |
|    ent_clip_fraction        | 0.666      |
|    ent_entropy_loss         | 7.27       |
|    ent_loss                 | -0.0154    |
|    ent_policy_gradient_loss | -0.0209    |
|    ent_std                  | 0.0977     |
|    ent_value_loss           | 0.0194     |
|    entropy_loss             | 6.28       |
|    explained_variance       | 0.978      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.172      |
|    n_updates                | 6590       |
|    policy_gradient_loss     | 0.164      |
|    std                      | 0.11       |
|    value_loss               | 0.0174     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 936      |
|    ep_rew_mean     | 3.52e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 660      |
|    time_elapsed    | 8941     |
|    total_timesteps | 1351680  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 913       |
|    ep_rew_mean              | 3.45e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 661       |
|    time_elapsed             | 8951      |
|    total_timesteps          | 1353728   |
| train/                      |           |
|    approx_kl                | 5.1151276 |
|    clip_fraction            | 0.959     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.2201221 |
|    ent_clip_fraction        | 0.677     |
|    ent_entropy_loss         | 7.29      |
|    ent_loss                 | -0.041    |
|    ent_policy_gradient_loss | 0.00549   |
|    ent_std                  | 0.0972    |
|    ent_value_loss           | 0.0179    |
|    entropy_loss             | 6.34      |
|    explained_variance       | 0.576     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.175     |
|    n_updates                | 6600      |
|    policy_gradient_loss     | 0.191     |
|    std                      | 0.109     |
|    value_loss               | 0.0175    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 907       |
|    ep_rew_mean              | 3.43e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 662       |
|    time_elapsed             | 8961      |
|    total_timesteps          | 1355776   |
| train/                      |           |
|    approx_kl                | 4.4818273 |
|    clip_fraction            | 0.954     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.6481102 |
|    ent_clip_fraction        | 0.694     |
|    ent_entropy_loss         | 7.34      |
|    ent_loss                 | -0.0412   |
|    ent_policy_gradient_loss | -0.00721  |
|    ent_std                  | 0.0966    |
|    ent_value_loss           | 0.0469    |
|    entropy_loss             | 6.33      |
|    explained_variance       | 0.169     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.201     |
|    n_updates                | 6610      |
|    policy_gradient_loss     | 0.181     |
|    std                      | 0.11      |
|    value_loss               | 0.0473    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 888       |
|    ep_rew_mean              | 3.35e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 663       |
|    time_elapsed             | 8972      |
|    total_timesteps          | 1357824   |
| train/                      |           |
|    approx_kl                | 4.4730506 |
|    clip_fraction            | 0.94      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.813503  |
|    ent_clip_fraction        | 0.728     |
|    ent_entropy_loss         | 7.36      |
|    ent_loss                 | 0.0593    |
|    ent_policy_gradient_loss | 0.0151    |
|    ent_std                  | 0.0967    |
|    ent_value_loss           | 0.0526    |
|    entropy_loss             | 6.26      |
|    explained_variance       | 0.524     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.079     |
|    n_updates                | 6620      |
|    policy_gradient_loss     | 0.176     |
|    std                      | 0.111     |
|    value_loss               | 0.0512    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 879       |
|    ep_rew_mean              | 3.31e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 664       |
|    time_elapsed             | 8982      |
|    total_timesteps          | 1359872   |
| train/                      |           |
|    approx_kl                | 4.915063  |
|    clip_fraction            | 0.945     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.4971414 |
|    ent_clip_fraction        | 0.74      |
|    ent_entropy_loss         | 7.34      |
|    ent_loss                 | -0.0269   |
|    ent_policy_gradient_loss | 0.0256    |
|    ent_std                  | 0.0969    |
|    ent_value_loss           | 0.0781    |
|    entropy_loss             | 6.25      |
|    explained_variance       | 0.436     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.187     |
|    n_updates                | 6630      |
|    policy_gradient_loss     | 0.215     |
|    std                      | 0.111     |
|    value_loss               | 0.077     |
-------------------------------------------
Eval num_timesteps=1360000, episode_reward=2967.84 +/- 1526.75
Episode length: 857.60 +/- 301.21
------------------------------------------
| eval/                       |          |
|    mean_ep_length           | 858      |
|    mean_reward              | 2.97e+03 |
| time/                       |          |
|    total_timesteps          | 1360000  |
| train/                      |          |
|    approx_kl                | 4.842634 |
|    clip_fraction            | 0.942    |
|    clip_range               | 0.2      |
|    ent_approx_kl            | 1.765096 |
|    ent_clip_fraction        | 0.735    |
|    ent_entropy_loss         | 7.35     |
|    ent_loss                 | -0.0403  |
|    ent_policy_gradient_loss | 0.0203   |
|    ent_std                  | 0.0968   |
|    ent_value_loss           | 0.0467   |
|    entropy_loss             | 6.24     |
|    explained_variance       | 0.522    |
|    learning_rate            | 0.0003   |
|    loss                     | 0.204    |
|    n_updates                | 6640     |
|    policy_gradient_loss     | 0.192    |
|    std                      | 0.111    |
|    value_loss               | 0.0473   |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 873      |
|    ep_rew_mean     | 3.28e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 665      |
|    time_elapsed    | 9010     |
|    total_timesteps | 1361920  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 870       |
|    ep_rew_mean              | 3.27e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 666       |
|    time_elapsed             | 9020      |
|    total_timesteps          | 1363968   |
| train/                      |           |
|    approx_kl                | 4.496936  |
|    clip_fraction            | 0.957     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.9585173 |
|    ent_clip_fraction        | 0.704     |
|    ent_entropy_loss         | 7.33      |
|    ent_loss                 | 0.0153    |
|    ent_policy_gradient_loss | 0.00863   |
|    ent_std                  | 0.0972    |
|    ent_value_loss           | 0.0319    |
|    entropy_loss             | 6.2       |
|    explained_variance       | 0.343     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.145     |
|    n_updates                | 6650      |
|    policy_gradient_loss     | 0.243     |
|    std                      | 0.112     |
|    value_loss               | 0.0319    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 870       |
|    ep_rew_mean              | 3.27e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 667       |
|    time_elapsed             | 9030      |
|    total_timesteps          | 1366016   |
| train/                      |           |
|    approx_kl                | 4.7556334 |
|    clip_fraction            | 0.963     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.068743  |
|    ent_clip_fraction        | 0.697     |
|    ent_entropy_loss         | 7.29      |
|    ent_loss                 | -0.027    |
|    ent_policy_gradient_loss | 0.00862   |
|    ent_std                  | 0.0977    |
|    ent_value_loss           | 0.0316    |
|    entropy_loss             | 6.13      |
|    explained_variance       | 0.242     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.222     |
|    n_updates                | 6660      |
|    policy_gradient_loss     | 0.183     |
|    std                      | 0.113     |
|    value_loss               | 0.0311    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 870       |
|    ep_rew_mean              | 3.27e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 668       |
|    time_elapsed             | 9040      |
|    total_timesteps          | 1368064   |
| train/                      |           |
|    approx_kl                | 4.7269006 |
|    clip_fraction            | 0.972     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.9614648 |
|    ent_clip_fraction        | 0.677     |
|    ent_entropy_loss         | 7.29      |
|    ent_loss                 | -0.0621   |
|    ent_policy_gradient_loss | -0.0264   |
|    ent_std                  | 0.0973    |
|    ent_value_loss           | 0.00526   |
|    entropy_loss             | 6.06      |
|    explained_variance       | 0.455     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.122     |
|    n_updates                | 6670      |
|    policy_gradient_loss     | 0.257     |
|    std                      | 0.114     |
|    value_loss               | 0.00495   |
-------------------------------------------
Eval num_timesteps=1370000, episode_reward=3674.32 +/- 1125.30
Episode length: 882.96 +/- 248.25
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 883       |
|    mean_reward              | 3.67e+03  |
| time/                       |           |
|    total_timesteps          | 1370000   |
| train/                      |           |
|    approx_kl                | 4.504657  |
|    clip_fraction            | 0.969     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.0262172 |
|    ent_clip_fraction        | 0.68      |
|    ent_entropy_loss         | 7.3       |
|    ent_loss                 | -0.0522   |
|    ent_policy_gradient_loss | -0.0241   |
|    ent_std                  | 0.0973    |
|    ent_value_loss           | 0.00731   |
|    entropy_loss             | 6.06      |
|    explained_variance       | 0.671     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.216     |
|    n_updates                | 6680      |
|    policy_gradient_loss     | 0.416     |
|    std                      | 0.113     |
|    value_loss               | 0.00709   |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 864      |
|    ep_rew_mean     | 3.26e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 669      |
|    time_elapsed    | 9067     |
|    total_timesteps | 1370112  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 864       |
|    ep_rew_mean              | 3.26e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 670       |
|    time_elapsed             | 9078      |
|    total_timesteps          | 1372160   |
| train/                      |           |
|    approx_kl                | 4.6624126 |
|    clip_fraction            | 0.963     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.1145003 |
|    ent_clip_fraction        | 0.685     |
|    ent_entropy_loss         | 7.3       |
|    ent_loss                 | -0.00178  |
|    ent_policy_gradient_loss | 6.71e-05  |
|    ent_std                  | 0.0973    |
|    ent_value_loss           | 0.025     |
|    entropy_loss             | 6.08      |
|    explained_variance       | 0.513     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.214     |
|    n_updates                | 6690      |
|    policy_gradient_loss     | 0.221     |
|    std                      | 0.113     |
|    value_loss               | 0.0259    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 864       |
|    ep_rew_mean              | 3.26e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 671       |
|    time_elapsed             | 9088      |
|    total_timesteps          | 1374208   |
| train/                      |           |
|    approx_kl                | 3.5452423 |
|    clip_fraction            | 0.903     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.836617  |
|    ent_clip_fraction        | 0.806     |
|    ent_entropy_loss         | 7.32      |
|    ent_loss                 | 0.00812   |
|    ent_policy_gradient_loss | 0.0731    |
|    ent_std                  | 0.0971    |
|    ent_value_loss           | 0.00745   |
|    entropy_loss             | 6.06      |
|    explained_variance       | 0.388     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.166     |
|    n_updates                | 6700      |
|    policy_gradient_loss     | 0.168     |
|    std                      | 0.114     |
|    value_loss               | 0.00783   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 864       |
|    ep_rew_mean              | 3.19e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 672       |
|    time_elapsed             | 9098      |
|    total_timesteps          | 1376256   |
| train/                      |           |
|    approx_kl                | 3.0927854 |
|    clip_fraction            | 0.853     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.9029074 |
|    ent_clip_fraction        | 0.839     |
|    ent_entropy_loss         | 7.31      |
|    ent_loss                 | 0.0983    |
|    ent_policy_gradient_loss | 0.129     |
|    ent_std                  | 0.0975    |
|    ent_value_loss           | 0.00577   |
|    entropy_loss             | 6.08      |
|    explained_variance       | 0.586     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0839    |
|    n_updates                | 6710      |
|    policy_gradient_loss     | 0.135     |
|    std                      | 0.113     |
|    value_loss               | 0.00557   |
-------------------------------------------
------------------------------------------
| rollout/                    |          |
|    ep_len_mean              | 854      |
|    ep_rew_mean              | 3.12e+03 |
| time/                       |          |
|    fps                      | 151      |
|    iterations               | 673      |
|    time_elapsed             | 9108     |
|    total_timesteps          | 1378304  |
| train/                      |          |
|    approx_kl                | 9.652745 |
|    clip_fraction            | 0.929    |
|    clip_range               | 0.2      |
|    ent_approx_kl            | 6.951832 |
|    ent_clip_fraction        | 0.694    |
|    ent_entropy_loss         | 7.32     |
|    ent_loss                 | 0.0443   |
|    ent_policy_gradient_loss | 0.0529   |
|    ent_std                  | 0.0969   |
|    ent_value_loss           | 0.0226   |
|    entropy_loss             | 6.07     |
|    explained_variance       | 0.952    |
|    learning_rate            | 0.0003   |
|    loss                     | 0.0949   |
|    n_updates                | 6720     |
|    policy_gradient_loss     | 0.119    |
|    std                      | 0.114    |
|    value_loss               | 0.0245   |
------------------------------------------
Eval num_timesteps=1380000, episode_reward=2593.28 +/- 1320.85
Episode length: 767.08 +/- 304.86
------------------------------------------
| eval/                       |          |
|    mean_ep_length           | 767      |
|    mean_reward              | 2.59e+03 |
| time/                       |          |
|    total_timesteps          | 1380000  |
| train/                      |          |
|    approx_kl                | 7.290527 |
|    clip_fraction            | 0.944    |
|    clip_range               | 0.2      |
|    ent_approx_kl            | 2.420853 |
|    ent_clip_fraction        | 0.706    |
|    ent_entropy_loss         | 7.35     |
|    ent_loss                 | 0.0722   |
|    ent_policy_gradient_loss | 0.0575   |
|    ent_std                  | 0.0969   |
|    ent_value_loss           | 0.0278   |
|    entropy_loss             | 6.05     |
|    explained_variance       | 0.967    |
|    learning_rate            | 0.0003   |
|    loss                     | 0.063    |
|    n_updates                | 6730     |
|    policy_gradient_loss     | 0.119    |
|    std                      | 0.114    |
|    value_loss               | 0.029    |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 829      |
|    ep_rew_mean     | 3.02e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 674      |
|    time_elapsed    | 9135     |
|    total_timesteps | 1380352  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 822       |
|    ep_rew_mean              | 2.95e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 675       |
|    time_elapsed             | 9145      |
|    total_timesteps          | 1382400   |
| train/                      |           |
|    approx_kl                | 4.1938124 |
|    clip_fraction            | 0.91      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.54807   |
|    ent_clip_fraction        | 0.782     |
|    ent_entropy_loss         | 7.37      |
|    ent_loss                 | 0.0224    |
|    ent_policy_gradient_loss | 0.0469    |
|    ent_std                  | 0.0964    |
|    ent_value_loss           | 0.0554    |
|    entropy_loss             | 6         |
|    explained_variance       | 0.322     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.178     |
|    n_updates                | 6740      |
|    policy_gradient_loss     | 0.175     |
|    std                      | 0.115     |
|    value_loss               | 0.0569    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 824       |
|    ep_rew_mean              | 2.95e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 676       |
|    time_elapsed             | 9155      |
|    total_timesteps          | 1384448   |
| train/                      |           |
|    approx_kl                | 7.7172594 |
|    clip_fraction            | 0.879     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 7.7019677 |
|    ent_clip_fraction        | 0.784     |
|    ent_entropy_loss         | 7.41      |
|    ent_loss                 | 0.0401    |
|    ent_policy_gradient_loss | 0.0368    |
|    ent_std                  | 0.0956    |
|    ent_value_loss           | 0.0281    |
|    entropy_loss             | 5.93      |
|    explained_variance       | 0.967     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.148     |
|    n_updates                | 6750      |
|    policy_gradient_loss     | 0.149     |
|    std                      | 0.116     |
|    value_loss               | 0.0276    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 820       |
|    ep_rew_mean              | 2.93e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 677       |
|    time_elapsed             | 9165      |
|    total_timesteps          | 1386496   |
| train/                      |           |
|    approx_kl                | 5.05747   |
|    clip_fraction            | 0.956     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.7627733 |
|    ent_clip_fraction        | 0.712     |
|    ent_entropy_loss         | 7.46      |
|    ent_loss                 | -0.045    |
|    ent_policy_gradient_loss | -0.0133   |
|    ent_std                  | 0.0951    |
|    ent_value_loss           | 0.00825   |
|    entropy_loss             | 5.9       |
|    explained_variance       | 0.415     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.144     |
|    n_updates                | 6760      |
|    policy_gradient_loss     | 0.237     |
|    std                      | 0.116     |
|    value_loss               | 0.0075    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 796       |
|    ep_rew_mean              | 2.84e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 678       |
|    time_elapsed             | 9176      |
|    total_timesteps          | 1388544   |
| train/                      |           |
|    approx_kl                | 5.0103464 |
|    clip_fraction            | 0.975     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.7121697 |
|    ent_clip_fraction        | 0.661     |
|    ent_entropy_loss         | 7.5       |
|    ent_loss                 | -0.0234   |
|    ent_policy_gradient_loss | -0.0199   |
|    ent_std                  | 0.0948    |
|    ent_value_loss           | 0.025     |
|    entropy_loss             | 5.96      |
|    explained_variance       | 0.374     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.152     |
|    n_updates                | 6770      |
|    policy_gradient_loss     | 0.213     |
|    std                      | 0.114     |
|    value_loss               | 0.022     |
-------------------------------------------
Eval num_timesteps=1390000, episode_reward=3512.53 +/- 1359.19
Episode length: 910.08 +/- 227.64
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 910       |
|    mean_reward              | 3.51e+03  |
| time/                       |           |
|    total_timesteps          | 1390000   |
| train/                      |           |
|    approx_kl                | 4.0212774 |
|    clip_fraction            | 0.934     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.5235772 |
|    ent_clip_fraction        | 0.736     |
|    ent_entropy_loss         | 7.51      |
|    ent_loss                 | 0.00258   |
|    ent_policy_gradient_loss | 0.0145    |
|    ent_std                  | 0.0947    |
|    ent_value_loss           | 0.0538    |
|    entropy_loss             | 6         |
|    explained_variance       | 0.595     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.144     |
|    n_updates                | 6780      |
|    policy_gradient_loss     | 0.189     |
|    std                      | 0.114     |
|    value_loss               | 0.0544    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 796      |
|    ep_rew_mean     | 2.84e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 679      |
|    time_elapsed    | 9204     |
|    total_timesteps | 1390592  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 791       |
|    ep_rew_mean              | 2.84e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 680       |
|    time_elapsed             | 9214      |
|    total_timesteps          | 1392640   |
| train/                      |           |
|    approx_kl                | 5.5161877 |
|    clip_fraction            | 0.982     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.5327835 |
|    ent_clip_fraction        | 0.665     |
|    ent_entropy_loss         | 7.53      |
|    ent_loss                 | -0.0738   |
|    ent_policy_gradient_loss | -0.0314   |
|    ent_std                  | 0.0945    |
|    ent_value_loss           | 0.0218    |
|    entropy_loss             | 5.98      |
|    explained_variance       | 0.457     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.183     |
|    n_updates                | 6790      |
|    policy_gradient_loss     | 0.24      |
|    std                      | 0.115     |
|    value_loss               | 0.0207    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 788       |
|    ep_rew_mean              | 2.83e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 681       |
|    time_elapsed             | 9225      |
|    total_timesteps          | 1394688   |
| train/                      |           |
|    approx_kl                | 4.6678085 |
|    clip_fraction            | 0.969     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.622681  |
|    ent_clip_fraction        | 0.686     |
|    ent_entropy_loss         | 7.54      |
|    ent_loss                 | 0.0365    |
|    ent_policy_gradient_loss | 0.00311   |
|    ent_std                  | 0.0944    |
|    ent_value_loss           | 0.0426    |
|    entropy_loss             | 6.01      |
|    explained_variance       | 0.466     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.182     |
|    n_updates                | 6800      |
|    policy_gradient_loss     | 0.276     |
|    std                      | 0.114     |
|    value_loss               | 0.0424    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 796       |
|    ep_rew_mean              | 2.86e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 682       |
|    time_elapsed             | 9235      |
|    total_timesteps          | 1396736   |
| train/                      |           |
|    approx_kl                | 4.5390053 |
|    clip_fraction            | 0.952     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.342761  |
|    ent_clip_fraction        | 0.721     |
|    ent_entropy_loss         | 7.56      |
|    ent_loss                 | 0.00179   |
|    ent_policy_gradient_loss | -0.00175  |
|    ent_std                  | 0.0943    |
|    ent_value_loss           | 0.0228    |
|    entropy_loss             | 6.09      |
|    explained_variance       | 0.531     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.168     |
|    n_updates                | 6810      |
|    policy_gradient_loss     | 0.194     |
|    std                      | 0.113     |
|    value_loss               | 0.0232    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 796       |
|    ep_rew_mean              | 2.86e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 683       |
|    time_elapsed             | 9245      |
|    total_timesteps          | 1398784   |
| train/                      |           |
|    approx_kl                | 4.25132   |
|    clip_fraction            | 0.958     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.7038791 |
|    ent_clip_fraction        | 0.708     |
|    ent_entropy_loss         | 7.57      |
|    ent_loss                 | -0.0522   |
|    ent_policy_gradient_loss | -0.0118   |
|    ent_std                  | 0.0941    |
|    ent_value_loss           | 0.00626   |
|    entropy_loss             | 6.1       |
|    explained_variance       | 0.351     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.216     |
|    n_updates                | 6820      |
|    policy_gradient_loss     | 0.211     |
|    std                      | 0.113     |
|    value_loss               | 0.00674   |
-------------------------------------------
Eval num_timesteps=1400000, episode_reward=2298.06 +/- 1547.89
Episode length: 722.00 +/- 361.28
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 722        |
|    mean_reward              | 2.3e+03    |
| time/                       |            |
|    total_timesteps          | 1400000    |
| train/                      |            |
|    approx_kl                | 4.8864813  |
|    clip_fraction            | 0.975      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.94670045 |
|    ent_clip_fraction        | 0.672      |
|    ent_entropy_loss         | 7.6        |
|    ent_loss                 | -0.0614    |
|    ent_policy_gradient_loss | -0.0424    |
|    ent_std                  | 0.0937     |
|    ent_value_loss           | 0.00577    |
|    entropy_loss             | 6.11       |
|    explained_variance       | 0.592      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.29       |
|    n_updates                | 6830       |
|    policy_gradient_loss     | 0.253      |
|    std                      | 0.113      |
|    value_loss               | 0.00561    |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 796      |
|    ep_rew_mean     | 2.91e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 684      |
|    time_elapsed    | 9272     |
|    total_timesteps | 1400832  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 781       |
|    ep_rew_mean              | 2.85e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 685       |
|    time_elapsed             | 9282      |
|    total_timesteps          | 1402880   |
| train/                      |           |
|    approx_kl                | 3.3642924 |
|    clip_fraction            | 0.899     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 4.0767155 |
|    ent_clip_fraction        | 0.807     |
|    ent_entropy_loss         | 7.62      |
|    ent_loss                 | 0.0455    |
|    ent_policy_gradient_loss | 0.0343    |
|    ent_std                  | 0.0935    |
|    ent_value_loss           | 0.00932   |
|    entropy_loss             | 6.14      |
|    explained_variance       | 0.677     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.12      |
|    n_updates                | 6840      |
|    policy_gradient_loss     | 0.215     |
|    std                      | 0.112     |
|    value_loss               | 0.00954   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 781       |
|    ep_rew_mean              | 2.84e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 686       |
|    time_elapsed             | 9292      |
|    total_timesteps          | 1404928   |
| train/                      |           |
|    approx_kl                | 5.019035  |
|    clip_fraction            | 0.967     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.2741113 |
|    ent_clip_fraction        | 0.692     |
|    ent_entropy_loss         | 7.67      |
|    ent_loss                 | 0.00416   |
|    ent_policy_gradient_loss | 0.0108    |
|    ent_std                  | 0.0926    |
|    ent_value_loss           | 0.042     |
|    entropy_loss             | 6.16      |
|    explained_variance       | 0.277     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.208     |
|    n_updates                | 6850      |
|    policy_gradient_loss     | 0.193     |
|    std                      | 0.112     |
|    value_loss               | 0.0406    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 764       |
|    ep_rew_mean              | 2.77e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 687       |
|    time_elapsed             | 9302      |
|    total_timesteps          | 1406976   |
| train/                      |           |
|    approx_kl                | 4.0312777 |
|    clip_fraction            | 0.931     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.4319122 |
|    ent_clip_fraction        | 0.768     |
|    ent_entropy_loss         | 7.71      |
|    ent_loss                 | -0.0134   |
|    ent_policy_gradient_loss | 0.0505    |
|    ent_std                  | 0.0923    |
|    ent_value_loss           | 0.0108    |
|    entropy_loss             | 6.16      |
|    explained_variance       | 0.567     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.252     |
|    n_updates                | 6860      |
|    policy_gradient_loss     | 0.193     |
|    std                      | 0.112     |
|    value_loss               | 0.0109    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 751        |
|    ep_rew_mean              | 2.71e+03   |
| time/                       |            |
|    fps                      | 151        |
|    iterations               | 688        |
|    time_elapsed             | 9313       |
|    total_timesteps          | 1409024    |
| train/                      |            |
|    approx_kl                | 5.4859486  |
|    clip_fraction            | 0.982      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.15250067 |
|    ent_clip_fraction        | 0.657      |
|    ent_entropy_loss         | 7.75       |
|    ent_loss                 | -0.0474    |
|    ent_policy_gradient_loss | -0.0239    |
|    ent_std                  | 0.0916     |
|    ent_value_loss           | 0.102      |
|    entropy_loss             | 6.18       |
|    explained_variance       | 0.48       |
|    learning_rate            | 0.0003     |
|    loss                     | 0.277      |
|    n_updates                | 6870       |
|    policy_gradient_loss     | 0.195      |
|    std                      | 0.111      |
|    value_loss               | 0.0997     |
--------------------------------------------
Eval num_timesteps=1410000, episode_reward=2425.29 +/- 1499.18
Episode length: 762.96 +/- 329.81
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 763       |
|    mean_reward              | 2.43e+03  |
| time/                       |           |
|    total_timesteps          | 1410000   |
| train/                      |           |
|    approx_kl                | 6.547452  |
|    clip_fraction            | 0.97      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.4220648 |
|    ent_clip_fraction        | 0.679     |
|    ent_entropy_loss         | 7.82      |
|    ent_loss                 | -0.0238   |
|    ent_policy_gradient_loss | 0.0222    |
|    ent_std                  | 0.0909    |
|    ent_value_loss           | 0.0512    |
|    entropy_loss             | 6.23      |
|    explained_variance       | 0.942     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.18      |
|    n_updates                | 6880      |
|    policy_gradient_loss     | 0.189     |
|    std                      | 0.111     |
|    value_loss               | 0.0524    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 753      |
|    ep_rew_mean     | 2.72e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 689      |
|    time_elapsed    | 9338     |
|    total_timesteps | 1411072  |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 756        |
|    ep_rew_mean              | 2.77e+03   |
| time/                       |            |
|    fps                      | 151        |
|    iterations               | 690        |
|    time_elapsed             | 9348       |
|    total_timesteps          | 1413120    |
| train/                      |            |
|    approx_kl                | 4.926265   |
|    clip_fraction            | 0.978      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.47741902 |
|    ent_clip_fraction        | 0.675      |
|    ent_entropy_loss         | 7.85       |
|    ent_loss                 | -0.0355    |
|    ent_policy_gradient_loss | -0.0177    |
|    ent_std                  | 0.0906     |
|    ent_value_loss           | 0.0347     |
|    entropy_loss             | 6.24       |
|    explained_variance       | 0.327      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.213      |
|    n_updates                | 6890       |
|    policy_gradient_loss     | 0.209      |
|    std                      | 0.111      |
|    value_loss               | 0.0348     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 756       |
|    ep_rew_mean              | 2.79e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 691       |
|    time_elapsed             | 9357      |
|    total_timesteps          | 1415168   |
| train/                      |           |
|    approx_kl                | 4.5884876 |
|    clip_fraction            | 0.973     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.7903807 |
|    ent_clip_fraction        | 0.689     |
|    ent_entropy_loss         | 7.91      |
|    ent_loss                 | -0.0411   |
|    ent_policy_gradient_loss | -0.0138   |
|    ent_std                  | 0.0901    |
|    ent_value_loss           | 0.0227    |
|    entropy_loss             | 6.26      |
|    explained_variance       | 0.576     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.148     |
|    n_updates                | 6900      |
|    policy_gradient_loss     | 0.212     |
|    std                      | 0.111     |
|    value_loss               | 0.0243    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 752       |
|    ep_rew_mean              | 2.78e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 692       |
|    time_elapsed             | 9367      |
|    total_timesteps          | 1417216   |
| train/                      |           |
|    approx_kl                | 3.7278967 |
|    clip_fraction            | 0.921     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.8073997 |
|    ent_clip_fraction        | 0.81      |
|    ent_entropy_loss         | 7.95      |
|    ent_loss                 | 0.00621   |
|    ent_policy_gradient_loss | 0.0655    |
|    ent_std                  | 0.0897    |
|    ent_value_loss           | 0.0133    |
|    entropy_loss             | 6.26      |
|    explained_variance       | 0.485     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.175     |
|    n_updates                | 6910      |
|    policy_gradient_loss     | 0.197     |
|    std                      | 0.111     |
|    value_loss               | 0.0149    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 750       |
|    ep_rew_mean              | 2.74e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 693       |
|    time_elapsed             | 9378      |
|    total_timesteps          | 1419264   |
| train/                      |           |
|    approx_kl                | 4.5233593 |
|    clip_fraction            | 0.953     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.487821  |
|    ent_clip_fraction        | 0.716     |
|    ent_entropy_loss         | 7.96      |
|    ent_loss                 | -0.0322   |
|    ent_policy_gradient_loss | 0.022     |
|    ent_std                  | 0.0894    |
|    ent_value_loss           | 0.0395    |
|    entropy_loss             | 6.25      |
|    explained_variance       | 0.435     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.15      |
|    n_updates                | 6920      |
|    policy_gradient_loss     | 0.153     |
|    std                      | 0.111     |
|    value_loss               | 0.0385    |
-------------------------------------------
Eval num_timesteps=1420000, episode_reward=4403.06 +/- 920.34
Episode length: 972.76 +/- 92.56
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 973       |
|    mean_reward              | 4.4e+03   |
| time/                       |           |
|    total_timesteps          | 1420000   |
| train/                      |           |
|    approx_kl                | 13.761539 |
|    clip_fraction            | 0.916     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.0365982 |
|    ent_clip_fraction        | 0.795     |
|    ent_entropy_loss         | 7.94      |
|    ent_loss                 | 0.0774    |
|    ent_policy_gradient_loss | 0.109     |
|    ent_std                  | 0.0902    |
|    ent_value_loss           | 0.0312    |
|    entropy_loss             | 6.29      |
|    explained_variance       | 0.957     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0859    |
|    n_updates                | 6930      |
|    policy_gradient_loss     | 0.0743    |
|    std                      | 0.11      |
|    value_loss               | 0.0373    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 750      |
|    ep_rew_mean     | 2.73e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 694      |
|    time_elapsed    | 9406     |
|    total_timesteps | 1421312  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 746       |
|    ep_rew_mean              | 2.76e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 695       |
|    time_elapsed             | 9416      |
|    total_timesteps          | 1423360   |
| train/                      |           |
|    approx_kl                | 5.1602273 |
|    clip_fraction            | 0.967     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.6815842 |
|    ent_clip_fraction        | 0.737     |
|    ent_entropy_loss         | 7.89      |
|    ent_loss                 | -0.0227   |
|    ent_policy_gradient_loss | 0.0263    |
|    ent_std                  | 0.0905    |
|    ent_value_loss           | 0.0143    |
|    entropy_loss             | 6.34      |
|    explained_variance       | -0.105    |
|    learning_rate            | 0.0003    |
|    loss                     | 0.174     |
|    n_updates                | 6940      |
|    policy_gradient_loss     | 0.244     |
|    std                      | 0.109     |
|    value_loss               | 0.014     |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 739        |
|    ep_rew_mean              | 2.75e+03   |
| time/                       |            |
|    fps                      | 151        |
|    iterations               | 696        |
|    time_elapsed             | 9426       |
|    total_timesteps          | 1425408    |
| train/                      |            |
|    approx_kl                | 4.9704638  |
|    clip_fraction            | 0.974      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.58366334 |
|    ent_clip_fraction        | 0.686      |
|    ent_entropy_loss         | 7.87       |
|    ent_loss                 | -0.0116    |
|    ent_policy_gradient_loss | -0.00824   |
|    ent_std                  | 0.0908     |
|    ent_value_loss           | 0.0243     |
|    entropy_loss             | 6.34       |
|    explained_variance       | 0.55       |
|    learning_rate            | 0.0003     |
|    loss                     | 0.2        |
|    n_updates                | 6950       |
|    policy_gradient_loss     | 0.205      |
|    std                      | 0.11       |
|    value_loss               | 0.0236     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 739       |
|    ep_rew_mean              | 2.73e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 697       |
|    time_elapsed             | 9436      |
|    total_timesteps          | 1427456   |
| train/                      |           |
|    approx_kl                | 4.234394  |
|    clip_fraction            | 0.94      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.5695348 |
|    ent_clip_fraction        | 0.755     |
|    ent_entropy_loss         | 7.86      |
|    ent_loss                 | -0.00685  |
|    ent_policy_gradient_loss | 0.00842   |
|    ent_std                  | 0.0908    |
|    ent_value_loss           | 0.0376    |
|    entropy_loss             | 6.27      |
|    explained_variance       | 0.596     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.12      |
|    n_updates                | 6960      |
|    policy_gradient_loss     | 0.157     |
|    std                      | 0.111     |
|    value_loss               | 0.0404    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 753       |
|    ep_rew_mean              | 2.79e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 698       |
|    time_elapsed             | 9447      |
|    total_timesteps          | 1429504   |
| train/                      |           |
|    approx_kl                | 12.699215 |
|    clip_fraction            | 0.967     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.1253624 |
|    ent_clip_fraction        | 0.684     |
|    ent_entropy_loss         | 7.87      |
|    ent_loss                 | 0.00417   |
|    ent_policy_gradient_loss | 0.015     |
|    ent_std                  | 0.0906    |
|    ent_value_loss           | 0.0295    |
|    entropy_loss             | 6.27      |
|    explained_variance       | 0.968     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.147     |
|    n_updates                | 6970      |
|    policy_gradient_loss     | 0.164     |
|    std                      | 0.11      |
|    value_loss               | 0.029     |
-------------------------------------------
Eval num_timesteps=1430000, episode_reward=3872.74 +/- 1197.20
Episode length: 922.92 +/- 216.66
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 923       |
|    mean_reward              | 3.87e+03  |
| time/                       |           |
|    total_timesteps          | 1430000   |
| train/                      |           |
|    approx_kl                | 4.5195637 |
|    clip_fraction            | 0.964     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.4936165 |
|    ent_clip_fraction        | 0.724     |
|    ent_entropy_loss         | 7.9       |
|    ent_loss                 | 0.0399    |
|    ent_policy_gradient_loss | 0.012     |
|    ent_std                  | 0.0902    |
|    ent_value_loss           | 0.00921   |
|    entropy_loss             | 6.28      |
|    explained_variance       | 0.252     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.19      |
|    n_updates                | 6980      |
|    policy_gradient_loss     | 0.222     |
|    std                      | 0.11      |
|    value_loss               | 0.009     |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 756      |
|    ep_rew_mean     | 2.8e+03  |
| time/              |          |
|    fps             | 151      |
|    iterations      | 699      |
|    time_elapsed    | 9474     |
|    total_timesteps | 1431552  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 769       |
|    ep_rew_mean              | 2.86e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 700       |
|    time_elapsed             | 9485      |
|    total_timesteps          | 1433600   |
| train/                      |           |
|    approx_kl                | 3.7124448 |
|    clip_fraction            | 0.896     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.4708693 |
|    ent_clip_fraction        | 0.825     |
|    ent_entropy_loss         | 7.88      |
|    ent_loss                 | 0.0451    |
|    ent_policy_gradient_loss | 0.144     |
|    ent_std                  | 0.0909    |
|    ent_value_loss           | 0.00944   |
|    entropy_loss             | 6.28      |
|    explained_variance       | 0.524     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.162     |
|    n_updates                | 6990      |
|    policy_gradient_loss     | 0.156     |
|    std                      | 0.11      |
|    value_loss               | 0.00969   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 784       |
|    ep_rew_mean              | 2.92e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 701       |
|    time_elapsed             | 9495      |
|    total_timesteps          | 1435648   |
| train/                      |           |
|    approx_kl                | 2.8847768 |
|    clip_fraction            | 0.846     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 5.2715893 |
|    ent_clip_fraction        | 0.866     |
|    ent_entropy_loss         | 7.83      |
|    ent_loss                 | 0.0777    |
|    ent_policy_gradient_loss | 0.115     |
|    ent_std                  | 0.0913    |
|    ent_value_loss           | 0.00878   |
|    entropy_loss             | 6.26      |
|    explained_variance       | 0.608     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.151     |
|    n_updates                | 7000      |
|    policy_gradient_loss     | 0.148     |
|    std                      | 0.111     |
|    value_loss               | 0.0095    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 788       |
|    ep_rew_mean              | 2.94e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 702       |
|    time_elapsed             | 9505      |
|    total_timesteps          | 1437696   |
| train/                      |           |
|    approx_kl                | 5.6194324 |
|    clip_fraction            | 0.978     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.7415118 |
|    ent_clip_fraction        | 0.678     |
|    ent_entropy_loss         | 7.81      |
|    ent_loss                 | -0.0646   |
|    ent_policy_gradient_loss | -0.0123   |
|    ent_std                  | 0.0914    |
|    ent_value_loss           | 0.0173    |
|    entropy_loss             | 6.23      |
|    explained_variance       | 0.35      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.203     |
|    n_updates                | 7010      |
|    policy_gradient_loss     | 0.306     |
|    std                      | 0.111     |
|    value_loss               | 0.0171    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 794       |
|    ep_rew_mean              | 2.97e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 703       |
|    time_elapsed             | 9515      |
|    total_timesteps          | 1439744   |
| train/                      |           |
|    approx_kl                | 4.443102  |
|    clip_fraction            | 0.969     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.2126997 |
|    ent_clip_fraction        | 0.682     |
|    ent_entropy_loss         | 7.81      |
|    ent_loss                 | -0.0601   |
|    ent_policy_gradient_loss | -0.0174   |
|    ent_std                  | 0.0913    |
|    ent_value_loss           | 0.0063    |
|    entropy_loss             | 6.27      |
|    explained_variance       | 0.599     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.275     |
|    n_updates                | 7020      |
|    policy_gradient_loss     | 0.253     |
|    std                      | 0.11      |
|    value_loss               | 0.0061    |
-------------------------------------------
Eval num_timesteps=1440000, episode_reward=4199.85 +/- 896.74
Episode length: 1000.00 +/- 0.00
------------------------------------------
| eval/                       |          |
|    mean_ep_length           | 1e+03    |
|    mean_reward              | 4.2e+03  |
| time/                       |          |
|    total_timesteps          | 1440000  |
| train/                      |          |
|    approx_kl                | 3.615193 |
|    clip_fraction            | 0.925    |
|    clip_range               | 0.2      |
|    ent_approx_kl            | 3.767716 |
|    ent_clip_fraction        | 0.784    |
|    ent_entropy_loss         | 7.82     |
|    ent_loss                 | -0.0715  |
|    ent_policy_gradient_loss | 0.0232   |
|    ent_std                  | 0.0913   |
|    ent_value_loss           | 0.00852  |
|    entropy_loss             | 6.24     |
|    explained_variance       | 0.612    |
|    learning_rate            | 0.0003   |
|    loss                     | 0.236    |
|    n_updates                | 7030     |
|    policy_gradient_loss     | 0.222    |
|    std                      | 0.111    |
|    value_loss               | 0.00839  |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 800      |
|    ep_rew_mean     | 3e+03    |
| time/              |          |
|    fps             | 151      |
|    iterations      | 704      |
|    time_elapsed    | 9543     |
|    total_timesteps | 1441792  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 796       |
|    ep_rew_mean              | 2.98e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 705       |
|    time_elapsed             | 9553      |
|    total_timesteps          | 1443840   |
| train/                      |           |
|    approx_kl                | 3.4931164 |
|    clip_fraction            | 0.918     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.2602308 |
|    ent_clip_fraction        | 0.78      |
|    ent_entropy_loss         | 7.82      |
|    ent_loss                 | -0.0246   |
|    ent_policy_gradient_loss | 0.0616    |
|    ent_std                  | 0.0913    |
|    ent_value_loss           | 0.00717   |
|    entropy_loss             | 6.17      |
|    explained_variance       | 0.526     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.221     |
|    n_updates                | 7040      |
|    policy_gradient_loss     | 0.216     |
|    std                      | 0.112     |
|    value_loss               | 0.00721   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 792       |
|    ep_rew_mean              | 2.97e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 706       |
|    time_elapsed             | 9563      |
|    total_timesteps          | 1445888   |
| train/                      |           |
|    approx_kl                | 2.9782567 |
|    clip_fraction            | 0.88      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 4.460196  |
|    ent_clip_fraction        | 0.807     |
|    ent_entropy_loss         | 7.84      |
|    ent_loss                 | 0.0558    |
|    ent_policy_gradient_loss | 0.0472    |
|    ent_std                  | 0.0909    |
|    ent_value_loss           | 0.0261    |
|    entropy_loss             | 6.14      |
|    explained_variance       | 0.449     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.135     |
|    n_updates                | 7050      |
|    policy_gradient_loss     | 0.163     |
|    std                      | 0.113     |
|    value_loss               | 0.0286    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 795       |
|    ep_rew_mean              | 2.95e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 707       |
|    time_elapsed             | 9574      |
|    total_timesteps          | 1447936   |
| train/                      |           |
|    approx_kl                | 8.229624  |
|    clip_fraction            | 0.977     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.9023769 |
|    ent_clip_fraction        | 0.686     |
|    ent_entropy_loss         | 7.89      |
|    ent_loss                 | -0.0419   |
|    ent_policy_gradient_loss | -0.00599  |
|    ent_std                  | 0.0902    |
|    ent_value_loss           | 0.039     |
|    entropy_loss             | 6.14      |
|    explained_variance       | 0.954     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.154     |
|    n_updates                | 7060      |
|    policy_gradient_loss     | 0.174     |
|    std                      | 0.112     |
|    value_loss               | 0.0386    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 795       |
|    ep_rew_mean              | 2.96e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 708       |
|    time_elapsed             | 9584      |
|    total_timesteps          | 1449984   |
| train/                      |           |
|    approx_kl                | 3.8010283 |
|    clip_fraction            | 0.885     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.6432967 |
|    ent_clip_fraction        | 0.835     |
|    ent_entropy_loss         | 7.89      |
|    ent_loss                 | 0.0908    |
|    ent_policy_gradient_loss | 0.118     |
|    ent_std                  | 0.0907    |
|    ent_value_loss           | 0.027     |
|    entropy_loss             | 6.13      |
|    explained_variance       | 0.853     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0946    |
|    n_updates                | 7070      |
|    policy_gradient_loss     | 0.0985    |
|    std                      | 0.113     |
|    value_loss               | 0.0277    |
-------------------------------------------
Eval num_timesteps=1450000, episode_reward=3783.25 +/- 1481.11
Episode length: 827.56 +/- 316.27
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 828       |
|    mean_reward              | 3.78e+03  |
| time/                       |           |
|    total_timesteps          | 1450000   |
| train/                      |           |
|    approx_kl                | 3.8289387 |
|    clip_fraction            | 0.943     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.2234797 |
|    ent_clip_fraction        | 0.744     |
|    ent_entropy_loss         | 7.84      |
|    ent_loss                 | 0.0025    |
|    ent_policy_gradient_loss | 0.0483    |
|    ent_std                  | 0.0912    |
|    ent_value_loss           | 0.00689   |
|    entropy_loss             | 6.13      |
|    explained_variance       | 0.404     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.212     |
|    n_updates                | 7080      |
|    policy_gradient_loss     | 0.189     |
|    std                      | 0.112     |
|    value_loss               | 0.00686   |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 795      |
|    ep_rew_mean     | 2.95e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 709      |
|    time_elapsed    | 9612     |
|    total_timesteps | 1452032  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 795       |
|    ep_rew_mean              | 2.95e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 710       |
|    time_elapsed             | 9622      |
|    total_timesteps          | 1454080   |
| train/                      |           |
|    approx_kl                | 4.5299644 |
|    clip_fraction            | 0.885     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.1152124 |
|    ent_clip_fraction        | 0.802     |
|    ent_entropy_loss         | 7.82      |
|    ent_loss                 | 0.0198    |
|    ent_policy_gradient_loss | 0.0362    |
|    ent_std                  | 0.0912    |
|    ent_value_loss           | 0.023     |
|    entropy_loss             | 6.17      |
|    explained_variance       | 0.792     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.128     |
|    n_updates                | 7090      |
|    policy_gradient_loss     | 0.151     |
|    std                      | 0.112     |
|    value_loss               | 0.0237    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 795       |
|    ep_rew_mean              | 2.99e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 711       |
|    time_elapsed             | 9632      |
|    total_timesteps          | 1456128   |
| train/                      |           |
|    approx_kl                | 5.7949085 |
|    clip_fraction            | 0.943     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.681849  |
|    ent_clip_fraction        | 0.753     |
|    ent_entropy_loss         | 7.84      |
|    ent_loss                 | 0.0417    |
|    ent_policy_gradient_loss | 0.0189    |
|    ent_std                  | 0.0909    |
|    ent_value_loss           | 0.0268    |
|    entropy_loss             | 6.19      |
|    explained_variance       | 0.873     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.12      |
|    n_updates                | 7100      |
|    policy_gradient_loss     | 0.154     |
|    std                      | 0.112     |
|    value_loss               | 0.027     |
-------------------------------------------
------------------------------------------
| rollout/                    |          |
|    ep_len_mean              | 805      |
|    ep_rew_mean              | 3.04e+03 |
| time/                       |          |
|    fps                      | 151      |
|    iterations               | 712      |
|    time_elapsed             | 9642     |
|    total_timesteps          | 1458176  |
| train/                      |          |
|    approx_kl                | 8.365005 |
|    clip_fraction            | 0.948    |
|    clip_range               | 0.2      |
|    ent_approx_kl            | 5.131365 |
|    ent_clip_fraction        | 0.826    |
|    ent_entropy_loss         | 7.86     |
|    ent_loss                 | -0.0449  |
|    ent_policy_gradient_loss | 0.0389   |
|    ent_std                  | 0.0906   |
|    ent_value_loss           | 0.00515  |
|    entropy_loss             | 6.21     |
|    explained_variance       | 0.991    |
|    learning_rate            | 0.0003   |
|    loss                     | 0.197    |
|    n_updates                | 7110     |
|    policy_gradient_loss     | 0.244    |
|    std                      | 0.111    |
|    value_loss               | 0.00554  |
------------------------------------------
Eval num_timesteps=1460000, episode_reward=3916.73 +/- 1448.08
Episode length: 950.04 +/- 179.12
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 950       |
|    mean_reward              | 3.92e+03  |
| time/                       |           |
|    total_timesteps          | 1460000   |
| train/                      |           |
|    approx_kl                | 3.904469  |
|    clip_fraction            | 0.907     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.4968777 |
|    ent_clip_fraction        | 0.798     |
|    ent_entropy_loss         | 7.87      |
|    ent_loss                 | -0.000768 |
|    ent_policy_gradient_loss | 0.0869    |
|    ent_std                  | 0.0908    |
|    ent_value_loss           | 0.0109    |
|    entropy_loss             | 6.25      |
|    explained_variance       | 0.57      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.177     |
|    n_updates                | 7120      |
|    policy_gradient_loss     | 0.153     |
|    std                      | 0.111     |
|    value_loss               | 0.0107    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 805      |
|    ep_rew_mean     | 3.08e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 713      |
|    time_elapsed    | 9669     |
|    total_timesteps | 1460224  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 822       |
|    ep_rew_mean              | 3.12e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 714       |
|    time_elapsed             | 9679      |
|    total_timesteps          | 1462272   |
| train/                      |           |
|    approx_kl                | 7.6032114 |
|    clip_fraction            | 0.968     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.6809299 |
|    ent_clip_fraction        | 0.725     |
|    ent_entropy_loss         | 7.87      |
|    ent_loss                 | -0.037    |
|    ent_policy_gradient_loss | 0.00474   |
|    ent_std                  | 0.0903    |
|    ent_value_loss           | 0.0156    |
|    entropy_loss             | 6.27      |
|    explained_variance       | 0.961     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.205     |
|    n_updates                | 7130      |
|    policy_gradient_loss     | 0.229     |
|    std                      | 0.111     |
|    value_loss               | 0.0149    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 830       |
|    ep_rew_mean              | 3.12e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 715       |
|    time_elapsed             | 9689      |
|    total_timesteps          | 1464320   |
| train/                      |           |
|    approx_kl                | 10.234499 |
|    clip_fraction            | 0.915     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 17.977913 |
|    ent_clip_fraction        | 0.772     |
|    ent_entropy_loss         | 7.9       |
|    ent_loss                 | -0.0279   |
|    ent_policy_gradient_loss | -0.0149   |
|    ent_std                  | 0.0901    |
|    ent_value_loss           | 0.0148    |
|    entropy_loss             | 6.24      |
|    explained_variance       | 0.986     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.088     |
|    n_updates                | 7140      |
|    policy_gradient_loss     | 0.194     |
|    std                      | 0.111     |
|    value_loss               | 0.0145    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 838       |
|    ep_rew_mean              | 3.19e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 716       |
|    time_elapsed             | 9699      |
|    total_timesteps          | 1466368   |
| train/                      |           |
|    approx_kl                | 10.545781 |
|    clip_fraction            | 0.945     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.7395687 |
|    ent_clip_fraction        | 0.777     |
|    ent_entropy_loss         | 7.89      |
|    ent_loss                 | -0.00956  |
|    ent_policy_gradient_loss | 0.0523    |
|    ent_std                  | 0.0906    |
|    ent_value_loss           | 0.00908   |
|    entropy_loss             | 6.21      |
|    explained_variance       | 0.981     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.209     |
|    n_updates                | 7150      |
|    policy_gradient_loss     | 0.189     |
|    std                      | 0.111     |
|    value_loss               | 0.00884   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 838       |
|    ep_rew_mean              | 3.19e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 717       |
|    time_elapsed             | 9709      |
|    total_timesteps          | 1468416   |
| train/                      |           |
|    approx_kl                | 5.7145557 |
|    clip_fraction            | 0.956     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.8577664 |
|    ent_clip_fraction        | 0.755     |
|    ent_entropy_loss         | 7.86      |
|    ent_loss                 | -0.0201   |
|    ent_policy_gradient_loss | 0.0197    |
|    ent_std                  | 0.0908    |
|    ent_value_loss           | 0.0192    |
|    entropy_loss             | 6.23      |
|    explained_variance       | 0.38      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.235     |
|    n_updates                | 7160      |
|    policy_gradient_loss     | 0.183     |
|    std                      | 0.111     |
|    value_loss               | 0.0185    |
-------------------------------------------
Eval num_timesteps=1470000, episode_reward=3892.85 +/- 787.55
Episode length: 977.04 +/- 112.48
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 977       |
|    mean_reward              | 3.89e+03  |
| time/                       |           |
|    total_timesteps          | 1470000   |
| train/                      |           |
|    approx_kl                | 4.9993167 |
|    clip_fraction            | 0.916     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 4.195779  |
|    ent_clip_fraction        | 0.821     |
|    ent_entropy_loss         | 7.84      |
|    ent_loss                 | 0.0721    |
|    ent_policy_gradient_loss | 0.135     |
|    ent_std                  | 0.0908    |
|    ent_value_loss           | 0.00961   |
|    entropy_loss             | 6.26      |
|    explained_variance       | 0.595     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.157     |
|    n_updates                | 7170      |
|    policy_gradient_loss     | 0.21      |
|    std                      | 0.111     |
|    value_loss               | 0.00976   |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 841      |
|    ep_rew_mean     | 3.21e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 718      |
|    time_elapsed    | 9736     |
|    total_timesteps | 1470464  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 850       |
|    ep_rew_mean              | 3.26e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 719       |
|    time_elapsed             | 9746      |
|    total_timesteps          | 1472512   |
| train/                      |           |
|    approx_kl                | 4.8805914 |
|    clip_fraction            | 0.954     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.0476303 |
|    ent_clip_fraction        | 0.752     |
|    ent_entropy_loss         | 7.86      |
|    ent_loss                 | 0.0954    |
|    ent_policy_gradient_loss | 0.0328    |
|    ent_std                  | 0.0906    |
|    ent_value_loss           | 0.00565   |
|    entropy_loss             | 6.24      |
|    explained_variance       | 0.491     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.16      |
|    n_updates                | 7180      |
|    policy_gradient_loss     | 0.221     |
|    std                      | 0.111     |
|    value_loss               | 0.00579   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 858       |
|    ep_rew_mean              | 3.28e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 720       |
|    time_elapsed             | 9756      |
|    total_timesteps          | 1474560   |
| train/                      |           |
|    approx_kl                | 7.8413615 |
|    clip_fraction            | 0.937     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.1446118 |
|    ent_clip_fraction        | 0.761     |
|    ent_entropy_loss         | 7.87      |
|    ent_loss                 | 0.0185    |
|    ent_policy_gradient_loss | 0.037     |
|    ent_std                  | 0.0903    |
|    ent_value_loss           | 0.0115    |
|    entropy_loss             | 6.26      |
|    explained_variance       | 0.948     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.151     |
|    n_updates                | 7190      |
|    policy_gradient_loss     | 0.175     |
|    std                      | 0.11      |
|    value_loss               | 0.0106    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 866       |
|    ep_rew_mean              | 3.28e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 721       |
|    time_elapsed             | 9766      |
|    total_timesteps          | 1476608   |
| train/                      |           |
|    approx_kl                | 4.937663  |
|    clip_fraction            | 0.824     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 6.7848196 |
|    ent_clip_fraction        | 0.893     |
|    ent_entropy_loss         | 7.89      |
|    ent_loss                 | 0.103     |
|    ent_policy_gradient_loss | 0.139     |
|    ent_std                  | 0.0905    |
|    ent_value_loss           | 0.00607   |
|    entropy_loss             | 6.29      |
|    explained_variance       | 0.955     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.102     |
|    n_updates                | 7200      |
|    policy_gradient_loss     | 0.121     |
|    std                      | 0.111     |
|    value_loss               | 0.00659   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 868       |
|    ep_rew_mean              | 3.3e+03   |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 722       |
|    time_elapsed             | 9775      |
|    total_timesteps          | 1478656   |
| train/                      |           |
|    approx_kl                | 9.305472  |
|    clip_fraction            | 0.919     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.1055565 |
|    ent_clip_fraction        | 0.764     |
|    ent_entropy_loss         | 7.86      |
|    ent_loss                 | 0.109     |
|    ent_policy_gradient_loss | 0.0961    |
|    ent_std                  | 0.091     |
|    ent_value_loss           | 0.0141    |
|    entropy_loss             | 6.3       |
|    explained_variance       | 0.987     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.117     |
|    n_updates                | 7210      |
|    policy_gradient_loss     | 0.105     |
|    std                      | 0.11      |
|    value_loss               | 0.0143    |
-------------------------------------------
Eval num_timesteps=1480000, episode_reward=4002.36 +/- 1069.17
Episode length: 968.40 +/- 154.81
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 968       |
|    mean_reward              | 4e+03     |
| time/                       |           |
|    total_timesteps          | 1480000   |
| train/                      |           |
|    approx_kl                | 5.4831095 |
|    clip_fraction            | 0.981     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.8459141 |
|    ent_clip_fraction        | 0.665     |
|    ent_entropy_loss         | 7.85      |
|    ent_loss                 | -0.0727   |
|    ent_policy_gradient_loss | -0.0337   |
|    ent_std                  | 0.0905    |
|    ent_value_loss           | 0.00584   |
|    entropy_loss             | 6.31      |
|    explained_variance       | 0.642     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.251     |
|    n_updates                | 7220      |
|    policy_gradient_loss     | 0.253     |
|    std                      | 0.11      |
|    value_loss               | 0.00566   |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 874      |
|    ep_rew_mean     | 3.32e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 723      |
|    time_elapsed    | 9803     |
|    total_timesteps | 1480704  |
---------------------------------
------------------------------------------
| rollout/                    |          |
|    ep_len_mean              | 869      |
|    ep_rew_mean              | 3.3e+03  |
| time/                       |          |
|    fps                      | 151      |
|    iterations               | 724      |
|    time_elapsed             | 9813     |
|    total_timesteps          | 1482752  |
| train/                      |          |
|    approx_kl                | 6.996097 |
|    clip_fraction            | 0.899    |
|    clip_range               | 0.2      |
|    ent_approx_kl            | 3.694424 |
|    ent_clip_fraction        | 0.812    |
|    ent_entropy_loss         | 7.84     |
|    ent_loss                 | 0.0986   |
|    ent_policy_gradient_loss | 0.0871   |
|    ent_std                  | 0.0911   |
|    ent_value_loss           | 0.0165   |
|    entropy_loss             | 6.37     |
|    explained_variance       | 0.964    |
|    learning_rate            | 0.0003   |
|    loss                     | 0.181    |
|    n_updates                | 7230     |
|    policy_gradient_loss     | 0.123    |
|    std                      | 0.109    |
|    value_loss               | 0.0164   |
------------------------------------------
------------------------------------------
| rollout/                    |          |
|    ep_len_mean              | 868      |
|    ep_rew_mean              | 3.28e+03 |
| time/                       |          |
|    fps                      | 151      |
|    iterations               | 725      |
|    time_elapsed             | 9823     |
|    total_timesteps          | 1484800  |
| train/                      |          |
|    approx_kl                | 4.630726 |
|    clip_fraction            | 0.895    |
|    clip_range               | 0.2      |
|    ent_approx_kl            | 2.86238  |
|    ent_clip_fraction        | 0.815    |
|    ent_entropy_loss         | 7.79     |
|    ent_loss                 | 0.0952   |
|    ent_policy_gradient_loss | 0.113    |
|    ent_std                  | 0.0918   |
|    ent_value_loss           | 0.0253   |
|    entropy_loss             | 6.42     |
|    explained_variance       | 0.429    |
|    learning_rate            | 0.0003   |
|    loss                     | 0.228    |
|    n_updates                | 7240     |
|    policy_gradient_loss     | 0.154    |
|    std                      | 0.108    |
|    value_loss               | 0.0249   |
------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 868       |
|    ep_rew_mean              | 3.24e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 726       |
|    time_elapsed             | 9834      |
|    total_timesteps          | 1486848   |
| train/                      |           |
|    approx_kl                | 14.742823 |
|    clip_fraction            | 0.963     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.2829423 |
|    ent_clip_fraction        | 0.672     |
|    ent_entropy_loss         | 7.78      |
|    ent_loss                 | 0.01      |
|    ent_policy_gradient_loss | 0.0156    |
|    ent_std                  | 0.0914    |
|    ent_value_loss           | 0.0379    |
|    entropy_loss             | 6.46      |
|    explained_variance       | 0.955     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.12      |
|    n_updates                | 7250      |
|    policy_gradient_loss     | 0.147     |
|    std                      | 0.107     |
|    value_loss               | 0.038     |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 868       |
|    ep_rew_mean              | 3.23e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 727       |
|    time_elapsed             | 9844      |
|    total_timesteps          | 1488896   |
| train/                      |           |
|    approx_kl                | 10.070623 |
|    clip_fraction            | 0.972     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.3638206 |
|    ent_clip_fraction        | 0.709     |
|    ent_entropy_loss         | 7.81      |
|    ent_loss                 | -0.0741   |
|    ent_policy_gradient_loss | 0.00716   |
|    ent_std                  | 0.091     |
|    ent_value_loss           | 0.0313    |
|    entropy_loss             | 6.52      |
|    explained_variance       | 0.944     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.228     |
|    n_updates                | 7260      |
|    policy_gradient_loss     | 0.184     |
|    std                      | 0.107     |
|    value_loss               | 0.0309    |
-------------------------------------------
Eval num_timesteps=1490000, episode_reward=3815.28 +/- 1153.12
Episode length: 962.56 +/- 183.42
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 963       |
|    mean_reward              | 3.82e+03  |
| time/                       |           |
|    total_timesteps          | 1490000   |
| train/                      |           |
|    approx_kl                | 6.8739944 |
|    clip_fraction            | 0.97      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.6200852 |
|    ent_clip_fraction        | 0.71      |
|    ent_entropy_loss         | 7.85      |
|    ent_loss                 | -0.0572   |
|    ent_policy_gradient_loss | 0.00672   |
|    ent_std                  | 0.0906    |
|    ent_value_loss           | 0.0315    |
|    entropy_loss             | 6.54      |
|    explained_variance       | 0.895     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.199     |
|    n_updates                | 7270      |
|    policy_gradient_loss     | 0.237     |
|    std                      | 0.107     |
|    value_loss               | 0.0309    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 876      |
|    ep_rew_mean     | 3.27e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 728      |
|    time_elapsed    | 9871     |
|    total_timesteps | 1490944  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 874       |
|    ep_rew_mean              | 3.24e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 729       |
|    time_elapsed             | 9881      |
|    total_timesteps          | 1492992   |
| train/                      |           |
|    approx_kl                | 2.9932814 |
|    clip_fraction            | 0.817     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 5.890008  |
|    ent_clip_fraction        | 0.905     |
|    ent_entropy_loss         | 7.87      |
|    ent_loss                 | 0.105     |
|    ent_policy_gradient_loss | 0.157     |
|    ent_std                  | 0.0906    |
|    ent_value_loss           | 0.00753   |
|    entropy_loss             | 6.54      |
|    explained_variance       | 0.532     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.153     |
|    n_updates                | 7280      |
|    policy_gradient_loss     | 0.139     |
|    std                      | 0.107     |
|    value_loss               | 0.00857   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 879       |
|    ep_rew_mean              | 3.23e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 730       |
|    time_elapsed             | 9891      |
|    total_timesteps          | 1495040   |
| train/                      |           |
|    approx_kl                | 4.9130344 |
|    clip_fraction            | 0.974     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.5462024 |
|    ent_clip_fraction        | 0.619     |
|    ent_entropy_loss         | 7.87      |
|    ent_loss                 | -0.0499   |
|    ent_policy_gradient_loss | -0.0256   |
|    ent_std                  | 0.0902    |
|    ent_value_loss           | 0.0425    |
|    entropy_loss             | 6.51      |
|    explained_variance       | 0.939     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.157     |
|    n_updates                | 7290      |
|    policy_gradient_loss     | 0.166     |
|    std                      | 0.107     |
|    value_loss               | 0.0375    |
-------------------------------------------
------------------------------------------
| rollout/                    |          |
|    ep_len_mean              | 888      |
|    ep_rew_mean              | 3.27e+03 |
| time/                       |          |
|    fps                      | 151      |
|    iterations               | 731      |
|    time_elapsed             | 9901     |
|    total_timesteps          | 1497088  |
| train/                      |          |
|    approx_kl                | 8.4046   |
|    clip_fraction            | 0.971    |
|    clip_range               | 0.2      |
|    ent_approx_kl            | 4.140504 |
|    ent_clip_fraction        | 0.738    |
|    ent_entropy_loss         | 7.89     |
|    ent_loss                 | 0.0116   |
|    ent_policy_gradient_loss | 0.00304  |
|    ent_std                  | 0.0903   |
|    ent_value_loss           | 0.015    |
|    entropy_loss             | 6.53     |
|    explained_variance       | 0.968    |
|    learning_rate            | 0.0003   |
|    loss                     | 0.166    |
|    n_updates                | 7300     |
|    policy_gradient_loss     | 0.196    |
|    std                      | 0.107    |
|    value_loss               | 0.0156   |
------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 897       |
|    ep_rew_mean              | 3.34e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 732       |
|    time_elapsed             | 9911      |
|    total_timesteps          | 1499136   |
| train/                      |           |
|    approx_kl                | 5.07825   |
|    clip_fraction            | 0.934     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.7758608 |
|    ent_clip_fraction        | 0.785     |
|    ent_entropy_loss         | 7.87      |
|    ent_loss                 | -0.0238   |
|    ent_policy_gradient_loss | 0.0354    |
|    ent_std                  | 0.0907    |
|    ent_value_loss           | 0.016     |
|    entropy_loss             | 6.55      |
|    explained_variance       | 0.57      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.16      |
|    n_updates                | 7310      |
|    policy_gradient_loss     | 0.19      |
|    std                      | 0.107     |
|    value_loss               | 0.0179    |
-------------------------------------------
Eval num_timesteps=1500000, episode_reward=3060.46 +/- 1580.84
Episode length: 810.72 +/- 321.16
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 811       |
|    mean_reward              | 3.06e+03  |
| time/                       |           |
|    total_timesteps          | 1500000   |
| train/                      |           |
|    approx_kl                | 7.515999  |
|    clip_fraction            | 0.975     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.4571629 |
|    ent_clip_fraction        | 0.725     |
|    ent_entropy_loss         | 7.89      |
|    ent_loss                 | -0.0334   |
|    ent_policy_gradient_loss | -0.0232   |
|    ent_std                  | 0.0902    |
|    ent_value_loss           | 0.0164    |
|    entropy_loss             | 6.52      |
|    explained_variance       | 0.977     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.187     |
|    n_updates                | 7320      |
|    policy_gradient_loss     | 0.228     |
|    std                      | 0.107     |
|    value_loss               | 0.0176    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 906      |
|    ep_rew_mean     | 3.35e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 733      |
|    time_elapsed    | 9939     |
|    total_timesteps | 1501184  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 896       |
|    ep_rew_mean              | 3.31e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 734       |
|    time_elapsed             | 9949      |
|    total_timesteps          | 1503232   |
| train/                      |           |
|    approx_kl                | 6.8165417 |
|    clip_fraction            | 0.956     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.7404089 |
|    ent_clip_fraction        | 0.729     |
|    ent_entropy_loss         | 7.88      |
|    ent_loss                 | 0.014     |
|    ent_policy_gradient_loss | 0.0284    |
|    ent_std                  | 0.0906    |
|    ent_value_loss           | 0.0227    |
|    entropy_loss             | 6.51      |
|    explained_variance       | 0.962     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.211     |
|    n_updates                | 7330      |
|    policy_gradient_loss     | 0.172     |
|    std                      | 0.107     |
|    value_loss               | 0.0228    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 896       |
|    ep_rew_mean              | 3.29e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 735       |
|    time_elapsed             | 9960      |
|    total_timesteps          | 1505280   |
| train/                      |           |
|    approx_kl                | 4.5689325 |
|    clip_fraction            | 0.919     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.1298041 |
|    ent_clip_fraction        | 0.776     |
|    ent_entropy_loss         | 7.89      |
|    ent_loss                 | 0.0167    |
|    ent_policy_gradient_loss | 0.0372    |
|    ent_std                  | 0.0901    |
|    ent_value_loss           | 0.0549    |
|    entropy_loss             | 6.51      |
|    explained_variance       | 0.543     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.142     |
|    n_updates                | 7340      |
|    policy_gradient_loss     | 0.136     |
|    std                      | 0.107     |
|    value_loss               | 0.0589    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 902       |
|    ep_rew_mean              | 3.28e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 736       |
|    time_elapsed             | 9969      |
|    total_timesteps          | 1507328   |
| train/                      |           |
|    approx_kl                | 8.586776  |
|    clip_fraction            | 0.959     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.6454346 |
|    ent_clip_fraction        | 0.74      |
|    ent_entropy_loss         | 7.91      |
|    ent_loss                 | 0.0787    |
|    ent_policy_gradient_loss | 0.0479    |
|    ent_std                  | 0.0902    |
|    ent_value_loss           | 0.0285    |
|    entropy_loss             | 6.51      |
|    explained_variance       | 0.966     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0935    |
|    n_updates                | 7350      |
|    policy_gradient_loss     | 0.145     |
|    std                      | 0.107     |
|    value_loss               | 0.0284    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 905       |
|    ep_rew_mean              | 3.27e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 737       |
|    time_elapsed             | 9979      |
|    total_timesteps          | 1509376   |
| train/                      |           |
|    approx_kl                | 13.008257 |
|    clip_fraction            | 0.942     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 6.353191  |
|    ent_clip_fraction        | 0.825     |
|    ent_entropy_loss         | 7.92      |
|    ent_loss                 | 0.0366    |
|    ent_policy_gradient_loss | 0.0544    |
|    ent_std                  | 0.0898    |
|    ent_value_loss           | 0.0118    |
|    entropy_loss             | 6.58      |
|    explained_variance       | 0.986     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.103     |
|    n_updates                | 7360      |
|    policy_gradient_loss     | 0.178     |
|    std                      | 0.106     |
|    value_loss               | 0.0117    |
-------------------------------------------
Eval num_timesteps=1510000, episode_reward=3860.03 +/- 1365.54
Episode length: 954.52 +/- 192.71
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 955       |
|    mean_reward              | 3.86e+03  |
| time/                       |           |
|    total_timesteps          | 1510000   |
| train/                      |           |
|    approx_kl                | 11.085335 |
|    clip_fraction            | 0.895     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.3975935 |
|    ent_clip_fraction        | 0.797     |
|    ent_entropy_loss         | 7.9       |
|    ent_loss                 | 0.109     |
|    ent_policy_gradient_loss | 0.0867    |
|    ent_std                  | 0.0905    |
|    ent_value_loss           | 0.0508    |
|    entropy_loss             | 6.65      |
|    explained_variance       | 0.953     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0322    |
|    n_updates                | 7370      |
|    policy_gradient_loss     | 0.0734    |
|    std                      | 0.105     |
|    value_loss               | 0.051     |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 905      |
|    ep_rew_mean     | 3.26e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 738      |
|    time_elapsed    | 10006    |
|    total_timesteps | 1511424  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 909       |
|    ep_rew_mean              | 3.24e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 739       |
|    time_elapsed             | 10017     |
|    total_timesteps          | 1513472   |
| train/                      |           |
|    approx_kl                | 9.166938  |
|    clip_fraction            | 0.955     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.7927241 |
|    ent_clip_fraction        | 0.7       |
|    ent_entropy_loss         | 7.88      |
|    ent_loss                 | 0.0455    |
|    ent_policy_gradient_loss | 0.0621    |
|    ent_std                  | 0.0906    |
|    ent_value_loss           | 0.0203    |
|    entropy_loss             | 6.68      |
|    explained_variance       | 0.97      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0168    |
|    n_updates                | 7380      |
|    policy_gradient_loss     | 0.155     |
|    std                      | 0.105     |
|    value_loss               | 0.0209    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 909       |
|    ep_rew_mean              | 3.21e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 740       |
|    time_elapsed             | 10027     |
|    total_timesteps          | 1515520   |
| train/                      |           |
|    approx_kl                | 13.900102 |
|    clip_fraction            | 0.978     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.9931427 |
|    ent_clip_fraction        | 0.687     |
|    ent_entropy_loss         | 7.87      |
|    ent_loss                 | -0.0107   |
|    ent_policy_gradient_loss | -0.00357  |
|    ent_std                  | 0.0906    |
|    ent_value_loss           | 0.0252    |
|    entropy_loss             | 6.65      |
|    explained_variance       | 0.97      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.13      |
|    n_updates                | 7390      |
|    policy_gradient_loss     | 0.161     |
|    std                      | 0.106     |
|    value_loss               | 0.0234    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 912       |
|    ep_rew_mean              | 3.22e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 741       |
|    time_elapsed             | 10037     |
|    total_timesteps          | 1517568   |
| train/                      |           |
|    approx_kl                | 8.997442  |
|    clip_fraction            | 0.984     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.2076244 |
|    ent_clip_fraction        | 0.686     |
|    ent_entropy_loss         | 7.85      |
|    ent_loss                 | -0.0553   |
|    ent_policy_gradient_loss | -0.0165   |
|    ent_std                  | 0.0912    |
|    ent_value_loss           | 0.00741   |
|    entropy_loss             | 6.61      |
|    explained_variance       | 0.969     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.221     |
|    n_updates                | 7400      |
|    policy_gradient_loss     | 0.215     |
|    std                      | 0.106     |
|    value_loss               | 0.00588   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 921       |
|    ep_rew_mean              | 3.21e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 742       |
|    time_elapsed             | 10047     |
|    total_timesteps          | 1519616   |
| train/                      |           |
|    approx_kl                | 17.247076 |
|    clip_fraction            | 0.958     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.4727511 |
|    ent_clip_fraction        | 0.72      |
|    ent_entropy_loss         | 7.79      |
|    ent_loss                 | 0.0828    |
|    ent_policy_gradient_loss | 0.0515    |
|    ent_std                  | 0.0915    |
|    ent_value_loss           | 0.0363    |
|    entropy_loss             | 6.62      |
|    explained_variance       | 0.962     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.099     |
|    n_updates                | 7410      |
|    policy_gradient_loss     | 0.14      |
|    std                      | 0.106     |
|    value_loss               | 0.0355    |
-------------------------------------------
Eval num_timesteps=1520000, episode_reward=3431.87 +/- 1539.97
Episode length: 927.28 +/- 218.58
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 927       |
|    mean_reward              | 3.43e+03  |
| time/                       |           |
|    total_timesteps          | 1520000   |
| train/                      |           |
|    approx_kl                | 32.4734   |
|    clip_fraction            | 0.959     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 5.6511164 |
|    ent_clip_fraction        | 0.787     |
|    ent_entropy_loss         | 7.79      |
|    ent_loss                 | -0.0305   |
|    ent_policy_gradient_loss | 0.0219    |
|    ent_std                  | 0.0915    |
|    ent_value_loss           | 0.0236    |
|    entropy_loss             | 6.59      |
|    explained_variance       | 0.966     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.164     |
|    n_updates                | 7420      |
|    policy_gradient_loss     | 0.17      |
|    std                      | 0.106     |
|    value_loss               | 0.0257    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 921      |
|    ep_rew_mean     | 3.17e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 743      |
|    time_elapsed    | 10076    |
|    total_timesteps | 1521664  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 921       |
|    ep_rew_mean              | 3.18e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 744       |
|    time_elapsed             | 10086     |
|    total_timesteps          | 1523712   |
| train/                      |           |
|    approx_kl                | 12.984911 |
|    clip_fraction            | 0.976     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.7551093 |
|    ent_clip_fraction        | 0.693     |
|    ent_entropy_loss         | 7.81      |
|    ent_loss                 | -0.025    |
|    ent_policy_gradient_loss | 0.00752   |
|    ent_std                  | 0.0911    |
|    ent_value_loss           | 0.0173    |
|    entropy_loss             | 6.58      |
|    explained_variance       | 0.98      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.156     |
|    n_updates                | 7430      |
|    policy_gradient_loss     | 0.175     |
|    std                      | 0.106     |
|    value_loss               | 0.0162    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 918        |
|    ep_rew_mean              | 3.17e+03   |
| time/                       |            |
|    fps                      | 151        |
|    iterations               | 745        |
|    time_elapsed             | 10096      |
|    total_timesteps          | 1525760    |
| train/                      |            |
|    approx_kl                | 5.718149   |
|    clip_fraction            | 0.971      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.96616983 |
|    ent_clip_fraction        | 0.716      |
|    ent_entropy_loss         | 7.8        |
|    ent_loss                 | -0.0298    |
|    ent_policy_gradient_loss | -0.000421  |
|    ent_std                  | 0.0917     |
|    ent_value_loss           | 0.0132     |
|    entropy_loss             | 6.58       |
|    explained_variance       | 0.124      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.267      |
|    n_updates                | 7440       |
|    policy_gradient_loss     | 0.213      |
|    std                      | 0.106      |
|    value_loss               | 0.0136     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 918       |
|    ep_rew_mean              | 3.16e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 746       |
|    time_elapsed             | 10106     |
|    total_timesteps          | 1527808   |
| train/                      |           |
|    approx_kl                | 7.8484507 |
|    clip_fraction            | 0.959     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.6188849 |
|    ent_clip_fraction        | 0.738     |
|    ent_entropy_loss         | 7.78      |
|    ent_loss                 | -0.00775  |
|    ent_policy_gradient_loss | 0.0118    |
|    ent_std                  | 0.0916    |
|    ent_value_loss           | 0.0265    |
|    entropy_loss             | 6.56      |
|    explained_variance       | 0.926     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.201     |
|    n_updates                | 7450      |
|    policy_gradient_loss     | 0.189     |
|    std                      | 0.107     |
|    value_loss               | 0.0253    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 918       |
|    ep_rew_mean              | 3.16e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 747       |
|    time_elapsed             | 10116     |
|    total_timesteps          | 1529856   |
| train/                      |           |
|    approx_kl                | 6.3972774 |
|    clip_fraction            | 0.97      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.4541094 |
|    ent_clip_fraction        | 0.715     |
|    ent_entropy_loss         | 7.8       |
|    ent_loss                 | -0.0135   |
|    ent_policy_gradient_loss | -0.00801  |
|    ent_std                  | 0.0914    |
|    ent_value_loss           | 0.00818   |
|    entropy_loss             | 6.52      |
|    explained_variance       | 0.888     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.212     |
|    n_updates                | 7460      |
|    policy_gradient_loss     | 0.263     |
|    std                      | 0.108     |
|    value_loss               | 0.00808   |
-------------------------------------------
Eval num_timesteps=1530000, episode_reward=4152.69 +/- 1369.46
Episode length: 927.12 +/- 233.95
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 927       |
|    mean_reward              | 4.15e+03  |
| time/                       |           |
|    total_timesteps          | 1530000   |
| train/                      |           |
|    approx_kl                | 5.3430037 |
|    clip_fraction            | 0.973     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.4345913 |
|    ent_clip_fraction        | 0.689     |
|    ent_entropy_loss         | 7.79      |
|    ent_loss                 | -0.0372   |
|    ent_policy_gradient_loss | -0.0148   |
|    ent_std                  | 0.0916    |
|    ent_value_loss           | 0.00554   |
|    entropy_loss             | 6.47      |
|    explained_variance       | 0.567     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.264     |
|    n_updates                | 7470      |
|    policy_gradient_loss     | 0.263     |
|    std                      | 0.108     |
|    value_loss               | 0.0052    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 918      |
|    ep_rew_mean     | 3.16e+03 |
| time/              |          |
|    fps             | 151      |
|    iterations      | 748      |
|    time_elapsed    | 10144    |
|    total_timesteps | 1531904  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 909       |
|    ep_rew_mean              | 3.13e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 749       |
|    time_elapsed             | 10154     |
|    total_timesteps          | 1533952   |
| train/                      |           |
|    approx_kl                | 3.1247473 |
|    clip_fraction            | 0.789     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 5.383006  |
|    ent_clip_fraction        | 0.909     |
|    ent_entropy_loss         | 7.73      |
|    ent_loss                 | 0.264     |
|    ent_policy_gradient_loss | 0.201     |
|    ent_std                  | 0.0929    |
|    ent_value_loss           | 0.00854   |
|    entropy_loss             | 6.51      |
|    explained_variance       | 0.577     |
|    learning_rate            | 0.0003    |
|    loss                     | -0.00372  |
|    n_updates                | 7480      |
|    policy_gradient_loss     | 0.0599    |
|    std                      | 0.107     |
|    value_loss               | 0.00877   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 912       |
|    ep_rew_mean              | 3.14e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 750       |
|    time_elapsed             | 10165     |
|    total_timesteps          | 1536000   |
| train/                      |           |
|    approx_kl                | 5.1837096 |
|    clip_fraction            | 0.928     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.2686782 |
|    ent_clip_fraction        | 0.775     |
|    ent_entropy_loss         | 7.64      |
|    ent_loss                 | 0.0297    |
|    ent_policy_gradient_loss | 0.518     |
|    ent_std                  | 0.0936    |
|    ent_value_loss           | 0.0346    |
|    entropy_loss             | 6.54      |
|    explained_variance       | 0.549     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.163     |
|    n_updates                | 7490      |
|    policy_gradient_loss     | 0.152     |
|    std                      | 0.107     |
|    value_loss               | 0.0367    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 912       |
|    ep_rew_mean              | 3.15e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 751       |
|    time_elapsed             | 10175     |
|    total_timesteps          | 1538048   |
| train/                      |           |
|    approx_kl                | 6.9253626 |
|    clip_fraction            | 0.953     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.8431463 |
|    ent_clip_fraction        | 0.74      |
|    ent_entropy_loss         | 7.6       |
|    ent_loss                 | 0.0193    |
|    ent_policy_gradient_loss | 0.0115    |
|    ent_std                  | 0.0937    |
|    ent_value_loss           | 0.0257    |
|    entropy_loss             | 6.54      |
|    explained_variance       | 0.947     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.173     |
|    n_updates                | 7500      |
|    policy_gradient_loss     | 0.168     |
|    std                      | 0.107     |
|    value_loss               | 0.0247    |
-------------------------------------------
Eval num_timesteps=1540000, episode_reward=3775.23 +/- 1594.90
Episode length: 961.28 +/- 189.69
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 961       |
|    mean_reward              | 3.78e+03  |
| time/                       |           |
|    total_timesteps          | 1540000   |
| train/                      |           |
|    approx_kl                | 6.6042004 |
|    clip_fraction            | 0.969     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.0156516 |
|    ent_clip_fraction        | 0.716     |
|    ent_entropy_loss         | 7.59      |
|    ent_loss                 | -0.00588  |
|    ent_policy_gradient_loss | 0.00225   |
|    ent_std                  | 0.0941    |
|    ent_value_loss           | 0.0107    |
|    entropy_loss             | 6.54      |
|    explained_variance       | 0.956     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.201     |
|    n_updates                | 7510      |
|    policy_gradient_loss     | 0.19      |
|    std                      | 0.107     |
|    value_loss               | 0.0106    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 915      |
|    ep_rew_mean     | 3.17e+03 |
| time/              |          |
|    fps             | 150      |
|    iterations      | 752      |
|    time_elapsed    | 10203    |
|    total_timesteps | 1540096  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 915       |
|    ep_rew_mean              | 3.17e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 753       |
|    time_elapsed             | 10213     |
|    total_timesteps          | 1542144   |
| train/                      |           |
|    approx_kl                | 4.078832  |
|    clip_fraction            | 0.916     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.7955604 |
|    ent_clip_fraction        | 0.765     |
|    ent_entropy_loss         | 7.58      |
|    ent_loss                 | 0.0486    |
|    ent_policy_gradient_loss | 0.0625    |
|    ent_std                  | 0.0941    |
|    ent_value_loss           | 0.007     |
|    entropy_loss             | 6.57      |
|    explained_variance       | 0.625     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.161     |
|    n_updates                | 7520      |
|    policy_gradient_loss     | 0.177     |
|    std                      | 0.106     |
|    value_loss               | 0.00741   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 898       |
|    ep_rew_mean              | 3.07e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 754       |
|    time_elapsed             | 10223     |
|    total_timesteps          | 1544192   |
| train/                      |           |
|    approx_kl                | 5.844401  |
|    clip_fraction            | 0.958     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.2292645 |
|    ent_clip_fraction        | 0.706     |
|    ent_entropy_loss         | 7.56      |
|    ent_loss                 | 0.0723    |
|    ent_policy_gradient_loss | 0.0393    |
|    ent_std                  | 0.0943    |
|    ent_value_loss           | 0.00685   |
|    entropy_loss             | 6.59      |
|    explained_variance       | 0.661     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.172     |
|    n_updates                | 7530      |
|    policy_gradient_loss     | 0.25      |
|    std                      | 0.106     |
|    value_loss               | 0.00667   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 893       |
|    ep_rew_mean              | 3.08e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 755       |
|    time_elapsed             | 10234     |
|    total_timesteps          | 1546240   |
| train/                      |           |
|    approx_kl                | 10.194496 |
|    clip_fraction            | 0.934     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.4214094 |
|    ent_clip_fraction        | 0.729     |
|    ent_entropy_loss         | 7.58      |
|    ent_loss                 | 0.0426    |
|    ent_policy_gradient_loss | 0.0323    |
|    ent_std                  | 0.0936    |
|    ent_value_loss           | 0.0272    |
|    entropy_loss             | 6.6       |
|    explained_variance       | 0.96      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.122     |
|    n_updates                | 7540      |
|    policy_gradient_loss     | 0.155     |
|    std                      | 0.106     |
|    value_loss               | 0.0319    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 877       |
|    ep_rew_mean              | 3.01e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 756       |
|    time_elapsed             | 10244     |
|    total_timesteps          | 1548288   |
| train/                      |           |
|    approx_kl                | 5.2574368 |
|    clip_fraction            | 0.955     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.8481419 |
|    ent_clip_fraction        | 0.735     |
|    ent_entropy_loss         | 7.63      |
|    ent_loss                 | -0.0114   |
|    ent_policy_gradient_loss | 0.0269    |
|    ent_std                  | 0.0931    |
|    ent_value_loss           | 0.0281    |
|    entropy_loss             | 6.58      |
|    explained_variance       | 0.566     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.224     |
|    n_updates                | 7550      |
|    policy_gradient_loss     | 0.185     |
|    std                      | 0.106     |
|    value_loss               | 0.0264    |
-------------------------------------------
Eval num_timesteps=1550000, episode_reward=3413.55 +/- 1306.44
Episode length: 863.88 +/- 271.84
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 864        |
|    mean_reward              | 3.41e+03   |
| time/                       |            |
|    total_timesteps          | 1550000    |
| train/                      |            |
|    approx_kl                | 12.3126335 |
|    clip_fraction            | 0.963      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 1.854137   |
|    ent_clip_fraction        | 0.687      |
|    ent_entropy_loss         | 7.66       |
|    ent_loss                 | 0.00463    |
|    ent_policy_gradient_loss | 0.00357    |
|    ent_std                  | 0.0929     |
|    ent_value_loss           | 0.0475     |
|    entropy_loss             | 6.59       |
|    explained_variance       | 0.951      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.16       |
|    n_updates                | 7560       |
|    policy_gradient_loss     | 0.157      |
|    std                      | 0.106      |
|    value_loss               | 0.0452     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 877      |
|    ep_rew_mean     | 3.04e+03 |
| time/              |          |
|    fps             | 150      |
|    iterations      | 757      |
|    time_elapsed    | 10272    |
|    total_timesteps | 1550336  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 877       |
|    ep_rew_mean              | 3.01e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 758       |
|    time_elapsed             | 10282     |
|    total_timesteps          | 1552384   |
| train/                      |           |
|    approx_kl                | 6.000079  |
|    clip_fraction            | 0.966     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.4905223 |
|    ent_clip_fraction        | 0.733     |
|    ent_entropy_loss         | 7.66      |
|    ent_loss                 | 0.00988   |
|    ent_policy_gradient_loss | 0.0219    |
|    ent_std                  | 0.093     |
|    ent_value_loss           | 0.0267    |
|    entropy_loss             | 6.56      |
|    explained_variance       | 0.879     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.164     |
|    n_updates                | 7570      |
|    policy_gradient_loss     | 0.185     |
|    std                      | 0.107     |
|    value_loss               | 0.0265    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 877       |
|    ep_rew_mean              | 3e+03     |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 759       |
|    time_elapsed             | 10292     |
|    total_timesteps          | 1554432   |
| train/                      |           |
|    approx_kl                | 13.484803 |
|    clip_fraction            | 0.937     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.9809182 |
|    ent_clip_fraction        | 0.748     |
|    ent_entropy_loss         | 7.68      |
|    ent_loss                 | 0.0493    |
|    ent_policy_gradient_loss | 0.0665    |
|    ent_std                  | 0.0927    |
|    ent_value_loss           | 0.0164    |
|    entropy_loss             | 6.55      |
|    explained_variance       | 0.985     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.126     |
|    n_updates                | 7580      |
|    policy_gradient_loss     | 0.13      |
|    std                      | 0.107     |
|    value_loss               | 0.0168    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 877       |
|    ep_rew_mean              | 2.98e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 760       |
|    time_elapsed             | 10303     |
|    total_timesteps          | 1556480   |
| train/                      |           |
|    approx_kl                | 4.9182982 |
|    clip_fraction            | 0.917     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.2699115 |
|    ent_clip_fraction        | 0.773     |
|    ent_entropy_loss         | 7.69      |
|    ent_loss                 | 0.0564    |
|    ent_policy_gradient_loss | 0.0328    |
|    ent_std                  | 0.0926    |
|    ent_value_loss           | 0.0362    |
|    entropy_loss             | 6.56      |
|    explained_variance       | 0.807     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.173     |
|    n_updates                | 7590      |
|    policy_gradient_loss     | 0.17      |
|    std                      | 0.107     |
|    value_loss               | 0.0356    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 854       |
|    ep_rew_mean              | 2.89e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 761       |
|    time_elapsed             | 10313     |
|    total_timesteps          | 1558528   |
| train/                      |           |
|    approx_kl                | 14.267921 |
|    clip_fraction            | 0.921     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 6.252268  |
|    ent_clip_fraction        | 0.784     |
|    ent_entropy_loss         | 7.68      |
|    ent_loss                 | 0.093     |
|    ent_policy_gradient_loss | 0.0722    |
|    ent_std                  | 0.0931    |
|    ent_value_loss           | 0.0275    |
|    entropy_loss             | 6.56      |
|    explained_variance       | 0.975     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.146     |
|    n_updates                | 7600      |
|    policy_gradient_loss     | 0.128     |
|    std                      | 0.107     |
|    value_loss               | 0.0268    |
-------------------------------------------
Eval num_timesteps=1560000, episode_reward=3618.93 +/- 1403.38
Episode length: 906.36 +/- 257.95
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 906       |
|    mean_reward              | 3.62e+03  |
| time/                       |           |
|    total_timesteps          | 1560000   |
| train/                      |           |
|    approx_kl                | 5.0670404 |
|    clip_fraction            | 0.93      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.4410083 |
|    ent_clip_fraction        | 0.758     |
|    ent_entropy_loss         | 7.67      |
|    ent_loss                 | 0.0129    |
|    ent_policy_gradient_loss | 0.0405    |
|    ent_std                  | 0.0929    |
|    ent_value_loss           | 0.0599    |
|    entropy_loss             | 6.56      |
|    explained_variance       | 0.38      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.13      |
|    n_updates                | 7610      |
|    policy_gradient_loss     | 0.141     |
|    std                      | 0.107     |
|    value_loss               | 0.0637    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 854      |
|    ep_rew_mean     | 2.9e+03  |
| time/              |          |
|    fps             | 150      |
|    iterations      | 762      |
|    time_elapsed    | 10341    |
|    total_timesteps | 1560576  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 839       |
|    ep_rew_mean              | 2.85e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 763       |
|    time_elapsed             | 10351     |
|    total_timesteps          | 1562624   |
| train/                      |           |
|    approx_kl                | 6.1112275 |
|    clip_fraction            | 0.977     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.047856  |
|    ent_clip_fraction        | 0.698     |
|    ent_entropy_loss         | 7.68      |
|    ent_loss                 | -0.0231   |
|    ent_policy_gradient_loss | -0.000606 |
|    ent_std                  | 0.0928    |
|    ent_value_loss           | 0.0111    |
|    entropy_loss             | 6.54      |
|    explained_variance       | 0.205     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.234     |
|    n_updates                | 7620      |
|    policy_gradient_loss     | 0.243     |
|    std                      | 0.107     |
|    value_loss               | 0.0104    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 829       |
|    ep_rew_mean              | 2.81e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 764       |
|    time_elapsed             | 10361     |
|    total_timesteps          | 1564672   |
| train/                      |           |
|    approx_kl                | 5.953253  |
|    clip_fraction            | 0.967     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.8583412 |
|    ent_clip_fraction        | 0.684     |
|    ent_entropy_loss         | 7.71      |
|    ent_loss                 | -0.044    |
|    ent_policy_gradient_loss | -0.015    |
|    ent_std                  | 0.0922    |
|    ent_value_loss           | 0.0448    |
|    entropy_loss             | 6.51      |
|    explained_variance       | 0.407     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.282     |
|    n_updates                | 7630      |
|    policy_gradient_loss     | 0.188     |
|    std                      | 0.108     |
|    value_loss               | 0.0441    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 835       |
|    ep_rew_mean              | 2.84e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 765       |
|    time_elapsed             | 10371     |
|    total_timesteps          | 1566720   |
| train/                      |           |
|    approx_kl                | 5.6142964 |
|    clip_fraction            | 0.977     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.5325116 |
|    ent_clip_fraction        | 0.651     |
|    ent_entropy_loss         | 7.75      |
|    ent_loss                 | -0.0462   |
|    ent_policy_gradient_loss | -0.0174   |
|    ent_std                  | 0.0919    |
|    ent_value_loss           | 0.0258    |
|    entropy_loss             | 6.49      |
|    explained_variance       | 0.575     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.164     |
|    n_updates                | 7640      |
|    policy_gradient_loss     | 0.204     |
|    std                      | 0.107     |
|    value_loss               | 0.0252    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 835       |
|    ep_rew_mean              | 2.87e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 766       |
|    time_elapsed             | 10382     |
|    total_timesteps          | 1568768   |
| train/                      |           |
|    approx_kl                | 6.794089  |
|    clip_fraction            | 0.967     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.2594919 |
|    ent_clip_fraction        | 0.698     |
|    ent_entropy_loss         | 7.75      |
|    ent_loss                 | -0.0932   |
|    ent_policy_gradient_loss | -0.0195   |
|    ent_std                  | 0.092     |
|    ent_value_loss           | 0.0215    |
|    entropy_loss             | 6.52      |
|    explained_variance       | 0.328     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.283     |
|    n_updates                | 7650      |
|    policy_gradient_loss     | 0.213     |
|    std                      | 0.107     |
|    value_loss               | 0.0208    |
-------------------------------------------
Eval num_timesteps=1570000, episode_reward=3533.09 +/- 1561.97
Episode length: 916.36 +/- 226.77
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 916       |
|    mean_reward              | 3.53e+03  |
| time/                       |           |
|    total_timesteps          | 1570000   |
| train/                      |           |
|    approx_kl                | 8.844492  |
|    clip_fraction            | 0.958     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.7796507 |
|    ent_clip_fraction        | 0.703     |
|    ent_entropy_loss         | 7.76      |
|    ent_loss                 | 0.0576    |
|    ent_policy_gradient_loss | 0.0292    |
|    ent_std                  | 0.0917    |
|    ent_value_loss           | 0.0455    |
|    entropy_loss             | 6.53      |
|    explained_variance       | 0.948     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.13      |
|    n_updates                | 7660      |
|    policy_gradient_loss     | 0.147     |
|    std                      | 0.107     |
|    value_loss               | 0.0449    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 835      |
|    ep_rew_mean     | 2.91e+03 |
| time/              |          |
|    fps             | 150      |
|    iterations      | 767      |
|    time_elapsed    | 10410    |
|    total_timesteps | 1570816  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 843       |
|    ep_rew_mean              | 2.94e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 768       |
|    time_elapsed             | 10420     |
|    total_timesteps          | 1572864   |
| train/                      |           |
|    approx_kl                | 5.0538635 |
|    clip_fraction            | 0.956     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.9295201 |
|    ent_clip_fraction        | 0.743     |
|    ent_entropy_loss         | 7.78      |
|    ent_loss                 | -0.0394   |
|    ent_policy_gradient_loss | 0.0543    |
|    ent_std                  | 0.0917    |
|    ent_value_loss           | 0.00993   |
|    entropy_loss             | 6.51      |
|    explained_variance       | 0.204     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.247     |
|    n_updates                | 7670      |
|    policy_gradient_loss     | 0.171     |
|    std                      | 0.108     |
|    value_loss               | 0.0101    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 828        |
|    ep_rew_mean              | 2.87e+03   |
| time/                       |            |
|    fps                      | 150        |
|    iterations               | 769        |
|    time_elapsed             | 10430      |
|    total_timesteps          | 1574912    |
| train/                      |            |
|    approx_kl                | 5.818346   |
|    clip_fraction            | 0.973      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.91249204 |
|    ent_clip_fraction        | 0.68       |
|    ent_entropy_loss         | 7.77       |
|    ent_loss                 | -0.0745    |
|    ent_policy_gradient_loss | -0.0171    |
|    ent_std                  | 0.0918     |
|    ent_value_loss           | 0.00801    |
|    entropy_loss             | 6.49       |
|    explained_variance       | 0.534      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.251      |
|    n_updates                | 7680       |
|    policy_gradient_loss     | 0.287      |
|    std                      | 0.107      |
|    value_loss               | 0.00753    |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 832       |
|    ep_rew_mean              | 2.88e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 770       |
|    time_elapsed             | 10441     |
|    total_timesteps          | 1576960   |
| train/                      |           |
|    approx_kl                | 13.255267 |
|    clip_fraction            | 0.931     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 6.9738255 |
|    ent_clip_fraction        | 0.849     |
|    ent_entropy_loss         | 7.77      |
|    ent_loss                 | -0.0105   |
|    ent_policy_gradient_loss | 0.0671    |
|    ent_std                  | 0.0914    |
|    ent_value_loss           | 0.0411    |
|    entropy_loss             | 6.54      |
|    explained_variance       | 0.88      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.144     |
|    n_updates                | 7690      |
|    policy_gradient_loss     | 0.127     |
|    std                      | 0.107     |
|    value_loss               | 0.0435    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 829       |
|    ep_rew_mean              | 2.87e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 771       |
|    time_elapsed             | 10451     |
|    total_timesteps          | 1579008   |
| train/                      |           |
|    approx_kl                | 5.330452  |
|    clip_fraction            | 0.954     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.0919664 |
|    ent_clip_fraction        | 0.637     |
|    ent_entropy_loss         | 7.8       |
|    ent_loss                 | -0.0249   |
|    ent_policy_gradient_loss | -0.00727  |
|    ent_std                  | 0.0913    |
|    ent_value_loss           | 0.0452    |
|    entropy_loss             | 6.59      |
|    explained_variance       | 0.949     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.1       |
|    n_updates                | 7700      |
|    policy_gradient_loss     | 0.143     |
|    std                      | 0.105     |
|    value_loss               | 0.041     |
-------------------------------------------
Eval num_timesteps=1580000, episode_reward=3146.36 +/- 1700.87
Episode length: 942.32 +/- 196.91
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 942       |
|    mean_reward              | 3.15e+03  |
| time/                       |           |
|    total_timesteps          | 1580000   |
| train/                      |           |
|    approx_kl                | 5.0829906 |
|    clip_fraction            | 0.953     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.2587016 |
|    ent_clip_fraction        | 0.736     |
|    ent_entropy_loss         | 7.81      |
|    ent_loss                 | 0.0252    |
|    ent_policy_gradient_loss | 0.0493    |
|    ent_std                  | 0.0913    |
|    ent_value_loss           | 0.034     |
|    entropy_loss             | 6.71      |
|    explained_variance       | 0.398     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.174     |
|    n_updates                | 7710      |
|    policy_gradient_loss     | 0.199     |
|    std                      | 0.104     |
|    value_loss               | 0.0338    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 821      |
|    ep_rew_mean     | 2.82e+03 |
| time/              |          |
|    fps             | 150      |
|    iterations      | 772      |
|    time_elapsed    | 10479    |
|    total_timesteps | 1581056  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 821       |
|    ep_rew_mean              | 2.86e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 773       |
|    time_elapsed             | 10489     |
|    total_timesteps          | 1583104   |
| train/                      |           |
|    approx_kl                | 4.6271977 |
|    clip_fraction            | 0.894     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 8.402563  |
|    ent_clip_fraction        | 0.82      |
|    ent_entropy_loss         | 7.78      |
|    ent_loss                 | 0.0973    |
|    ent_policy_gradient_loss | 27.5      |
|    ent_std                  | 0.0918    |
|    ent_value_loss           | 0.0445    |
|    entropy_loss             | 6.74      |
|    explained_variance       | 0.931     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.104     |
|    n_updates                | 7720      |
|    policy_gradient_loss     | 0.112     |
|    std                      | 0.104     |
|    value_loss               | 0.0489    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 824       |
|    ep_rew_mean              | 2.85e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 774       |
|    time_elapsed             | 10500     |
|    total_timesteps          | 1585152   |
| train/                      |           |
|    approx_kl                | 5.3142385 |
|    clip_fraction            | 0.964     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.5452493 |
|    ent_clip_fraction        | 0.721     |
|    ent_entropy_loss         | 7.76      |
|    ent_loss                 | 0.0253    |
|    ent_policy_gradient_loss | 0.0118    |
|    ent_std                  | 0.0919    |
|    ent_value_loss           | 0.018     |
|    entropy_loss             | 6.72      |
|    explained_variance       | 0.918     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.215     |
|    n_updates                | 7730      |
|    policy_gradient_loss     | 0.176     |
|    std                      | 0.105     |
|    value_loss               | 0.0172    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 824        |
|    ep_rew_mean              | 2.82e+03   |
| time/                       |            |
|    fps                      | 151        |
|    iterations               | 775        |
|    time_elapsed             | 10510      |
|    total_timesteps          | 1587200    |
| train/                      |            |
|    approx_kl                | 4.602482   |
|    clip_fraction            | 0.932      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.39718872 |
|    ent_clip_fraction        | 0.61       |
|    ent_entropy_loss         | 7.74       |
|    ent_loss                 | -0.0112    |
|    ent_policy_gradient_loss | -0.00623   |
|    ent_std                  | 0.092      |
|    ent_value_loss           | 0.0475     |
|    entropy_loss             | 6.76       |
|    explained_variance       | 0.933      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.173      |
|    n_updates                | 7740       |
|    policy_gradient_loss     | 0.329      |
|    std                      | 0.103      |
|    value_loss               | 0.0464     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 824        |
|    ep_rew_mean              | 2.84e+03   |
| time/                       |            |
|    fps                      | 151        |
|    iterations               | 776        |
|    time_elapsed             | 10520      |
|    total_timesteps          | 1589248    |
| train/                      |            |
|    approx_kl                | 5.0319495  |
|    clip_fraction            | 0.964      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.94840914 |
|    ent_clip_fraction        | 0.682      |
|    ent_entropy_loss         | 7.73       |
|    ent_loss                 | 0.0365     |
|    ent_policy_gradient_loss | -0.000898  |
|    ent_std                  | 0.0922     |
|    ent_value_loss           | 0.0317     |
|    entropy_loss             | 6.83       |
|    explained_variance       | 0.968      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.142      |
|    n_updates                | 7750       |
|    policy_gradient_loss     | 0.167      |
|    std                      | 0.103      |
|    value_loss               | 0.0322     |
--------------------------------------------
Eval num_timesteps=1590000, episode_reward=3184.53 +/- 1435.97
Episode length: 894.96 +/- 251.70
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 895       |
|    mean_reward              | 3.18e+03  |
| time/                       |           |
|    total_timesteps          | 1590000   |
| train/                      |           |
|    approx_kl                | 3.2778163 |
|    clip_fraction            | 0.818     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 5.8783236 |
|    ent_clip_fraction        | 0.906     |
|    ent_entropy_loss         | 7.71      |
|    ent_loss                 | 0.189     |
|    ent_policy_gradient_loss | 0.145     |
|    ent_std                  | 0.0926    |
|    ent_value_loss           | 0.0171    |
|    entropy_loss             | 6.81      |
|    explained_variance       | 0.96      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0076    |
|    n_updates                | 7760      |
|    policy_gradient_loss     | 0.0794    |
|    std                      | 0.103     |
|    value_loss               | 0.0177    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 828      |
|    ep_rew_mean     | 2.85e+03 |
| time/              |          |
|    fps             | 150      |
|    iterations      | 777      |
|    time_elapsed    | 10548    |
|    total_timesteps | 1591296  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 828       |
|    ep_rew_mean              | 2.89e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 778       |
|    time_elapsed             | 10558     |
|    total_timesteps          | 1593344   |
| train/                      |           |
|    approx_kl                | 5.6934614 |
|    clip_fraction            | 0.964     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.2694001 |
|    ent_clip_fraction        | 0.694     |
|    ent_entropy_loss         | 7.68      |
|    ent_loss                 | -0.0201   |
|    ent_policy_gradient_loss | 0.0138    |
|    ent_std                  | 0.0928    |
|    ent_value_loss           | 0.00622   |
|    entropy_loss             | 6.79      |
|    explained_variance       | 0.596     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.174     |
|    n_updates                | 7770      |
|    policy_gradient_loss     | 0.239     |
|    std                      | 0.104     |
|    value_loss               | 0.00636   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 828       |
|    ep_rew_mean              | 2.95e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 779       |
|    time_elapsed             | 10568     |
|    total_timesteps          | 1595392   |
| train/                      |           |
|    approx_kl                | 5.483303  |
|    clip_fraction            | 0.971     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.4517663 |
|    ent_clip_fraction        | 0.694     |
|    ent_entropy_loss         | 7.69      |
|    ent_loss                 | -0.0642   |
|    ent_policy_gradient_loss | -0.0132   |
|    ent_std                  | 0.0926    |
|    ent_value_loss           | 0.00788   |
|    entropy_loss             | 6.74      |
|    explained_variance       | 0.621     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.22      |
|    n_updates                | 7780      |
|    policy_gradient_loss     | 0.252     |
|    std                      | 0.104     |
|    value_loss               | 0.00756   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 828       |
|    ep_rew_mean              | 2.94e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 780       |
|    time_elapsed             | 10579     |
|    total_timesteps          | 1597440   |
| train/                      |           |
|    approx_kl                | 5.630056  |
|    clip_fraction            | 0.96      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.4649715 |
|    ent_clip_fraction        | 0.696     |
|    ent_entropy_loss         | 7.71      |
|    ent_loss                 | 0.0153    |
|    ent_policy_gradient_loss | 0.0153    |
|    ent_std                  | 0.0922    |
|    ent_value_loss           | 0.0212    |
|    entropy_loss             | 6.72      |
|    explained_variance       | 0.978     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.174     |
|    n_updates                | 7790      |
|    policy_gradient_loss     | 0.164     |
|    std                      | 0.105     |
|    value_loss               | 0.0203    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 828        |
|    ep_rew_mean              | 2.93e+03   |
| time/                       |            |
|    fps                      | 151        |
|    iterations               | 781        |
|    time_elapsed             | 10589      |
|    total_timesteps          | 1599488    |
| train/                      |            |
|    approx_kl                | 5.706852   |
|    clip_fraction            | 0.969      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.62541956 |
|    ent_clip_fraction        | 0.654      |
|    ent_entropy_loss         | 7.72       |
|    ent_loss                 | -0.0556    |
|    ent_policy_gradient_loss | -0.00754   |
|    ent_std                  | 0.0921     |
|    ent_value_loss           | 0.019      |
|    entropy_loss             | 6.69       |
|    explained_variance       | 0.979      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.208      |
|    n_updates                | 7800       |
|    policy_gradient_loss     | 0.177      |
|    std                      | 0.105      |
|    value_loss               | 0.0174     |
--------------------------------------------
Eval num_timesteps=1600000, episode_reward=3880.59 +/- 1167.92
Episode length: 965.64 +/- 116.74
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 966       |
|    mean_reward              | 3.88e+03  |
| time/                       |           |
|    total_timesteps          | 1600000   |
| train/                      |           |
|    approx_kl                | 6.1529264 |
|    clip_fraction            | 0.975     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.9593774 |
|    ent_clip_fraction        | 0.693     |
|    ent_entropy_loss         | 7.75      |
|    ent_loss                 | -0.0693   |
|    ent_policy_gradient_loss | -0.0149   |
|    ent_std                  | 0.092     |
|    ent_value_loss           | 0.00672   |
|    entropy_loss             | 6.66      |
|    explained_variance       | 0.937     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.245     |
|    n_updates                | 7810      |
|    policy_gradient_loss     | 0.282     |
|    std                      | 0.105     |
|    value_loss               | 0.00704   |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 834      |
|    ep_rew_mean     | 3.01e+03 |
| time/              |          |
|    fps             | 150      |
|    iterations      | 782      |
|    time_elapsed    | 10617    |
|    total_timesteps | 1601536  |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 834        |
|    ep_rew_mean              | 3.05e+03   |
| time/                       |            |
|    fps                      | 150        |
|    iterations               | 783        |
|    time_elapsed             | 10627      |
|    total_timesteps          | 1603584    |
| train/                      |            |
|    approx_kl                | 6.3173842  |
|    clip_fraction            | 0.98       |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.62672037 |
|    ent_clip_fraction        | 0.657      |
|    ent_entropy_loss         | 7.77       |
|    ent_loss                 | -0.0424    |
|    ent_policy_gradient_loss | -0.0198    |
|    ent_std                  | 0.0915     |
|    ent_value_loss           | 0.0105     |
|    entropy_loss             | 6.64       |
|    explained_variance       | 0.902      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.276      |
|    n_updates                | 7820       |
|    policy_gradient_loss     | 0.214      |
|    std                      | 0.106      |
|    value_loss               | 0.00998    |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 834        |
|    ep_rew_mean              | 3.03e+03   |
| time/                       |            |
|    fps                      | 150        |
|    iterations               | 784        |
|    time_elapsed             | 10637      |
|    total_timesteps          | 1605632    |
| train/                      |            |
|    approx_kl                | 5.6668825  |
|    clip_fraction            | 0.974      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.48910642 |
|    ent_clip_fraction        | 0.663      |
|    ent_entropy_loss         | 7.78       |
|    ent_loss                 | -0.0117    |
|    ent_policy_gradient_loss | -0.0115    |
|    ent_std                  | 0.0916     |
|    ent_value_loss           | 0.0205     |
|    entropy_loss             | 6.61       |
|    explained_variance       | 0.959      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.166      |
|    n_updates                | 7830       |
|    policy_gradient_loss     | 0.189      |
|    std                      | 0.106      |
|    value_loss               | 0.0206     |
--------------------------------------------
------------------------------------------
| rollout/                    |          |
|    ep_len_mean              | 834      |
|    ep_rew_mean              | 3.02e+03 |
| time/                       |          |
|    fps                      | 150      |
|    iterations               | 785      |
|    time_elapsed             | 10648    |
|    total_timesteps          | 1607680  |
| train/                      |          |
|    approx_kl                | 7.332165 |
|    clip_fraction            | 0.912    |
|    clip_range               | 0.2      |
|    ent_approx_kl            | 9.748266 |
|    ent_clip_fraction        | 0.745    |
|    ent_entropy_loss         | 7.81     |
|    ent_loss                 | 0.012    |
|    ent_policy_gradient_loss | 0.0165   |
|    ent_std                  | 0.091    |
|    ent_value_loss           | 0.0233   |
|    entropy_loss             | 6.6      |
|    explained_variance       | 0.977    |
|    learning_rate            | 0.0003   |
|    loss                     | 0.0963   |
|    n_updates                | 7840     |
|    policy_gradient_loss     | 0.141    |
|    std                      | 0.106    |
|    value_loss               | 0.0242   |
------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 837       |
|    ep_rew_mean              | 3.02e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 786       |
|    time_elapsed             | 10658     |
|    total_timesteps          | 1609728   |
| train/                      |           |
|    approx_kl                | 3.8708377 |
|    clip_fraction            | 0.887     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.6321638 |
|    ent_clip_fraction        | 0.844     |
|    ent_entropy_loss         | 7.79      |
|    ent_loss                 | 0.0486    |
|    ent_policy_gradient_loss | 0.0894    |
|    ent_std                  | 0.0917    |
|    ent_value_loss           | 0.0161    |
|    entropy_loss             | 6.62      |
|    explained_variance       | 0.45      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.144     |
|    n_updates                | 7850      |
|    policy_gradient_loss     | 0.133     |
|    std                      | 0.106     |
|    value_loss               | 0.0157    |
-------------------------------------------
Eval num_timesteps=1610000, episode_reward=3528.93 +/- 1487.02
Episode length: 931.44 +/- 204.36
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 931       |
|    mean_reward              | 3.53e+03  |
| time/                       |           |
|    total_timesteps          | 1610000   |
| train/                      |           |
|    approx_kl                | 10.025219 |
|    clip_fraction            | 0.97      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.3971971 |
|    ent_clip_fraction        | 0.699     |
|    ent_entropy_loss         | 7.79      |
|    ent_loss                 | 0.00924   |
|    ent_policy_gradient_loss | 0.0473    |
|    ent_std                  | 0.0914    |
|    ent_value_loss           | 0.0214    |
|    entropy_loss             | 6.58      |
|    explained_variance       | 0.963     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.242     |
|    n_updates                | 7860      |
|    policy_gradient_loss     | 0.176     |
|    std                      | 0.107     |
|    value_loss               | 0.022     |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 837      |
|    ep_rew_mean     | 2.99e+03 |
| time/              |          |
|    fps             | 150      |
|    iterations      | 787      |
|    time_elapsed    | 10686    |
|    total_timesteps | 1611776  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 837       |
|    ep_rew_mean              | 2.99e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 788       |
|    time_elapsed             | 10697     |
|    total_timesteps          | 1613824   |
| train/                      |           |
|    approx_kl                | 6.897561  |
|    clip_fraction            | 0.883     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 5.1002564 |
|    ent_clip_fraction        | 0.844     |
|    ent_entropy_loss         | 7.74      |
|    ent_loss                 | 0.0793    |
|    ent_policy_gradient_loss | 0.143     |
|    ent_std                  | 0.0927    |
|    ent_value_loss           | 0.0186    |
|    entropy_loss             | 6.61      |
|    explained_variance       | 0.977     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0749    |
|    n_updates                | 7870      |
|    policy_gradient_loss     | 0.0237    |
|    std                      | 0.106     |
|    value_loss               | 0.0192    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 838       |
|    ep_rew_mean              | 2.96e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 789       |
|    time_elapsed             | 10707     |
|    total_timesteps          | 1615872   |
| train/                      |           |
|    approx_kl                | 2.7835875 |
|    clip_fraction            | 0.826     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 4.6130114 |
|    ent_clip_fraction        | 0.882     |
|    ent_entropy_loss         | 7.67      |
|    ent_loss                 | 0.000448  |
|    ent_policy_gradient_loss | 0.173     |
|    ent_std                  | 0.0932    |
|    ent_value_loss           | 0.00616   |
|    entropy_loss             | 6.68      |
|    explained_variance       | 0.302     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.154     |
|    n_updates                | 7880      |
|    policy_gradient_loss     | 0.0928    |
|    std                      | 0.105     |
|    value_loss               | 0.00586   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 833       |
|    ep_rew_mean              | 2.93e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 790       |
|    time_elapsed             | 10717     |
|    total_timesteps          | 1617920   |
| train/                      |           |
|    approx_kl                | 3.8294287 |
|    clip_fraction            | 0.887     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.9887683 |
|    ent_clip_fraction        | 0.748     |
|    ent_entropy_loss         | 7.66      |
|    ent_loss                 | 0.0105    |
|    ent_policy_gradient_loss | 0.0527    |
|    ent_std                  | 0.0928    |
|    ent_value_loss           | 0.0283    |
|    entropy_loss             | 6.72      |
|    explained_variance       | 0.968     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.103     |
|    n_updates                | 7890      |
|    policy_gradient_loss     | 0.105     |
|    std                      | 0.104     |
|    value_loss               | 0.0302    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 833       |
|    ep_rew_mean              | 2.95e+03  |
| time/                       |           |
|    fps                      | 151       |
|    iterations               | 791       |
|    time_elapsed             | 10727     |
|    total_timesteps          | 1619968   |
| train/                      |           |
|    approx_kl                | 5.4077063 |
|    clip_fraction            | 0.967     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.5227273 |
|    ent_clip_fraction        | 0.669     |
|    ent_entropy_loss         | 7.69      |
|    ent_loss                 | -0.0169   |
|    ent_policy_gradient_loss | -0.00576  |
|    ent_std                  | 0.0926    |
|    ent_value_loss           | 0.0406    |
|    entropy_loss             | 6.73      |
|    explained_variance       | 0.897     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.137     |
|    n_updates                | 7900      |
|    policy_gradient_loss     | 0.157     |
|    std                      | 0.105     |
|    value_loss               | 0.0386    |
-------------------------------------------
Eval num_timesteps=1620000, episode_reward=2761.32 +/- 1808.23
Episode length: 746.92 +/- 373.92
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 747       |
|    mean_reward              | 2.76e+03  |
| time/                       |           |
|    total_timesteps          | 1620000   |
| train/                      |           |
|    approx_kl                | 2.8488908 |
|    clip_fraction            | 0.861     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 4.214245  |
|    ent_clip_fraction        | 0.876     |
|    ent_entropy_loss         | 7.69      |
|    ent_loss                 | 0.166     |
|    ent_policy_gradient_loss | 0.132     |
|    ent_std                  | 0.0927    |
|    ent_value_loss           | 0.0115    |
|    entropy_loss             | 6.7       |
|    explained_variance       | -0.245    |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0898    |
|    n_updates                | 7910      |
|    policy_gradient_loss     | 0.121     |
|    std                      | 0.105     |
|    value_loss               | 0.0147    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 833      |
|    ep_rew_mean     | 2.95e+03 |
| time/              |          |
|    fps             | 150      |
|    iterations      | 792      |
|    time_elapsed    | 10756    |
|    total_timesteps | 1622016  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 833       |
|    ep_rew_mean              | 2.92e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 793       |
|    time_elapsed             | 10766     |
|    total_timesteps          | 1624064   |
| train/                      |           |
|    approx_kl                | 7.789031  |
|    clip_fraction            | 0.921     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.0884233 |
|    ent_clip_fraction        | 0.752     |
|    ent_entropy_loss         | 7.68      |
|    ent_loss                 | -0.00215  |
|    ent_policy_gradient_loss | 0.0665    |
|    ent_std                  | 0.0928    |
|    ent_value_loss           | 0.0248    |
|    entropy_loss             | 6.72      |
|    explained_variance       | 0.962     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.141     |
|    n_updates                | 7920      |
|    policy_gradient_loss     | 0.141     |
|    std                      | 0.104     |
|    value_loss               | 0.0248    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 833       |
|    ep_rew_mean              | 2.92e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 794       |
|    time_elapsed             | 10777     |
|    total_timesteps          | 1626112   |
| train/                      |           |
|    approx_kl                | 7.8864694 |
|    clip_fraction            | 0.974     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.3338118 |
|    ent_clip_fraction        | 0.698     |
|    ent_entropy_loss         | 7.67      |
|    ent_loss                 | -0.0667   |
|    ent_policy_gradient_loss | -0.0162   |
|    ent_std                  | 0.0927    |
|    ent_value_loss           | 0.00639   |
|    entropy_loss             | 6.75      |
|    explained_variance       | 0.99      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.138     |
|    n_updates                | 7930      |
|    policy_gradient_loss     | 0.231     |
|    std                      | 0.104     |
|    value_loss               | 0.00589   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 843       |
|    ep_rew_mean              | 2.98e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 795       |
|    time_elapsed             | 10787     |
|    total_timesteps          | 1628160   |
| train/                      |           |
|    approx_kl                | 4.7059646 |
|    clip_fraction            | 0.951     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.2759844 |
|    ent_clip_fraction        | 0.717     |
|    ent_entropy_loss         | 7.68      |
|    ent_loss                 | -0.053    |
|    ent_policy_gradient_loss | 0.0472    |
|    ent_std                  | 0.0929    |
|    ent_value_loss           | 0.00744   |
|    entropy_loss             | 6.75      |
|    explained_variance       | 0.637     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.207     |
|    n_updates                | 7940      |
|    policy_gradient_loss     | 0.178     |
|    std                      | 0.104     |
|    value_loss               | 0.00786   |
-------------------------------------------
Eval num_timesteps=1630000, episode_reward=3510.93 +/- 1736.66
Episode length: 921.68 +/- 258.48
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 922       |
|    mean_reward              | 3.51e+03  |
| time/                       |           |
|    total_timesteps          | 1630000   |
| train/                      |           |
|    approx_kl                | 6.011945  |
|    clip_fraction            | 0.969     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.6936054 |
|    ent_clip_fraction        | 0.656     |
|    ent_entropy_loss         | 7.66      |
|    ent_loss                 | -0.0296   |
|    ent_policy_gradient_loss | 0.000561  |
|    ent_std                  | 0.0929    |
|    ent_value_loss           | 0.0143    |
|    entropy_loss             | 6.72      |
|    explained_variance       | 0.979     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.142     |
|    n_updates                | 7950      |
|    policy_gradient_loss     | 0.184     |
|    std                      | 0.105     |
|    value_loss               | 0.0137    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 850      |
|    ep_rew_mean     | 3.01e+03 |
| time/              |          |
|    fps             | 150      |
|    iterations      | 796      |
|    time_elapsed    | 10815    |
|    total_timesteps | 1630208  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 855       |
|    ep_rew_mean              | 3e+03     |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 797       |
|    time_elapsed             | 10825     |
|    total_timesteps          | 1632256   |
| train/                      |           |
|    approx_kl                | 3.8152938 |
|    clip_fraction            | 0.925     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.5011091 |
|    ent_clip_fraction        | 0.784     |
|    ent_entropy_loss         | 7.64      |
|    ent_loss                 | 0.0681    |
|    ent_policy_gradient_loss | 0.0955    |
|    ent_std                  | 0.0934    |
|    ent_value_loss           | 0.00635   |
|    entropy_loss             | 6.72      |
|    explained_variance       | 0.528     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.156     |
|    n_updates                | 7960      |
|    policy_gradient_loss     | 0.197     |
|    std                      | 0.105     |
|    value_loss               | 0.00611   |
-------------------------------------------
------------------------------------------
| rollout/                    |          |
|    ep_len_mean              | 864      |
|    ep_rew_mean              | 3.04e+03 |
| time/                       |          |
|    fps                      | 150      |
|    iterations               | 798      |
|    time_elapsed             | 10836    |
|    total_timesteps          | 1634304  |
| train/                      |          |
|    approx_kl                | 5.784036 |
|    clip_fraction            | 0.973    |
|    clip_range               | 0.2      |
|    ent_approx_kl            | 0.762947 |
|    ent_clip_fraction        | 0.666    |
|    ent_entropy_loss         | 7.64     |
|    ent_loss                 | -0.00711 |
|    ent_policy_gradient_loss | -0.0243  |
|    ent_std                  | 0.093    |
|    ent_value_loss           | 0.0172   |
|    entropy_loss             | 6.67     |
|    explained_variance       | 0.983    |
|    learning_rate            | 0.0003   |
|    loss                     | 0.168    |
|    n_updates                | 7970     |
|    policy_gradient_loss     | 0.18     |
|    std                      | 0.105    |
|    value_loss               | 0.0176   |
------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 871       |
|    ep_rew_mean              | 3.09e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 799       |
|    time_elapsed             | 10846     |
|    total_timesteps          | 1636352   |
| train/                      |           |
|    approx_kl                | 4.3432026 |
|    clip_fraction            | 0.965     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.0871542 |
|    ent_clip_fraction        | 0.696     |
|    ent_entropy_loss         | 7.67      |
|    ent_loss                 | 0.0137    |
|    ent_policy_gradient_loss | 0.00744   |
|    ent_std                  | 0.0927    |
|    ent_value_loss           | 0.00467   |
|    entropy_loss             | 6.63      |
|    explained_variance       | 0.424     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.225     |
|    n_updates                | 7980      |
|    policy_gradient_loss     | 0.225     |
|    std                      | 0.106     |
|    value_loss               | 0.0045    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 871       |
|    ep_rew_mean              | 3.08e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 800       |
|    time_elapsed             | 10856     |
|    total_timesteps          | 1638400   |
| train/                      |           |
|    approx_kl                | 5.076907  |
|    clip_fraction            | 0.945     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.8984827 |
|    ent_clip_fraction        | 0.73      |
|    ent_entropy_loss         | 7.67      |
|    ent_loss                 | -0.0354   |
|    ent_policy_gradient_loss | 0.00751   |
|    ent_std                  | 0.0927    |
|    ent_value_loss           | 0.0214    |
|    entropy_loss             | 6.61      |
|    explained_variance       | 0.946     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.142     |
|    n_updates                | 7990      |
|    policy_gradient_loss     | 0.158     |
|    std                      | 0.106     |
|    value_loss               | 0.0201    |
-------------------------------------------
Eval num_timesteps=1640000, episode_reward=3711.45 +/- 1193.62
Episode length: 1000.00 +/- 0.00
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 1e+03     |
|    mean_reward              | 3.71e+03  |
| time/                       |           |
|    total_timesteps          | 1640000   |
| train/                      |           |
|    approx_kl                | 4.393853  |
|    clip_fraction            | 0.908     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.5887613 |
|    ent_clip_fraction        | 0.779     |
|    ent_entropy_loss         | 7.67      |
|    ent_loss                 | -0.0195   |
|    ent_policy_gradient_loss | 0.0449    |
|    ent_std                  | 0.0929    |
|    ent_value_loss           | 0.0194    |
|    entropy_loss             | 6.62      |
|    explained_variance       | 0.966     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.253     |
|    n_updates                | 8000      |
|    policy_gradient_loss     | 0.155     |
|    std                      | 0.106     |
|    value_loss               | 0.0202    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 871      |
|    ep_rew_mean     | 3.12e+03 |
| time/              |          |
|    fps             | 150      |
|    iterations      | 801      |
|    time_elapsed    | 10883    |
|    total_timesteps | 1640448  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 871       |
|    ep_rew_mean              | 3.14e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 802       |
|    time_elapsed             | 10893     |
|    total_timesteps          | 1642496   |
| train/                      |           |
|    approx_kl                | 4.560631  |
|    clip_fraction            | 0.938     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.8768644 |
|    ent_clip_fraction        | 0.759     |
|    ent_entropy_loss         | 7.66      |
|    ent_loss                 | -0.0162   |
|    ent_policy_gradient_loss | 0.0745    |
|    ent_std                  | 0.0931    |
|    ent_value_loss           | 0.00402   |
|    entropy_loss             | 6.62      |
|    explained_variance       | 0.408     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.232     |
|    n_updates                | 8010      |
|    policy_gradient_loss     | 0.204     |
|    std                      | 0.106     |
|    value_loss               | 0.00382   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 878       |
|    ep_rew_mean              | 3.17e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 803       |
|    time_elapsed             | 10903     |
|    total_timesteps          | 1644544   |
| train/                      |           |
|    approx_kl                | 7.365659  |
|    clip_fraction            | 0.941     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.8631644 |
|    ent_clip_fraction        | 0.738     |
|    ent_entropy_loss         | 7.63      |
|    ent_loss                 | 0.09      |
|    ent_policy_gradient_loss | 0.0361    |
|    ent_std                  | 0.0934    |
|    ent_value_loss           | 0.0123    |
|    entropy_loss             | 6.62      |
|    explained_variance       | 0.983     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.125     |
|    n_updates                | 8020      |
|    policy_gradient_loss     | 0.153     |
|    std                      | 0.106     |
|    value_loss               | 0.0123    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 888        |
|    ep_rew_mean              | 3.21e+03   |
| time/                       |            |
|    fps                      | 150        |
|    iterations               | 804        |
|    time_elapsed             | 10913      |
|    total_timesteps          | 1646592    |
| train/                      |            |
|    approx_kl                | 4.556266   |
|    clip_fraction            | 0.964      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.84527403 |
|    ent_clip_fraction        | 0.673      |
|    ent_entropy_loss         | 7.61       |
|    ent_loss                 | -0.0449    |
|    ent_policy_gradient_loss | 0.00162    |
|    ent_std                  | 0.0934     |
|    ent_value_loss           | 0.014      |
|    entropy_loss             | 6.61       |
|    explained_variance       | 0.603      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.188      |
|    n_updates                | 8030       |
|    policy_gradient_loss     | 0.185      |
|    std                      | 0.106      |
|    value_loss               | 0.0141     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 887       |
|    ep_rew_mean              | 3.2e+03   |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 805       |
|    time_elapsed             | 10923     |
|    total_timesteps          | 1648640   |
| train/                      |           |
|    approx_kl                | 6.2707043 |
|    clip_fraction            | 0.972     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.5723904 |
|    ent_clip_fraction        | 0.672     |
|    ent_entropy_loss         | 7.62      |
|    ent_loss                 | -0.0605   |
|    ent_policy_gradient_loss | -0.0256   |
|    ent_std                  | 0.0933    |
|    ent_value_loss           | 0.0232    |
|    entropy_loss             | 6.6       |
|    explained_variance       | 0.352     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.248     |
|    n_updates                | 8040      |
|    policy_gradient_loss     | 0.184     |
|    std                      | 0.106     |
|    value_loss               | 0.0205    |
-------------------------------------------
Eval num_timesteps=1650000, episode_reward=3716.23 +/- 1060.26
Episode length: 926.44 +/- 193.57
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 926        |
|    mean_reward              | 3.72e+03   |
| time/                       |            |
|    total_timesteps          | 1650000    |
| train/                      |            |
|    approx_kl                | 6.6036053  |
|    clip_fraction            | 0.977      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.44770783 |
|    ent_clip_fraction        | 0.667      |
|    ent_entropy_loss         | 7.64       |
|    ent_loss                 | -0.0344    |
|    ent_policy_gradient_loss | -0.0228    |
|    ent_std                  | 0.0932     |
|    ent_value_loss           | 0.0336     |
|    entropy_loss             | 6.63       |
|    explained_variance       | 0.536      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.286      |
|    n_updates                | 8050       |
|    policy_gradient_loss     | 0.241      |
|    std                      | 0.105      |
|    value_loss               | 0.0335     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 886      |
|    ep_rew_mean     | 3.2e+03  |
| time/              |          |
|    fps             | 150      |
|    iterations      | 806      |
|    time_elapsed    | 10951    |
|    total_timesteps | 1650688  |
---------------------------------
------------------------------------------
| rollout/                    |          |
|    ep_len_mean              | 891      |
|    ep_rew_mean              | 3.23e+03 |
| time/                       |          |
|    fps                      | 150      |
|    iterations               | 807      |
|    time_elapsed             | 10962    |
|    total_timesteps          | 1652736  |
| train/                      |          |
|    approx_kl                | 4.247651 |
|    clip_fraction            | 0.908    |
|    clip_range               | 0.2      |
|    ent_approx_kl            | 2.589701 |
|    ent_clip_fraction        | 0.787    |
|    ent_entropy_loss         | 7.63     |
|    ent_loss                 | 0.0841   |
|    ent_policy_gradient_loss | 0.0573   |
|    ent_std                  | 0.0935   |
|    ent_value_loss           | 0.0393   |
|    entropy_loss             | 6.64     |
|    explained_variance       | 0.418    |
|    learning_rate            | 0.0003   |
|    loss                     | 0.185    |
|    n_updates                | 8060     |
|    policy_gradient_loss     | 0.14     |
|    std                      | 0.106    |
|    value_loss               | 0.0414   |
------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 894        |
|    ep_rew_mean              | 3.24e+03   |
| time/                       |            |
|    fps                      | 150        |
|    iterations               | 808        |
|    time_elapsed             | 10972      |
|    total_timesteps          | 1654784    |
| train/                      |            |
|    approx_kl                | 4.4594784  |
|    clip_fraction            | 0.967      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.92784524 |
|    ent_clip_fraction        | 0.685      |
|    ent_entropy_loss         | 7.6        |
|    ent_loss                 | -0.0223    |
|    ent_policy_gradient_loss | -0.0182    |
|    ent_std                  | 0.0938     |
|    ent_value_loss           | 0.00441    |
|    entropy_loss             | 6.61       |
|    explained_variance       | 0.479      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.163      |
|    n_updates                | 8070       |
|    policy_gradient_loss     | 0.328      |
|    std                      | 0.106      |
|    value_loss               | 0.00434    |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 894       |
|    ep_rew_mean              | 3.21e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 809       |
|    time_elapsed             | 10982     |
|    total_timesteps          | 1656832   |
| train/                      |           |
|    approx_kl                | 6.838339  |
|    clip_fraction            | 0.964     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.7965876 |
|    ent_clip_fraction        | 0.702     |
|    ent_entropy_loss         | 7.61      |
|    ent_loss                 | 0.0153    |
|    ent_policy_gradient_loss | 0.0157    |
|    ent_std                  | 0.0933    |
|    ent_value_loss           | 0.0246    |
|    entropy_loss             | 6.65      |
|    explained_variance       | 0.956     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.146     |
|    n_updates                | 8080      |
|    policy_gradient_loss     | 0.154     |
|    std                      | 0.105     |
|    value_loss               | 0.0249    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 894       |
|    ep_rew_mean              | 3.23e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 810       |
|    time_elapsed             | 10993     |
|    total_timesteps          | 1658880   |
| train/                      |           |
|    approx_kl                | 5.371918  |
|    clip_fraction            | 0.964     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.2318736 |
|    ent_clip_fraction        | 0.725     |
|    ent_entropy_loss         | 7.62      |
|    ent_loss                 | -0.00134  |
|    ent_policy_gradient_loss | 0.016     |
|    ent_std                  | 0.0935    |
|    ent_value_loss           | 0.00814   |
|    entropy_loss             | 6.69      |
|    explained_variance       | 0.969     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.183     |
|    n_updates                | 8090      |
|    policy_gradient_loss     | 0.208     |
|    std                      | 0.105     |
|    value_loss               | 0.00801   |
-------------------------------------------
Eval num_timesteps=1660000, episode_reward=3299.44 +/- 1446.50
Episode length: 873.64 +/- 258.67
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 874       |
|    mean_reward              | 3.3e+03   |
| time/                       |           |
|    total_timesteps          | 1660000   |
| train/                      |           |
|    approx_kl                | 5.8230968 |
|    clip_fraction            | 0.972     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.7810782 |
|    ent_clip_fraction        | 0.672     |
|    ent_entropy_loss         | 7.61      |
|    ent_loss                 | -0.000777 |
|    ent_policy_gradient_loss | -0.0215   |
|    ent_std                  | 0.0935    |
|    ent_value_loss           | 0.0134    |
|    entropy_loss             | 6.69      |
|    explained_variance       | 0.474     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.212     |
|    n_updates                | 8100      |
|    policy_gradient_loss     | 0.266     |
|    std                      | 0.105     |
|    value_loss               | 0.0127    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 894      |
|    ep_rew_mean     | 3.22e+03 |
| time/              |          |
|    fps             | 150      |
|    iterations      | 811      |
|    time_elapsed    | 11021    |
|    total_timesteps | 1660928  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 894       |
|    ep_rew_mean              | 3.21e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 812       |
|    time_elapsed             | 11031     |
|    total_timesteps          | 1662976   |
| train/                      |           |
|    approx_kl                | 2.8350186 |
|    clip_fraction            | 0.773     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 4.7863073 |
|    ent_clip_fraction        | 0.9       |
|    ent_entropy_loss         | 7.57      |
|    ent_loss                 | 0.114     |
|    ent_policy_gradient_loss | 0.138     |
|    ent_std                  | 0.0945    |
|    ent_value_loss           | 0.0252    |
|    entropy_loss             | 6.7       |
|    explained_variance       | 0.883     |
|    learning_rate            | 0.0003    |
|    loss                     | -0.00855  |
|    n_updates                | 8110      |
|    policy_gradient_loss     | 0.0553    |
|    std                      | 0.105     |
|    value_loss               | 0.0256    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 909       |
|    ep_rew_mean              | 3.27e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 813       |
|    time_elapsed             | 11041     |
|    total_timesteps          | 1665024   |
| train/                      |           |
|    approx_kl                | 6.5599217 |
|    clip_fraction            | 0.909     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.5486743 |
|    ent_clip_fraction        | 0.826     |
|    ent_entropy_loss         | 7.49      |
|    ent_loss                 | -0.0131   |
|    ent_policy_gradient_loss | 0.0935    |
|    ent_std                  | 0.0953    |
|    ent_value_loss           | 0.0137    |
|    entropy_loss             | 6.7       |
|    explained_variance       | 0.974     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.155     |
|    n_updates                | 8120      |
|    policy_gradient_loss     | 0.122     |
|    std                      | 0.105     |
|    value_loss               | 0.0135    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 907       |
|    ep_rew_mean              | 3.3e+03   |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 814       |
|    time_elapsed             | 11052     |
|    total_timesteps          | 1667072   |
| train/                      |           |
|    approx_kl                | 5.8647804 |
|    clip_fraction            | 0.913     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.640427  |
|    ent_clip_fraction        | 0.79      |
|    ent_entropy_loss         | 7.43      |
|    ent_loss                 | 0.0197    |
|    ent_policy_gradient_loss | 0.0417    |
|    ent_std                  | 0.0959    |
|    ent_value_loss           | 0.0259    |
|    entropy_loss             | 6.68      |
|    explained_variance       | 0.948     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.14      |
|    n_updates                | 8130      |
|    policy_gradient_loss     | 0.148     |
|    std                      | 0.105     |
|    value_loss               | 0.0258    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 915        |
|    ep_rew_mean              | 3.38e+03   |
| time/                       |            |
|    fps                      | 150        |
|    iterations               | 815        |
|    time_elapsed             | 11062      |
|    total_timesteps          | 1669120    |
| train/                      |            |
|    approx_kl                | 5.8620405  |
|    clip_fraction            | 0.968      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.50408846 |
|    ent_clip_fraction        | 0.654      |
|    ent_entropy_loss         | 7.41       |
|    ent_loss                 | -0.0228    |
|    ent_policy_gradient_loss | -0.0133    |
|    ent_std                  | 0.0959     |
|    ent_value_loss           | 0.0254     |
|    entropy_loss             | 6.64       |
|    explained_variance       | 0.319      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.16       |
|    n_updates                | 8140       |
|    policy_gradient_loss     | 0.191      |
|    std                      | 0.106      |
|    value_loss               | 0.0245     |
--------------------------------------------
Eval num_timesteps=1670000, episode_reward=3221.23 +/- 1617.84
Episode length: 984.04 +/- 58.18
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 984        |
|    mean_reward              | 3.22e+03   |
| time/                       |            |
|    total_timesteps          | 1670000    |
| train/                      |            |
|    approx_kl                | 5.3753376  |
|    clip_fraction            | 0.973      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.16237326 |
|    ent_clip_fraction        | 0.654      |
|    ent_entropy_loss         | 7.4        |
|    ent_loss                 | -0.0255    |
|    ent_policy_gradient_loss | -0.0259    |
|    ent_std                  | 0.0959     |
|    ent_value_loss           | 0.0478     |
|    entropy_loss             | 6.57       |
|    explained_variance       | 0.539      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.175      |
|    n_updates                | 8150       |
|    policy_gradient_loss     | 0.187      |
|    std                      | 0.107      |
|    value_loss               | 0.0443     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 909      |
|    ep_rew_mean     | 3.37e+03 |
| time/              |          |
|    fps             | 150      |
|    iterations      | 816      |
|    time_elapsed    | 11091    |
|    total_timesteps | 1671168  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 917       |
|    ep_rew_mean              | 3.41e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 817       |
|    time_elapsed             | 11101     |
|    total_timesteps          | 1673216   |
| train/                      |           |
|    approx_kl                | 3.7506819 |
|    clip_fraction            | 0.94      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.2736536 |
|    ent_clip_fraction        | 0.725     |
|    ent_entropy_loss         | 7.43      |
|    ent_loss                 | 0.0158    |
|    ent_policy_gradient_loss | 0.0163    |
|    ent_std                  | 0.0954    |
|    ent_value_loss           | 0.0466    |
|    entropy_loss             | 6.54      |
|    explained_variance       | 0.352     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.143     |
|    n_updates                | 8160      |
|    policy_gradient_loss     | 0.151     |
|    std                      | 0.107     |
|    value_loss               | 0.0465    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 917       |
|    ep_rew_mean              | 3.41e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 818       |
|    time_elapsed             | 11111     |
|    total_timesteps          | 1675264   |
| train/                      |           |
|    approx_kl                | 5.296184  |
|    clip_fraction            | 0.964     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.0470663 |
|    ent_clip_fraction        | 0.697     |
|    ent_entropy_loss         | 7.44      |
|    ent_loss                 | -0.024    |
|    ent_policy_gradient_loss | 0.00174   |
|    ent_std                  | 0.0955    |
|    ent_value_loss           | 0.0253    |
|    entropy_loss             | 6.51      |
|    explained_variance       | 0.896     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.158     |
|    n_updates                | 8170      |
|    policy_gradient_loss     | 0.177     |
|    std                      | 0.108     |
|    value_loss               | 0.0257    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 925       |
|    ep_rew_mean              | 3.45e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 819       |
|    time_elapsed             | 11122     |
|    total_timesteps          | 1677312   |
| train/                      |           |
|    approx_kl                | 2.2394145 |
|    clip_fraction            | 0.819     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.8905156 |
|    ent_clip_fraction        | 0.878     |
|    ent_entropy_loss         | 7.45      |
|    ent_loss                 | 0.113     |
|    ent_policy_gradient_loss | 0.108     |
|    ent_std                  | 0.0954    |
|    ent_value_loss           | 0.00446   |
|    entropy_loss             | 6.47      |
|    explained_variance       | 0.668     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0404    |
|    n_updates                | 8180      |
|    policy_gradient_loss     | 0.142     |
|    std                      | 0.108     |
|    value_loss               | 0.00453   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 938       |
|    ep_rew_mean              | 3.54e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 820       |
|    time_elapsed             | 11132     |
|    total_timesteps          | 1679360   |
| train/                      |           |
|    approx_kl                | 8.349595  |
|    clip_fraction            | 0.974     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.7778474 |
|    ent_clip_fraction        | 0.687     |
|    ent_entropy_loss         | 7.44      |
|    ent_loss                 | -0.0339   |
|    ent_policy_gradient_loss | 0.00229   |
|    ent_std                  | 0.0956    |
|    ent_value_loss           | 0.0158    |
|    entropy_loss             | 6.46      |
|    explained_variance       | 0.978     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.103     |
|    n_updates                | 8190      |
|    policy_gradient_loss     | 0.141     |
|    std                      | 0.108     |
|    value_loss               | 0.0156    |
-------------------------------------------
Eval num_timesteps=1680000, episode_reward=3851.52 +/- 1490.39
Episode length: 949.60 +/- 167.55
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 950       |
|    mean_reward              | 3.85e+03  |
| time/                       |           |
|    total_timesteps          | 1680000   |
| train/                      |           |
|    approx_kl                | 3.998818  |
|    clip_fraction            | 0.938     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.9618192 |
|    ent_clip_fraction        | 0.755     |
|    ent_entropy_loss         | 7.44      |
|    ent_loss                 | 0.0252    |
|    ent_policy_gradient_loss | 0.0482    |
|    ent_std                  | 0.0956    |
|    ent_value_loss           | 0.00688   |
|    entropy_loss             | 6.5       |
|    explained_variance       | 0.511     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.189     |
|    n_updates                | 8200      |
|    policy_gradient_loss     | 0.177     |
|    std                      | 0.108     |
|    value_loss               | 0.00743   |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 938      |
|    ep_rew_mean     | 3.5e+03  |
| time/              |          |
|    fps             | 150      |
|    iterations      | 821      |
|    time_elapsed    | 11160    |
|    total_timesteps | 1681408  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 936       |
|    ep_rew_mean              | 3.5e+03   |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 822       |
|    time_elapsed             | 11170     |
|    total_timesteps          | 1683456   |
| train/                      |           |
|    approx_kl                | 2.7512014 |
|    clip_fraction            | 0.905     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 4.628449  |
|    ent_clip_fraction        | 0.707     |
|    ent_entropy_loss         | 7.44      |
|    ent_loss                 | 0.0133    |
|    ent_policy_gradient_loss | 0.0498    |
|    ent_std                  | 0.0957    |
|    ent_value_loss           | 0.0201    |
|    entropy_loss             | 6.48      |
|    explained_variance       | 0.959     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.126     |
|    n_updates                | 8210      |
|    policy_gradient_loss     | 0.0836    |
|    std                      | 0.108     |
|    value_loss               | 0.022     |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 930       |
|    ep_rew_mean              | 3.44e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 823       |
|    time_elapsed             | 11180     |
|    total_timesteps          | 1685504   |
| train/                      |           |
|    approx_kl                | 5.0492864 |
|    clip_fraction            | 0.949     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.3100709 |
|    ent_clip_fraction        | 0.7       |
|    ent_entropy_loss         | 7.45      |
|    ent_loss                 | -0.0136   |
|    ent_policy_gradient_loss | 0.0122    |
|    ent_std                  | 0.0954    |
|    ent_value_loss           | 0.0276    |
|    entropy_loss             | 6.46      |
|    explained_variance       | 0.246     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.162     |
|    n_updates                | 8220      |
|    policy_gradient_loss     | 0.162     |
|    std                      | 0.108     |
|    value_loss               | 0.0262    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 927       |
|    ep_rew_mean              | 3.44e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 824       |
|    time_elapsed             | 11190     |
|    total_timesteps          | 1687552   |
| train/                      |           |
|    approx_kl                | 4.430317  |
|    clip_fraction            | 0.96      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.6111151 |
|    ent_clip_fraction        | 0.669     |
|    ent_entropy_loss         | 7.51      |
|    ent_loss                 | -0.0128   |
|    ent_policy_gradient_loss | -0.0125   |
|    ent_std                  | 0.0944    |
|    ent_value_loss           | 0.0328    |
|    entropy_loss             | 6.47      |
|    explained_variance       | 0.965     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.164     |
|    n_updates                | 8230      |
|    policy_gradient_loss     | 0.184     |
|    std                      | 0.108     |
|    value_loss               | 0.034     |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 923       |
|    ep_rew_mean              | 3.47e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 825       |
|    time_elapsed             | 11200     |
|    total_timesteps          | 1689600   |
| train/                      |           |
|    approx_kl                | 3.8622265 |
|    clip_fraction            | 0.93      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.8225039 |
|    ent_clip_fraction        | 0.762     |
|    ent_entropy_loss         | 7.51      |
|    ent_loss                 | 0.0685    |
|    ent_policy_gradient_loss | 0.295     |
|    ent_std                  | 0.095     |
|    ent_value_loss           | 0.0264    |
|    entropy_loss             | 6.48      |
|    explained_variance       | 0.484     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.136     |
|    n_updates                | 8240      |
|    policy_gradient_loss     | 0.14      |
|    std                      | 0.108     |
|    value_loss               | 0.0259    |
-------------------------------------------
Eval num_timesteps=1690000, episode_reward=3020.76 +/- 1676.31
Episode length: 710.84 +/- 353.50
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 711       |
|    mean_reward              | 3.02e+03  |
| time/                       |           |
|    total_timesteps          | 1690000   |
| train/                      |           |
|    approx_kl                | 4.6138144 |
|    clip_fraction            | 0.958     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.3601766 |
|    ent_clip_fraction        | 0.714     |
|    ent_entropy_loss         | 7.5       |
|    ent_loss                 | 0.017     |
|    ent_policy_gradient_loss | 0.2       |
|    ent_std                  | 0.0947    |
|    ent_value_loss           | 0.0321    |
|    entropy_loss             | 6.46      |
|    explained_variance       | 0.47      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.17      |
|    n_updates                | 8250      |
|    policy_gradient_loss     | 0.246     |
|    std                      | 0.108     |
|    value_loss               | 0.0321    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 923      |
|    ep_rew_mean     | 3.48e+03 |
| time/              |          |
|    fps             | 150      |
|    iterations      | 826      |
|    time_elapsed    | 11226    |
|    total_timesteps | 1691648  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 914       |
|    ep_rew_mean              | 3.45e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 827       |
|    time_elapsed             | 11236     |
|    total_timesteps          | 1693696   |
| train/                      |           |
|    approx_kl                | 4.4852033 |
|    clip_fraction            | 0.958     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.3591983 |
|    ent_clip_fraction        | 0.698     |
|    ent_entropy_loss         | 7.51      |
|    ent_loss                 | -0.0204   |
|    ent_policy_gradient_loss | 0.024     |
|    ent_std                  | 0.0948    |
|    ent_value_loss           | 0.00485   |
|    entropy_loss             | 6.45      |
|    explained_variance       | 0.425     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.168     |
|    n_updates                | 8260      |
|    policy_gradient_loss     | 0.219     |
|    std                      | 0.108     |
|    value_loss               | 0.00505   |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 914        |
|    ep_rew_mean              | 3.42e+03   |
| time/                       |            |
|    fps                      | 150        |
|    iterations               | 828        |
|    time_elapsed             | 11247      |
|    total_timesteps          | 1695744    |
| train/                      |            |
|    approx_kl                | 5.692276   |
|    clip_fraction            | 0.971      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.60927284 |
|    ent_clip_fraction        | 0.672      |
|    ent_entropy_loss         | 7.52       |
|    ent_loss                 | 0.00876    |
|    ent_policy_gradient_loss | -0.00983   |
|    ent_std                  | 0.0944     |
|    ent_value_loss           | 0.0414     |
|    entropy_loss             | 6.43       |
|    explained_variance       | 0.642      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.172      |
|    n_updates                | 8270       |
|    policy_gradient_loss     | 0.193      |
|    std                      | 0.108      |
|    value_loss               | 0.0411     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 901       |
|    ep_rew_mean              | 3.37e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 829       |
|    time_elapsed             | 11257     |
|    total_timesteps          | 1697792   |
| train/                      |           |
|    approx_kl                | 3.6391377 |
|    clip_fraction            | 0.912     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 10.607367 |
|    ent_clip_fraction        | 0.724     |
|    ent_entropy_loss         | 7.55      |
|    ent_loss                 | -0.0376   |
|    ent_policy_gradient_loss | -0.0262   |
|    ent_std                  | 0.0939    |
|    ent_value_loss           | 0.0213    |
|    entropy_loss             | 6.41      |
|    explained_variance       | 0.972     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.184     |
|    n_updates                | 8280      |
|    policy_gradient_loss     | 0.152     |
|    std                      | 0.109     |
|    value_loss               | 0.0217    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 894        |
|    ep_rew_mean              | 3.37e+03   |
| time/                       |            |
|    fps                      | 150        |
|    iterations               | 830        |
|    time_elapsed             | 11267      |
|    total_timesteps          | 1699840    |
| train/                      |            |
|    approx_kl                | 4.819904   |
|    clip_fraction            | 0.972      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.76061875 |
|    ent_clip_fraction        | 0.658      |
|    ent_entropy_loss         | 7.58       |
|    ent_loss                 | -0.0153    |
|    ent_policy_gradient_loss | -0.0319    |
|    ent_std                  | 0.0939     |
|    ent_value_loss           | 0.0525     |
|    entropy_loss             | 6.37       |
|    explained_variance       | 0.845      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.259      |
|    n_updates                | 8290       |
|    policy_gradient_loss     | 0.203      |
|    std                      | 0.11       |
|    value_loss               | 0.0508     |
--------------------------------------------
Eval num_timesteps=1700000, episode_reward=4223.16 +/- 1084.12
Episode length: 1000.00 +/- 0.00
--------------------------------------------
| eval/                       |            |
|    mean_ep_length           | 1e+03      |
|    mean_reward              | 4.22e+03   |
| time/                       |            |
|    total_timesteps          | 1700000    |
| train/                      |            |
|    approx_kl                | 4.463337   |
|    clip_fraction            | 0.974      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.34585047 |
|    ent_clip_fraction        | 0.672      |
|    ent_entropy_loss         | 7.56       |
|    ent_loss                 | -0.0615    |
|    ent_policy_gradient_loss | -0.00445   |
|    ent_std                  | 0.0943     |
|    ent_value_loss           | 0.03       |
|    entropy_loss             | 6.31       |
|    explained_variance       | 0.305      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.206      |
|    n_updates                | 8300       |
|    policy_gradient_loss     | 0.2        |
|    std                      | 0.11       |
|    value_loss               | 0.0302     |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 894      |
|    ep_rew_mean     | 3.4e+03  |
| time/              |          |
|    fps             | 150      |
|    iterations      | 831      |
|    time_elapsed    | 11295    |
|    total_timesteps | 1701888  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 894       |
|    ep_rew_mean              | 3.38e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 832       |
|    time_elapsed             | 11305     |
|    total_timesteps          | 1703936   |
| train/                      |           |
|    approx_kl                | 5.323593  |
|    clip_fraction            | 0.966     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.8204508 |
|    ent_clip_fraction        | 0.694     |
|    ent_entropy_loss         | 7.54      |
|    ent_loss                 | -0.0243   |
|    ent_policy_gradient_loss | 0.00262   |
|    ent_std                  | 0.0945    |
|    ent_value_loss           | 0.0157    |
|    entropy_loss             | 6.3       |
|    explained_variance       | 0.969     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.154     |
|    n_updates                | 8310      |
|    policy_gradient_loss     | 0.183     |
|    std                      | 0.11      |
|    value_loss               | 0.0154    |
-------------------------------------------
------------------------------------------
| rollout/                    |          |
|    ep_len_mean              | 896      |
|    ep_rew_mean              | 3.42e+03 |
| time/                       |          |
|    fps                      | 150      |
|    iterations               | 833      |
|    time_elapsed             | 11315    |
|    total_timesteps          | 1705984  |
| train/                      |          |
|    approx_kl                | 3.016967 |
|    clip_fraction            | 0.839    |
|    clip_range               | 0.2      |
|    ent_approx_kl            | 4.150284 |
|    ent_clip_fraction        | 0.839    |
|    ent_entropy_loss         | 7.44     |
|    ent_loss                 | 0.139    |
|    ent_policy_gradient_loss | 0.146    |
|    ent_std                  | 0.0968   |
|    ent_value_loss           | 0.0191   |
|    entropy_loss             | 6.34     |
|    explained_variance       | 0.972    |
|    learning_rate            | 0.0003   |
|    loss                     | -0.00192 |
|    n_updates                | 8320     |
|    policy_gradient_loss     | 0.0142   |
|    std                      | 0.109    |
|    value_loss               | 0.0222   |
------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 909        |
|    ep_rew_mean              | 3.48e+03   |
| time/                       |            |
|    fps                      | 150        |
|    iterations               | 834        |
|    time_elapsed             | 11325      |
|    total_timesteps          | 1708032    |
| train/                      |            |
|    approx_kl                | 4.5282745  |
|    clip_fraction            | 0.966      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.79010665 |
|    ent_clip_fraction        | 0.676      |
|    ent_entropy_loss         | 7.35       |
|    ent_loss                 | -0.0651    |
|    ent_policy_gradient_loss | -0.014     |
|    ent_std                  | 0.0966     |
|    ent_value_loss           | 0.0277     |
|    entropy_loss             | 6.33       |
|    explained_variance       | 0.226      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.212      |
|    n_updates                | 8330       |
|    policy_gradient_loss     | 0.21       |
|    std                      | 0.11       |
|    value_loss               | 0.0254     |
--------------------------------------------
Eval num_timesteps=1710000, episode_reward=2989.06 +/- 1918.42
Episode length: 729.76 +/- 380.30
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 730       |
|    mean_reward              | 2.99e+03  |
| time/                       |           |
|    total_timesteps          | 1710000   |
| train/                      |           |
|    approx_kl                | 4.0975347 |
|    clip_fraction            | 0.949     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.5826406 |
|    ent_clip_fraction        | 0.763     |
|    ent_entropy_loss         | 7.36      |
|    ent_loss                 | -0.0314   |
|    ent_policy_gradient_loss | 0.0161    |
|    ent_std                  | 0.0964    |
|    ent_value_loss           | 0.0106    |
|    entropy_loss             | 6.31      |
|    explained_variance       | 0.113     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.108     |
|    n_updates                | 8340      |
|    policy_gradient_loss     | 0.215     |
|    std                      | 0.11      |
|    value_loss               | 0.0108    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 909      |
|    ep_rew_mean     | 3.48e+03 |
| time/              |          |
|    fps             | 150      |
|    iterations      | 835      |
|    time_elapsed    | 11352    |
|    total_timesteps | 1710080  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 895       |
|    ep_rew_mean              | 3.41e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 836       |
|    time_elapsed             | 11362     |
|    total_timesteps          | 1712128   |
| train/                      |           |
|    approx_kl                | 6.980076  |
|    clip_fraction            | 0.954     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.6342683 |
|    ent_clip_fraction        | 0.709     |
|    ent_entropy_loss         | 7.38      |
|    ent_loss                 | -0.0122   |
|    ent_policy_gradient_loss | 0.0263    |
|    ent_std                  | 0.096     |
|    ent_value_loss           | 0.0224    |
|    entropy_loss             | 6.31      |
|    explained_variance       | 0.971     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.156     |
|    n_updates                | 8350      |
|    policy_gradient_loss     | 0.161     |
|    std                      | 0.11      |
|    value_loss               | 0.0236    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 895       |
|    ep_rew_mean              | 3.39e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 837       |
|    time_elapsed             | 11372     |
|    total_timesteps          | 1714176   |
| train/                      |           |
|    approx_kl                | 7.0750103 |
|    clip_fraction            | 0.944     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.8366232 |
|    ent_clip_fraction        | 0.732     |
|    ent_entropy_loss         | 7.42      |
|    ent_loss                 | 0.0203    |
|    ent_policy_gradient_loss | 0.0534    |
|    ent_std                  | 0.0956    |
|    ent_value_loss           | 0.0469    |
|    entropy_loss             | 6.33      |
|    explained_variance       | 0.938     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.113     |
|    n_updates                | 8360      |
|    policy_gradient_loss     | 0.272     |
|    std                      | 0.11      |
|    value_loss               | 0.046     |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 888       |
|    ep_rew_mean              | 3.36e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 838       |
|    time_elapsed             | 11382     |
|    total_timesteps          | 1716224   |
| train/                      |           |
|    approx_kl                | 6.74241   |
|    clip_fraction            | 0.893     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.5785017 |
|    ent_clip_fraction        | 0.797     |
|    ent_entropy_loss         | 7.41      |
|    ent_loss                 | 0.11      |
|    ent_policy_gradient_loss | 0.087     |
|    ent_std                  | 0.0962    |
|    ent_value_loss           | 0.0281    |
|    entropy_loss             | 6.36      |
|    explained_variance       | 0.953     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0746    |
|    n_updates                | 8370      |
|    policy_gradient_loss     | 0.0851    |
|    std                      | 0.109     |
|    value_loss               | 0.028     |
-------------------------------------------
------------------------------------------
| rollout/                    |          |
|    ep_len_mean              | 888      |
|    ep_rew_mean              | 3.34e+03 |
| time/                       |          |
|    fps                      | 150      |
|    iterations               | 839      |
|    time_elapsed             | 11392    |
|    total_timesteps          | 1718272  |
| train/                      |          |
|    approx_kl                | 3.730206 |
|    clip_fraction            | 0.872    |
|    clip_range               | 0.2      |
|    ent_approx_kl            | 7.625981 |
|    ent_clip_fraction        | 0.822    |
|    ent_entropy_loss         | 7.36     |
|    ent_loss                 | 0.0519   |
|    ent_policy_gradient_loss | 0.111    |
|    ent_std                  | 0.0965   |
|    ent_value_loss           | 0.0286   |
|    entropy_loss             | 6.39     |
|    explained_variance       | 0.319    |
|    learning_rate            | 0.0003   |
|    loss                     | 0.134    |
|    n_updates                | 8380     |
|    policy_gradient_loss     | 0.14     |
|    std                      | 0.109    |
|    value_loss               | 0.0282   |
------------------------------------------
Eval num_timesteps=1720000, episode_reward=3767.69 +/- 1517.93
Episode length: 939.88 +/- 199.88
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 940       |
|    mean_reward              | 3.77e+03  |
| time/                       |           |
|    total_timesteps          | 1720000   |
| train/                      |           |
|    approx_kl                | 6.366264  |
|    clip_fraction            | 0.871     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 4.4656982 |
|    ent_clip_fraction        | 0.791     |
|    ent_entropy_loss         | 7.3       |
|    ent_loss                 | 0.0806    |
|    ent_policy_gradient_loss | 0.12      |
|    ent_std                  | 0.0978    |
|    ent_value_loss           | 0.0122    |
|    entropy_loss             | 6.42      |
|    explained_variance       | 0.978     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0255    |
|    n_updates                | 8390      |
|    policy_gradient_loss     | 0.0191    |
|    std                      | 0.108     |
|    value_loss               | 0.0147    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 888      |
|    ep_rew_mean     | 3.37e+03 |
| time/              |          |
|    fps             | 150      |
|    iterations      | 840      |
|    time_elapsed    | 11420    |
|    total_timesteps | 1720320  |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 888        |
|    ep_rew_mean              | 3.37e+03   |
| time/                       |            |
|    fps                      | 150        |
|    iterations               | 841        |
|    time_elapsed             | 11430      |
|    total_timesteps          | 1722368    |
| train/                      |            |
|    approx_kl                | 4.5100904  |
|    clip_fraction            | 0.965      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.92361933 |
|    ent_clip_fraction        | 0.685      |
|    ent_entropy_loss         | 7.23       |
|    ent_loss                 | 0.00872    |
|    ent_policy_gradient_loss | -0.00923   |
|    ent_std                  | 0.0983     |
|    ent_value_loss           | 0.00725    |
|    entropy_loss             | 6.4        |
|    explained_variance       | 0.817      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.175      |
|    n_updates                | 8400       |
|    policy_gradient_loss     | 0.218      |
|    std                      | 0.109      |
|    value_loss               | 0.00636    |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 878       |
|    ep_rew_mean              | 3.3e+03   |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 842       |
|    time_elapsed             | 11440     |
|    total_timesteps          | 1724416   |
| train/                      |           |
|    approx_kl                | 4.1498327 |
|    clip_fraction            | 0.891     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.1432667 |
|    ent_clip_fraction        | 0.792     |
|    ent_entropy_loss         | 7.2       |
|    ent_loss                 | -0.00168  |
|    ent_policy_gradient_loss | 0.0499    |
|    ent_std                  | 0.0986    |
|    ent_value_loss           | 0.0125    |
|    entropy_loss             | 6.35      |
|    explained_variance       | 0.85      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.291     |
|    n_updates                | 8410      |
|    policy_gradient_loss     | 0.14      |
|    std                      | 0.11      |
|    value_loss               | 0.0134    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 872       |
|    ep_rew_mean              | 3.28e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 843       |
|    time_elapsed             | 11449     |
|    total_timesteps          | 1726464   |
| train/                      |           |
|    approx_kl                | 7.66239   |
|    clip_fraction            | 0.931     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.7499557 |
|    ent_clip_fraction        | 0.716     |
|    ent_entropy_loss         | 7.18      |
|    ent_loss                 | 0.0233    |
|    ent_policy_gradient_loss | 0.0248    |
|    ent_std                  | 0.0987    |
|    ent_value_loss           | 0.0356    |
|    entropy_loss             | 6.3       |
|    explained_variance       | 0.956     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0983    |
|    n_updates                | 8420      |
|    policy_gradient_loss     | 0.127     |
|    std                      | 0.11      |
|    value_loss               | 0.0341    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 872       |
|    ep_rew_mean              | 3.28e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 844       |
|    time_elapsed             | 11459     |
|    total_timesteps          | 1728512   |
| train/                      |           |
|    approx_kl                | 6.1754484 |
|    clip_fraction            | 0.959     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.7050306 |
|    ent_clip_fraction        | 0.693     |
|    ent_entropy_loss         | 7.17      |
|    ent_loss                 | -0.0412   |
|    ent_policy_gradient_loss | 0.00141   |
|    ent_std                  | 0.0988    |
|    ent_value_loss           | 0.0255    |
|    entropy_loss             | 6.29      |
|    explained_variance       | 0.186     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.149     |
|    n_updates                | 8430      |
|    policy_gradient_loss     | 0.158     |
|    std                      | 0.11      |
|    value_loss               | 0.0212    |
-------------------------------------------
Eval num_timesteps=1730000, episode_reward=4013.47 +/- 1250.33
Episode length: 871.52 +/- 243.82
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 872       |
|    mean_reward              | 4.01e+03  |
| time/                       |           |
|    total_timesteps          | 1730000   |
| train/                      |           |
|    approx_kl                | 3.3621082 |
|    clip_fraction            | 0.904     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.2736142 |
|    ent_clip_fraction        | 0.786     |
|    ent_entropy_loss         | 7.19      |
|    ent_loss                 | 0.102     |
|    ent_policy_gradient_loss | 0.071     |
|    ent_std                  | 0.0984    |
|    ent_value_loss           | 0.0132    |
|    entropy_loss             | 6.26      |
|    explained_variance       | 0.521     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0503    |
|    n_updates                | 8440      |
|    policy_gradient_loss     | 0.122     |
|    std                      | 0.111     |
|    value_loss               | 0.0153    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 868      |
|    ep_rew_mean     | 3.28e+03 |
| time/              |          |
|    fps             | 150      |
|    iterations      | 845      |
|    time_elapsed    | 11487    |
|    total_timesteps | 1730560  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 865       |
|    ep_rew_mean              | 3.23e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 846       |
|    time_elapsed             | 11498     |
|    total_timesteps          | 1732608   |
| train/                      |           |
|    approx_kl                | 5.790202  |
|    clip_fraction            | 0.973     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.2600065 |
|    ent_clip_fraction        | 0.645     |
|    ent_entropy_loss         | 7.22      |
|    ent_loss                 | -0.0226   |
|    ent_policy_gradient_loss | -0.0253   |
|    ent_std                  | 0.0981    |
|    ent_value_loss           | 0.0348    |
|    entropy_loss             | 6.22      |
|    explained_variance       | 0.933     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.167     |
|    n_updates                | 8450      |
|    policy_gradient_loss     | 0.184     |
|    std                      | 0.111     |
|    value_loss               | 0.0354    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 867       |
|    ep_rew_mean              | 3.25e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 847       |
|    time_elapsed             | 11508     |
|    total_timesteps          | 1734656   |
| train/                      |           |
|    approx_kl                | 6.226465  |
|    clip_fraction            | 0.944     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.6770895 |
|    ent_clip_fraction        | 0.7       |
|    ent_entropy_loss         | 7.23      |
|    ent_loss                 | 0.14      |
|    ent_policy_gradient_loss | 0.0333    |
|    ent_std                  | 0.098     |
|    ent_value_loss           | 0.02      |
|    entropy_loss             | 6.25      |
|    explained_variance       | 0.972     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0848    |
|    n_updates                | 8460      |
|    policy_gradient_loss     | 0.153     |
|    std                      | 0.111     |
|    value_loss               | 0.0207    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 867       |
|    ep_rew_mean              | 3.25e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 848       |
|    time_elapsed             | 11518     |
|    total_timesteps          | 1736704   |
| train/                      |           |
|    approx_kl                | 3.488189  |
|    clip_fraction            | 0.94      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.7535335 |
|    ent_clip_fraction        | 0.725     |
|    ent_entropy_loss         | 7.28      |
|    ent_loss                 | 0.02      |
|    ent_policy_gradient_loss | 0.00206   |
|    ent_std                  | 0.0972    |
|    ent_value_loss           | 0.00586   |
|    entropy_loss             | 6.25      |
|    explained_variance       | 0.499     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.184     |
|    n_updates                | 8470      |
|    policy_gradient_loss     | 0.266     |
|    std                      | 0.111     |
|    value_loss               | 0.00573   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 878       |
|    ep_rew_mean              | 3.27e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 849       |
|    time_elapsed             | 11528     |
|    total_timesteps          | 1738752   |
| train/                      |           |
|    approx_kl                | 4.724086  |
|    clip_fraction            | 0.95      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.9228868 |
|    ent_clip_fraction        | 0.745     |
|    ent_entropy_loss         | 7.3       |
|    ent_loss                 | -0.0143   |
|    ent_policy_gradient_loss | 0.0206    |
|    ent_std                  | 0.0971    |
|    ent_value_loss           | 0.0119    |
|    entropy_loss             | 6.25      |
|    explained_variance       | 0.541     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0845    |
|    n_updates                | 8480      |
|    policy_gradient_loss     | 0.175     |
|    std                      | 0.111     |
|    value_loss               | 0.0123    |
-------------------------------------------
Eval num_timesteps=1740000, episode_reward=3853.33 +/- 1629.96
Episode length: 847.04 +/- 313.59
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 847       |
|    mean_reward              | 3.85e+03  |
| time/                       |           |
|    total_timesteps          | 1740000   |
| train/                      |           |
|    approx_kl                | 8.22723   |
|    clip_fraction            | 0.957     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.2093468 |
|    ent_clip_fraction        | 0.705     |
|    ent_entropy_loss         | 7.29      |
|    ent_loss                 | 0.048     |
|    ent_policy_gradient_loss | 0.0278    |
|    ent_std                  | 0.0974    |
|    ent_value_loss           | 0.012     |
|    entropy_loss             | 6.26      |
|    explained_variance       | 0.977     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.146     |
|    n_updates                | 8490      |
|    policy_gradient_loss     | 0.149     |
|    std                      | 0.11      |
|    value_loss               | 0.0114    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 874      |
|    ep_rew_mean     | 3.25e+03 |
| time/              |          |
|    fps             | 150      |
|    iterations      | 850      |
|    time_elapsed    | 11556    |
|    total_timesteps | 1740800  |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 880        |
|    ep_rew_mean              | 3.28e+03   |
| time/                       |            |
|    fps                      | 150        |
|    iterations               | 851        |
|    time_elapsed             | 11566      |
|    total_timesteps          | 1742848    |
| train/                      |            |
|    approx_kl                | 4.650209   |
|    clip_fraction            | 0.967      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.71543336 |
|    ent_clip_fraction        | 0.679      |
|    ent_entropy_loss         | 7.28       |
|    ent_loss                 | -0.00335   |
|    ent_policy_gradient_loss | -0.00929   |
|    ent_std                  | 0.0976     |
|    ent_value_loss           | 0.0226     |
|    entropy_loss             | 6.27       |
|    explained_variance       | 0.641      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.237      |
|    n_updates                | 8500       |
|    policy_gradient_loss     | 0.194      |
|    std                      | 0.111      |
|    value_loss               | 0.023      |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 872       |
|    ep_rew_mean              | 3.28e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 852       |
|    time_elapsed             | 11576     |
|    total_timesteps          | 1744896   |
| train/                      |           |
|    approx_kl                | 4.5212235 |
|    clip_fraction            | 0.962     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.6317208 |
|    ent_clip_fraction        | 0.663     |
|    ent_entropy_loss         | 7.28      |
|    ent_loss                 | 0.00881   |
|    ent_policy_gradient_loss | -0.0108   |
|    ent_std                  | 0.0973    |
|    ent_value_loss           | 0.00753   |
|    entropy_loss             | 6.28      |
|    explained_variance       | 0.615     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.14      |
|    n_updates                | 8510      |
|    policy_gradient_loss     | 0.191     |
|    std                      | 0.11      |
|    value_loss               | 0.00707   |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 871        |
|    ep_rew_mean              | 3.26e+03   |
| time/                       |            |
|    fps                      | 150        |
|    iterations               | 853        |
|    time_elapsed             | 11586      |
|    total_timesteps          | 1746944    |
| train/                      |            |
|    approx_kl                | 3.9117951  |
|    clip_fraction            | 0.959      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.83141947 |
|    ent_clip_fraction        | 0.665      |
|    ent_entropy_loss         | 7.33       |
|    ent_loss                 | 0.00554    |
|    ent_policy_gradient_loss | -0.00196   |
|    ent_std                  | 0.0965     |
|    ent_value_loss           | 0.0242     |
|    entropy_loss             | 6.29       |
|    explained_variance       | 0.524      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.149      |
|    n_updates                | 8520       |
|    policy_gradient_loss     | 0.171      |
|    std                      | 0.11       |
|    value_loss               | 0.0244     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 871        |
|    ep_rew_mean              | 3.27e+03   |
| time/                       |            |
|    fps                      | 150        |
|    iterations               | 854        |
|    time_elapsed             | 11596      |
|    total_timesteps          | 1748992    |
| train/                      |            |
|    approx_kl                | 8.808268   |
|    clip_fraction            | 0.977      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.32793757 |
|    ent_clip_fraction        | 0.65       |
|    ent_entropy_loss         | 7.37       |
|    ent_loss                 | -0.046     |
|    ent_policy_gradient_loss | -0.0207    |
|    ent_std                  | 0.0962     |
|    ent_value_loss           | 0.0357     |
|    entropy_loss             | 6.27       |
|    explained_variance       | 0.955      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.188      |
|    n_updates                | 8530       |
|    policy_gradient_loss     | 0.163      |
|    std                      | 0.11       |
|    value_loss               | 0.0339     |
--------------------------------------------
Eval num_timesteps=1750000, episode_reward=3764.40 +/- 1356.66
Episode length: 958.04 +/- 130.57
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 958       |
|    mean_reward              | 3.76e+03  |
| time/                       |           |
|    total_timesteps          | 1750000   |
| train/                      |           |
|    approx_kl                | 3.9646714 |
|    clip_fraction            | 0.942     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.1928464 |
|    ent_clip_fraction        | 0.734     |
|    ent_entropy_loss         | 7.38      |
|    ent_loss                 | -0.0481   |
|    ent_policy_gradient_loss | 0.024     |
|    ent_std                  | 0.0964    |
|    ent_value_loss           | 0.0068    |
|    entropy_loss             | 6.26      |
|    explained_variance       | 0.184     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.132     |
|    n_updates                | 8540      |
|    policy_gradient_loss     | 0.218     |
|    std                      | 0.111     |
|    value_loss               | 0.00694   |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 863      |
|    ep_rew_mean     | 3.25e+03 |
| time/              |          |
|    fps             | 150      |
|    iterations      | 855      |
|    time_elapsed    | 11625    |
|    total_timesteps | 1751040  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 862       |
|    ep_rew_mean              | 3.23e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 856       |
|    time_elapsed             | 11635     |
|    total_timesteps          | 1753088   |
| train/                      |           |
|    approx_kl                | 4.7254014 |
|    clip_fraction            | 0.969     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.765489  |
|    ent_clip_fraction        | 0.663     |
|    ent_entropy_loss         | 7.36      |
|    ent_loss                 | 0.00363   |
|    ent_policy_gradient_loss | -0.0111   |
|    ent_std                  | 0.0965    |
|    ent_value_loss           | 0.0276    |
|    entropy_loss             | 6.23      |
|    explained_variance       | 0.451     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.222     |
|    n_updates                | 8550      |
|    policy_gradient_loss     | 0.197     |
|    std                      | 0.111     |
|    value_loss               | 0.0275    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 860       |
|    ep_rew_mean              | 3.22e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 857       |
|    time_elapsed             | 11645     |
|    total_timesteps          | 1755136   |
| train/                      |           |
|    approx_kl                | 6.112163  |
|    clip_fraction            | 0.969     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.8391979 |
|    ent_clip_fraction        | 0.666     |
|    ent_entropy_loss         | 7.37      |
|    ent_loss                 | 0.00105   |
|    ent_policy_gradient_loss | 0.00382   |
|    ent_std                  | 0.0962    |
|    ent_value_loss           | 0.035     |
|    entropy_loss             | 6.22      |
|    explained_variance       | 0.943     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.201     |
|    n_updates                | 8560      |
|    policy_gradient_loss     | 0.17      |
|    std                      | 0.111     |
|    value_loss               | 0.0339    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 865       |
|    ep_rew_mean              | 3.21e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 858       |
|    time_elapsed             | 11655     |
|    total_timesteps          | 1757184   |
| train/                      |           |
|    approx_kl                | 5.891004  |
|    clip_fraction            | 0.976     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.5033279 |
|    ent_clip_fraction        | 0.641     |
|    ent_entropy_loss         | 7.38      |
|    ent_loss                 | -0.0317   |
|    ent_policy_gradient_loss | -0.034    |
|    ent_std                  | 0.0963    |
|    ent_value_loss           | 0.0419    |
|    entropy_loss             | 6.19      |
|    explained_variance       | 0.611     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.219     |
|    n_updates                | 8570      |
|    policy_gradient_loss     | 0.22      |
|    std                      | 0.112     |
|    value_loss               | 0.0433    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 858       |
|    ep_rew_mean              | 3.17e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 859       |
|    time_elapsed             | 11666     |
|    total_timesteps          | 1759232   |
| train/                      |           |
|    approx_kl                | 8.199579  |
|    clip_fraction            | 0.961     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.4350059 |
|    ent_clip_fraction        | 0.698     |
|    ent_entropy_loss         | 7.37      |
|    ent_loss                 | 0.0538    |
|    ent_policy_gradient_loss | 0.0179    |
|    ent_std                  | 0.0963    |
|    ent_value_loss           | 0.0177    |
|    entropy_loss             | 6.21      |
|    explained_variance       | 0.979     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.15      |
|    n_updates                | 8580      |
|    policy_gradient_loss     | 0.198     |
|    std                      | 0.111     |
|    value_loss               | 0.0178    |
-------------------------------------------
Eval num_timesteps=1760000, episode_reward=3905.00 +/- 1457.01
Episode length: 898.12 +/- 266.92
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 898       |
|    mean_reward              | 3.91e+03  |
| time/                       |           |
|    total_timesteps          | 1760000   |
| train/                      |           |
|    approx_kl                | 4.727569  |
|    clip_fraction            | 0.946     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.7979931 |
|    ent_clip_fraction        | 0.735     |
|    ent_entropy_loss         | 7.37      |
|    ent_loss                 | 0.0268    |
|    ent_policy_gradient_loss | 0.0184    |
|    ent_std                  | 0.0965    |
|    ent_value_loss           | 0.0316    |
|    entropy_loss             | 6.21      |
|    explained_variance       | 0.563     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.239     |
|    n_updates                | 8590      |
|    policy_gradient_loss     | 0.163     |
|    std                      | 0.111     |
|    value_loss               | 0.0307    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 853      |
|    ep_rew_mean     | 3.12e+03 |
| time/              |          |
|    fps             | 150      |
|    iterations      | 860      |
|    time_elapsed    | 11694    |
|    total_timesteps | 1761280  |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 827        |
|    ep_rew_mean              | 3.04e+03   |
| time/                       |            |
|    fps                      | 150        |
|    iterations               | 861        |
|    time_elapsed             | 11704      |
|    total_timesteps          | 1763328    |
| train/                      |            |
|    approx_kl                | 12.51123   |
|    clip_fraction            | 0.981      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.38133803 |
|    ent_clip_fraction        | 0.627      |
|    ent_entropy_loss         | 7.38       |
|    ent_loss                 | -0.0689    |
|    ent_policy_gradient_loss | -0.0268    |
|    ent_std                  | 0.0961     |
|    ent_value_loss           | 0.035      |
|    entropy_loss             | 6.21       |
|    explained_variance       | 0.947      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.209      |
|    n_updates                | 8600       |
|    policy_gradient_loss     | 0.209      |
|    std                      | 0.111      |
|    value_loss               | 0.032      |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 820        |
|    ep_rew_mean              | 3.04e+03   |
| time/                       |            |
|    fps                      | 150        |
|    iterations               | 862        |
|    time_elapsed             | 11715      |
|    total_timesteps          | 1765376    |
| train/                      |            |
|    approx_kl                | 5.1267405  |
|    clip_fraction            | 0.956      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.69389355 |
|    ent_clip_fraction        | 0.688      |
|    ent_entropy_loss         | 7.43       |
|    ent_loss                 | 0.0305     |
|    ent_policy_gradient_loss | -0.00237   |
|    ent_std                  | 0.0953     |
|    ent_value_loss           | 0.0725     |
|    entropy_loss             | 6.24       |
|    explained_variance       | 0.85       |
|    learning_rate            | 0.0003     |
|    loss                     | 0.194      |
|    n_updates                | 8610       |
|    policy_gradient_loss     | 0.177      |
|    std                      | 0.111      |
|    value_loss               | 0.0744     |
--------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 825        |
|    ep_rew_mean              | 3.06e+03   |
| time/                       |            |
|    fps                      | 150        |
|    iterations               | 863        |
|    time_elapsed             | 11725      |
|    total_timesteps          | 1767424    |
| train/                      |            |
|    approx_kl                | 4.741555   |
|    clip_fraction            | 0.97       |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.45714346 |
|    ent_clip_fraction        | 0.657      |
|    ent_entropy_loss         | 7.44       |
|    ent_loss                 | -0.0194    |
|    ent_policy_gradient_loss | -0.0172    |
|    ent_std                  | 0.0955     |
|    ent_value_loss           | 0.0399     |
|    entropy_loss             | 6.26       |
|    explained_variance       | 0.386      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.111      |
|    n_updates                | 8620       |
|    policy_gradient_loss     | 0.182      |
|    std                      | 0.111      |
|    value_loss               | 0.0389     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 816       |
|    ep_rew_mean              | 3.06e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 864       |
|    time_elapsed             | 11735     |
|    total_timesteps          | 1769472   |
| train/                      |           |
|    approx_kl                | 4.6566935 |
|    clip_fraction            | 0.961     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.2682616 |
|    ent_clip_fraction        | 0.728     |
|    ent_entropy_loss         | 7.44      |
|    ent_loss                 | -0.0214   |
|    ent_policy_gradient_loss | -0.0111   |
|    ent_std                  | 0.0956    |
|    ent_value_loss           | 0.00675   |
|    entropy_loss             | 6.23      |
|    explained_variance       | 0.364     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.136     |
|    n_updates                | 8630      |
|    policy_gradient_loss     | 0.221     |
|    std                      | 0.111     |
|    value_loss               | 0.00735   |
-------------------------------------------
Eval num_timesteps=1770000, episode_reward=3916.28 +/- 1280.81
Episode length: 874.00 +/- 278.46
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 874       |
|    mean_reward              | 3.92e+03  |
| time/                       |           |
|    total_timesteps          | 1770000   |
| train/                      |           |
|    approx_kl                | 3.7339015 |
|    clip_fraction            | 0.931     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 13.932423 |
|    ent_clip_fraction        | 0.693     |
|    ent_entropy_loss         | 7.46      |
|    ent_loss                 | -0.0616   |
|    ent_policy_gradient_loss | 0.0539    |
|    ent_std                  | 0.095     |
|    ent_value_loss           | 0.0328    |
|    entropy_loss             | 6.2       |
|    explained_variance       | 0.939     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.18      |
|    n_updates                | 8640      |
|    policy_gradient_loss     | 0.177     |
|    std                      | 0.112     |
|    value_loss               | 0.0353    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 820      |
|    ep_rew_mean     | 3.01e+03 |
| time/              |          |
|    fps             | 150      |
|    iterations      | 865      |
|    time_elapsed    | 11763    |
|    total_timesteps | 1771520  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 820       |
|    ep_rew_mean              | 3e+03     |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 866       |
|    time_elapsed             | 11773     |
|    total_timesteps          | 1773568   |
| train/                      |           |
|    approx_kl                | 3.9198003 |
|    clip_fraction            | 0.848     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 6.064109  |
|    ent_clip_fraction        | 0.838     |
|    ent_entropy_loss         | 7.5       |
|    ent_loss                 | 0.0116    |
|    ent_policy_gradient_loss | 0.0722    |
|    ent_std                  | 0.0949    |
|    ent_value_loss           | 0.0161    |
|    entropy_loss             | 6.2       |
|    explained_variance       | 0.982     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0953    |
|    n_updates                | 8650      |
|    policy_gradient_loss     | 0.118     |
|    std                      | 0.111     |
|    value_loss               | 0.0181    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 820       |
|    ep_rew_mean              | 3e+03     |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 867       |
|    time_elapsed             | 11783     |
|    total_timesteps          | 1775616   |
| train/                      |           |
|    approx_kl                | 4.738855  |
|    clip_fraction            | 0.96      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.4415579 |
|    ent_clip_fraction        | 0.741     |
|    ent_entropy_loss         | 7.49      |
|    ent_loss                 | 0.0254    |
|    ent_policy_gradient_loss | 0.00538   |
|    ent_std                  | 0.0951    |
|    ent_value_loss           | 0.02      |
|    entropy_loss             | 6.23      |
|    explained_variance       | 0.387     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.187     |
|    n_updates                | 8660      |
|    policy_gradient_loss     | 0.178     |
|    std                      | 0.111     |
|    value_loss               | 0.0184    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 829       |
|    ep_rew_mean              | 3.05e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 868       |
|    time_elapsed             | 11793     |
|    total_timesteps          | 1777664   |
| train/                      |           |
|    approx_kl                | 4.196825  |
|    clip_fraction            | 0.886     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.7309332 |
|    ent_clip_fraction        | 0.818     |
|    ent_entropy_loss         | 7.46      |
|    ent_loss                 | 0.0367    |
|    ent_policy_gradient_loss | 0.063     |
|    ent_std                  | 0.0956    |
|    ent_value_loss           | 0.00742   |
|    entropy_loss             | 6.25      |
|    explained_variance       | 0.281     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.118     |
|    n_updates                | 8670      |
|    policy_gradient_loss     | 0.174     |
|    std                      | 0.111     |
|    value_loss               | 0.00839   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 823       |
|    ep_rew_mean              | 3.09e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 869       |
|    time_elapsed             | 11804     |
|    total_timesteps          | 1779712   |
| train/                      |           |
|    approx_kl                | 4.8297634 |
|    clip_fraction            | 0.969     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.153477  |
|    ent_clip_fraction        | 0.69      |
|    ent_entropy_loss         | 7.45      |
|    ent_loss                 | -0.0722   |
|    ent_policy_gradient_loss | -0.0214   |
|    ent_std                  | 0.0955    |
|    ent_value_loss           | 0.00522   |
|    entropy_loss             | 6.24      |
|    explained_variance       | 0.618     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.176     |
|    n_updates                | 8680      |
|    policy_gradient_loss     | 0.252     |
|    std                      | 0.111     |
|    value_loss               | 0.00534   |
-------------------------------------------
Eval num_timesteps=1780000, episode_reward=4654.63 +/- 211.86
Episode length: 1000.00 +/- 0.00
------------------------------------------
| eval/                       |          |
|    mean_ep_length           | 1e+03    |
|    mean_reward              | 4.65e+03 |
| time/                       |          |
|    total_timesteps          | 1780000  |
| train/                      |          |
|    approx_kl                | 7.186971 |
|    clip_fraction            | 0.911    |
|    clip_range               | 0.2      |
|    ent_approx_kl            | 3.125513 |
|    ent_clip_fraction        | 0.777    |
|    ent_entropy_loss         | 7.46     |
|    ent_loss                 | 0.00725  |
|    ent_policy_gradient_loss | 0.0288   |
|    ent_std                  | 0.0952   |
|    ent_value_loss           | 0.0199   |
|    entropy_loss             | 6.26     |
|    explained_variance       | 0.948    |
|    learning_rate            | 0.0003   |
|    loss                     | 0.11     |
|    n_updates                | 8690     |
|    policy_gradient_loss     | 0.137    |
|    std                      | 0.11     |
|    value_loss               | 0.0198   |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 837      |
|    ep_rew_mean     | 3.12e+03 |
| time/              |          |
|    fps             | 150      |
|    iterations      | 870      |
|    time_elapsed    | 11832    |
|    total_timesteps | 1781760  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 835       |
|    ep_rew_mean              | 3.1e+03   |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 871       |
|    time_elapsed             | 11843     |
|    total_timesteps          | 1783808   |
| train/                      |           |
|    approx_kl                | 5.992938  |
|    clip_fraction            | 0.97      |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.7434809 |
|    ent_clip_fraction        | 0.666     |
|    ent_entropy_loss         | 7.5       |
|    ent_loss                 | 0.0172    |
|    ent_policy_gradient_loss | -0.00987  |
|    ent_std                  | 0.0946    |
|    ent_value_loss           | 0.0333    |
|    entropy_loss             | 6.28      |
|    explained_variance       | 0.937     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0682    |
|    n_updates                | 8700      |
|    policy_gradient_loss     | 0.167     |
|    std                      | 0.11      |
|    value_loss               | 0.0338    |
-------------------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 831        |
|    ep_rew_mean              | 3.1e+03    |
| time/                       |            |
|    fps                      | 150        |
|    iterations               | 872        |
|    time_elapsed             | 11853      |
|    total_timesteps          | 1785856    |
| train/                      |            |
|    approx_kl                | 4.7685     |
|    clip_fraction            | 0.968      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.59501684 |
|    ent_clip_fraction        | 0.674      |
|    ent_entropy_loss         | 7.53       |
|    ent_loss                 | -0.0485    |
|    ent_policy_gradient_loss | -0.0155    |
|    ent_std                  | 0.0947     |
|    ent_value_loss           | 0.0295     |
|    entropy_loss             | 6.3        |
|    explained_variance       | 0.375      |
|    learning_rate            | 0.0003     |
|    loss                     | 0.267      |
|    n_updates                | 8710       |
|    policy_gradient_loss     | 0.185      |
|    std                      | 0.11       |
|    value_loss               | 0.0289     |
--------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 822       |
|    ep_rew_mean              | 3.09e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 873       |
|    time_elapsed             | 11864     |
|    total_timesteps          | 1787904   |
| train/                      |           |
|    approx_kl                | 5.535943  |
|    clip_fraction            | 0.942     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.6104003 |
|    ent_clip_fraction        | 0.74      |
|    ent_entropy_loss         | 7.49      |
|    ent_loss                 | -0.00201  |
|    ent_policy_gradient_loss | 0.0167    |
|    ent_std                  | 0.0951    |
|    ent_value_loss           | 0.0236    |
|    entropy_loss             | 6.33      |
|    explained_variance       | 0.478     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.253     |
|    n_updates                | 8720      |
|    policy_gradient_loss     | 0.188     |
|    std                      | 0.11      |
|    value_loss               | 0.0235    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 822       |
|    ep_rew_mean              | 3.05e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 874       |
|    time_elapsed             | 11874     |
|    total_timesteps          | 1789952   |
| train/                      |           |
|    approx_kl                | 4.4433427 |
|    clip_fraction            | 0.968     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.8750392 |
|    ent_clip_fraction        | 0.665     |
|    ent_entropy_loss         | 7.49      |
|    ent_loss                 | 0.0145    |
|    ent_policy_gradient_loss | -0.00347  |
|    ent_std                  | 0.0949    |
|    ent_value_loss           | 0.0438    |
|    entropy_loss             | 6.31      |
|    explained_variance       | 0.567     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.131     |
|    n_updates                | 8730      |
|    policy_gradient_loss     | 0.174     |
|    std                      | 0.11      |
|    value_loss               | 0.0439    |
-------------------------------------------
Eval num_timesteps=1790000, episode_reward=4056.34 +/- 1220.21
Episode length: 960.64 +/- 188.18
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 961       |
|    mean_reward              | 4.06e+03  |
| time/                       |           |
|    total_timesteps          | 1790000   |
| train/                      |           |
|    approx_kl                | 8.229847  |
|    clip_fraction            | 0.954     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.4475138 |
|    ent_clip_fraction        | 0.701     |
|    ent_entropy_loss         | 7.49      |
|    ent_loss                 | 0.00218   |
|    ent_policy_gradient_loss | 0.015     |
|    ent_std                  | 0.0951    |
|    ent_value_loss           | 0.0186    |
|    entropy_loss             | 6.31      |
|    explained_variance       | 0.982     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.129     |
|    n_updates                | 8740      |
|    policy_gradient_loss     | 0.14      |
|    std                      | 0.11      |
|    value_loss               | 0.0194    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 822      |
|    ep_rew_mean     | 3.06e+03 |
| time/              |          |
|    fps             | 150      |
|    iterations      | 875      |
|    time_elapsed    | 11901    |
|    total_timesteps | 1792000  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 822       |
|    ep_rew_mean              | 3.11e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 876       |
|    time_elapsed             | 11911     |
|    total_timesteps          | 1794048   |
| train/                      |           |
|    approx_kl                | 4.7528067 |
|    clip_fraction            | 0.976     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.6675341 |
|    ent_clip_fraction        | 0.662     |
|    ent_entropy_loss         | 7.47      |
|    ent_loss                 | -0.0655   |
|    ent_policy_gradient_loss | -0.0309   |
|    ent_std                  | 0.0954    |
|    ent_value_loss           | 0.00822   |
|    entropy_loss             | 6.3       |
|    explained_variance       | 0.245     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.212     |
|    n_updates                | 8750      |
|    policy_gradient_loss     | 0.218     |
|    std                      | 0.11      |
|    value_loss               | 0.00817   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 836       |
|    ep_rew_mean              | 3.16e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 877       |
|    time_elapsed             | 11921     |
|    total_timesteps          | 1796096   |
| train/                      |           |
|    approx_kl                | 3.3414657 |
|    clip_fraction            | 0.932     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.5647368 |
|    ent_clip_fraction        | 0.765     |
|    ent_entropy_loss         | 7.5       |
|    ent_loss                 | -0.0141   |
|    ent_policy_gradient_loss | 0.0198    |
|    ent_std                  | 0.0948    |
|    ent_value_loss           | 0.00602   |
|    entropy_loss             | 6.3       |
|    explained_variance       | 0.588     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.129     |
|    n_updates                | 8760      |
|    policy_gradient_loss     | 0.217     |
|    std                      | 0.11      |
|    value_loss               | 0.00595   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 836       |
|    ep_rew_mean              | 3.18e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 878       |
|    time_elapsed             | 11932     |
|    total_timesteps          | 1798144   |
| train/                      |           |
|    approx_kl                | 4.0659924 |
|    clip_fraction            | 0.949     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.9567277 |
|    ent_clip_fraction        | 0.724     |
|    ent_entropy_loss         | 7.49      |
|    ent_loss                 | 0.00677   |
|    ent_policy_gradient_loss | 0.0118    |
|    ent_std                  | 0.0952    |
|    ent_value_loss           | 0.00638   |
|    entropy_loss             | 6.26      |
|    explained_variance       | 0.627     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.169     |
|    n_updates                | 8770      |
|    policy_gradient_loss     | 0.216     |
|    std                      | 0.111     |
|    value_loss               | 0.00682   |
-------------------------------------------
Eval num_timesteps=1800000, episode_reward=4064.45 +/- 1339.71
Episode length: 964.56 +/- 164.48
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 965       |
|    mean_reward              | 4.06e+03  |
| time/                       |           |
|    total_timesteps          | 1800000   |
| train/                      |           |
|    approx_kl                | 5.1272097 |
|    clip_fraction            | 0.974     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.3723342 |
|    ent_clip_fraction        | 0.619     |
|    ent_entropy_loss         | 7.47      |
|    ent_loss                 | -0.0642   |
|    ent_policy_gradient_loss | -0.0301   |
|    ent_std                  | 0.0955    |
|    ent_value_loss           | 0.0132    |
|    entropy_loss             | 6.2       |
|    explained_variance       | 0.931     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.181     |
|    n_updates                | 8780      |
|    policy_gradient_loss     | 0.208     |
|    std                      | 0.112     |
|    value_loss               | 0.0131    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 843      |
|    ep_rew_mean     | 3.19e+03 |
| time/              |          |
|    fps             | 150      |
|    iterations      | 879      |
|    time_elapsed    | 11960    |
|    total_timesteps | 1800192  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 843       |
|    ep_rew_mean              | 3.19e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 880       |
|    time_elapsed             | 11970     |
|    total_timesteps          | 1802240   |
| train/                      |           |
|    approx_kl                | 6.065531  |
|    clip_fraction            | 0.776     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 4.9070883 |
|    ent_clip_fraction        | 0.88      |
|    ent_entropy_loss         | 7.36      |
|    ent_loss                 | 0.0514    |
|    ent_policy_gradient_loss | 0.158     |
|    ent_std                  | 0.0978    |
|    ent_value_loss           | 0.014     |
|    entropy_loss             | 6.17      |
|    explained_variance       | 0.986     |
|    learning_rate            | 0.0003    |
|    loss                     | -0.00912  |
|    n_updates                | 8790      |
|    policy_gradient_loss     | -0.0142   |
|    std                      | 0.112     |
|    value_loss               | 0.0159    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 839       |
|    ep_rew_mean              | 3.18e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 881       |
|    time_elapsed             | 11980     |
|    total_timesteps          | 1804288   |
| train/                      |           |
|    approx_kl                | 5.554393  |
|    clip_fraction            | 0.944     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.8457623 |
|    ent_clip_fraction        | 0.723     |
|    ent_entropy_loss         | 7.28      |
|    ent_loss                 | -0.0254   |
|    ent_policy_gradient_loss | 0.0252    |
|    ent_std                  | 0.0974    |
|    ent_value_loss           | 0.00587   |
|    entropy_loss             | 6.13      |
|    explained_variance       | 0.992     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.211     |
|    n_updates                | 8800      |
|    policy_gradient_loss     | 0.175     |
|    std                      | 0.113     |
|    value_loss               | 0.00528   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 839       |
|    ep_rew_mean              | 3.14e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 882       |
|    time_elapsed             | 11991     |
|    total_timesteps          | 1806336   |
| train/                      |           |
|    approx_kl                | 3.4005904 |
|    clip_fraction            | 0.934     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.7778847 |
|    ent_clip_fraction        | 0.721     |
|    ent_entropy_loss         | 7.31      |
|    ent_loss                 | 0.0513    |
|    ent_policy_gradient_loss | 0.0226    |
|    ent_std                  | 0.0969    |
|    ent_value_loss           | 0.0303    |
|    entropy_loss             | 6.12      |
|    explained_variance       | 0.525     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.17      |
|    n_updates                | 8810      |
|    policy_gradient_loss     | 0.155     |
|    std                      | 0.113     |
|    value_loss               | 0.0299    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 841       |
|    ep_rew_mean              | 3.16e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 883       |
|    time_elapsed             | 12001     |
|    total_timesteps          | 1808384   |
| train/                      |           |
|    approx_kl                | 10.306994 |
|    clip_fraction            | 0.938     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.4586622 |
|    ent_clip_fraction        | 0.697     |
|    ent_entropy_loss         | 7.32      |
|    ent_loss                 | 0.106     |
|    ent_policy_gradient_loss | 0.0578    |
|    ent_std                  | 0.0972    |
|    ent_value_loss           | 0.00976   |
|    entropy_loss             | 6.16      |
|    explained_variance       | 0.988     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0138    |
|    n_updates                | 8820      |
|    policy_gradient_loss     | 0.102     |
|    std                      | 0.112     |
|    value_loss               | 0.0102    |
-------------------------------------------
Eval num_timesteps=1810000, episode_reward=3311.81 +/- 1611.21
Episode length: 790.88 +/- 334.77
------------------------------------------
| eval/                       |          |
|    mean_ep_length           | 791      |
|    mean_reward              | 3.31e+03 |
| time/                       |          |
|    total_timesteps          | 1810000  |
| train/                      |          |
|    approx_kl                | 7.86707  |
|    clip_fraction            | 0.939    |
|    clip_range               | 0.2      |
|    ent_approx_kl            | 2.262969 |
|    ent_clip_fraction        | 0.741    |
|    ent_entropy_loss         | 7.33     |
|    ent_loss                 | 0.00158  |
|    ent_policy_gradient_loss | 0.0765   |
|    ent_std                  | 0.0967   |
|    ent_value_loss           | 0.0173   |
|    entropy_loss             | 6.21     |
|    explained_variance       | 0.978    |
|    learning_rate            | 0.0003   |
|    loss                     | 0.131    |
|    n_updates                | 8830     |
|    policy_gradient_loss     | 0.131    |
|    std                      | 0.111    |
|    value_loss               | 0.0176   |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 856      |
|    ep_rew_mean     | 3.21e+03 |
| time/              |          |
|    fps             | 150      |
|    iterations      | 884      |
|    time_elapsed    | 12028    |
|    total_timesteps | 1810432  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 847       |
|    ep_rew_mean              | 3.16e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 885       |
|    time_elapsed             | 12038     |
|    total_timesteps          | 1812480   |
| train/                      |           |
|    approx_kl                | 6.0708036 |
|    clip_fraction            | 0.915     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 2.353251  |
|    ent_clip_fraction        | 0.752     |
|    ent_entropy_loss         | 7.33      |
|    ent_loss                 | 0.0447    |
|    ent_policy_gradient_loss | 0.0664    |
|    ent_std                  | 0.0974    |
|    ent_value_loss           | 0.0173    |
|    entropy_loss             | 6.21      |
|    explained_variance       | 0.978     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0617    |
|    n_updates                | 8840      |
|    policy_gradient_loss     | 0.125     |
|    std                      | 0.112     |
|    value_loss               | 0.0177    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 841       |
|    ep_rew_mean              | 3.14e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 886       |
|    time_elapsed             | 12048     |
|    total_timesteps          | 1814528   |
| train/                      |           |
|    approx_kl                | 6.251119  |
|    clip_fraction            | 0.874     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.0486293 |
|    ent_clip_fraction        | 0.781     |
|    ent_entropy_loss         | 7.3       |
|    ent_loss                 | 0.0471    |
|    ent_policy_gradient_loss | 0.0683    |
|    ent_std                  | 0.0974    |
|    ent_value_loss           | 0.0424    |
|    entropy_loss             | 6.22      |
|    explained_variance       | 0.929     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.08      |
|    n_updates                | 8850      |
|    policy_gradient_loss     | 0.0965    |
|    std                      | 0.111     |
|    value_loss               | 0.0435    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 841       |
|    ep_rew_mean              | 3.17e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 887       |
|    time_elapsed             | 12058     |
|    total_timesteps          | 1816576   |
| train/                      |           |
|    approx_kl                | 4.2565904 |
|    clip_fraction            | 0.966     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.3559103 |
|    ent_clip_fraction        | 0.689     |
|    ent_entropy_loss         | 7.32      |
|    ent_loss                 | -0.0238   |
|    ent_policy_gradient_loss | -0.0148   |
|    ent_std                  | 0.0969    |
|    ent_value_loss           | 0.0306    |
|    entropy_loss             | 6.21      |
|    explained_variance       | 0.375     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.222     |
|    n_updates                | 8860      |
|    policy_gradient_loss     | 0.189     |
|    std                      | 0.112     |
|    value_loss               | 0.0295    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 849       |
|    ep_rew_mean              | 3.2e+03   |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 888       |
|    time_elapsed             | 12068     |
|    total_timesteps          | 1818624   |
| train/                      |           |
|    approx_kl                | 4.933815  |
|    clip_fraction            | 0.964     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.2430214 |
|    ent_clip_fraction        | 0.694     |
|    ent_entropy_loss         | 7.33      |
|    ent_loss                 | -0.0751   |
|    ent_policy_gradient_loss | -0.013    |
|    ent_std                  | 0.0969    |
|    ent_value_loss           | 0.0111    |
|    entropy_loss             | 6.17      |
|    explained_variance       | 0.547     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.132     |
|    n_updates                | 8870      |
|    policy_gradient_loss     | 0.212     |
|    std                      | 0.112     |
|    value_loss               | 0.01      |
-------------------------------------------
Eval num_timesteps=1820000, episode_reward=3626.13 +/- 1603.63
Episode length: 933.04 +/- 183.85
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 933       |
|    mean_reward              | 3.63e+03  |
| time/                       |           |
|    total_timesteps          | 1820000   |
| train/                      |           |
|    approx_kl                | 4.293298  |
|    clip_fraction            | 0.885     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 3.1312423 |
|    ent_clip_fraction        | 0.781     |
|    ent_entropy_loss         | 7.32      |
|    ent_loss                 | 0.0596    |
|    ent_policy_gradient_loss | 0.0607    |
|    ent_std                  | 0.0972    |
|    ent_value_loss           | 0.0187    |
|    entropy_loss             | 6.15      |
|    explained_variance       | 0.936     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.119     |
|    n_updates                | 8880      |
|    policy_gradient_loss     | 0.519     |
|    std                      | 0.112     |
|    value_loss               | 0.0189    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 849      |
|    ep_rew_mean     | 3.2e+03  |
| time/              |          |
|    fps             | 150      |
|    iterations      | 889      |
|    time_elapsed    | 12097    |
|    total_timesteps | 1820672  |
---------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 849       |
|    ep_rew_mean              | 3.2e+03   |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 890       |
|    time_elapsed             | 12107     |
|    total_timesteps          | 1822720   |
| train/                      |           |
|    approx_kl                | 5.2789288 |
|    clip_fraction            | 0.967     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.2019777 |
|    ent_clip_fraction        | 0.707     |
|    ent_entropy_loss         | 7.32      |
|    ent_loss                 | -0.0492   |
|    ent_policy_gradient_loss | -0.0051   |
|    ent_std                  | 0.0969    |
|    ent_value_loss           | 0.0148    |
|    entropy_loss             | 6.15      |
|    explained_variance       | 0.521     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0523    |
|    n_updates                | 8890      |
|    policy_gradient_loss     | 0.227     |
|    std                      | 0.113     |
|    value_loss               | 0.0145    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 844       |
|    ep_rew_mean              | 3.17e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 891       |
|    time_elapsed             | 12117     |
|    total_timesteps          | 1824768   |
| train/                      |           |
|    approx_kl                | 4.8869476 |
|    clip_fraction            | 0.966     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.7876351 |
|    ent_clip_fraction        | 0.664     |
|    ent_entropy_loss         | 7.32      |
|    ent_loss                 | -0.0527   |
|    ent_policy_gradient_loss | -0.00727  |
|    ent_std                  | 0.0972    |
|    ent_value_loss           | 0.00687   |
|    entropy_loss             | 6.14      |
|    explained_variance       | 0.493     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.173     |
|    n_updates                | 8900      |
|    policy_gradient_loss     | 0.221     |
|    std                      | 0.112     |
|    value_loss               | 0.00643   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 844       |
|    ep_rew_mean              | 3.17e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 892       |
|    time_elapsed             | 12127     |
|    total_timesteps          | 1826816   |
| train/                      |           |
|    approx_kl                | 6.19621   |
|    clip_fraction            | 0.957     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.6819335 |
|    ent_clip_fraction        | 0.675     |
|    ent_entropy_loss         | 7.34      |
|    ent_loss                 | -0.00217  |
|    ent_policy_gradient_loss | 0.0074    |
|    ent_std                  | 0.0966    |
|    ent_value_loss           | 0.036     |
|    entropy_loss             | 6.16      |
|    explained_variance       | 0.944     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.15      |
|    n_updates                | 8910      |
|    policy_gradient_loss     | 0.144     |
|    std                      | 0.112     |
|    value_loss               | 0.0351    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 844       |
|    ep_rew_mean              | 3.16e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 893       |
|    time_elapsed             | 12138     |
|    total_timesteps          | 1828864   |
| train/                      |           |
|    approx_kl                | 3.7653985 |
|    clip_fraction            | 0.947     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.4224093 |
|    ent_clip_fraction        | 0.728     |
|    ent_entropy_loss         | 7.37      |
|    ent_loss                 | -0.0382   |
|    ent_policy_gradient_loss | 0.0247    |
|    ent_std                  | 0.0965    |
|    ent_value_loss           | 0.0145    |
|    entropy_loss             | 6.16      |
|    explained_variance       | 0.409     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.0591    |
|    n_updates                | 8920      |
|    policy_gradient_loss     | 0.16      |
|    std                      | 0.112     |
|    value_loss               | 0.0143    |
-------------------------------------------
Eval num_timesteps=1830000, episode_reward=4412.65 +/- 814.88
Episode length: 956.20 +/- 151.18
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 956       |
|    mean_reward              | 4.41e+03  |
| time/                       |           |
|    total_timesteps          | 1830000   |
| train/                      |           |
|    approx_kl                | 4.7574286 |
|    clip_fraction            | 0.965     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.7362853 |
|    ent_clip_fraction        | 0.667     |
|    ent_entropy_loss         | 7.37      |
|    ent_loss                 | -0.023    |
|    ent_policy_gradient_loss | -0.0119   |
|    ent_std                  | 0.0964    |
|    ent_value_loss           | 0.0265    |
|    entropy_loss             | 6.15      |
|    explained_variance       | 0.44      |
|    learning_rate            | 0.0003    |
|    loss                     | 0.209     |
|    n_updates                | 8930      |
|    policy_gradient_loss     | 0.172     |
|    std                      | 0.112     |
|    value_loss               | 0.0259    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 844      |
|    ep_rew_mean     | 3.19e+03 |
| time/              |          |
|    fps             | 150      |
|    iterations      | 894      |
|    time_elapsed    | 12166    |
|    total_timesteps | 1830912  |
---------------------------------
------------------------------------------
| rollout/                    |          |
|    ep_len_mean              | 844      |
|    ep_rew_mean              | 3.18e+03 |
| time/                       |          |
|    fps                      | 150      |
|    iterations               | 895      |
|    time_elapsed             | 12176    |
|    total_timesteps          | 1832960  |
| train/                      |          |
|    approx_kl                | 3.784603 |
|    clip_fraction            | 0.951    |
|    clip_range               | 0.2      |
|    ent_approx_kl            | 1.047739 |
|    ent_clip_fraction        | 0.69     |
|    ent_entropy_loss         | 7.39     |
|    ent_loss                 | -0.0195  |
|    ent_policy_gradient_loss | 0.00534  |
|    ent_std                  | 0.0962   |
|    ent_value_loss           | 0.0195   |
|    entropy_loss             | 6.15     |
|    explained_variance       | 0.581    |
|    learning_rate            | 0.0003   |
|    loss                     | 0.162    |
|    n_updates                | 8940     |
|    policy_gradient_loss     | 0.205    |
|    std                      | 0.112    |
|    value_loss               | 0.0199   |
------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 844       |
|    ep_rew_mean              | 3.14e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 896       |
|    time_elapsed             | 12186     |
|    total_timesteps          | 1835008   |
| train/                      |           |
|    approx_kl                | 3.7568593 |
|    clip_fraction            | 0.928     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.9534659 |
|    ent_clip_fraction        | 0.742     |
|    ent_entropy_loss         | 7.39      |
|    ent_loss                 | 0.00317   |
|    ent_policy_gradient_loss | 0.0354    |
|    ent_std                  | 0.096     |
|    ent_value_loss           | 0.00687   |
|    entropy_loss             | 6.17      |
|    explained_variance       | 0.683     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.121     |
|    n_updates                | 8950      |
|    policy_gradient_loss     | 0.197     |
|    std                      | 0.112     |
|    value_loss               | 0.00637   |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 853       |
|    ep_rew_mean              | 3.17e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 897       |
|    time_elapsed             | 12196     |
|    total_timesteps          | 1837056   |
| train/                      |           |
|    approx_kl                | 5.4881344 |
|    clip_fraction            | 0.918     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 12.036127 |
|    ent_clip_fraction        | 0.73      |
|    ent_entropy_loss         | 7.44      |
|    ent_loss                 | -0.0109   |
|    ent_policy_gradient_loss | -0.00301  |
|    ent_std                  | 0.0954    |
|    ent_value_loss           | 0.014     |
|    entropy_loss             | 6.18      |
|    explained_variance       | 0.986     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.187     |
|    n_updates                | 8960      |
|    policy_gradient_loss     | 0.164     |
|    std                      | 0.112     |
|    value_loss               | 0.0138    |
-------------------------------------------
-------------------------------------------
| rollout/                    |           |
|    ep_len_mean              | 848       |
|    ep_rew_mean              | 3.16e+03  |
| time/                       |           |
|    fps                      | 150       |
|    iterations               | 898       |
|    time_elapsed             | 12206     |
|    total_timesteps          | 1839104   |
| train/                      |           |
|    approx_kl                | 4.87077   |
|    clip_fraction            | 0.968     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 1.0714068 |
|    ent_clip_fraction        | 0.69      |
|    ent_entropy_loss         | 7.48      |
|    ent_loss                 | -0.0168   |
|    ent_policy_gradient_loss | -0.00394  |
|    ent_std                  | 0.0951    |
|    ent_value_loss           | 0.0118    |
|    entropy_loss             | 6.2       |
|    explained_variance       | 0.683     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.179     |
|    n_updates                | 8970      |
|    policy_gradient_loss     | 0.2       |
|    std                      | 0.112     |
|    value_loss               | 0.0115    |
-------------------------------------------
Eval num_timesteps=1840000, episode_reward=3402.08 +/- 1321.80
Episode length: 790.96 +/- 295.41
-------------------------------------------
| eval/                       |           |
|    mean_ep_length           | 791       |
|    mean_reward              | 3.4e+03   |
| time/                       |           |
|    total_timesteps          | 1840000   |
| train/                      |           |
|    approx_kl                | 4.902328  |
|    clip_fraction            | 0.966     |
|    clip_range               | 0.2       |
|    ent_approx_kl            | 0.6604173 |
|    ent_clip_fraction        | 0.629     |
|    ent_entropy_loss         | 7.5       |
|    ent_loss                 | -0.00223  |
|    ent_policy_gradient_loss | -0.0125   |
|    ent_std                  | 0.0947    |
|    ent_value_loss           | 0.035     |
|    entropy_loss             | 6.22      |
|    explained_variance       | 0.941     |
|    learning_rate            | 0.0003    |
|    loss                     | 0.187     |
|    n_updates                | 8980      |
|    policy_gradient_loss     | 0.152     |
|    std                      | 0.111     |
|    value_loss               | 0.0338    |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 849      |
|    ep_rew_mean     | 3.17e+03 |
| time/              |          |
|    fps             | 150      |
|    iterations      | 899      |
|    time_elapsed    | 12234    |
|    total_timesteps | 1841152  |
---------------------------------
--------------------------------------------
| rollout/                    |            |
|    ep_len_mean              | 849        |
|    ep_rew_mean              | 3.17e+03   |
| time/                       |            |
|    fps                      | 150        |
|    iterations               | 900        |
|    time_elapsed             | 12244      |
|    total_timesteps          | 1843200    |
| train/                      |            |
|    approx_kl                | 6.9747934  |
|    clip_fraction            | 0.973      |
|    clip_range               | 0.2        |
|    ent_approx_kl            | 0.60811347 |
|    ent_clip_fraction        | 0.673      |
|    ent_entropy_loss         | 7.53       |
|    ent_loss                 | 0.0247     |
|    ent_policy_gradient_loss | -0.01      |
|    ent_std                  | 0.0945     |
|    ent_value_loss           | 0.0405     |
|    entropy_loss             | 6.27       |
|    explained_variance       | 0.95       |
|    learning_rate            | 0.0003     |
|    loss                     | 0.156      |
|    n_updates                | 8990       |
|    policy_gradient_loss     | 0.157      |
|    std                      | 0.11       |
|    value_loss               | 0.04       |
--------------------------------------------
slurmstepd: error: *** JOB 591883 ON dgk710 CANCELLED AT 2024-01-28T20:48:05 ***
