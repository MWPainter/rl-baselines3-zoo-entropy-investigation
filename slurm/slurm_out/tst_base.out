Running experiment tst_base
 
	GCC 9.1.0 environment now loaded

	CUDA-11.2 loaded

W&B offline. Running your script from this directory will only write metadata locally. Use wandb disabled to completely turn off W&B.
========== Ant-v4 ==========
Seed: 897820105
wandb: Tracking run with wandb version 0.16.2
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Loading hyperparameters from: /jmain02/home/J2AD008/wga37/mmp10-wga37/rl-baselines3-zoo-entropy-investigation/hyperparams/ppo.yml
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('n_timesteps', 1000000.0),
             ('normalize', True),
             ('policy', 'MlpPolicy'),
             ('ppo_mode', 'opt')])
Using 1 environments
Overwriting n_timesteps with n=2000000
Creating test environment
Normalization activated: {'norm_reward': False, 'training': False}
Normalizing input and reward
Using cuda device
Log path: /jmain02/home/J2AD008/wga37/mmp10-wga37/rl-baselines3-zoo-entropy-investigation/logs/tst_base/Ant-v4/"opt"/ppo/Ant-v4_1_8aa3f5b1-d8b0-4677-b9a2-b4af109917ce
Logging to runs/Ant-v4_opt_897820105_1706462624/Ant-v4/PPO_1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 226      |
|    ep_rew_mean     | -231     |
| time/              |          |
|    fps             | 179      |
|    iterations      | 1        |
|    time_elapsed    | 11       |
|    total_timesteps | 2048     |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 134         |
|    ep_rew_mean          | -139        |
| time/                   |             |
|    fps                  | 187         |
|    iterations           | 2           |
|    time_elapsed         | 21          |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.017434373 |
|    clip_fraction        | 0.16        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.538      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0275      |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.0313     |
|    std                  | 0.996       |
|    value_loss           | 0.37        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 180         |
|    ep_rew_mean          | -190        |
| time/                   |             |
|    fps                  | 195         |
|    iterations           | 3           |
|    time_elapsed         | 31          |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.015561702 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.0693      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00102    |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0319     |
|    std                  | 0.99        |
|    value_loss           | 0.0856      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 160         |
|    ep_rew_mean          | -171        |
| time/                   |             |
|    fps                  | 201         |
|    iterations           | 4           |
|    time_elapsed         | 40          |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.014696034 |
|    clip_fraction        | 0.139       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.13       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0419     |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.0312     |
|    std                  | 0.983       |
|    value_loss           | 0.0453      |
-----------------------------------------
Eval num_timesteps=10000, episode_reward=990.72 +/- 22.91
Episode length: 1000.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 1e+03       |
|    mean_reward          | 991         |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.014478894 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.329       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00469     |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0318     |
|    std                  | 0.979       |
|    value_loss           | 0.0817      |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 141      |
|    ep_rew_mean     | -148     |
| time/              |          |
|    fps             | 143      |
|    iterations      | 5        |
|    time_elapsed    | 71       |
|    total_timesteps | 10240    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 140         |
|    ep_rew_mean          | -148        |
| time/                   |             |
|    fps                  | 152         |
|    iterations           | 6           |
|    time_elapsed         | 80          |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.016263764 |
|    clip_fraction        | 0.154       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.442       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0132      |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.0351     |
|    std                  | 0.97        |
|    value_loss           | 0.11        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 152         |
|    ep_rew_mean          | -160        |
| time/                   |             |
|    fps                  | 159         |
|    iterations           | 7           |
|    time_elapsed         | 89          |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.016195986 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.575       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0139     |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0362     |
|    std                  | 0.964       |
|    value_loss           | 0.0953      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 143         |
|    ep_rew_mean          | -150        |
| time/                   |             |
|    fps                  | 164         |
|    iterations           | 8           |
|    time_elapsed         | 99          |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.017587908 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.685       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0355     |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0387     |
|    std                  | 0.959       |
|    value_loss           | 0.0509      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 106         |
|    ep_rew_mean          | -108        |
| time/                   |             |
|    fps                  | 169         |
|    iterations           | 9           |
|    time_elapsed         | 108         |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.016029045 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.698       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00147    |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0353     |
|    std                  | 0.954       |
|    value_loss           | 0.0871      |
-----------------------------------------
Eval num_timesteps=20000, episode_reward=863.66 +/- 16.66
Episode length: 1000.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 1e+03       |
|    mean_reward          | 864         |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.015726289 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.535       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0207     |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.0399     |
|    std                  | 0.95        |
|    value_loss           | 0.145       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 122      |
|    ep_rew_mean     | -123     |
| time/              |          |
|    fps             | 147      |
|    iterations      | 10       |
|    time_elapsed    | 139      |
|    total_timesteps | 20480    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 130        |
|    ep_rew_mean          | -132       |
| time/                   |            |
|    fps                  | 151        |
|    iterations           | 11         |
|    time_elapsed         | 148        |
|    total_timesteps      | 22528      |
| train/                  |            |
|    approx_kl            | 0.01810193 |
|    clip_fraction        | 0.179      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.9      |
|    explained_variance   | 0.757      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0058    |
|    n_updates            | 100        |
|    policy_gradient_loss | -0.0387    |
|    std                  | 0.94       |
|    value_loss           | 0.0807     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 105         |
|    ep_rew_mean          | -105        |
| time/                   |             |
|    fps                  | 155         |
|    iterations           | 12          |
|    time_elapsed         | 158         |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.017796379 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.554       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0112     |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.0376     |
|    std                  | 0.933       |
|    value_loss           | 0.0772      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 89.5        |
|    ep_rew_mean          | -89.3       |
| time/                   |             |
|    fps                  | 158         |
|    iterations           | 13          |
|    time_elapsed         | 167         |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.019880563 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.717       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0329     |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0422     |
|    std                  | 0.923       |
|    value_loss           | 0.0911      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 78.3        |
|    ep_rew_mean          | -78.9       |
| time/                   |             |
|    fps                  | 162         |
|    iterations           | 14          |
|    time_elapsed         | 176         |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.016826808 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.368       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0165      |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.0397     |
|    std                  | 0.92        |
|    value_loss           | 0.142       |
-----------------------------------------
Eval num_timesteps=30000, episode_reward=662.04 +/- 359.09
Episode length: 750.44 +/- 408.11
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 750         |
|    mean_reward          | 662         |
| time/                   |             |
|    total_timesteps      | 30000       |
| train/                  |             |
|    approx_kl            | 0.021995455 |
|    clip_fraction        | 0.227       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.733       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0151     |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.0468     |
|    std                  | 0.915       |
|    value_loss           | 0.0809      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 70.9     |
|    ep_rew_mean     | -71.3    |
| time/              |          |
|    fps             | 148      |
|    iterations      | 15       |
|    time_elapsed    | 206      |
|    total_timesteps | 30720    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 60.7       |
|    ep_rew_mean          | -62.4      |
| time/                   |            |
|    fps                  | 151        |
|    iterations           | 16         |
|    time_elapsed         | 216        |
|    total_timesteps      | 32768      |
| train/                  |            |
|    approx_kl            | 0.01923073 |
|    clip_fraction        | 0.206      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | 0.742      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0204    |
|    n_updates            | 150        |
|    policy_gradient_loss | -0.0442    |
|    std                  | 0.907      |
|    value_loss           | 0.0979     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 81.7        |
|    ep_rew_mean          | -81         |
| time/                   |             |
|    fps                  | 154         |
|    iterations           | 17          |
|    time_elapsed         | 225         |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 0.017975617 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.779       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0445     |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.0441     |
|    std                  | 0.905       |
|    value_loss           | 0.0877      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 91.1       |
|    ep_rew_mean          | -90.5      |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 18         |
|    time_elapsed         | 234        |
|    total_timesteps      | 36864      |
| train/                  |            |
|    approx_kl            | 0.01813483 |
|    clip_fraction        | 0.201      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | 0.697      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0513    |
|    n_updates            | 170        |
|    policy_gradient_loss | -0.0404    |
|    std                  | 0.893      |
|    value_loss           | 0.0592     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 90.8        |
|    ep_rew_mean          | -88.4       |
| time/                   |             |
|    fps                  | 159         |
|    iterations           | 19          |
|    time_elapsed         | 244         |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.017295483 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.778       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0141     |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.041      |
|    std                  | 0.886       |
|    value_loss           | 0.0728      |
-----------------------------------------
Eval num_timesteps=40000, episode_reward=632.55 +/- 327.62
Episode length: 718.16 +/- 369.27
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 718         |
|    mean_reward          | 633         |
| time/                   |             |
|    total_timesteps      | 40000       |
| train/                  |             |
|    approx_kl            | 0.022007562 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.85        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0373     |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.0467     |
|    std                  | 0.88        |
|    value_loss           | 0.0632      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 111      |
|    ep_rew_mean     | -105     |
| time/              |          |
|    fps             | 150      |
|    iterations      | 20       |
|    time_elapsed    | 272      |
|    total_timesteps | 40960    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 117         |
|    ep_rew_mean          | -108        |
| time/                   |             |
|    fps                  | 152         |
|    iterations           | 21          |
|    time_elapsed         | 282         |
|    total_timesteps      | 43008       |
| train/                  |             |
|    approx_kl            | 0.018178534 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.844       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0517     |
|    n_updates            | 200         |
|    policy_gradient_loss | -0.0429     |
|    std                  | 0.872       |
|    value_loss           | 0.0375      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 118         |
|    ep_rew_mean          | -109        |
| time/                   |             |
|    fps                  | 154         |
|    iterations           | 22          |
|    time_elapsed         | 291         |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.016239252 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.797       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0091     |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.0417     |
|    std                  | 0.865       |
|    value_loss           | 0.0903      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 117         |
|    ep_rew_mean          | -107        |
| time/                   |             |
|    fps                  | 156         |
|    iterations           | 23          |
|    time_elapsed         | 301         |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.018860951 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.876       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0318     |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.044      |
|    std                  | 0.86        |
|    value_loss           | 0.0653      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 127         |
|    ep_rew_mean          | -115        |
| time/                   |             |
|    fps                  | 158         |
|    iterations           | 24          |
|    time_elapsed         | 310         |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.019570176 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.829       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0259     |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.042      |
|    std                  | 0.851       |
|    value_loss           | 0.0307      |
-----------------------------------------
Eval num_timesteps=50000, episode_reward=409.36 +/- 325.22
Episode length: 458.64 +/- 392.57
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 459        |
|    mean_reward          | 409        |
| time/                   |            |
|    total_timesteps      | 50000      |
| train/                  |            |
|    approx_kl            | 0.01994911 |
|    clip_fraction        | 0.216      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10        |
|    explained_variance   | 0.739      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0452    |
|    n_updates            | 240        |
|    policy_gradient_loss | -0.045     |
|    std                  | 0.846      |
|    value_loss           | 0.0424     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 136      |
|    ep_rew_mean     | -121     |
| time/              |          |
|    fps             | 153      |
|    iterations      | 25       |
|    time_elapsed    | 333      |
|    total_timesteps | 51200    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 148         |
|    ep_rew_mean          | -130        |
| time/                   |             |
|    fps                  | 155         |
|    iterations           | 26          |
|    time_elapsed         | 343         |
|    total_timesteps      | 53248       |
| train/                  |             |
|    approx_kl            | 0.022251405 |
|    clip_fraction        | 0.227       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.95       |
|    explained_variance   | 0.816       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0413     |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.0467     |
|    std                  | 0.835       |
|    value_loss           | 0.0631      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 141         |
|    ep_rew_mean          | -124        |
| time/                   |             |
|    fps                  | 156         |
|    iterations           | 27          |
|    time_elapsed         | 352         |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.019852756 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.86       |
|    explained_variance   | 0.852       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0396     |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.0436     |
|    std                  | 0.828       |
|    value_loss           | 0.0492      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 123        |
|    ep_rew_mean          | -109       |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 28         |
|    time_elapsed         | 362        |
|    total_timesteps      | 57344      |
| train/                  |            |
|    approx_kl            | 0.02148247 |
|    clip_fraction        | 0.235      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.81      |
|    explained_variance   | 0.821      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0464    |
|    n_updates            | 270        |
|    policy_gradient_loss | -0.0448    |
|    std                  | 0.824      |
|    value_loss           | 0.0709     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 123         |
|    ep_rew_mean          | -106        |
| time/                   |             |
|    fps                  | 159         |
|    iterations           | 29          |
|    time_elapsed         | 371         |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.019805849 |
|    clip_fraction        | 0.219       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.77       |
|    explained_variance   | 0.743       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0466     |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.0486     |
|    std                  | 0.819       |
|    value_loss           | 0.111       |
-----------------------------------------
Eval num_timesteps=60000, episode_reward=350.72 +/- 301.32
Episode length: 419.16 +/- 372.31
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 419       |
|    mean_reward          | 351       |
| time/                   |           |
|    total_timesteps      | 60000     |
| train/                  |           |
|    approx_kl            | 0.0177457 |
|    clip_fraction        | 0.207     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.72     |
|    explained_variance   | 0.847     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0423   |
|    n_updates            | 290       |
|    policy_gradient_loss | -0.0461   |
|    std                  | 0.814     |
|    value_loss           | 0.0554    |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 116      |
|    ep_rew_mean     | -97.6    |
| time/              |          |
|    fps             | 156      |
|    iterations      | 30       |
|    time_elapsed    | 392      |
|    total_timesteps | 61440    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 115         |
|    ep_rew_mean          | -96.8       |
| time/                   |             |
|    fps                  | 157         |
|    iterations           | 31          |
|    time_elapsed         | 402         |
|    total_timesteps      | 63488       |
| train/                  |             |
|    approx_kl            | 0.020717712 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.66       |
|    explained_variance   | 0.84        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0516     |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.0474     |
|    std                  | 0.807       |
|    value_loss           | 0.0771      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 115         |
|    ep_rew_mean          | -96.7       |
| time/                   |             |
|    fps                  | 159         |
|    iterations           | 32          |
|    time_elapsed         | 411         |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.017862149 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.56       |
|    explained_variance   | 0.604       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0583     |
|    n_updates            | 310         |
|    policy_gradient_loss | -0.0424     |
|    std                  | 0.796       |
|    value_loss           | 0.0176      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 113         |
|    ep_rew_mean          | -90.1       |
| time/                   |             |
|    fps                  | 160         |
|    iterations           | 33          |
|    time_elapsed         | 421         |
|    total_timesteps      | 67584       |
| train/                  |             |
|    approx_kl            | 0.021932214 |
|    clip_fraction        | 0.247       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.44       |
|    explained_variance   | 0.774       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0505     |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.0467     |
|    std                  | 0.783       |
|    value_loss           | 0.0329      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 133         |
|    ep_rew_mean          | -106        |
| time/                   |             |
|    fps                  | 161         |
|    iterations           | 34          |
|    time_elapsed         | 430         |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.020428248 |
|    clip_fraction        | 0.21        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.37       |
|    explained_variance   | 0.767       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0165     |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.0453     |
|    std                  | 0.78        |
|    value_loss           | 0.105       |
-----------------------------------------
Eval num_timesteps=70000, episode_reward=256.08 +/- 303.37
Episode length: 340.48 +/- 415.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 340         |
|    mean_reward          | 256         |
| time/                   |             |
|    total_timesteps      | 70000       |
| train/                  |             |
|    approx_kl            | 0.019228598 |
|    clip_fraction        | 0.221       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.32       |
|    explained_variance   | 0.891       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0334     |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.0455     |
|    std                  | 0.772       |
|    value_loss           | 0.0548      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 124      |
|    ep_rew_mean     | -96.7    |
| time/              |          |
|    fps             | 159      |
|    iterations      | 35       |
|    time_elapsed    | 449      |
|    total_timesteps | 71680    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 125         |
|    ep_rew_mean          | -95.9       |
| time/                   |             |
|    fps                  | 160         |
|    iterations           | 36          |
|    time_elapsed         | 459         |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 0.019366018 |
|    clip_fraction        | 0.232       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.27       |
|    explained_variance   | 0.842       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0248     |
|    n_updates            | 350         |
|    policy_gradient_loss | -0.0479     |
|    std                  | 0.77        |
|    value_loss           | 0.0703      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 96.8        |
|    ep_rew_mean          | -69.6       |
| time/                   |             |
|    fps                  | 161         |
|    iterations           | 37          |
|    time_elapsed         | 468         |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 0.020150531 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.23       |
|    explained_variance   | 0.873       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0415     |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.0472     |
|    std                  | 0.765       |
|    value_loss           | 0.0698      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 85.3        |
|    ep_rew_mean          | -58.3       |
| time/                   |             |
|    fps                  | 162         |
|    iterations           | 38          |
|    time_elapsed         | 479         |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.021775011 |
|    clip_fraction        | 0.24        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.17       |
|    explained_variance   | 0.878       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0268     |
|    n_updates            | 370         |
|    policy_gradient_loss | -0.0466     |
|    std                  | 0.758       |
|    value_loss           | 0.0584      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 94         |
|    ep_rew_mean          | -64.2      |
| time/                   |            |
|    fps                  | 163        |
|    iterations           | 39         |
|    time_elapsed         | 489        |
|    total_timesteps      | 79872      |
| train/                  |            |
|    approx_kl            | 0.02042573 |
|    clip_fraction        | 0.229      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.12      |
|    explained_variance   | 0.872      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0406    |
|    n_updates            | 380        |
|    policy_gradient_loss | -0.0466    |
|    std                  | 0.756      |
|    value_loss           | 0.0656     |
----------------------------------------
Eval num_timesteps=80000, episode_reward=257.15 +/- 301.40
Episode length: 333.08 +/- 409.01
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 333         |
|    mean_reward          | 257         |
| time/                   |             |
|    total_timesteps      | 80000       |
| train/                  |             |
|    approx_kl            | 0.018832702 |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.06       |
|    explained_variance   | 0.773       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0761     |
|    n_updates            | 390         |
|    policy_gradient_loss | -0.0486     |
|    std                  | 0.749       |
|    value_loss           | 0.0225      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 90.3     |
|    ep_rew_mean     | -60.2    |
| time/              |          |
|    fps             | 161      |
|    iterations      | 40       |
|    time_elapsed    | 508      |
|    total_timesteps | 81920    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 96.5        |
|    ep_rew_mean          | -63.5       |
| time/                   |             |
|    fps                  | 162         |
|    iterations           | 41          |
|    time_elapsed         | 517         |
|    total_timesteps      | 83968       |
| train/                  |             |
|    approx_kl            | 0.020179842 |
|    clip_fraction        | 0.232       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9          |
|    explained_variance   | 0.874       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0702     |
|    n_updates            | 400         |
|    policy_gradient_loss | -0.0499     |
|    std                  | 0.744       |
|    value_loss           | 0.0606      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 123         |
|    ep_rew_mean          | -81.8       |
| time/                   |             |
|    fps                  | 163         |
|    iterations           | 42          |
|    time_elapsed         | 526         |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.019992799 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.92       |
|    explained_variance   | 0.88        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0822     |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.0473     |
|    std                  | 0.735       |
|    value_loss           | 0.0251      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 120        |
|    ep_rew_mean          | -80.6      |
| time/                   |            |
|    fps                  | 164        |
|    iterations           | 43         |
|    time_elapsed         | 536        |
|    total_timesteps      | 88064      |
| train/                  |            |
|    approx_kl            | 0.01827814 |
|    clip_fraction        | 0.226      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.84      |
|    explained_variance   | 0.753      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0493    |
|    n_updates            | 420        |
|    policy_gradient_loss | -0.0448    |
|    std                  | 0.73       |
|    value_loss           | 0.0293     |
----------------------------------------
Eval num_timesteps=90000, episode_reward=295.39 +/- 329.93
Episode length: 371.56 +/- 434.74
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 372         |
|    mean_reward          | 295         |
| time/                   |             |
|    total_timesteps      | 90000       |
| train/                  |             |
|    approx_kl            | 0.023121763 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.79       |
|    explained_variance   | 0.877       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0473     |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.0498     |
|    std                  | 0.724       |
|    value_loss           | 0.0475      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 133      |
|    ep_rew_mean     | -89.2    |
| time/              |          |
|    fps             | 161      |
|    iterations      | 44       |
|    time_elapsed    | 558      |
|    total_timesteps | 90112    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 104         |
|    ep_rew_mean          | -66.7       |
| time/                   |             |
|    fps                  | 162         |
|    iterations           | 45          |
|    time_elapsed         | 568         |
|    total_timesteps      | 92160       |
| train/                  |             |
|    approx_kl            | 0.018932082 |
|    clip_fraction        | 0.216       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.71       |
|    explained_variance   | 0.87        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0479     |
|    n_updates            | 440         |
|    policy_gradient_loss | -0.0476     |
|    std                  | 0.718       |
|    value_loss           | 0.0493      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 86.8        |
|    ep_rew_mean          | -57.5       |
| time/                   |             |
|    fps                  | 163         |
|    iterations           | 46          |
|    time_elapsed         | 577         |
|    total_timesteps      | 94208       |
| train/                  |             |
|    approx_kl            | 0.018728875 |
|    clip_fraction        | 0.223       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.65       |
|    explained_variance   | 0.858       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0345     |
|    n_updates            | 450         |
|    policy_gradient_loss | -0.0474     |
|    std                  | 0.711       |
|    value_loss           | 0.0618      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 70          |
|    ep_rew_mean          | -44.5       |
| time/                   |             |
|    fps                  | 163         |
|    iterations           | 47          |
|    time_elapsed         | 587         |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 0.021908065 |
|    clip_fraction        | 0.24        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.56       |
|    explained_variance   | 0.878       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0471     |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.0497     |
|    std                  | 0.703       |
|    value_loss           | 0.0422      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80.4        |
|    ep_rew_mean          | -52.1       |
| time/                   |             |
|    fps                  | 164         |
|    iterations           | 48          |
|    time_elapsed         | 596         |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.023301205 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.5        |
|    explained_variance   | 0.905       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0612     |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.0532     |
|    std                  | 0.699       |
|    value_loss           | 0.0424      |
-----------------------------------------
Eval num_timesteps=100000, episode_reward=119.03 +/- 174.42
Episode length: 151.08 +/- 259.79
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 151         |
|    mean_reward          | 119         |
| time/                   |             |
|    total_timesteps      | 100000      |
| train/                  |             |
|    approx_kl            | 0.022264212 |
|    clip_fraction        | 0.264       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.42       |
|    explained_variance   | 0.867       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0681     |
|    n_updates            | 480         |
|    policy_gradient_loss | -0.0532     |
|    std                  | 0.691       |
|    value_loss           | 0.0462      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 91       |
|    ep_rew_mean     | -55.7    |
| time/              |          |
|    fps             | 163      |
|    iterations      | 49       |
|    time_elapsed    | 612      |
|    total_timesteps | 100352   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 106         |
|    ep_rew_mean          | -65.2       |
| time/                   |             |
|    fps                  | 164         |
|    iterations           | 50          |
|    time_elapsed         | 622         |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 0.018873882 |
|    clip_fraction        | 0.216       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.35       |
|    explained_variance   | 0.896       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.06       |
|    n_updates            | 490         |
|    policy_gradient_loss | -0.0467     |
|    std                  | 0.686       |
|    value_loss           | 0.0343      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 115        |
|    ep_rew_mean          | -69.6      |
| time/                   |            |
|    fps                  | 165        |
|    iterations           | 51         |
|    time_elapsed         | 631        |
|    total_timesteps      | 104448     |
| train/                  |            |
|    approx_kl            | 0.02376562 |
|    clip_fraction        | 0.271      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.28      |
|    explained_variance   | 0.846      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0373    |
|    n_updates            | 500        |
|    policy_gradient_loss | -0.0551    |
|    std                  | 0.679      |
|    value_loss           | 0.0515     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 107        |
|    ep_rew_mean          | -60.8      |
| time/                   |            |
|    fps                  | 166        |
|    iterations           | 52         |
|    time_elapsed         | 641        |
|    total_timesteps      | 106496     |
| train/                  |            |
|    approx_kl            | 0.01729244 |
|    clip_fraction        | 0.222      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.22      |
|    explained_variance   | 0.859      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0507    |
|    n_updates            | 510        |
|    policy_gradient_loss | -0.0478    |
|    std                  | 0.675      |
|    value_loss           | 0.0471     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 114         |
|    ep_rew_mean          | -63.5       |
| time/                   |             |
|    fps                  | 166         |
|    iterations           | 53          |
|    time_elapsed         | 650         |
|    total_timesteps      | 108544      |
| train/                  |             |
|    approx_kl            | 0.021191642 |
|    clip_fraction        | 0.248       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.18       |
|    explained_variance   | 0.879       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0639     |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.0521     |
|    std                  | 0.672       |
|    value_loss           | 0.0274      |
-----------------------------------------
Eval num_timesteps=110000, episode_reward=216.33 +/- 215.10
Episode length: 290.36 +/- 344.79
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 290         |
|    mean_reward          | 216         |
| time/                   |             |
|    total_timesteps      | 110000      |
| train/                  |             |
|    approx_kl            | 0.020413946 |
|    clip_fraction        | 0.248       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.14       |
|    explained_variance   | 0.861       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0424     |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.0542     |
|    std                  | 0.668       |
|    value_loss           | 0.039       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 117      |
|    ep_rew_mean     | -63.9    |
| time/              |          |
|    fps             | 164      |
|    iterations      | 54       |
|    time_elapsed    | 670      |
|    total_timesteps | 110592   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 96.3        |
|    ep_rew_mean          | -52.4       |
| time/                   |             |
|    fps                  | 165         |
|    iterations           | 55          |
|    time_elapsed         | 679         |
|    total_timesteps      | 112640      |
| train/                  |             |
|    approx_kl            | 0.021515284 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.07       |
|    explained_variance   | 0.862       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0477     |
|    n_updates            | 540         |
|    policy_gradient_loss | -0.0519     |
|    std                  | 0.662       |
|    value_loss           | 0.043       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 78.1        |
|    ep_rew_mean          | -42.9       |
| time/                   |             |
|    fps                  | 166         |
|    iterations           | 56          |
|    time_elapsed         | 689         |
|    total_timesteps      | 114688      |
| train/                  |             |
|    approx_kl            | 0.020792227 |
|    clip_fraction        | 0.24        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.01       |
|    explained_variance   | 0.784       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0417     |
|    n_updates            | 550         |
|    policy_gradient_loss | -0.0522     |
|    std                  | 0.657       |
|    value_loss           | 0.0663      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 77.8       |
|    ep_rew_mean          | -42.6      |
| time/                   |            |
|    fps                  | 167        |
|    iterations           | 57         |
|    time_elapsed         | 698        |
|    total_timesteps      | 116736     |
| train/                  |            |
|    approx_kl            | 0.02026795 |
|    clip_fraction        | 0.244      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.96      |
|    explained_variance   | 0.495      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0486    |
|    n_updates            | 560        |
|    policy_gradient_loss | -0.0546    |
|    std                  | 0.655      |
|    value_loss           | 0.0801     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 94.5        |
|    ep_rew_mean          | -48.4       |
| time/                   |             |
|    fps                  | 167         |
|    iterations           | 58          |
|    time_elapsed         | 707         |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.019560229 |
|    clip_fraction        | 0.239       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.92       |
|    explained_variance   | 0.775       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0577     |
|    n_updates            | 570         |
|    policy_gradient_loss | -0.0481     |
|    std                  | 0.649       |
|    value_loss           | 0.02        |
-----------------------------------------
Eval num_timesteps=120000, episode_reward=202.51 +/- 248.96
Episode length: 326.40 +/- 421.76
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 326         |
|    mean_reward          | 203         |
| time/                   |             |
|    total_timesteps      | 120000      |
| train/                  |             |
|    approx_kl            | 0.021506269 |
|    clip_fraction        | 0.252       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.83       |
|    explained_variance   | 0.918       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.077      |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.0524     |
|    std                  | 0.642       |
|    value_loss           | 0.0178      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 112      |
|    ep_rew_mean     | -57.3    |
| time/              |          |
|    fps             | 166      |
|    iterations      | 59       |
|    time_elapsed    | 726      |
|    total_timesteps | 120832   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 108         |
|    ep_rew_mean          | -54.3       |
| time/                   |             |
|    fps                  | 166         |
|    iterations           | 60          |
|    time_elapsed         | 736         |
|    total_timesteps      | 122880      |
| train/                  |             |
|    approx_kl            | 0.021620015 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.76       |
|    explained_variance   | 0.859       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0619     |
|    n_updates            | 590         |
|    policy_gradient_loss | -0.0492     |
|    std                  | 0.636       |
|    value_loss           | 0.0134      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 116         |
|    ep_rew_mean          | -55.5       |
| time/                   |             |
|    fps                  | 167         |
|    iterations           | 61          |
|    time_elapsed         | 745         |
|    total_timesteps      | 124928      |
| train/                  |             |
|    approx_kl            | 0.023063356 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.67       |
|    explained_variance   | 0.917       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0642     |
|    n_updates            | 600         |
|    policy_gradient_loss | -0.0558     |
|    std                  | 0.629       |
|    value_loss           | 0.0212      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 127         |
|    ep_rew_mean          | -61.3       |
| time/                   |             |
|    fps                  | 168         |
|    iterations           | 62          |
|    time_elapsed         | 754         |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.021545416 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.6        |
|    explained_variance   | 0.893       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0609     |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.053      |
|    std                  | 0.624       |
|    value_loss           | 0.0268      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 145         |
|    ep_rew_mean          | -67.6       |
| time/                   |             |
|    fps                  | 168         |
|    iterations           | 63          |
|    time_elapsed         | 764         |
|    total_timesteps      | 129024      |
| train/                  |             |
|    approx_kl            | 0.021950332 |
|    clip_fraction        | 0.266       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.52       |
|    explained_variance   | 0.835       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0515     |
|    n_updates            | 620         |
|    policy_gradient_loss | -0.0519     |
|    std                  | 0.617       |
|    value_loss           | 0.0229      |
-----------------------------------------
Eval num_timesteps=130000, episode_reward=318.15 +/- 281.19
Episode length: 462.64 +/- 433.09
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 463        |
|    mean_reward          | 318        |
| time/                   |            |
|    total_timesteps      | 130000     |
| train/                  |            |
|    approx_kl            | 0.02576554 |
|    clip_fraction        | 0.283      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.42      |
|    explained_variance   | 0.876      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0663    |
|    n_updates            | 630        |
|    policy_gradient_loss | -0.0577    |
|    std                  | 0.61       |
|    value_loss           | 0.0271     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 101      |
|    ep_rew_mean     | -46.2    |
| time/              |          |
|    fps             | 166      |
|    iterations      | 64       |
|    time_elapsed    | 786      |
|    total_timesteps | 131072   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 111         |
|    ep_rew_mean          | -50.5       |
| time/                   |             |
|    fps                  | 167         |
|    iterations           | 65          |
|    time_elapsed         | 795         |
|    total_timesteps      | 133120      |
| train/                  |             |
|    approx_kl            | 0.027142067 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.34       |
|    explained_variance   | 0.629       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0631     |
|    n_updates            | 640         |
|    policy_gradient_loss | -0.0605     |
|    std                  | 0.605       |
|    value_loss           | 0.0743      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 120         |
|    ep_rew_mean          | -54.1       |
| time/                   |             |
|    fps                  | 167         |
|    iterations           | 66          |
|    time_elapsed         | 805         |
|    total_timesteps      | 135168      |
| train/                  |             |
|    approx_kl            | 0.021303853 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.26       |
|    explained_variance   | 0.645       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0461     |
|    n_updates            | 650         |
|    policy_gradient_loss | -0.0495     |
|    std                  | 0.597       |
|    value_loss           | 0.0147      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 110         |
|    ep_rew_mean          | -45.9       |
| time/                   |             |
|    fps                  | 168         |
|    iterations           | 67          |
|    time_elapsed         | 814         |
|    total_timesteps      | 137216      |
| train/                  |             |
|    approx_kl            | 0.023326216 |
|    clip_fraction        | 0.263       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.17       |
|    explained_variance   | 0.879       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0623     |
|    n_updates            | 660         |
|    policy_gradient_loss | -0.0495     |
|    std                  | 0.591       |
|    value_loss           | 0.0254      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 98.3        |
|    ep_rew_mean          | -35         |
| time/                   |             |
|    fps                  | 169         |
|    iterations           | 68          |
|    time_elapsed         | 823         |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 0.024748527 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.09       |
|    explained_variance   | 0.825       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0627     |
|    n_updates            | 670         |
|    policy_gradient_loss | -0.0547     |
|    std                  | 0.585       |
|    value_loss           | 0.043       |
-----------------------------------------
Eval num_timesteps=140000, episode_reward=108.64 +/- 156.34
Episode length: 154.72 +/- 267.50
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 155         |
|    mean_reward          | 109         |
| time/                   |             |
|    total_timesteps      | 140000      |
| train/                  |             |
|    approx_kl            | 0.026857793 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.02       |
|    explained_variance   | 0.832       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0722     |
|    n_updates            | 680         |
|    policy_gradient_loss | -0.0567     |
|    std                  | 0.58        |
|    value_loss           | 0.0403      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 105      |
|    ep_rew_mean     | -32.8    |
| time/              |          |
|    fps             | 168      |
|    iterations      | 69       |
|    time_elapsed    | 838      |
|    total_timesteps | 141312   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 114         |
|    ep_rew_mean          | -34.4       |
| time/                   |             |
|    fps                  | 169         |
|    iterations           | 70          |
|    time_elapsed         | 847         |
|    total_timesteps      | 143360      |
| train/                  |             |
|    approx_kl            | 0.025177317 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.95       |
|    explained_variance   | 0.74        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.049      |
|    n_updates            | 690         |
|    policy_gradient_loss | -0.058      |
|    std                  | 0.576       |
|    value_loss           | 0.0545      |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 115       |
|    ep_rew_mean          | -31.6     |
| time/                   |           |
|    fps                  | 169       |
|    iterations           | 71        |
|    time_elapsed         | 856       |
|    total_timesteps      | 145408    |
| train/                  |           |
|    approx_kl            | 0.0225483 |
|    clip_fraction        | 0.263     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.87     |
|    explained_variance   | 0.784     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0762   |
|    n_updates            | 700       |
|    policy_gradient_loss | -0.0507   |
|    std                  | 0.569     |
|    value_loss           | 0.0216    |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 126         |
|    ep_rew_mean          | -34.8       |
| time/                   |             |
|    fps                  | 170         |
|    iterations           | 72          |
|    time_elapsed         | 866         |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.026012167 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.78       |
|    explained_variance   | 0.753       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0785     |
|    n_updates            | 710         |
|    policy_gradient_loss | -0.0557     |
|    std                  | 0.562       |
|    value_loss           | 0.0184      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 127         |
|    ep_rew_mean          | -34.1       |
| time/                   |             |
|    fps                  | 170         |
|    iterations           | 73          |
|    time_elapsed         | 875         |
|    total_timesteps      | 149504      |
| train/                  |             |
|    approx_kl            | 0.027545348 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.66       |
|    explained_variance   | 0.856       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0835     |
|    n_updates            | 720         |
|    policy_gradient_loss | -0.0561     |
|    std                  | 0.553       |
|    value_loss           | 0.0102      |
-----------------------------------------
Eval num_timesteps=150000, episode_reward=161.88 +/- 197.56
Episode length: 217.28 +/- 305.61
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 217         |
|    mean_reward          | 162         |
| time/                   |             |
|    total_timesteps      | 150000      |
| train/                  |             |
|    approx_kl            | 0.024487903 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.54       |
|    explained_variance   | 0.745       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0716     |
|    n_updates            | 730         |
|    policy_gradient_loss | -0.0567     |
|    std                  | 0.546       |
|    value_loss           | 0.0449      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 124      |
|    ep_rew_mean     | -33.5    |
| time/              |          |
|    fps             | 169      |
|    iterations      | 74       |
|    time_elapsed    | 896      |
|    total_timesteps | 151552   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 133         |
|    ep_rew_mean          | -38.1       |
| time/                   |             |
|    fps                  | 169         |
|    iterations           | 75          |
|    time_elapsed         | 905         |
|    total_timesteps      | 153600      |
| train/                  |             |
|    approx_kl            | 0.026381642 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.46       |
|    explained_variance   | 0.737       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0642     |
|    n_updates            | 740         |
|    policy_gradient_loss | -0.0575     |
|    std                  | 0.541       |
|    value_loss           | 0.0333      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 151         |
|    ep_rew_mean          | -45.5       |
| time/                   |             |
|    fps                  | 170         |
|    iterations           | 76          |
|    time_elapsed         | 915         |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.026598006 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.38       |
|    explained_variance   | 0.744       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.051      |
|    n_updates            | 750         |
|    policy_gradient_loss | -0.0586     |
|    std                  | 0.536       |
|    value_loss           | 0.0285      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 161         |
|    ep_rew_mean          | -45.7       |
| time/                   |             |
|    fps                  | 170         |
|    iterations           | 77          |
|    time_elapsed         | 924         |
|    total_timesteps      | 157696      |
| train/                  |             |
|    approx_kl            | 0.024472639 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.27       |
|    explained_variance   | 0.578       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.075      |
|    n_updates            | 760         |
|    policy_gradient_loss | -0.0523     |
|    std                  | 0.527       |
|    value_loss           | 0.0195      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 154         |
|    ep_rew_mean          | -39.7       |
| time/                   |             |
|    fps                  | 171         |
|    iterations           | 78          |
|    time_elapsed         | 933         |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.025396705 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.17       |
|    explained_variance   | 0.837       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0071     |
|    n_updates            | 770         |
|    policy_gradient_loss | -0.0502     |
|    std                  | 0.522       |
|    value_loss           | 0.0111      |
-----------------------------------------
Eval num_timesteps=160000, episode_reward=206.18 +/- 243.17
Episode length: 239.16 +/- 308.38
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 239        |
|    mean_reward          | 206        |
| time/                   |            |
|    total_timesteps      | 160000     |
| train/                  |            |
|    approx_kl            | 0.02803571 |
|    clip_fraction        | 0.313      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.1       |
|    explained_variance   | 0.783      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.066     |
|    n_updates            | 780        |
|    policy_gradient_loss | -0.0576    |
|    std                  | 0.518      |
|    value_loss           | 0.0273     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 136      |
|    ep_rew_mean     | -32      |
| time/              |          |
|    fps             | 170      |
|    iterations      | 79       |
|    time_elapsed    | 949      |
|    total_timesteps | 161792   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 148         |
|    ep_rew_mean          | -32.7       |
| time/                   |             |
|    fps                  | 170         |
|    iterations           | 80          |
|    time_elapsed         | 958         |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.025497567 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.02       |
|    explained_variance   | 0.808       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0611     |
|    n_updates            | 790         |
|    policy_gradient_loss | -0.0528     |
|    std                  | 0.512       |
|    value_loss           | 0.0188      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 149         |
|    ep_rew_mean          | -31.5       |
| time/                   |             |
|    fps                  | 171         |
|    iterations           | 81          |
|    time_elapsed         | 968         |
|    total_timesteps      | 165888      |
| train/                  |             |
|    approx_kl            | 0.028565634 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.94       |
|    explained_variance   | 0.816       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0633     |
|    n_updates            | 800         |
|    policy_gradient_loss | -0.0554     |
|    std                  | 0.507       |
|    value_loss           | 0.0247      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 169        |
|    ep_rew_mean          | -34.4      |
| time/                   |            |
|    fps                  | 171        |
|    iterations           | 82         |
|    time_elapsed         | 977        |
|    total_timesteps      | 167936     |
| train/                  |            |
|    approx_kl            | 0.02878559 |
|    clip_fraction        | 0.313      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.84      |
|    explained_variance   | 0.743      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0741    |
|    n_updates            | 810        |
|    policy_gradient_loss | -0.0608    |
|    std                  | 0.5        |
|    value_loss           | 0.0403     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 160         |
|    ep_rew_mean          | -28.2       |
| time/                   |             |
|    fps                  | 172         |
|    iterations           | 83          |
|    time_elapsed         | 986         |
|    total_timesteps      | 169984      |
| train/                  |             |
|    approx_kl            | 0.025934735 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.75       |
|    explained_variance   | 0.76        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0563     |
|    n_updates            | 820         |
|    policy_gradient_loss | -0.0546     |
|    std                  | 0.495       |
|    value_loss           | 0.0097      |
-----------------------------------------
Eval num_timesteps=170000, episode_reward=206.67 +/- 182.07
Episode length: 212.28 +/- 248.26
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 212         |
|    mean_reward          | 207         |
| time/                   |             |
|    total_timesteps      | 170000      |
| train/                  |             |
|    approx_kl            | 0.024370492 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.67       |
|    explained_variance   | 0.737       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0704     |
|    n_updates            | 830         |
|    policy_gradient_loss | -0.0569     |
|    std                  | 0.491       |
|    value_loss           | 0.0282      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 129      |
|    ep_rew_mean     | -15.5    |
| time/              |          |
|    fps             | 171      |
|    iterations      | 84       |
|    time_elapsed    | 1003     |
|    total_timesteps | 172032   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 130         |
|    ep_rew_mean          | -14.6       |
| time/                   |             |
|    fps                  | 171         |
|    iterations           | 85          |
|    time_elapsed         | 1012        |
|    total_timesteps      | 174080      |
| train/                  |             |
|    approx_kl            | 0.027070526 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.58       |
|    explained_variance   | 0.815       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0763     |
|    n_updates            | 840         |
|    policy_gradient_loss | -0.0585     |
|    std                  | 0.485       |
|    value_loss           | 0.0201      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 119         |
|    ep_rew_mean          | -9.36       |
| time/                   |             |
|    fps                  | 172         |
|    iterations           | 86          |
|    time_elapsed         | 1022        |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.024231788 |
|    clip_fraction        | 0.247       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.51       |
|    explained_variance   | 0.688       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0785     |
|    n_updates            | 850         |
|    policy_gradient_loss | -0.0541     |
|    std                  | 0.481       |
|    value_loss           | 0.0254      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 122        |
|    ep_rew_mean          | -8.44      |
| time/                   |            |
|    fps                  | 172        |
|    iterations           | 87         |
|    time_elapsed         | 1032       |
|    total_timesteps      | 178176     |
| train/                  |            |
|    approx_kl            | 0.02930731 |
|    clip_fraction        | 0.302      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.44      |
|    explained_variance   | 0.784      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0791    |
|    n_updates            | 860        |
|    policy_gradient_loss | -0.0593    |
|    std                  | 0.476      |
|    value_loss           | 0.0195     |
----------------------------------------
Eval num_timesteps=180000, episode_reward=195.51 +/- 252.34
Episode length: 222.28 +/- 324.45
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 222        |
|    mean_reward          | 196        |
| time/                   |            |
|    total_timesteps      | 180000     |
| train/                  |            |
|    approx_kl            | 0.02921195 |
|    clip_fraction        | 0.312      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.31      |
|    explained_variance   | 0.724      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0588    |
|    n_updates            | 870        |
|    policy_gradient_loss | -0.0545    |
|    std                  | 0.467      |
|    value_loss           | 0.0141     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 115      |
|    ep_rew_mean     | -2.56    |
| time/              |          |
|    fps             | 171      |
|    iterations      | 88       |
|    time_elapsed    | 1052     |
|    total_timesteps | 180224   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 132         |
|    ep_rew_mean          | -1.88       |
| time/                   |             |
|    fps                  | 171         |
|    iterations           | 89          |
|    time_elapsed         | 1061        |
|    total_timesteps      | 182272      |
| train/                  |             |
|    approx_kl            | 0.031657547 |
|    clip_fraction        | 0.323       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.21       |
|    explained_variance   | 0.755       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0868     |
|    n_updates            | 880         |
|    policy_gradient_loss | -0.0582     |
|    std                  | 0.464       |
|    value_loss           | 0.0307      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 127         |
|    ep_rew_mean          | 0.0873      |
| time/                   |             |
|    fps                  | 172         |
|    iterations           | 90          |
|    time_elapsed         | 1070        |
|    total_timesteps      | 184320      |
| train/                  |             |
|    approx_kl            | 0.029277276 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.14       |
|    explained_variance   | 0.772       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0774     |
|    n_updates            | 890         |
|    policy_gradient_loss | -0.0577     |
|    std                  | 0.458       |
|    value_loss           | 0.0246      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 121         |
|    ep_rew_mean          | 3.43        |
| time/                   |             |
|    fps                  | 172         |
|    iterations           | 91          |
|    time_elapsed         | 1080        |
|    total_timesteps      | 186368      |
| train/                  |             |
|    approx_kl            | 0.030493606 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.05       |
|    explained_variance   | 0.714       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0751     |
|    n_updates            | 900         |
|    policy_gradient_loss | -0.06       |
|    std                  | 0.454       |
|    value_loss           | 0.0268      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 123         |
|    ep_rew_mean          | 6.69        |
| time/                   |             |
|    fps                  | 172         |
|    iterations           | 92          |
|    time_elapsed         | 1089        |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 0.026391583 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.99       |
|    explained_variance   | 0.7         |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0349     |
|    n_updates            | 910         |
|    policy_gradient_loss | -0.0533     |
|    std                  | 0.451       |
|    value_loss           | 0.0319      |
-----------------------------------------
Eval num_timesteps=190000, episode_reward=187.65 +/- 236.49
Episode length: 214.04 +/- 313.60
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 214       |
|    mean_reward          | 188       |
| time/                   |           |
|    total_timesteps      | 190000    |
| train/                  |           |
|    approx_kl            | 0.0276077 |
|    clip_fraction        | 0.302     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.94     |
|    explained_variance   | 0.696     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0796   |
|    n_updates            | 920       |
|    policy_gradient_loss | -0.0571   |
|    std                  | 0.448     |
|    value_loss           | 0.0339    |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 109      |
|    ep_rew_mean     | 8.55     |
| time/              |          |
|    fps             | 170      |
|    iterations      | 93       |
|    time_elapsed    | 1116     |
|    total_timesteps | 190464   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 109         |
|    ep_rew_mean          | 9.29        |
| time/                   |             |
|    fps                  | 171         |
|    iterations           | 94          |
|    time_elapsed         | 1125        |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 0.028718762 |
|    clip_fraction        | 0.298       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.87       |
|    explained_variance   | 0.752       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0729     |
|    n_updates            | 930         |
|    policy_gradient_loss | -0.0562     |
|    std                  | 0.443       |
|    value_loss           | 0.0193      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 91.5        |
|    ep_rew_mean          | 15.3        |
| time/                   |             |
|    fps                  | 171         |
|    iterations           | 95          |
|    time_elapsed         | 1135        |
|    total_timesteps      | 194560      |
| train/                  |             |
|    approx_kl            | 0.029496213 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.77       |
|    explained_variance   | 0.701       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0711     |
|    n_updates            | 940         |
|    policy_gradient_loss | -0.0568     |
|    std                  | 0.438       |
|    value_loss           | 0.0175      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 105         |
|    ep_rew_mean          | 17.9        |
| time/                   |             |
|    fps                  | 171         |
|    iterations           | 96          |
|    time_elapsed         | 1144        |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.029682204 |
|    clip_fraction        | 0.322       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.7        |
|    explained_variance   | 0.564       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0808     |
|    n_updates            | 950         |
|    policy_gradient_loss | -0.0609     |
|    std                  | 0.435       |
|    value_loss           | 0.0447      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 111         |
|    ep_rew_mean          | 17.8        |
| time/                   |             |
|    fps                  | 172         |
|    iterations           | 97          |
|    time_elapsed         | 1153        |
|    total_timesteps      | 198656      |
| train/                  |             |
|    approx_kl            | 0.031407446 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.62       |
|    explained_variance   | 0.57        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.078      |
|    n_updates            | 960         |
|    policy_gradient_loss | -0.0617     |
|    std                  | 0.43        |
|    value_loss           | 0.0227      |
-----------------------------------------
Eval num_timesteps=200000, episode_reward=360.09 +/- 282.25
Episode length: 406.68 +/- 364.83
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 407         |
|    mean_reward          | 360         |
| time/                   |             |
|    total_timesteps      | 200000      |
| train/                  |             |
|    approx_kl            | 0.030718789 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.53       |
|    explained_variance   | 0.407       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0911     |
|    n_updates            | 970         |
|    policy_gradient_loss | -0.0611     |
|    std                  | 0.426       |
|    value_loss           | 0.0193      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 121      |
|    ep_rew_mean     | 18.2     |
| time/              |          |
|    fps             | 170      |
|    iterations      | 98       |
|    time_elapsed    | 1177     |
|    total_timesteps | 200704   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 107         |
|    ep_rew_mean          | 21.6        |
| time/                   |             |
|    fps                  | 170         |
|    iterations           | 99          |
|    time_elapsed         | 1187        |
|    total_timesteps      | 202752      |
| train/                  |             |
|    approx_kl            | 0.029132519 |
|    clip_fraction        | 0.322       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.48       |
|    explained_variance   | 0.555       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0712     |
|    n_updates            | 980         |
|    policy_gradient_loss | -0.0598     |
|    std                  | 0.423       |
|    value_loss           | 0.0269      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 113        |
|    ep_rew_mean          | 24         |
| time/                   |            |
|    fps                  | 171        |
|    iterations           | 100        |
|    time_elapsed         | 1196       |
|    total_timesteps      | 204800     |
| train/                  |            |
|    approx_kl            | 0.02998598 |
|    clip_fraction        | 0.303      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.42      |
|    explained_variance   | 0.431      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0829    |
|    n_updates            | 990        |
|    policy_gradient_loss | -0.0572    |
|    std                  | 0.42       |
|    value_loss           | 0.0309     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 129         |
|    ep_rew_mean          | 26.2        |
| time/                   |             |
|    fps                  | 171         |
|    iterations           | 101         |
|    time_elapsed         | 1205        |
|    total_timesteps      | 206848      |
| train/                  |             |
|    approx_kl            | 0.030864047 |
|    clip_fraction        | 0.319       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.37       |
|    explained_variance   | 0.503       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0618     |
|    n_updates            | 1000        |
|    policy_gradient_loss | -0.0616     |
|    std                  | 0.418       |
|    value_loss           | 0.0576      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 130         |
|    ep_rew_mean          | 27.4        |
| time/                   |             |
|    fps                  | 171         |
|    iterations           | 102         |
|    time_elapsed         | 1215        |
|    total_timesteps      | 208896      |
| train/                  |             |
|    approx_kl            | 0.029836379 |
|    clip_fraction        | 0.317       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.29       |
|    explained_variance   | 0.611       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0726     |
|    n_updates            | 1010        |
|    policy_gradient_loss | -0.0574     |
|    std                  | 0.412       |
|    value_loss           | 0.0103      |
-----------------------------------------
Eval num_timesteps=210000, episode_reward=331.79 +/- 296.86
Episode length: 313.20 +/- 320.50
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 313         |
|    mean_reward          | 332         |
| time/                   |             |
|    total_timesteps      | 210000      |
| train/                  |             |
|    approx_kl            | 0.034138307 |
|    clip_fraction        | 0.326       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.22       |
|    explained_variance   | 0.716       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0457     |
|    n_updates            | 1020        |
|    policy_gradient_loss | -0.0578     |
|    std                  | 0.41        |
|    value_loss           | 0.0263      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 127      |
|    ep_rew_mean     | 31.4     |
| time/              |          |
|    fps             | 170      |
|    iterations      | 103      |
|    time_elapsed    | 1234     |
|    total_timesteps | 210944   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 125         |
|    ep_rew_mean          | 33.6        |
| time/                   |             |
|    fps                  | 171         |
|    iterations           | 104         |
|    time_elapsed         | 1243        |
|    total_timesteps      | 212992      |
| train/                  |             |
|    approx_kl            | 0.028102309 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.16       |
|    explained_variance   | 0.649       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.08       |
|    n_updates            | 1030        |
|    policy_gradient_loss | -0.0598     |
|    std                  | 0.406       |
|    value_loss           | 0.0464      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 146         |
|    ep_rew_mean          | 35.8        |
| time/                   |             |
|    fps                  | 171         |
|    iterations           | 105         |
|    time_elapsed         | 1252        |
|    total_timesteps      | 215040      |
| train/                  |             |
|    approx_kl            | 0.032038264 |
|    clip_fraction        | 0.336       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.1        |
|    explained_variance   | 0.547       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0764     |
|    n_updates            | 1040        |
|    policy_gradient_loss | -0.0559     |
|    std                  | 0.404       |
|    value_loss           | 0.0187      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 157         |
|    ep_rew_mean          | 38.1        |
| time/                   |             |
|    fps                  | 171         |
|    iterations           | 106         |
|    time_elapsed         | 1262        |
|    total_timesteps      | 217088      |
| train/                  |             |
|    approx_kl            | 0.030055713 |
|    clip_fraction        | 0.298       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.05       |
|    explained_variance   | 0.584       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.056      |
|    n_updates            | 1050        |
|    policy_gradient_loss | -0.0568     |
|    std                  | 0.401       |
|    value_loss           | 0.0157      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 161         |
|    ep_rew_mean          | 38.6        |
| time/                   |             |
|    fps                  | 172         |
|    iterations           | 107         |
|    time_elapsed         | 1271        |
|    total_timesteps      | 219136      |
| train/                  |             |
|    approx_kl            | 0.032027952 |
|    clip_fraction        | 0.335       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.98       |
|    explained_variance   | 0.666       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0704     |
|    n_updates            | 1060        |
|    policy_gradient_loss | -0.0572     |
|    std                  | 0.397       |
|    value_loss           | 0.0182      |
-----------------------------------------
Eval num_timesteps=220000, episode_reward=656.84 +/- 249.72
Episode length: 742.92 +/- 322.10
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 743         |
|    mean_reward          | 657         |
| time/                   |             |
|    total_timesteps      | 220000      |
| train/                  |             |
|    approx_kl            | 0.034980565 |
|    clip_fraction        | 0.358       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.9        |
|    explained_variance   | 0.543       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.087      |
|    n_updates            | 1070        |
|    policy_gradient_loss | -0.0631     |
|    std                  | 0.393       |
|    value_loss           | 0.0248      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 173      |
|    ep_rew_mean     | 40.2     |
| time/              |          |
|    fps             | 170      |
|    iterations      | 108      |
|    time_elapsed    | 1299     |
|    total_timesteps | 221184   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 184         |
|    ep_rew_mean          | 42.5        |
| time/                   |             |
|    fps                  | 170         |
|    iterations           | 109         |
|    time_elapsed         | 1308        |
|    total_timesteps      | 223232      |
| train/                  |             |
|    approx_kl            | 0.031348266 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.83       |
|    explained_variance   | 0.57        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0508     |
|    n_updates            | 1080        |
|    policy_gradient_loss | -0.0569     |
|    std                  | 0.39        |
|    value_loss           | 0.0274      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 200         |
|    ep_rew_mean          | 45.8        |
| time/                   |             |
|    fps                  | 170         |
|    iterations           | 110         |
|    time_elapsed         | 1318        |
|    total_timesteps      | 225280      |
| train/                  |             |
|    approx_kl            | 0.032923117 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.73       |
|    explained_variance   | 0.66        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0917     |
|    n_updates            | 1090        |
|    policy_gradient_loss | -0.0554     |
|    std                  | 0.384       |
|    value_loss           | 0.0109      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 189         |
|    ep_rew_mean          | 48          |
| time/                   |             |
|    fps                  | 171         |
|    iterations           | 111         |
|    time_elapsed         | 1327        |
|    total_timesteps      | 227328      |
| train/                  |             |
|    approx_kl            | 0.031859957 |
|    clip_fraction        | 0.319       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.59       |
|    explained_variance   | 0.764       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0772     |
|    n_updates            | 1100        |
|    policy_gradient_loss | -0.0544     |
|    std                  | 0.377       |
|    value_loss           | 0.00669     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 210         |
|    ep_rew_mean          | 53.1        |
| time/                   |             |
|    fps                  | 171         |
|    iterations           | 112         |
|    time_elapsed         | 1337        |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.035721004 |
|    clip_fraction        | 0.332       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.5        |
|    explained_variance   | 0.507       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0704     |
|    n_updates            | 1110        |
|    policy_gradient_loss | -0.061      |
|    std                  | 0.375       |
|    value_loss           | 0.0415      |
-----------------------------------------
Eval num_timesteps=230000, episode_reward=491.84 +/- 322.05
Episode length: 593.56 +/- 437.58
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 594        |
|    mean_reward          | 492        |
| time/                   |            |
|    total_timesteps      | 230000     |
| train/                  |            |
|    approx_kl            | 0.03427653 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.43      |
|    explained_variance   | 0.635      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0631    |
|    n_updates            | 1120       |
|    policy_gradient_loss | -0.059     |
|    std                  | 0.37       |
|    value_loss           | 0.015      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 229      |
|    ep_rew_mean     | 58.3     |
| time/              |          |
|    fps             | 169      |
|    iterations      | 113      |
|    time_elapsed    | 1366     |
|    total_timesteps | 231424   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 230        |
|    ep_rew_mean          | 63.2       |
| time/                   |            |
|    fps                  | 169        |
|    iterations           | 114        |
|    time_elapsed         | 1375       |
|    total_timesteps      | 233472     |
| train/                  |            |
|    approx_kl            | 0.03754565 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.32      |
|    explained_variance   | 0.784      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0732    |
|    n_updates            | 1130       |
|    policy_gradient_loss | -0.0603    |
|    std                  | 0.365      |
|    value_loss           | 0.00986    |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 234       |
|    ep_rew_mean          | 67.3      |
| time/                   |           |
|    fps                  | 170       |
|    iterations           | 115       |
|    time_elapsed         | 1385      |
|    total_timesteps      | 235520    |
| train/                  |           |
|    approx_kl            | 0.0382208 |
|    clip_fraction        | 0.365     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.23     |
|    explained_variance   | 0.412     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0926   |
|    n_updates            | 1140      |
|    policy_gradient_loss | -0.064    |
|    std                  | 0.362     |
|    value_loss           | 0.0534    |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 238        |
|    ep_rew_mean          | 74.5       |
| time/                   |            |
|    fps                  | 170        |
|    iterations           | 116        |
|    time_elapsed         | 1394       |
|    total_timesteps      | 237568     |
| train/                  |            |
|    approx_kl            | 0.03529099 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.17      |
|    explained_variance   | 0.648      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0781    |
|    n_updates            | 1150       |
|    policy_gradient_loss | -0.0593    |
|    std                  | 0.359      |
|    value_loss           | 0.0192     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 237        |
|    ep_rew_mean          | 76.9       |
| time/                   |            |
|    fps                  | 170        |
|    iterations           | 117        |
|    time_elapsed         | 1403       |
|    total_timesteps      | 239616     |
| train/                  |            |
|    approx_kl            | 0.03601989 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.1       |
|    explained_variance   | 0.583      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0758    |
|    n_updates            | 1160       |
|    policy_gradient_loss | -0.0582    |
|    std                  | 0.356      |
|    value_loss           | 0.0334     |
----------------------------------------
Eval num_timesteps=240000, episode_reward=794.20 +/- 389.18
Episode length: 707.44 +/- 371.06
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 707        |
|    mean_reward          | 794        |
| time/                   |            |
|    total_timesteps      | 240000     |
| train/                  |            |
|    approx_kl            | 0.03496913 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.05      |
|    explained_variance   | 0.483      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0664    |
|    n_updates            | 1170       |
|    policy_gradient_loss | -0.0587    |
|    std                  | 0.354      |
|    value_loss           | 0.0241     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | 83.5     |
| time/              |          |
|    fps             | 168      |
|    iterations      | 118      |
|    time_elapsed    | 1432     |
|    total_timesteps | 241664   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 248        |
|    ep_rew_mean          | 87         |
| time/                   |            |
|    fps                  | 169        |
|    iterations           | 119        |
|    time_elapsed         | 1441       |
|    total_timesteps      | 243712     |
| train/                  |            |
|    approx_kl            | 0.03485586 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3         |
|    explained_variance   | 0.507      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0739    |
|    n_updates            | 1180       |
|    policy_gradient_loss | -0.056     |
|    std                  | 0.352      |
|    value_loss           | 0.0241     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 256        |
|    ep_rew_mean          | 90.2       |
| time/                   |            |
|    fps                  | 169        |
|    iterations           | 120        |
|    time_elapsed         | 1450       |
|    total_timesteps      | 245760     |
| train/                  |            |
|    approx_kl            | 0.03926234 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.93      |
|    explained_variance   | 0.61       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0718    |
|    n_updates            | 1190       |
|    policy_gradient_loss | -0.0605    |
|    std                  | 0.349      |
|    value_loss           | 0.0292     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 267         |
|    ep_rew_mean          | 96          |
| time/                   |             |
|    fps                  | 169         |
|    iterations           | 121         |
|    time_elapsed         | 1460        |
|    total_timesteps      | 247808      |
| train/                  |             |
|    approx_kl            | 0.037695475 |
|    clip_fraction        | 0.335       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.87       |
|    explained_variance   | 0.677       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0706     |
|    n_updates            | 1200        |
|    policy_gradient_loss | -0.0572     |
|    std                  | 0.345       |
|    value_loss           | 0.0217      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 258         |
|    ep_rew_mean          | 98.8        |
| time/                   |             |
|    fps                  | 170         |
|    iterations           | 122         |
|    time_elapsed         | 1469        |
|    total_timesteps      | 249856      |
| train/                  |             |
|    approx_kl            | 0.034385763 |
|    clip_fraction        | 0.34        |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.77       |
|    explained_variance   | 0.536       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0725     |
|    n_updates            | 1210        |
|    policy_gradient_loss | -0.0551     |
|    std                  | 0.341       |
|    value_loss           | 0.0174      |
-----------------------------------------
Eval num_timesteps=250000, episode_reward=1086.22 +/- 256.51
Episode length: 917.36 +/- 212.83
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 917         |
|    mean_reward          | 1.09e+03    |
| time/                   |             |
|    total_timesteps      | 250000      |
| train/                  |             |
|    approx_kl            | 0.036944024 |
|    clip_fraction        | 0.365       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.68       |
|    explained_variance   | 0.609       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0505     |
|    n_updates            | 1220        |
|    policy_gradient_loss | -0.0557     |
|    std                  | 0.337       |
|    value_loss           | 0.0211      |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 257      |
|    ep_rew_mean     | 101      |
| time/              |          |
|    fps             | 168      |
|    iterations      | 123      |
|    time_elapsed    | 1499     |
|    total_timesteps | 251904   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 277         |
|    ep_rew_mean          | 108         |
| time/                   |             |
|    fps                  | 168         |
|    iterations           | 124         |
|    time_elapsed         | 1508        |
|    total_timesteps      | 253952      |
| train/                  |             |
|    approx_kl            | 0.036267966 |
|    clip_fraction        | 0.36        |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.57       |
|    explained_variance   | 0.556       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0593     |
|    n_updates            | 1230        |
|    policy_gradient_loss | -0.0525     |
|    std                  | 0.332       |
|    value_loss           | 0.00763     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 279         |
|    ep_rew_mean          | 111         |
| time/                   |             |
|    fps                  | 168         |
|    iterations           | 125         |
|    time_elapsed         | 1517        |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.035445265 |
|    clip_fraction        | 0.357       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.46       |
|    explained_variance   | 0.3         |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0613     |
|    n_updates            | 1240        |
|    policy_gradient_loss | -0.054      |
|    std                  | 0.328       |
|    value_loss           | 0.0104      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 285         |
|    ep_rew_mean          | 116         |
| time/                   |             |
|    fps                  | 168         |
|    iterations           | 126         |
|    time_elapsed         | 1527        |
|    total_timesteps      | 258048      |
| train/                  |             |
|    approx_kl            | 0.037542097 |
|    clip_fraction        | 0.368       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.36       |
|    explained_variance   | 0.711       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0702     |
|    n_updates            | 1250        |
|    policy_gradient_loss | -0.0621     |
|    std                  | 0.324       |
|    value_loss           | 0.0226      |
-----------------------------------------
Eval num_timesteps=260000, episode_reward=1022.58 +/- 353.96
Episode length: 888.12 +/- 294.86
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 888         |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 260000      |
| train/                  |             |
|    approx_kl            | 0.039170086 |
|    clip_fraction        | 0.356       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.31       |
|    explained_variance   | 0.866       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0884     |
|    n_updates            | 1260        |
|    policy_gradient_loss | -0.056      |
|    std                  | 0.323       |
|    value_loss           | 0.0111      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 296      |
|    ep_rew_mean     | 128      |
| time/              |          |
|    fps             | 167      |
|    iterations      | 127      |
|    time_elapsed    | 1557     |
|    total_timesteps | 260096   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 299         |
|    ep_rew_mean          | 131         |
| time/                   |             |
|    fps                  | 167         |
|    iterations           | 128         |
|    time_elapsed         | 1566        |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.039270144 |
|    clip_fraction        | 0.361       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.24       |
|    explained_variance   | 0.826       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0777     |
|    n_updates            | 1270        |
|    policy_gradient_loss | -0.054      |
|    std                  | 0.319       |
|    value_loss           | 0.0133      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 318         |
|    ep_rew_mean          | 141         |
| time/                   |             |
|    fps                  | 167         |
|    iterations           | 129         |
|    time_elapsed         | 1575        |
|    total_timesteps      | 264192      |
| train/                  |             |
|    approx_kl            | 0.041098386 |
|    clip_fraction        | 0.369       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.17       |
|    explained_variance   | 0.741       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0836     |
|    n_updates            | 1280        |
|    policy_gradient_loss | -0.0554     |
|    std                  | 0.317       |
|    value_loss           | 0.0298      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 332         |
|    ep_rew_mean          | 149         |
| time/                   |             |
|    fps                  | 167         |
|    iterations           | 130         |
|    time_elapsed         | 1585        |
|    total_timesteps      | 266240      |
| train/                  |             |
|    approx_kl            | 0.042486414 |
|    clip_fraction        | 0.366       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.83        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0886     |
|    n_updates            | 1290        |
|    policy_gradient_loss | -0.0568     |
|    std                  | 0.315       |
|    value_loss           | 0.018       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 329        |
|    ep_rew_mean          | 150        |
| time/                   |            |
|    fps                  | 168        |
|    iterations           | 131        |
|    time_elapsed         | 1594       |
|    total_timesteps      | 268288     |
| train/                  |            |
|    approx_kl            | 0.03828093 |
|    clip_fraction        | 0.371      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.05      |
|    explained_variance   | 0.702      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0493    |
|    n_updates            | 1300       |
|    policy_gradient_loss | -0.0504    |
|    std                  | 0.312      |
|    value_loss           | 0.0342     |
----------------------------------------
Eval num_timesteps=270000, episode_reward=775.58 +/- 472.44
Episode length: 624.12 +/- 390.97
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 624        |
|    mean_reward          | 776        |
| time/                   |            |
|    total_timesteps      | 270000     |
| train/                  |            |
|    approx_kl            | 0.03626761 |
|    clip_fraction        | 0.371      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.99      |
|    explained_variance   | 0.497      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0655    |
|    n_updates            | 1310       |
|    policy_gradient_loss | -0.0565    |
|    std                  | 0.31       |
|    value_loss           | 0.0336     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 333      |
|    ep_rew_mean     | 157      |
| time/              |          |
|    fps             | 167      |
|    iterations      | 132      |
|    time_elapsed    | 1618     |
|    total_timesteps | 270336   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 334       |
|    ep_rew_mean          | 160       |
| time/                   |           |
|    fps                  | 167       |
|    iterations           | 133       |
|    time_elapsed         | 1627      |
|    total_timesteps      | 272384    |
| train/                  |           |
|    approx_kl            | 0.0388505 |
|    clip_fraction        | 0.38      |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.94     |
|    explained_variance   | 0.661     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0587   |
|    n_updates            | 1320      |
|    policy_gradient_loss | -0.0612   |
|    std                  | 0.308     |
|    value_loss           | 0.0361    |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 339         |
|    ep_rew_mean          | 166         |
| time/                   |             |
|    fps                  | 167         |
|    iterations           | 134         |
|    time_elapsed         | 1636        |
|    total_timesteps      | 274432      |
| train/                  |             |
|    approx_kl            | 0.037775796 |
|    clip_fraction        | 0.359       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.9        |
|    explained_variance   | 0.583       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.068      |
|    n_updates            | 1330        |
|    policy_gradient_loss | -0.0547     |
|    std                  | 0.307       |
|    value_loss           | 0.0549      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 348         |
|    ep_rew_mean          | 173         |
| time/                   |             |
|    fps                  | 167         |
|    iterations           | 135         |
|    time_elapsed         | 1646        |
|    total_timesteps      | 276480      |
| train/                  |             |
|    approx_kl            | 0.046146557 |
|    clip_fraction        | 0.4         |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.82       |
|    explained_variance   | 0.787       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.094      |
|    n_updates            | 1340        |
|    policy_gradient_loss | -0.0581     |
|    std                  | 0.303       |
|    value_loss           | 0.0183      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 366        |
|    ep_rew_mean          | 180        |
| time/                   |            |
|    fps                  | 168        |
|    iterations           | 136        |
|    time_elapsed         | 1655       |
|    total_timesteps      | 278528     |
| train/                  |            |
|    approx_kl            | 0.03774166 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.76      |
|    explained_variance   | 0.579      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0663    |
|    n_updates            | 1350       |
|    policy_gradient_loss | -0.0509    |
|    std                  | 0.301      |
|    value_loss           | 0.0233     |
----------------------------------------
Eval num_timesteps=280000, episode_reward=935.74 +/- 381.87
Episode length: 759.80 +/- 328.82
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 760         |
|    mean_reward          | 936         |
| time/                   |             |
|    total_timesteps      | 280000      |
| train/                  |             |
|    approx_kl            | 0.044813033 |
|    clip_fraction        | 0.393       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.69       |
|    explained_variance   | 0.738       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0883     |
|    n_updates            | 1360        |
|    policy_gradient_loss | -0.0603     |
|    std                  | 0.298       |
|    value_loss           | 0.0147      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 375      |
|    ep_rew_mean     | 189      |
| time/              |          |
|    fps             | 166      |
|    iterations      | 137      |
|    time_elapsed    | 1684     |
|    total_timesteps | 280576   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 391        |
|    ep_rew_mean          | 196        |
| time/                   |            |
|    fps                  | 166        |
|    iterations           | 138        |
|    time_elapsed         | 1693       |
|    total_timesteps      | 282624     |
| train/                  |            |
|    approx_kl            | 0.04082506 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.63      |
|    explained_variance   | 0.801      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0788    |
|    n_updates            | 1370       |
|    policy_gradient_loss | -0.0589    |
|    std                  | 0.297      |
|    value_loss           | 0.0272     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 397        |
|    ep_rew_mean          | 205        |
| time/                   |            |
|    fps                  | 167        |
|    iterations           | 139        |
|    time_elapsed         | 1703       |
|    total_timesteps      | 284672     |
| train/                  |            |
|    approx_kl            | 0.04034036 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.56      |
|    explained_variance   | 0.829      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0702    |
|    n_updates            | 1380       |
|    policy_gradient_loss | -0.0543    |
|    std                  | 0.293      |
|    value_loss           | 0.0256     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 377         |
|    ep_rew_mean          | 204         |
| time/                   |             |
|    fps                  | 167         |
|    iterations           | 140         |
|    time_elapsed         | 1712        |
|    total_timesteps      | 286720      |
| train/                  |             |
|    approx_kl            | 0.043823972 |
|    clip_fraction        | 0.383       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.49       |
|    explained_variance   | 0.567       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0674     |
|    n_updates            | 1390        |
|    policy_gradient_loss | -0.0563     |
|    std                  | 0.291       |
|    value_loss           | 0.0534      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 378        |
|    ep_rew_mean          | 206        |
| time/                   |            |
|    fps                  | 167        |
|    iterations           | 141        |
|    time_elapsed         | 1722       |
|    total_timesteps      | 288768     |
| train/                  |            |
|    approx_kl            | 0.04310924 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.46      |
|    explained_variance   | 0.576      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0709    |
|    n_updates            | 1400       |
|    policy_gradient_loss | -0.0541    |
|    std                  | 0.291      |
|    value_loss           | 0.0548     |
----------------------------------------
Eval num_timesteps=290000, episode_reward=971.24 +/- 364.49
Episode length: 798.48 +/- 310.19
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 798         |
|    mean_reward          | 971         |
| time/                   |             |
|    total_timesteps      | 290000      |
| train/                  |             |
|    approx_kl            | 0.043718763 |
|    clip_fraction        | 0.398       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.4        |
|    explained_variance   | 0.623       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0796     |
|    n_updates            | 1410        |
|    policy_gradient_loss | -0.0522     |
|    std                  | 0.287       |
|    value_loss           | 0.0254      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 384      |
|    ep_rew_mean     | 214      |
| time/              |          |
|    fps             | 165      |
|    iterations      | 142      |
|    time_elapsed    | 1752     |
|    total_timesteps | 290816   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 386         |
|    ep_rew_mean          | 217         |
| time/                   |             |
|    fps                  | 166         |
|    iterations           | 143         |
|    time_elapsed         | 1763        |
|    total_timesteps      | 292864      |
| train/                  |             |
|    approx_kl            | 0.047041617 |
|    clip_fraction        | 0.386       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.32       |
|    explained_variance   | 0.431       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0654     |
|    n_updates            | 1420        |
|    policy_gradient_loss | -0.0533     |
|    std                  | 0.285       |
|    value_loss           | 0.0166      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 395        |
|    ep_rew_mean          | 223        |
| time/                   |            |
|    fps                  | 166        |
|    iterations           | 144        |
|    time_elapsed         | 1773       |
|    total_timesteps      | 294912     |
| train/                  |            |
|    approx_kl            | 0.04994437 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.23      |
|    explained_variance   | 0.694      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0739    |
|    n_updates            | 1430       |
|    policy_gradient_loss | -0.0551    |
|    std                  | 0.282      |
|    value_loss           | 0.0136     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 384         |
|    ep_rew_mean          | 223         |
| time/                   |             |
|    fps                  | 166         |
|    iterations           | 145         |
|    time_elapsed         | 1782        |
|    total_timesteps      | 296960      |
| train/                  |             |
|    approx_kl            | 0.038422085 |
|    clip_fraction        | 0.357       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.16       |
|    explained_variance   | 0.694       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0719     |
|    n_updates            | 1440        |
|    policy_gradient_loss | -0.0467     |
|    std                  | 0.279       |
|    value_loss           | 0.0201      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 375        |
|    ep_rew_mean          | 223        |
| time/                   |            |
|    fps                  | 166        |
|    iterations           | 146        |
|    time_elapsed         | 1792       |
|    total_timesteps      | 299008     |
| train/                  |            |
|    approx_kl            | 0.04358527 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.11      |
|    explained_variance   | 0.52       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0668    |
|    n_updates            | 1450       |
|    policy_gradient_loss | -0.0517    |
|    std                  | 0.278      |
|    value_loss           | 0.0348     |
----------------------------------------
Eval num_timesteps=300000, episode_reward=954.15 +/- 332.73
Episode length: 863.16 +/- 298.59
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 863         |
|    mean_reward          | 954         |
| time/                   |             |
|    total_timesteps      | 300000      |
| train/                  |             |
|    approx_kl            | 0.042073116 |
|    clip_fraction        | 0.39        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.06       |
|    explained_variance   | 0.389       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0721     |
|    n_updates            | 1460        |
|    policy_gradient_loss | -0.0566     |
|    std                  | 0.276       |
|    value_loss           | 0.0449      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 385      |
|    ep_rew_mean     | 229      |
| time/              |          |
|    fps             | 165      |
|    iterations      | 147      |
|    time_elapsed    | 1822     |
|    total_timesteps | 301056   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 381         |
|    ep_rew_mean          | 238         |
| time/                   |             |
|    fps                  | 165         |
|    iterations           | 148         |
|    time_elapsed         | 1831        |
|    total_timesteps      | 303104      |
| train/                  |             |
|    approx_kl            | 0.048358493 |
|    clip_fraction        | 0.416       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.02       |
|    explained_variance   | 0.805       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0808     |
|    n_updates            | 1470        |
|    policy_gradient_loss | -0.0585     |
|    std                  | 0.275       |
|    value_loss           | 0.0165      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 389         |
|    ep_rew_mean          | 249         |
| time/                   |             |
|    fps                  | 165         |
|    iterations           | 149         |
|    time_elapsed         | 1841        |
|    total_timesteps      | 305152      |
| train/                  |             |
|    approx_kl            | 0.044151064 |
|    clip_fraction        | 0.395       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.997      |
|    explained_variance   | 0.531       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0729     |
|    n_updates            | 1480        |
|    policy_gradient_loss | -0.054      |
|    std                  | 0.274       |
|    value_loss           | 0.0466      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 401        |
|    ep_rew_mean          | 257        |
| time/                   |            |
|    fps                  | 165        |
|    iterations           | 150        |
|    time_elapsed         | 1850       |
|    total_timesteps      | 307200     |
| train/                  |            |
|    approx_kl            | 0.04259987 |
|    clip_fraction        | 0.397      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.94      |
|    explained_variance   | 0.362      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0304    |
|    n_updates            | 1490       |
|    policy_gradient_loss | -0.0552    |
|    std                  | 0.271      |
|    value_loss           | 0.0416     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 423        |
|    ep_rew_mean          | 270        |
| time/                   |            |
|    fps                  | 166        |
|    iterations           | 151        |
|    time_elapsed         | 1860       |
|    total_timesteps      | 309248     |
| train/                  |            |
|    approx_kl            | 0.03963415 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.855     |
|    explained_variance   | 0.607      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0453    |
|    n_updates            | 1500       |
|    policy_gradient_loss | -0.0457    |
|    std                  | 0.269      |
|    value_loss           | 0.0182     |
----------------------------------------
Eval num_timesteps=310000, episode_reward=998.56 +/- 485.09
Episode length: 725.04 +/- 356.62
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 725         |
|    mean_reward          | 999         |
| time/                   |             |
|    total_timesteps      | 310000      |
| train/                  |             |
|    approx_kl            | 0.048526112 |
|    clip_fraction        | 0.396       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.78       |
|    explained_variance   | 0.608       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0819     |
|    n_updates            | 1510        |
|    policy_gradient_loss | -0.053      |
|    std                  | 0.266       |
|    value_loss           | 0.0124      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 427      |
|    ep_rew_mean     | 276      |
| time/              |          |
|    fps             | 164      |
|    iterations      | 152      |
|    time_elapsed    | 1887     |
|    total_timesteps | 311296   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 419       |
|    ep_rew_mean          | 275       |
| time/                   |           |
|    fps                  | 165       |
|    iterations           | 153       |
|    time_elapsed         | 1896      |
|    total_timesteps      | 313344    |
| train/                  |           |
|    approx_kl            | 0.0477783 |
|    clip_fraction        | 0.413     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.723    |
|    explained_variance   | 0.627     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0811   |
|    n_updates            | 1520      |
|    policy_gradient_loss | -0.0505   |
|    std                  | 0.265     |
|    value_loss           | 0.0134    |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 402        |
|    ep_rew_mean          | 271        |
| time/                   |            |
|    fps                  | 165        |
|    iterations           | 154        |
|    time_elapsed         | 1906       |
|    total_timesteps      | 315392     |
| train/                  |            |
|    approx_kl            | 0.04903561 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.658     |
|    explained_variance   | 0.535      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0506    |
|    n_updates            | 1530       |
|    policy_gradient_loss | -0.0543    |
|    std                  | 0.262      |
|    value_loss           | 0.0329     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 379         |
|    ep_rew_mean          | 267         |
| time/                   |             |
|    fps                  | 165         |
|    iterations           | 155         |
|    time_elapsed         | 1915        |
|    total_timesteps      | 317440      |
| train/                  |             |
|    approx_kl            | 0.047192276 |
|    clip_fraction        | 0.419       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.585      |
|    explained_variance   | 0.537       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0766     |
|    n_updates            | 1540        |
|    policy_gradient_loss | -0.0609     |
|    std                  | 0.26        |
|    value_loss           | 0.0695      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 377        |
|    ep_rew_mean          | 270        |
| time/                   |            |
|    fps                  | 165        |
|    iterations           | 156        |
|    time_elapsed         | 1924       |
|    total_timesteps      | 319488     |
| train/                  |            |
|    approx_kl            | 0.04702081 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.559     |
|    explained_variance   | 0.601      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0481    |
|    n_updates            | 1550       |
|    policy_gradient_loss | -0.0521    |
|    std                  | 0.26       |
|    value_loss           | 0.0572     |
----------------------------------------
Eval num_timesteps=320000, episode_reward=905.25 +/- 358.54
Episode length: 758.20 +/- 309.58
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 758         |
|    mean_reward          | 905         |
| time/                   |             |
|    total_timesteps      | 320000      |
| train/                  |             |
|    approx_kl            | 0.040610593 |
|    clip_fraction        | 0.402       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.512      |
|    explained_variance   | 0.759       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.06       |
|    n_updates            | 1560        |
|    policy_gradient_loss | -0.0542     |
|    std                  | 0.257       |
|    value_loss           | 0.0201      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 379      |
|    ep_rew_mean     | 276      |
| time/              |          |
|    fps             | 164      |
|    iterations      | 157      |
|    time_elapsed    | 1954     |
|    total_timesteps | 321536   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 392        |
|    ep_rew_mean          | 288        |
| time/                   |            |
|    fps                  | 164        |
|    iterations           | 158        |
|    time_elapsed         | 1963       |
|    total_timesteps      | 323584     |
| train/                  |            |
|    approx_kl            | 0.04980985 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.458     |
|    explained_variance   | 0.491      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.104     |
|    n_updates            | 1570       |
|    policy_gradient_loss | -0.056     |
|    std                  | 0.256      |
|    value_loss           | 0.0244     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 405        |
|    ep_rew_mean          | 300        |
| time/                   |            |
|    fps                  | 165        |
|    iterations           | 159        |
|    time_elapsed         | 1973       |
|    total_timesteps      | 325632     |
| train/                  |            |
|    approx_kl            | 0.05076261 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.4       |
|    explained_variance   | 0.573      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0579    |
|    n_updates            | 1580       |
|    policy_gradient_loss | -0.0566    |
|    std                  | 0.254      |
|    value_loss           | 0.043      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 412        |
|    ep_rew_mean          | 308        |
| time/                   |            |
|    fps                  | 165        |
|    iterations           | 160        |
|    time_elapsed         | 1982       |
|    total_timesteps      | 327680     |
| train/                  |            |
|    approx_kl            | 0.04700556 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.35      |
|    explained_variance   | 0.284      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0597    |
|    n_updates            | 1590       |
|    policy_gradient_loss | -0.0528    |
|    std                  | 0.253      |
|    value_loss           | 0.0333     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 415        |
|    ep_rew_mean          | 312        |
| time/                   |            |
|    fps                  | 165        |
|    iterations           | 161        |
|    time_elapsed         | 1991       |
|    total_timesteps      | 329728     |
| train/                  |            |
|    approx_kl            | 0.04774118 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.314     |
|    explained_variance   | 0.629      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0834    |
|    n_updates            | 1600       |
|    policy_gradient_loss | -0.05      |
|    std                  | 0.251      |
|    value_loss           | 0.031      |
----------------------------------------
Eval num_timesteps=330000, episode_reward=1246.59 +/- 441.67
Episode length: 849.48 +/- 288.90
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 849        |
|    mean_reward          | 1.25e+03   |
| time/                   |            |
|    total_timesteps      | 330000     |
| train/                  |            |
|    approx_kl            | 0.04912918 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.262     |
|    explained_variance   | 0.338      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0408    |
|    n_updates            | 1610       |
|    policy_gradient_loss | -0.0515    |
|    std                  | 0.25       |
|    value_loss           | 0.0219     |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 405      |
|    ep_rew_mean     | 315      |
| time/              |          |
|    fps             | 164      |
|    iterations      | 162      |
|    time_elapsed    | 2021     |
|    total_timesteps | 331776   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 412         |
|    ep_rew_mean          | 321         |
| time/                   |             |
|    fps                  | 164         |
|    iterations           | 163         |
|    time_elapsed         | 2031        |
|    total_timesteps      | 333824      |
| train/                  |             |
|    approx_kl            | 0.048460107 |
|    clip_fraction        | 0.436       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.231      |
|    explained_variance   | 0.436       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0334     |
|    n_updates            | 1620        |
|    policy_gradient_loss | -0.0513     |
|    std                  | 0.249       |
|    value_loss           | 0.0443      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 408         |
|    ep_rew_mean          | 322         |
| time/                   |             |
|    fps                  | 164         |
|    iterations           | 164         |
|    time_elapsed         | 2040        |
|    total_timesteps      | 335872      |
| train/                  |             |
|    approx_kl            | 0.049908042 |
|    clip_fraction        | 0.421       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.165      |
|    explained_variance   | 0.802       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0447     |
|    n_updates            | 1630        |
|    policy_gradient_loss | -0.0492     |
|    std                  | 0.246       |
|    value_loss           | 0.00782     |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 426        |
|    ep_rew_mean          | 337        |
| time/                   |            |
|    fps                  | 164        |
|    iterations           | 165        |
|    time_elapsed         | 2050       |
|    total_timesteps      | 337920     |
| train/                  |            |
|    approx_kl            | 0.04661295 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0978    |
|    explained_variance   | 0.628      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.075     |
|    n_updates            | 1640       |
|    policy_gradient_loss | -0.0454    |
|    std                  | 0.244      |
|    value_loss           | 0.0231     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 435        |
|    ep_rew_mean          | 345        |
| time/                   |            |
|    fps                  | 165        |
|    iterations           | 166        |
|    time_elapsed         | 2059       |
|    total_timesteps      | 339968     |
| train/                  |            |
|    approx_kl            | 0.05469592 |
|    clip_fraction        | 0.442      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0258    |
|    explained_variance   | 0.816      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0709    |
|    n_updates            | 1650       |
|    policy_gradient_loss | -0.0612    |
|    std                  | 0.243      |
|    value_loss           | 0.011      |
----------------------------------------
Eval num_timesteps=340000, episode_reward=1130.88 +/- 445.38
Episode length: 784.36 +/- 301.58
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 784        |
|    mean_reward          | 1.13e+03   |
| time/                   |            |
|    total_timesteps      | 340000     |
| train/                  |            |
|    approx_kl            | 0.04745142 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0341     |
|    explained_variance   | 0.748      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0461    |
|    n_updates            | 1660       |
|    policy_gradient_loss | -0.0502    |
|    std                  | 0.241      |
|    value_loss           | 0.0189     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 432      |
|    ep_rew_mean     | 344      |
| time/              |          |
|    fps             | 163      |
|    iterations      | 167      |
|    time_elapsed    | 2087     |
|    total_timesteps | 342016   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 445        |
|    ep_rew_mean          | 355        |
| time/                   |            |
|    fps                  | 164        |
|    iterations           | 168        |
|    time_elapsed         | 2096       |
|    total_timesteps      | 344064     |
| train/                  |            |
|    approx_kl            | 0.05781409 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0902     |
|    explained_variance   | 0.407      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0464    |
|    n_updates            | 1670       |
|    policy_gradient_loss | -0.0517    |
|    std                  | 0.239      |
|    value_loss           | 0.0423     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 435         |
|    ep_rew_mean          | 352         |
| time/                   |             |
|    fps                  | 164         |
|    iterations           | 169         |
|    time_elapsed         | 2106        |
|    total_timesteps      | 346112      |
| train/                  |             |
|    approx_kl            | 0.051676042 |
|    clip_fraction        | 0.442       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.147       |
|    explained_variance   | 0.501       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0634     |
|    n_updates            | 1680        |
|    policy_gradient_loss | -0.0514     |
|    std                  | 0.237       |
|    value_loss           | 0.0217      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 446         |
|    ep_rew_mean          | 363         |
| time/                   |             |
|    fps                  | 164         |
|    iterations           | 170         |
|    time_elapsed         | 2115        |
|    total_timesteps      | 348160      |
| train/                  |             |
|    approx_kl            | 0.047368012 |
|    clip_fraction        | 0.421       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.205       |
|    explained_variance   | 0.316       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0763     |
|    n_updates            | 1690        |
|    policy_gradient_loss | -0.0514     |
|    std                  | 0.236       |
|    value_loss           | 0.025       |
-----------------------------------------
Eval num_timesteps=350000, episode_reward=955.35 +/- 457.62
Episode length: 702.12 +/- 334.55
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 702         |
|    mean_reward          | 955         |
| time/                   |             |
|    total_timesteps      | 350000      |
| train/                  |             |
|    approx_kl            | 0.054525834 |
|    clip_fraction        | 0.439       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.272       |
|    explained_variance   | 0.742       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.064      |
|    n_updates            | 1700        |
|    policy_gradient_loss | -0.0536     |
|    std                  | 0.233       |
|    value_loss           | 0.0329      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 450      |
|    ep_rew_mean     | 369      |
| time/              |          |
|    fps             | 163      |
|    iterations      | 171      |
|    time_elapsed    | 2143     |
|    total_timesteps | 350208   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 440         |
|    ep_rew_mean          | 369         |
| time/                   |             |
|    fps                  | 163         |
|    iterations           | 172         |
|    time_elapsed         | 2152        |
|    total_timesteps      | 352256      |
| train/                  |             |
|    approx_kl            | 0.048840337 |
|    clip_fraction        | 0.435       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.341       |
|    explained_variance   | 0.581       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0652     |
|    n_updates            | 1710        |
|    policy_gradient_loss | -0.0516     |
|    std                  | 0.232       |
|    value_loss           | 0.0402      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 427         |
|    ep_rew_mean          | 371         |
| time/                   |             |
|    fps                  | 163         |
|    iterations           | 173         |
|    time_elapsed         | 2162        |
|    total_timesteps      | 354304      |
| train/                  |             |
|    approx_kl            | 0.049133193 |
|    clip_fraction        | 0.436       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.41        |
|    explained_variance   | 0.387       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0451     |
|    n_updates            | 1720        |
|    policy_gradient_loss | -0.0486     |
|    std                  | 0.23        |
|    value_loss           | 0.041       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 428        |
|    ep_rew_mean          | 378        |
| time/                   |            |
|    fps                  | 164        |
|    iterations           | 174        |
|    time_elapsed         | 2171       |
|    total_timesteps      | 356352     |
| train/                  |            |
|    approx_kl            | 0.04913529 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.459      |
|    explained_variance   | 0.498      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0446    |
|    n_updates            | 1730       |
|    policy_gradient_loss | -0.0532    |
|    std                  | 0.228      |
|    value_loss           | 0.0326     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 442         |
|    ep_rew_mean          | 392         |
| time/                   |             |
|    fps                  | 164         |
|    iterations           | 175         |
|    time_elapsed         | 2181        |
|    total_timesteps      | 358400      |
| train/                  |             |
|    approx_kl            | 0.054239467 |
|    clip_fraction        | 0.418       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.486       |
|    explained_variance   | 0.262       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0476     |
|    n_updates            | 1740        |
|    policy_gradient_loss | -0.0495     |
|    std                  | 0.228       |
|    value_loss           | 0.0531      |
-----------------------------------------
Eval num_timesteps=360000, episode_reward=913.69 +/- 418.02
Episode length: 663.76 +/- 316.37
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 664         |
|    mean_reward          | 914         |
| time/                   |             |
|    total_timesteps      | 360000      |
| train/                  |             |
|    approx_kl            | 0.060599204 |
|    clip_fraction        | 0.45        |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.522       |
|    explained_variance   | 0.363       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0681     |
|    n_updates            | 1750        |
|    policy_gradient_loss | -0.052      |
|    std                  | 0.226       |
|    value_loss           | 0.0361      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 457      |
|    ep_rew_mean     | 412      |
| time/              |          |
|    fps             | 163      |
|    iterations      | 176      |
|    time_elapsed    | 2207     |
|    total_timesteps | 360448   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 462        |
|    ep_rew_mean          | 416        |
| time/                   |            |
|    fps                  | 163        |
|    iterations           | 177        |
|    time_elapsed         | 2216       |
|    total_timesteps      | 362496     |
| train/                  |            |
|    approx_kl            | 0.06433913 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.563      |
|    explained_variance   | 0.617      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.061     |
|    n_updates            | 1760       |
|    policy_gradient_loss | -0.0569    |
|    std                  | 0.226      |
|    value_loss           | 0.0243     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 478        |
|    ep_rew_mean          | 430        |
| time/                   |            |
|    fps                  | 163        |
|    iterations           | 178        |
|    time_elapsed         | 2225       |
|    total_timesteps      | 364544     |
| train/                  |            |
|    approx_kl            | 0.05098413 |
|    clip_fraction        | 0.437      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.605      |
|    explained_variance   | 0.815      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0311    |
|    n_updates            | 1770       |
|    policy_gradient_loss | -0.0517    |
|    std                  | 0.224      |
|    value_loss           | 0.0253     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 484         |
|    ep_rew_mean          | 436         |
| time/                   |             |
|    fps                  | 164         |
|    iterations           | 179         |
|    time_elapsed         | 2235        |
|    total_timesteps      | 366592      |
| train/                  |             |
|    approx_kl            | 0.055777512 |
|    clip_fraction        | 0.45        |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.661       |
|    explained_variance   | 0.638       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0472     |
|    n_updates            | 1780        |
|    policy_gradient_loss | -0.0471     |
|    std                  | 0.223       |
|    value_loss           | 0.0331      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 490         |
|    ep_rew_mean          | 442         |
| time/                   |             |
|    fps                  | 164         |
|    iterations           | 180         |
|    time_elapsed         | 2244        |
|    total_timesteps      | 368640      |
| train/                  |             |
|    approx_kl            | 0.060432162 |
|    clip_fraction        | 0.457       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.727       |
|    explained_variance   | 0.837       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0972     |
|    n_updates            | 1790        |
|    policy_gradient_loss | -0.0546     |
|    std                  | 0.221       |
|    value_loss           | 0.0122      |
-----------------------------------------
Eval num_timesteps=370000, episode_reward=974.13 +/- 485.42
Episode length: 696.20 +/- 346.99
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 696        |
|    mean_reward          | 974        |
| time/                   |            |
|    total_timesteps      | 370000     |
| train/                  |            |
|    approx_kl            | 0.06318136 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.796      |
|    explained_variance   | 0.864      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0502    |
|    n_updates            | 1800       |
|    policy_gradient_loss | -0.0511    |
|    std                  | 0.219      |
|    value_loss           | 0.0118     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 498      |
|    ep_rew_mean     | 454      |
| time/              |          |
|    fps             | 163      |
|    iterations      | 181      |
|    time_elapsed    | 2270     |
|    total_timesteps | 370688   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 504         |
|    ep_rew_mean          | 467         |
| time/                   |             |
|    fps                  | 163         |
|    iterations           | 182         |
|    time_elapsed         | 2280        |
|    total_timesteps      | 372736      |
| train/                  |             |
|    approx_kl            | 0.060049564 |
|    clip_fraction        | 0.472       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.883       |
|    explained_variance   | 0.522       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0394     |
|    n_updates            | 1810        |
|    policy_gradient_loss | -0.0539     |
|    std                  | 0.216       |
|    value_loss           | 0.0324      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 507         |
|    ep_rew_mean          | 474         |
| time/                   |             |
|    fps                  | 163         |
|    iterations           | 183         |
|    time_elapsed         | 2289        |
|    total_timesteps      | 374784      |
| train/                  |             |
|    approx_kl            | 0.067739934 |
|    clip_fraction        | 0.472       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.958       |
|    explained_variance   | 0.376       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.102      |
|    n_updates            | 1820        |
|    policy_gradient_loss | -0.0539     |
|    std                  | 0.215       |
|    value_loss           | 0.0329      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 516        |
|    ep_rew_mean          | 481        |
| time/                   |            |
|    fps                  | 163        |
|    iterations           | 184        |
|    time_elapsed         | 2298       |
|    total_timesteps      | 376832     |
| train/                  |            |
|    approx_kl            | 0.05449806 |
|    clip_fraction        | 0.449      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.01       |
|    explained_variance   | 0.498      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0701    |
|    n_updates            | 1830       |
|    policy_gradient_loss | -0.0522    |
|    std                  | 0.214      |
|    value_loss           | 0.0267     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 525       |
|    ep_rew_mean          | 492       |
| time/                   |           |
|    fps                  | 164       |
|    iterations           | 185       |
|    time_elapsed         | 2308      |
|    total_timesteps      | 378880    |
| train/                  |           |
|    approx_kl            | 0.0662691 |
|    clip_fraction        | 0.47      |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.05      |
|    explained_variance   | 0.837     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0654   |
|    n_updates            | 1840      |
|    policy_gradient_loss | -0.0561   |
|    std                  | 0.213     |
|    value_loss           | 0.0178    |
---------------------------------------
Eval num_timesteps=380000, episode_reward=983.64 +/- 433.66
Episode length: 747.64 +/- 329.18
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 748        |
|    mean_reward          | 984        |
| time/                   |            |
|    total_timesteps      | 380000     |
| train/                  |            |
|    approx_kl            | 0.06875734 |
|    clip_fraction        | 0.469      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.09       |
|    explained_variance   | 0.697      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0863    |
|    n_updates            | 1850       |
|    policy_gradient_loss | -0.0513    |
|    std                  | 0.212      |
|    value_loss           | 0.0399     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 529      |
|    ep_rew_mean     | 503      |
| time/              |          |
|    fps             | 163      |
|    iterations      | 186      |
|    time_elapsed    | 2336     |
|    total_timesteps | 380928   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 537         |
|    ep_rew_mean          | 509         |
| time/                   |             |
|    fps                  | 163         |
|    iterations           | 187         |
|    time_elapsed         | 2345        |
|    total_timesteps      | 382976      |
| train/                  |             |
|    approx_kl            | 0.058381587 |
|    clip_fraction        | 0.444       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.12        |
|    explained_variance   | 0.305       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0615     |
|    n_updates            | 1860        |
|    policy_gradient_loss | -0.0497     |
|    std                  | 0.21        |
|    value_loss           | 0.0439      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 543         |
|    ep_rew_mean          | 519         |
| time/                   |             |
|    fps                  | 163         |
|    iterations           | 188         |
|    time_elapsed         | 2354        |
|    total_timesteps      | 385024      |
| train/                  |             |
|    approx_kl            | 0.054896094 |
|    clip_fraction        | 0.436       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.19        |
|    explained_variance   | 0.893       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0914     |
|    n_updates            | 1870        |
|    policy_gradient_loss | -0.0486     |
|    std                  | 0.209       |
|    value_loss           | 0.00412     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 545         |
|    ep_rew_mean          | 528         |
| time/                   |             |
|    fps                  | 163         |
|    iterations           | 189         |
|    time_elapsed         | 2364        |
|    total_timesteps      | 387072      |
| train/                  |             |
|    approx_kl            | 0.057522967 |
|    clip_fraction        | 0.457       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.23        |
|    explained_variance   | 0.691       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0588     |
|    n_updates            | 1880        |
|    policy_gradient_loss | -0.0535     |
|    std                  | 0.207       |
|    value_loss           | 0.0388      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 531        |
|    ep_rew_mean          | 528        |
| time/                   |            |
|    fps                  | 163        |
|    iterations           | 190        |
|    time_elapsed         | 2373       |
|    total_timesteps      | 389120     |
| train/                  |            |
|    approx_kl            | 0.06009191 |
|    clip_fraction        | 0.462      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.27       |
|    explained_variance   | 0.277      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0686    |
|    n_updates            | 1890       |
|    policy_gradient_loss | -0.0491    |
|    std                  | 0.207      |
|    value_loss           | 0.0339     |
----------------------------------------
Eval num_timesteps=390000, episode_reward=993.46 +/- 569.04
Episode length: 712.24 +/- 384.63
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 712         |
|    mean_reward          | 993         |
| time/                   |             |
|    total_timesteps      | 390000      |
| train/                  |             |
|    approx_kl            | 0.055241525 |
|    clip_fraction        | 0.447       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.29        |
|    explained_variance   | 0.566       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0518     |
|    n_updates            | 1900        |
|    policy_gradient_loss | -0.0461     |
|    std                  | 0.206       |
|    value_loss           | 0.055       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 535      |
|    ep_rew_mean     | 537      |
| time/              |          |
|    fps             | 162      |
|    iterations      | 191      |
|    time_elapsed    | 2400     |
|    total_timesteps | 391168   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 524        |
|    ep_rew_mean          | 533        |
| time/                   |            |
|    fps                  | 163        |
|    iterations           | 192        |
|    time_elapsed         | 2409       |
|    total_timesteps      | 393216     |
| train/                  |            |
|    approx_kl            | 0.06486933 |
|    clip_fraction        | 0.474      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.34       |
|    explained_variance   | 0.782      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0749    |
|    n_updates            | 1910       |
|    policy_gradient_loss | -0.0526    |
|    std                  | 0.205      |
|    value_loss           | 0.0235     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 533         |
|    ep_rew_mean          | 544         |
| time/                   |             |
|    fps                  | 163         |
|    iterations           | 193         |
|    time_elapsed         | 2419        |
|    total_timesteps      | 395264      |
| train/                  |             |
|    approx_kl            | 0.062023133 |
|    clip_fraction        | 0.475       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.39        |
|    explained_variance   | 0.827       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0586     |
|    n_updates            | 1920        |
|    policy_gradient_loss | -0.0504     |
|    std                  | 0.203       |
|    value_loss           | 0.0312      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 536        |
|    ep_rew_mean          | 552        |
| time/                   |            |
|    fps                  | 163        |
|    iterations           | 194        |
|    time_elapsed         | 2428       |
|    total_timesteps      | 397312     |
| train/                  |            |
|    approx_kl            | 0.06616648 |
|    clip_fraction        | 0.455      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.45       |
|    explained_variance   | 0.866      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0849    |
|    n_updates            | 1930       |
|    policy_gradient_loss | -0.0511    |
|    std                  | 0.202      |
|    value_loss           | 0.0115     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 538        |
|    ep_rew_mean          | 560        |
| time/                   |            |
|    fps                  | 163        |
|    iterations           | 195        |
|    time_elapsed         | 2437       |
|    total_timesteps      | 399360     |
| train/                  |            |
|    approx_kl            | 0.07258315 |
|    clip_fraction        | 0.477      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.48       |
|    explained_variance   | 0.757      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0361    |
|    n_updates            | 1940       |
|    policy_gradient_loss | -0.047     |
|    std                  | 0.201      |
|    value_loss           | 0.0461     |
----------------------------------------
Eval num_timesteps=400000, episode_reward=1036.83 +/- 611.52
Episode length: 667.00 +/- 390.06
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 667        |
|    mean_reward          | 1.04e+03   |
| time/                   |            |
|    total_timesteps      | 400000     |
| train/                  |            |
|    approx_kl            | 0.06705046 |
|    clip_fraction        | 0.487      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.52       |
|    explained_variance   | 0.722      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0877    |
|    n_updates            | 1950       |
|    policy_gradient_loss | -0.0523    |
|    std                  | 0.201      |
|    value_loss           | 0.0283     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 528      |
|    ep_rew_mean     | 550      |
| time/              |          |
|    fps             | 162      |
|    iterations      | 196      |
|    time_elapsed    | 2466     |
|    total_timesteps | 401408   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 529        |
|    ep_rew_mean          | 555        |
| time/                   |            |
|    fps                  | 162        |
|    iterations           | 197        |
|    time_elapsed         | 2476       |
|    total_timesteps      | 403456     |
| train/                  |            |
|    approx_kl            | 0.05691368 |
|    clip_fraction        | 0.463      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.55       |
|    explained_variance   | 0.572      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0447    |
|    n_updates            | 1960       |
|    policy_gradient_loss | -0.0494    |
|    std                  | 0.2        |
|    value_loss           | 0.056      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 539        |
|    ep_rew_mean          | 564        |
| time/                   |            |
|    fps                  | 163        |
|    iterations           | 198        |
|    time_elapsed         | 2485       |
|    total_timesteps      | 405504     |
| train/                  |            |
|    approx_kl            | 0.06811033 |
|    clip_fraction        | 0.477      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.6        |
|    explained_variance   | 0.286      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0278    |
|    n_updates            | 1970       |
|    policy_gradient_loss | -0.0506    |
|    std                  | 0.198      |
|    value_loss           | 0.0377     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 528        |
|    ep_rew_mean          | 559        |
| time/                   |            |
|    fps                  | 163        |
|    iterations           | 199        |
|    time_elapsed         | 2494       |
|    total_timesteps      | 407552     |
| train/                  |            |
|    approx_kl            | 0.06680164 |
|    clip_fraction        | 0.473      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.64       |
|    explained_variance   | 0.802      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0752    |
|    n_updates            | 1980       |
|    policy_gradient_loss | -0.0482    |
|    std                  | 0.197      |
|    value_loss           | 0.019      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 541        |
|    ep_rew_mean          | 576        |
| time/                   |            |
|    fps                  | 163        |
|    iterations           | 200        |
|    time_elapsed         | 2504       |
|    total_timesteps      | 409600     |
| train/                  |            |
|    approx_kl            | 0.06596927 |
|    clip_fraction        | 0.498      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.65       |
|    explained_variance   | 0.272      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0366    |
|    n_updates            | 1990       |
|    policy_gradient_loss | -0.0462    |
|    std                  | 0.197      |
|    value_loss           | 0.0591     |
----------------------------------------
Eval num_timesteps=410000, episode_reward=1138.27 +/- 563.76
Episode length: 707.64 +/- 334.13
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 708        |
|    mean_reward          | 1.14e+03   |
| time/                   |            |
|    total_timesteps      | 410000     |
| train/                  |            |
|    approx_kl            | 0.06922875 |
|    clip_fraction        | 0.49       |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.69       |
|    explained_variance   | 0.444      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0548    |
|    n_updates            | 2000       |
|    policy_gradient_loss | -0.0515    |
|    std                  | 0.196      |
|    value_loss           | 0.023      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 535      |
|    ep_rew_mean     | 575      |
| time/              |          |
|    fps             | 162      |
|    iterations      | 201      |
|    time_elapsed    | 2530     |
|    total_timesteps | 411648   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 547         |
|    ep_rew_mean          | 583         |
| time/                   |             |
|    fps                  | 162         |
|    iterations           | 202         |
|    time_elapsed         | 2540        |
|    total_timesteps      | 413696      |
| train/                  |             |
|    approx_kl            | 0.063398354 |
|    clip_fraction        | 0.473       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.72        |
|    explained_variance   | 0.556       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0557     |
|    n_updates            | 2010        |
|    policy_gradient_loss | -0.0465     |
|    std                  | 0.195       |
|    value_loss           | 0.0605      |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 552       |
|    ep_rew_mean          | 584       |
| time/                   |           |
|    fps                  | 163       |
|    iterations           | 203       |
|    time_elapsed         | 2549      |
|    total_timesteps      | 415744    |
| train/                  |           |
|    approx_kl            | 0.0374019 |
|    clip_fraction        | 0.395     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.78      |
|    explained_variance   | 0.804     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0379   |
|    n_updates            | 2020      |
|    policy_gradient_loss | -0.029    |
|    std                  | 0.194     |
|    value_loss           | 0.00118   |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 565         |
|    ep_rew_mean          | 599         |
| time/                   |             |
|    fps                  | 163         |
|    iterations           | 204         |
|    time_elapsed         | 2559        |
|    total_timesteps      | 417792      |
| train/                  |             |
|    approx_kl            | 0.070357785 |
|    clip_fraction        | 0.475       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.82        |
|    explained_variance   | 0.45        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0609     |
|    n_updates            | 2030        |
|    policy_gradient_loss | -0.0488     |
|    std                  | 0.193       |
|    value_loss           | 0.0372      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 575         |
|    ep_rew_mean          | 619         |
| time/                   |             |
|    fps                  | 163         |
|    iterations           | 205         |
|    time_elapsed         | 2568        |
|    total_timesteps      | 419840      |
| train/                  |             |
|    approx_kl            | 0.061391998 |
|    clip_fraction        | 0.463       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.86        |
|    explained_variance   | 0.846       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0486     |
|    n_updates            | 2040        |
|    policy_gradient_loss | -0.0472     |
|    std                  | 0.192       |
|    value_loss           | 0.0167      |
-----------------------------------------
Eval num_timesteps=420000, episode_reward=1136.45 +/- 645.60
Episode length: 637.80 +/- 353.26
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 638        |
|    mean_reward          | 1.14e+03   |
| time/                   |            |
|    total_timesteps      | 420000     |
| train/                  |            |
|    approx_kl            | 0.07336651 |
|    clip_fraction        | 0.503      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.92       |
|    explained_variance   | 0.645      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0455    |
|    n_updates            | 2050       |
|    policy_gradient_loss | -0.0582    |
|    std                  | 0.19       |
|    value_loss           | 0.026      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 573      |
|    ep_rew_mean     | 626      |
| time/              |          |
|    fps             | 162      |
|    iterations      | 206      |
|    time_elapsed    | 2594     |
|    total_timesteps | 421888   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 577        |
|    ep_rew_mean          | 639        |
| time/                   |            |
|    fps                  | 162        |
|    iterations           | 207        |
|    time_elapsed         | 2603       |
|    total_timesteps      | 423936     |
| train/                  |            |
|    approx_kl            | 0.07455063 |
|    clip_fraction        | 0.493      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.99       |
|    explained_variance   | 0.809      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0758    |
|    n_updates            | 2060       |
|    policy_gradient_loss | -0.0524    |
|    std                  | 0.189      |
|    value_loss           | 0.0338     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 579        |
|    ep_rew_mean          | 655        |
| time/                   |            |
|    fps                  | 163        |
|    iterations           | 208        |
|    time_elapsed         | 2613       |
|    total_timesteps      | 425984     |
| train/                  |            |
|    approx_kl            | 0.07630103 |
|    clip_fraction        | 0.484      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.04       |
|    explained_variance   | 0.762      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0835    |
|    n_updates            | 2070       |
|    policy_gradient_loss | -0.0521    |
|    std                  | 0.188      |
|    value_loss           | 0.0259     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 568        |
|    ep_rew_mean          | 648        |
| time/                   |            |
|    fps                  | 163        |
|    iterations           | 209        |
|    time_elapsed         | 2622       |
|    total_timesteps      | 428032     |
| train/                  |            |
|    approx_kl            | 0.07113959 |
|    clip_fraction        | 0.489      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.09       |
|    explained_variance   | 0.381      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0559    |
|    n_updates            | 2080       |
|    policy_gradient_loss | -0.0513    |
|    std                  | 0.186      |
|    value_loss           | 0.0228     |
----------------------------------------
Eval num_timesteps=430000, episode_reward=1264.56 +/- 624.85
Episode length: 719.12 +/- 338.64
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 719        |
|    mean_reward          | 1.26e+03   |
| time/                   |            |
|    total_timesteps      | 430000     |
| train/                  |            |
|    approx_kl            | 0.06764528 |
|    clip_fraction        | 0.491      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.15       |
|    explained_variance   | 0.77       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0529    |
|    n_updates            | 2090       |
|    policy_gradient_loss | -0.0508    |
|    std                  | 0.185      |
|    value_loss           | 0.0332     |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 546      |
|    ep_rew_mean     | 630      |
| time/              |          |
|    fps             | 162      |
|    iterations      | 210      |
|    time_elapsed    | 2650     |
|    total_timesteps | 430080   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 544        |
|    ep_rew_mean          | 634        |
| time/                   |            |
|    fps                  | 162        |
|    iterations           | 211        |
|    time_elapsed         | 2660       |
|    total_timesteps      | 432128     |
| train/                  |            |
|    approx_kl            | 0.07191268 |
|    clip_fraction        | 0.518      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.19       |
|    explained_variance   | 0.153      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0479    |
|    n_updates            | 2100       |
|    policy_gradient_loss | -0.0455    |
|    std                  | 0.184      |
|    value_loss           | 0.0768     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 534        |
|    ep_rew_mean          | 630        |
| time/                   |            |
|    fps                  | 162        |
|    iterations           | 212        |
|    time_elapsed         | 2669       |
|    total_timesteps      | 434176     |
| train/                  |            |
|    approx_kl            | 0.06601645 |
|    clip_fraction        | 0.468      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.24       |
|    explained_variance   | 0.743      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0534    |
|    n_updates            | 2110       |
|    policy_gradient_loss | -0.0449    |
|    std                  | 0.183      |
|    value_loss           | 0.0514     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 521        |
|    ep_rew_mean          | 632        |
| time/                   |            |
|    fps                  | 162        |
|    iterations           | 213        |
|    time_elapsed         | 2679       |
|    total_timesteps      | 436224     |
| train/                  |            |
|    approx_kl            | 0.07058303 |
|    clip_fraction        | 0.501      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.27       |
|    explained_variance   | 0.511      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0321    |
|    n_updates            | 2120       |
|    policy_gradient_loss | -0.0482    |
|    std                  | 0.183      |
|    value_loss           | 0.0778     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 529        |
|    ep_rew_mean          | 641        |
| time/                   |            |
|    fps                  | 163        |
|    iterations           | 214        |
|    time_elapsed         | 2688       |
|    total_timesteps      | 438272     |
| train/                  |            |
|    approx_kl            | 0.07298003 |
|    clip_fraction        | 0.505      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.31       |
|    explained_variance   | 0.317      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0802    |
|    n_updates            | 2130       |
|    policy_gradient_loss | -0.0447    |
|    std                  | 0.181      |
|    value_loss           | 0.0643     |
----------------------------------------
Eval num_timesteps=440000, episode_reward=1370.58 +/- 561.72
Episode length: 741.48 +/- 307.01
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 741        |
|    mean_reward          | 1.37e+03   |
| time/                   |            |
|    total_timesteps      | 440000     |
| train/                  |            |
|    approx_kl            | 0.07020792 |
|    clip_fraction        | 0.496      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.38       |
|    explained_variance   | 0.948      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0876    |
|    n_updates            | 2140       |
|    policy_gradient_loss | -0.0443    |
|    std                  | 0.18       |
|    value_loss           | 0.011      |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 526      |
|    ep_rew_mean     | 637      |
| time/              |          |
|    fps             | 161      |
|    iterations      | 215      |
|    time_elapsed    | 2718     |
|    total_timesteps | 440320   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 535        |
|    ep_rew_mean          | 647        |
| time/                   |            |
|    fps                  | 162        |
|    iterations           | 216        |
|    time_elapsed         | 2727       |
|    total_timesteps      | 442368     |
| train/                  |            |
|    approx_kl            | 0.06251098 |
|    clip_fraction        | 0.478      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.43       |
|    explained_variance   | 0.711      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0481    |
|    n_updates            | 2150       |
|    policy_gradient_loss | -0.0438    |
|    std                  | 0.179      |
|    value_loss           | 0.0567     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 525         |
|    ep_rew_mean          | 640         |
| time/                   |             |
|    fps                  | 162         |
|    iterations           | 217         |
|    time_elapsed         | 2737        |
|    total_timesteps      | 444416      |
| train/                  |             |
|    approx_kl            | 0.080988325 |
|    clip_fraction        | 0.526       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.46        |
|    explained_variance   | 0.808       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0726     |
|    n_updates            | 2160        |
|    policy_gradient_loss | -0.0492     |
|    std                  | 0.178       |
|    value_loss           | 0.0377      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 536        |
|    ep_rew_mean          | 655        |
| time/                   |            |
|    fps                  | 162        |
|    iterations           | 218        |
|    time_elapsed         | 2746       |
|    total_timesteps      | 446464     |
| train/                  |            |
|    approx_kl            | 0.07348829 |
|    clip_fraction        | 0.51       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.52       |
|    explained_variance   | 0.71       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0457    |
|    n_updates            | 2170       |
|    policy_gradient_loss | -0.0468    |
|    std                  | 0.177      |
|    value_loss           | 0.0365     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 527         |
|    ep_rew_mean          | 649         |
| time/                   |             |
|    fps                  | 162         |
|    iterations           | 219         |
|    time_elapsed         | 2755        |
|    total_timesteps      | 448512      |
| train/                  |             |
|    approx_kl            | 0.075970605 |
|    clip_fraction        | 0.488       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.56        |
|    explained_variance   | 0.908       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0498     |
|    n_updates            | 2180        |
|    policy_gradient_loss | -0.0461     |
|    std                  | 0.176       |
|    value_loss           | 0.0202      |
-----------------------------------------
Eval num_timesteps=450000, episode_reward=1727.57 +/- 425.64
Episode length: 881.68 +/- 216.85
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 882        |
|    mean_reward          | 1.73e+03   |
| time/                   |            |
|    total_timesteps      | 450000     |
| train/                  |            |
|    approx_kl            | 0.07303947 |
|    clip_fraction        | 0.475      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.6        |
|    explained_variance   | 0.87       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0357    |
|    n_updates            | 2190       |
|    policy_gradient_loss | -0.0423    |
|    std                  | 0.175      |
|    value_loss           | 0.0297     |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 530      |
|    ep_rew_mean     | 662      |
| time/              |          |
|    fps             | 161      |
|    iterations      | 220      |
|    time_elapsed    | 2785     |
|    total_timesteps | 450560   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 535        |
|    ep_rew_mean          | 679        |
| time/                   |            |
|    fps                  | 161        |
|    iterations           | 221        |
|    time_elapsed         | 2795       |
|    total_timesteps      | 452608     |
| train/                  |            |
|    approx_kl            | 0.08042402 |
|    clip_fraction        | 0.503      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.63       |
|    explained_variance   | 0.508      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0866    |
|    n_updates            | 2200       |
|    policy_gradient_loss | -0.0517    |
|    std                  | 0.175      |
|    value_loss           | 0.0224     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 538         |
|    ep_rew_mean          | 694         |
| time/                   |             |
|    fps                  | 162         |
|    iterations           | 222         |
|    time_elapsed         | 2804        |
|    total_timesteps      | 454656      |
| train/                  |             |
|    approx_kl            | 0.076691225 |
|    clip_fraction        | 0.529       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.65        |
|    explained_variance   | 0.409       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0383     |
|    n_updates            | 2210        |
|    policy_gradient_loss | -0.0443     |
|    std                  | 0.174       |
|    value_loss           | 0.0406      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 553        |
|    ep_rew_mean          | 711        |
| time/                   |            |
|    fps                  | 162        |
|    iterations           | 223        |
|    time_elapsed         | 2814       |
|    total_timesteps      | 456704     |
| train/                  |            |
|    approx_kl            | 0.07423563 |
|    clip_fraction        | 0.499      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.7        |
|    explained_variance   | 0.774      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0777    |
|    n_updates            | 2220       |
|    policy_gradient_loss | -0.0452    |
|    std                  | 0.173      |
|    value_loss           | 0.0291     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 559       |
|    ep_rew_mean          | 712       |
| time/                   |           |
|    fps                  | 162       |
|    iterations           | 224       |
|    time_elapsed         | 2823      |
|    total_timesteps      | 458752    |
| train/                  |           |
|    approx_kl            | 0.0778357 |
|    clip_fraction        | 0.504     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.75      |
|    explained_variance   | 0.88      |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0327   |
|    n_updates            | 2230      |
|    policy_gradient_loss | -0.0458   |
|    std                  | 0.172     |
|    value_loss           | 0.0306    |
---------------------------------------
Eval num_timesteps=460000, episode_reward=1495.39 +/- 647.29
Episode length: 744.04 +/- 317.04
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 744         |
|    mean_reward          | 1.5e+03     |
| time/                   |             |
|    total_timesteps      | 460000      |
| train/                  |             |
|    approx_kl            | 0.071117476 |
|    clip_fraction        | 0.478       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.82        |
|    explained_variance   | 0.935       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0547     |
|    n_updates            | 2240        |
|    policy_gradient_loss | -0.0382     |
|    std                  | 0.17        |
|    value_loss           | 0.0144      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 559      |
|    ep_rew_mean     | 719      |
| time/              |          |
|    fps             | 161      |
|    iterations      | 225      |
|    time_elapsed    | 2850     |
|    total_timesteps | 460800   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 573         |
|    ep_rew_mean          | 753         |
| time/                   |             |
|    fps                  | 161         |
|    iterations           | 226         |
|    time_elapsed         | 2859        |
|    total_timesteps      | 462848      |
| train/                  |             |
|    approx_kl            | 0.088965684 |
|    clip_fraction        | 0.533       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.87        |
|    explained_variance   | 0.127       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0587     |
|    n_updates            | 2250        |
|    policy_gradient_loss | -0.0445     |
|    std                  | 0.17        |
|    value_loss           | 0.0198      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 582        |
|    ep_rew_mean          | 770        |
| time/                   |            |
|    fps                  | 162        |
|    iterations           | 227        |
|    time_elapsed         | 2869       |
|    total_timesteps      | 464896     |
| train/                  |            |
|    approx_kl            | 0.07879856 |
|    clip_fraction        | 0.513      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.9        |
|    explained_variance   | 0.407      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0661    |
|    n_updates            | 2260       |
|    policy_gradient_loss | -0.0482    |
|    std                  | 0.169      |
|    value_loss           | 0.0196     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 597        |
|    ep_rew_mean          | 799        |
| time/                   |            |
|    fps                  | 162        |
|    iterations           | 228        |
|    time_elapsed         | 2880       |
|    total_timesteps      | 466944     |
| train/                  |            |
|    approx_kl            | 0.06835943 |
|    clip_fraction        | 0.506      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.91       |
|    explained_variance   | 0.389      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0451    |
|    n_updates            | 2270       |
|    policy_gradient_loss | -0.0449    |
|    std                  | 0.169      |
|    value_loss           | 0.0215     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 602        |
|    ep_rew_mean          | 811        |
| time/                   |            |
|    fps                  | 162        |
|    iterations           | 229        |
|    time_elapsed         | 2889       |
|    total_timesteps      | 468992     |
| train/                  |            |
|    approx_kl            | 0.08134719 |
|    clip_fraction        | 0.522      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.95       |
|    explained_variance   | 0.322      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0738    |
|    n_updates            | 2280       |
|    policy_gradient_loss | -0.0411    |
|    std                  | 0.168      |
|    value_loss           | 0.0431     |
----------------------------------------
Eval num_timesteps=470000, episode_reward=1114.54 +/- 709.41
Episode length: 578.28 +/- 357.44
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 578        |
|    mean_reward          | 1.11e+03   |
| time/                   |            |
|    total_timesteps      | 470000     |
| train/                  |            |
|    approx_kl            | 0.08758102 |
|    clip_fraction        | 0.527      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3          |
|    explained_variance   | 0.654      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0715    |
|    n_updates            | 2290       |
|    policy_gradient_loss | -0.0475    |
|    std                  | 0.167      |
|    value_loss           | 0.0128     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 604      |
|    ep_rew_mean     | 824      |
| time/              |          |
|    fps             | 161      |
|    iterations      | 230      |
|    time_elapsed    | 2913     |
|    total_timesteps | 471040   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 620        |
|    ep_rew_mean          | 840        |
| time/                   |            |
|    fps                  | 161        |
|    iterations           | 231        |
|    time_elapsed         | 2923       |
|    total_timesteps      | 473088     |
| train/                  |            |
|    approx_kl            | 0.08639757 |
|    clip_fraction        | 0.543      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.02       |
|    explained_variance   | 0.338      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0471    |
|    n_updates            | 2300       |
|    policy_gradient_loss | -0.0389    |
|    std                  | 0.166      |
|    value_loss           | 0.0566     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 612        |
|    ep_rew_mean          | 854        |
| time/                   |            |
|    fps                  | 162        |
|    iterations           | 232        |
|    time_elapsed         | 2932       |
|    total_timesteps      | 475136     |
| train/                  |            |
|    approx_kl            | 0.07977876 |
|    clip_fraction        | 0.504      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.05       |
|    explained_variance   | 0.919      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0694    |
|    n_updates            | 2310       |
|    policy_gradient_loss | -0.0397    |
|    std                  | 0.166      |
|    value_loss           | 0.0106     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 607        |
|    ep_rew_mean          | 851        |
| time/                   |            |
|    fps                  | 162        |
|    iterations           | 233        |
|    time_elapsed         | 2941       |
|    total_timesteps      | 477184     |
| train/                  |            |
|    approx_kl            | 0.07154964 |
|    clip_fraction        | 0.523      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.06       |
|    explained_variance   | 0.287      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00734   |
|    n_updates            | 2320       |
|    policy_gradient_loss | -0.0308    |
|    std                  | 0.166      |
|    value_loss           | 0.0449     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 592        |
|    ep_rew_mean          | 844        |
| time/                   |            |
|    fps                  | 162        |
|    iterations           | 234        |
|    time_elapsed         | 2951       |
|    total_timesteps      | 479232     |
| train/                  |            |
|    approx_kl            | 0.07360324 |
|    clip_fraction        | 0.529      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.05       |
|    explained_variance   | 0.873      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00579   |
|    n_updates            | 2330       |
|    policy_gradient_loss | -0.0351    |
|    std                  | 0.166      |
|    value_loss           | 0.035      |
----------------------------------------
Eval num_timesteps=480000, episode_reward=1565.22 +/- 686.53
Episode length: 748.48 +/- 325.76
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 748        |
|    mean_reward          | 1.57e+03   |
| time/                   |            |
|    total_timesteps      | 480000     |
| train/                  |            |
|    approx_kl            | 0.08243428 |
|    clip_fraction        | 0.561      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.07       |
|    explained_variance   | 0.172      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0237    |
|    n_updates            | 2340       |
|    policy_gradient_loss | -0.0359    |
|    std                  | 0.165      |
|    value_loss           | 0.0627     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 598      |
|    ep_rew_mean     | 862      |
| time/              |          |
|    fps             | 161      |
|    iterations      | 235      |
|    time_elapsed    | 2978     |
|    total_timesteps | 481280   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 595        |
|    ep_rew_mean          | 866        |
| time/                   |            |
|    fps                  | 161        |
|    iterations           | 236        |
|    time_elapsed         | 2987       |
|    total_timesteps      | 483328     |
| train/                  |            |
|    approx_kl            | 0.06771879 |
|    clip_fraction        | 0.505      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.11       |
|    explained_variance   | 0.25       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.056     |
|    n_updates            | 2350       |
|    policy_gradient_loss | -0.043     |
|    std                  | 0.164      |
|    value_loss           | 0.0163     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 579        |
|    ep_rew_mean          | 847        |
| time/                   |            |
|    fps                  | 161        |
|    iterations           | 237        |
|    time_elapsed         | 2997       |
|    total_timesteps      | 485376     |
| train/                  |            |
|    approx_kl            | 0.07105491 |
|    clip_fraction        | 0.526      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.16       |
|    explained_variance   | 0.233      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0561    |
|    n_updates            | 2360       |
|    policy_gradient_loss | -0.0385    |
|    std                  | 0.163      |
|    value_loss           | 0.026      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 586        |
|    ep_rew_mean          | 867        |
| time/                   |            |
|    fps                  | 162        |
|    iterations           | 238        |
|    time_elapsed         | 3006       |
|    total_timesteps      | 487424     |
| train/                  |            |
|    approx_kl            | 0.07499121 |
|    clip_fraction        | 0.51       |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.2        |
|    explained_variance   | 0.293      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0412    |
|    n_updates            | 2370       |
|    policy_gradient_loss | -0.0367    |
|    std                  | 0.163      |
|    value_loss           | 0.0307     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 598       |
|    ep_rew_mean          | 889       |
| time/                   |           |
|    fps                  | 162       |
|    iterations           | 239       |
|    time_elapsed         | 3015      |
|    total_timesteps      | 489472    |
| train/                  |           |
|    approx_kl            | 0.0781705 |
|    clip_fraction        | 0.527     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.22      |
|    explained_variance   | 0.387     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0273   |
|    n_updates            | 2380      |
|    policy_gradient_loss | -0.0343   |
|    std                  | 0.162     |
|    value_loss           | 0.0511    |
---------------------------------------
Eval num_timesteps=490000, episode_reward=1687.97 +/- 547.20
Episode length: 789.00 +/- 255.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 789       |
|    mean_reward          | 1.69e+03  |
| time/                   |           |
|    total_timesteps      | 490000    |
| train/                  |           |
|    approx_kl            | 0.0836675 |
|    clip_fraction        | 0.527     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.25      |
|    explained_variance   | 0.21      |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0603   |
|    n_updates            | 2390      |
|    policy_gradient_loss | -0.0387   |
|    std                  | 0.162     |
|    value_loss           | 0.0354    |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 610      |
|    ep_rew_mean     | 914      |
| time/              |          |
|    fps             | 161      |
|    iterations      | 240      |
|    time_elapsed    | 3044     |
|    total_timesteps | 491520   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 612         |
|    ep_rew_mean          | 928         |
| time/                   |             |
|    fps                  | 161         |
|    iterations           | 241         |
|    time_elapsed         | 3055        |
|    total_timesteps      | 493568      |
| train/                  |             |
|    approx_kl            | 0.088020355 |
|    clip_fraction        | 0.528       |
|    clip_range           | 0.2         |
|    entropy_loss         | 3.26        |
|    explained_variance   | 0.372       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0395     |
|    n_updates            | 2400        |
|    policy_gradient_loss | -0.0417     |
|    std                  | 0.161       |
|    value_loss           | 0.0338      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 616        |
|    ep_rew_mean          | 942        |
| time/                   |            |
|    fps                  | 161        |
|    iterations           | 242        |
|    time_elapsed         | 3064       |
|    total_timesteps      | 495616     |
| train/                  |            |
|    approx_kl            | 0.08148262 |
|    clip_fraction        | 0.526      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.29       |
|    explained_variance   | 0.558      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0849    |
|    n_updates            | 2410       |
|    policy_gradient_loss | -0.0436    |
|    std                  | 0.161      |
|    value_loss           | 0.0218     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 631        |
|    ep_rew_mean          | 965        |
| time/                   |            |
|    fps                  | 161        |
|    iterations           | 243        |
|    time_elapsed         | 3075       |
|    total_timesteps      | 497664     |
| train/                  |            |
|    approx_kl            | 0.07357757 |
|    clip_fraction        | 0.505      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.31       |
|    explained_variance   | 0.687      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0458    |
|    n_updates            | 2420       |
|    policy_gradient_loss | -0.0368    |
|    std                  | 0.161      |
|    value_loss           | 0.0345     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 639         |
|    ep_rew_mean          | 976         |
| time/                   |             |
|    fps                  | 162         |
|    iterations           | 244         |
|    time_elapsed         | 3084        |
|    total_timesteps      | 499712      |
| train/                  |             |
|    approx_kl            | 0.090649076 |
|    clip_fraction        | 0.547       |
|    clip_range           | 0.2         |
|    entropy_loss         | 3.35        |
|    explained_variance   | 0.942       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0618     |
|    n_updates            | 2430        |
|    policy_gradient_loss | -0.0531     |
|    std                  | 0.159       |
|    value_loss           | 0.0181      |
-----------------------------------------
Eval num_timesteps=500000, episode_reward=1430.35 +/- 846.01
Episode length: 666.72 +/- 385.55
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 667        |
|    mean_reward          | 1.43e+03   |
| time/                   |            |
|    total_timesteps      | 500000     |
| train/                  |            |
|    approx_kl            | 0.09246828 |
|    clip_fraction        | 0.54       |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.41       |
|    explained_variance   | 0.935      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0631    |
|    n_updates            | 2440       |
|    policy_gradient_loss | -0.0507    |
|    std                  | 0.158      |
|    value_loss           | 0.0163     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 654      |
|    ep_rew_mean     | 1e+03    |
| time/              |          |
|    fps             | 161      |
|    iterations      | 245      |
|    time_elapsed    | 3109     |
|    total_timesteps | 501760   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 640        |
|    ep_rew_mean          | 992        |
| time/                   |            |
|    fps                  | 161        |
|    iterations           | 246        |
|    time_elapsed         | 3118       |
|    total_timesteps      | 503808     |
| train/                  |            |
|    approx_kl            | 0.07798077 |
|    clip_fraction        | 0.543      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.44       |
|    explained_variance   | 0.864      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0672    |
|    n_updates            | 2450       |
|    policy_gradient_loss | -0.0375    |
|    std                  | 0.158      |
|    value_loss           | 0.0438     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 652         |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 161         |
|    iterations           | 247         |
|    time_elapsed         | 3128        |
|    total_timesteps      | 505856      |
| train/                  |             |
|    approx_kl            | 0.072344646 |
|    clip_fraction        | 0.508       |
|    clip_range           | 0.2         |
|    entropy_loss         | 3.49        |
|    explained_variance   | 0.903       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0461     |
|    n_updates            | 2460        |
|    policy_gradient_loss | -0.0371     |
|    std                  | 0.157       |
|    value_loss           | 0.0462      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 662        |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 161        |
|    iterations           | 248        |
|    time_elapsed         | 3137       |
|    total_timesteps      | 507904     |
| train/                  |            |
|    approx_kl            | 0.09389806 |
|    clip_fraction        | 0.541      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.56       |
|    explained_variance   | 0.427      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0931    |
|    n_updates            | 2470       |
|    policy_gradient_loss | -0.0471    |
|    std                  | 0.155      |
|    value_loss           | 0.0296     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 676         |
|    ep_rew_mean          | 1.07e+03    |
| time/                   |             |
|    fps                  | 162         |
|    iterations           | 249         |
|    time_elapsed         | 3146        |
|    total_timesteps      | 509952      |
| train/                  |             |
|    approx_kl            | 0.094985425 |
|    clip_fraction        | 0.551       |
|    clip_range           | 0.2         |
|    entropy_loss         | 3.6         |
|    explained_variance   | 0.924       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0711     |
|    n_updates            | 2480        |
|    policy_gradient_loss | -0.0482     |
|    std                  | 0.155       |
|    value_loss           | 0.0141      |
-----------------------------------------
Eval num_timesteps=510000, episode_reward=1649.62 +/- 725.26
Episode length: 798.24 +/- 321.58
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 798        |
|    mean_reward          | 1.65e+03   |
| time/                   |            |
|    total_timesteps      | 510000     |
| train/                  |            |
|    approx_kl            | 0.08883191 |
|    clip_fraction        | 0.549      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.61       |
|    explained_variance   | 0.392      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0476    |
|    n_updates            | 2490       |
|    policy_gradient_loss | -0.036     |
|    std                  | 0.155      |
|    value_loss           | 0.0338     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 684      |
|    ep_rew_mean     | 1.08e+03 |
| time/              |          |
|    fps             | 161      |
|    iterations      | 250      |
|    time_elapsed    | 3176     |
|    total_timesteps | 512000   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 685        |
|    ep_rew_mean          | 1.08e+03   |
| time/                   |            |
|    fps                  | 161        |
|    iterations           | 251        |
|    time_elapsed         | 3185       |
|    total_timesteps      | 514048     |
| train/                  |            |
|    approx_kl            | 0.07926424 |
|    clip_fraction        | 0.498      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.66       |
|    explained_variance   | 0.835      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0579    |
|    n_updates            | 2500       |
|    policy_gradient_loss | -0.0405    |
|    std                  | 0.153      |
|    value_loss           | 0.0167     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 683         |
|    ep_rew_mean          | 1.1e+03     |
| time/                   |             |
|    fps                  | 161         |
|    iterations           | 252         |
|    time_elapsed         | 3195        |
|    total_timesteps      | 516096      |
| train/                  |             |
|    approx_kl            | 0.087635756 |
|    clip_fraction        | 0.542       |
|    clip_range           | 0.2         |
|    entropy_loss         | 3.73        |
|    explained_variance   | 0.13        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0546     |
|    n_updates            | 2510        |
|    policy_gradient_loss | -0.0431     |
|    std                  | 0.152       |
|    value_loss           | 0.0391      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 689        |
|    ep_rew_mean          | 1.12e+03   |
| time/                   |            |
|    fps                  | 161        |
|    iterations           | 253        |
|    time_elapsed         | 3204       |
|    total_timesteps      | 518144     |
| train/                  |            |
|    approx_kl            | 0.09732206 |
|    clip_fraction        | 0.545      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.76       |
|    explained_variance   | 0.357      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0456    |
|    n_updates            | 2520       |
|    policy_gradient_loss | -0.0437    |
|    std                  | 0.151      |
|    value_loss           | 0.0261     |
----------------------------------------
Eval num_timesteps=520000, episode_reward=2082.93 +/- 482.02
Episode length: 964.36 +/- 92.90
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 964        |
|    mean_reward          | 2.08e+03   |
| time/                   |            |
|    total_timesteps      | 520000     |
| train/                  |            |
|    approx_kl            | 0.09395431 |
|    clip_fraction        | 0.534      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.8        |
|    explained_variance   | 0.887      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0331    |
|    n_updates            | 2530       |
|    policy_gradient_loss | -0.0376    |
|    std                  | 0.151      |
|    value_loss           | 0.0326     |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 687      |
|    ep_rew_mean     | 1.11e+03 |
| time/              |          |
|    fps             | 160      |
|    iterations      | 254      |
|    time_elapsed    | 3235     |
|    total_timesteps | 520192   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 690       |
|    ep_rew_mean          | 1.13e+03  |
| time/                   |           |
|    fps                  | 160       |
|    iterations           | 255       |
|    time_elapsed         | 3244      |
|    total_timesteps      | 522240    |
| train/                  |           |
|    approx_kl            | 0.0854823 |
|    clip_fraction        | 0.538     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.83      |
|    explained_variance   | 0.918     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0827   |
|    n_updates            | 2540      |
|    policy_gradient_loss | -0.0415   |
|    std                  | 0.15      |
|    value_loss           | 0.0186    |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 690        |
|    ep_rew_mean          | 1.13e+03   |
| time/                   |            |
|    fps                  | 161        |
|    iterations           | 256        |
|    time_elapsed         | 3253       |
|    total_timesteps      | 524288     |
| train/                  |            |
|    approx_kl            | 0.09303384 |
|    clip_fraction        | 0.559      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.86       |
|    explained_variance   | 0.499      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0613    |
|    n_updates            | 2550       |
|    policy_gradient_loss | -0.0444    |
|    std                  | 0.149      |
|    value_loss           | 0.0491     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 709        |
|    ep_rew_mean          | 1.16e+03   |
| time/                   |            |
|    fps                  | 161        |
|    iterations           | 257        |
|    time_elapsed         | 3263       |
|    total_timesteps      | 526336     |
| train/                  |            |
|    approx_kl            | 0.09998578 |
|    clip_fraction        | 0.571      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.89       |
|    explained_variance   | 0.97       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0788    |
|    n_updates            | 2560       |
|    policy_gradient_loss | -0.051     |
|    std                  | 0.149      |
|    value_loss           | 0.0122     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 695         |
|    ep_rew_mean          | 1.15e+03    |
| time/                   |             |
|    fps                  | 161         |
|    iterations           | 258         |
|    time_elapsed         | 3272        |
|    total_timesteps      | 528384      |
| train/                  |             |
|    approx_kl            | 0.094420634 |
|    clip_fraction        | 0.55        |
|    clip_range           | 0.2         |
|    entropy_loss         | 3.93        |
|    explained_variance   | 0.967       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0384     |
|    n_updates            | 2570        |
|    policy_gradient_loss | -0.0384     |
|    std                  | 0.148       |
|    value_loss           | 0.0129      |
-----------------------------------------
Eval num_timesteps=530000, episode_reward=1903.13 +/- 710.27
Episode length: 906.92 +/- 257.34
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 907        |
|    mean_reward          | 1.9e+03    |
| time/                   |            |
|    total_timesteps      | 530000     |
| train/                  |            |
|    approx_kl            | 0.08582462 |
|    clip_fraction        | 0.542      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.96       |
|    explained_variance   | 0.849      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0419    |
|    n_updates            | 2580       |
|    policy_gradient_loss | -0.0321    |
|    std                  | 0.147      |
|    value_loss           | 0.045      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 690      |
|    ep_rew_mean     | 1.15e+03 |
| time/              |          |
|    fps             | 160      |
|    iterations      | 259      |
|    time_elapsed    | 3302     |
|    total_timesteps | 530432   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 683        |
|    ep_rew_mean          | 1.13e+03   |
| time/                   |            |
|    fps                  | 160        |
|    iterations           | 260        |
|    time_elapsed         | 3311       |
|    total_timesteps      | 532480     |
| train/                  |            |
|    approx_kl            | 0.10416371 |
|    clip_fraction        | 0.545      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.02       |
|    explained_variance   | 0.896      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00968   |
|    n_updates            | 2590       |
|    policy_gradient_loss | -0.0428    |
|    std                  | 0.146      |
|    value_loss           | 0.0343     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 678         |
|    ep_rew_mean          | 1.12e+03    |
| time/                   |             |
|    fps                  | 160         |
|    iterations           | 261         |
|    time_elapsed         | 3321        |
|    total_timesteps      | 534528      |
| train/                  |             |
|    approx_kl            | 0.080389544 |
|    clip_fraction        | 0.537       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.04        |
|    explained_variance   | 0.922       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0572     |
|    n_updates            | 2600        |
|    policy_gradient_loss | -0.0345     |
|    std                  | 0.146       |
|    value_loss           | 0.0338      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 686        |
|    ep_rew_mean          | 1.15e+03   |
| time/                   |            |
|    fps                  | 161        |
|    iterations           | 262        |
|    time_elapsed         | 3330       |
|    total_timesteps      | 536576     |
| train/                  |            |
|    approx_kl            | 0.09957949 |
|    clip_fraction        | 0.556      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.06       |
|    explained_variance   | 0.884      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0819    |
|    n_updates            | 2610       |
|    policy_gradient_loss | -0.0441    |
|    std                  | 0.146      |
|    value_loss           | 0.0226     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 691        |
|    ep_rew_mean          | 1.16e+03   |
| time/                   |            |
|    fps                  | 161        |
|    iterations           | 263        |
|    time_elapsed         | 3340       |
|    total_timesteps      | 538624     |
| train/                  |            |
|    approx_kl            | 0.11009951 |
|    clip_fraction        | 0.587      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.11       |
|    explained_variance   | -0.2       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0671    |
|    n_updates            | 2620       |
|    policy_gradient_loss | -0.0453    |
|    std                  | 0.145      |
|    value_loss           | 0.00763    |
----------------------------------------
Eval num_timesteps=540000, episode_reward=2291.57 +/- 474.75
Episode length: 952.64 +/- 191.54
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 953         |
|    mean_reward          | 2.29e+03    |
| time/                   |             |
|    total_timesteps      | 540000      |
| train/                  |             |
|    approx_kl            | 0.095906526 |
|    clip_fraction        | 0.558       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.13        |
|    explained_variance   | 0.247       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0158     |
|    n_updates            | 2630        |
|    policy_gradient_loss | -0.0324     |
|    std                  | 0.144       |
|    value_loss           | 0.0447      |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 686      |
|    ep_rew_mean     | 1.17e+03 |
| time/              |          |
|    fps             | 160      |
|    iterations      | 264      |
|    time_elapsed    | 3373     |
|    total_timesteps | 540672   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 690        |
|    ep_rew_mean          | 1.19e+03   |
| time/                   |            |
|    fps                  | 160        |
|    iterations           | 265        |
|    time_elapsed         | 3386       |
|    total_timesteps      | 542720     |
| train/                  |            |
|    approx_kl            | 0.10625866 |
|    clip_fraction        | 0.561      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.19       |
|    explained_variance   | 0.35       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0809    |
|    n_updates            | 2640       |
|    policy_gradient_loss | -0.0367    |
|    std                  | 0.143      |
|    value_loss           | 0.021      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 693         |
|    ep_rew_mean          | 1.2e+03     |
| time/                   |             |
|    fps                  | 160         |
|    iterations           | 266         |
|    time_elapsed         | 3395        |
|    total_timesteps      | 544768      |
| train/                  |             |
|    approx_kl            | 0.094431356 |
|    clip_fraction        | 0.565       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.23        |
|    explained_variance   | 0.442       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0635     |
|    n_updates            | 2650        |
|    policy_gradient_loss | -0.0507     |
|    std                  | 0.143       |
|    value_loss           | 0.0106      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 698        |
|    ep_rew_mean          | 1.21e+03   |
| time/                   |            |
|    fps                  | 160        |
|    iterations           | 267        |
|    time_elapsed         | 3404       |
|    total_timesteps      | 546816     |
| train/                  |            |
|    approx_kl            | 0.09453057 |
|    clip_fraction        | 0.575      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.27       |
|    explained_variance   | 0.421      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0937    |
|    n_updates            | 2660       |
|    policy_gradient_loss | -0.0495    |
|    std                  | 0.142      |
|    value_loss           | 0.00833    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 707        |
|    ep_rew_mean          | 1.24e+03   |
| time/                   |            |
|    fps                  | 160        |
|    iterations           | 268        |
|    time_elapsed         | 3414       |
|    total_timesteps      | 548864     |
| train/                  |            |
|    approx_kl            | 0.10002358 |
|    clip_fraction        | 0.558      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.31       |
|    explained_variance   | 0.571      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0312    |
|    n_updates            | 2670       |
|    policy_gradient_loss | -0.0388    |
|    std                  | 0.141      |
|    value_loss           | 0.0206     |
----------------------------------------
Eval num_timesteps=550000, episode_reward=2200.64 +/- 551.39
Episode length: 960.32 +/- 194.39
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 960        |
|    mean_reward          | 2.2e+03    |
| time/                   |            |
|    total_timesteps      | 550000     |
| train/                  |            |
|    approx_kl            | 0.09493931 |
|    clip_fraction        | 0.558      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.35       |
|    explained_variance   | 0.395      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0469    |
|    n_updates            | 2680       |
|    policy_gradient_loss | -0.0458    |
|    std                  | 0.141      |
|    value_loss           | 0.0113     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 720      |
|    ep_rew_mean     | 1.27e+03 |
| time/              |          |
|    fps             | 159      |
|    iterations      | 269      |
|    time_elapsed    | 3443     |
|    total_timesteps | 550912   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 716         |
|    ep_rew_mean          | 1.27e+03    |
| time/                   |             |
|    fps                  | 160         |
|    iterations           | 270         |
|    time_elapsed         | 3453        |
|    total_timesteps      | 552960      |
| train/                  |             |
|    approx_kl            | 0.102196276 |
|    clip_fraction        | 0.554       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.37        |
|    explained_variance   | 0.405       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0591     |
|    n_updates            | 2690        |
|    policy_gradient_loss | -0.0507     |
|    std                  | 0.14        |
|    value_loss           | 0.00855     |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 724        |
|    ep_rew_mean          | 1.29e+03   |
| time/                   |            |
|    fps                  | 160        |
|    iterations           | 271        |
|    time_elapsed         | 3462       |
|    total_timesteps      | 555008     |
| train/                  |            |
|    approx_kl            | 0.09576674 |
|    clip_fraction        | 0.557      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.41       |
|    explained_variance   | 0.331      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0531    |
|    n_updates            | 2700       |
|    policy_gradient_loss | -0.0353    |
|    std                  | 0.139      |
|    value_loss           | 0.0379     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 731        |
|    ep_rew_mean          | 1.3e+03    |
| time/                   |            |
|    fps                  | 160        |
|    iterations           | 272        |
|    time_elapsed         | 3472       |
|    total_timesteps      | 557056     |
| train/                  |            |
|    approx_kl            | 0.09397715 |
|    clip_fraction        | 0.546      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.44       |
|    explained_variance   | 0.147      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0641    |
|    n_updates            | 2710       |
|    policy_gradient_loss | -0.0422    |
|    std                  | 0.139      |
|    value_loss           | 0.00775    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 740        |
|    ep_rew_mean          | 1.32e+03   |
| time/                   |            |
|    fps                  | 160        |
|    iterations           | 273        |
|    time_elapsed         | 3481       |
|    total_timesteps      | 559104     |
| train/                  |            |
|    approx_kl            | 0.09005956 |
|    clip_fraction        | 0.569      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.46       |
|    explained_variance   | 0.952      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0489    |
|    n_updates            | 2720       |
|    policy_gradient_loss | -0.0352    |
|    std                  | 0.139      |
|    value_loss           | 0.00924    |
----------------------------------------
Eval num_timesteps=560000, episode_reward=2017.33 +/- 771.78
Episode length: 887.52 +/- 276.90
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 888        |
|    mean_reward          | 2.02e+03   |
| time/                   |            |
|    total_timesteps      | 560000     |
| train/                  |            |
|    approx_kl            | 0.11115987 |
|    clip_fraction        | 0.559      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.48       |
|    explained_variance   | 0.305      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0314    |
|    n_updates            | 2730       |
|    policy_gradient_loss | -0.0406    |
|    std                  | 0.138      |
|    value_loss           | 0.0248     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 750      |
|    ep_rew_mean     | 1.35e+03 |
| time/              |          |
|    fps             | 159      |
|    iterations      | 274      |
|    time_elapsed    | 3511     |
|    total_timesteps | 561152   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 763         |
|    ep_rew_mean          | 1.38e+03    |
| time/                   |             |
|    fps                  | 159         |
|    iterations           | 275         |
|    time_elapsed         | 3520        |
|    total_timesteps      | 563200      |
| train/                  |             |
|    approx_kl            | 0.094538346 |
|    clip_fraction        | 0.576       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.51        |
|    explained_variance   | 0.326       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0651     |
|    n_updates            | 2740        |
|    policy_gradient_loss | -0.0324     |
|    std                  | 0.138       |
|    value_loss           | 0.0221      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 772        |
|    ep_rew_mean          | 1.39e+03   |
| time/                   |            |
|    fps                  | 160        |
|    iterations           | 276        |
|    time_elapsed         | 3530       |
|    total_timesteps      | 565248     |
| train/                  |            |
|    approx_kl            | 0.11178653 |
|    clip_fraction        | 0.579      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.56       |
|    explained_variance   | -0.0352    |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0753    |
|    n_updates            | 2750       |
|    policy_gradient_loss | -0.0403    |
|    std                  | 0.137      |
|    value_loss           | 0.00893    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 777        |
|    ep_rew_mean          | 1.4e+03    |
| time/                   |            |
|    fps                  | 160        |
|    iterations           | 277        |
|    time_elapsed         | 3540       |
|    total_timesteps      | 567296     |
| train/                  |            |
|    approx_kl            | 0.09436501 |
|    clip_fraction        | 0.544      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.57       |
|    explained_variance   | 0.98       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0761    |
|    n_updates            | 2760       |
|    policy_gradient_loss | -0.037     |
|    std                  | 0.137      |
|    value_loss           | 0.0085     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 782        |
|    ep_rew_mean          | 1.41e+03   |
| time/                   |            |
|    fps                  | 160        |
|    iterations           | 278        |
|    time_elapsed         | 3549       |
|    total_timesteps      | 569344     |
| train/                  |            |
|    approx_kl            | 0.11606318 |
|    clip_fraction        | 0.544      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.61       |
|    explained_variance   | 0.971      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0647    |
|    n_updates            | 2770       |
|    policy_gradient_loss | -0.0386    |
|    std                  | 0.136      |
|    value_loss           | 0.0136     |
----------------------------------------
Eval num_timesteps=570000, episode_reward=2341.83 +/- 451.35
Episode length: 932.16 +/- 163.05
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 932        |
|    mean_reward          | 2.34e+03   |
| time/                   |            |
|    total_timesteps      | 570000     |
| train/                  |            |
|    approx_kl            | 0.10734461 |
|    clip_fraction        | 0.56       |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.68       |
|    explained_variance   | 0.966      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0696    |
|    n_updates            | 2780       |
|    policy_gradient_loss | -0.0399    |
|    std                  | 0.135      |
|    value_loss           | 0.0111     |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 788      |
|    ep_rew_mean     | 1.42e+03 |
| time/              |          |
|    fps             | 159      |
|    iterations      | 279      |
|    time_elapsed    | 3579     |
|    total_timesteps | 571392   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 790         |
|    ep_rew_mean          | 1.43e+03    |
| time/                   |             |
|    fps                  | 159         |
|    iterations           | 280         |
|    time_elapsed         | 3588        |
|    total_timesteps      | 573440      |
| train/                  |             |
|    approx_kl            | 0.108444184 |
|    clip_fraction        | 0.588       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.73        |
|    explained_variance   | 0.85        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0389     |
|    n_updates            | 2790        |
|    policy_gradient_loss | -0.0422     |
|    std                  | 0.134       |
|    value_loss           | 0.0104      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 792        |
|    ep_rew_mean          | 1.43e+03   |
| time/                   |            |
|    fps                  | 159        |
|    iterations           | 281        |
|    time_elapsed         | 3597       |
|    total_timesteps      | 575488     |
| train/                  |            |
|    approx_kl            | 0.10943706 |
|    clip_fraction        | 0.559      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.75       |
|    explained_variance   | 0.912      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0369    |
|    n_updates            | 2800       |
|    policy_gradient_loss | -0.0338    |
|    std                  | 0.133      |
|    value_loss           | 0.0283     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 792        |
|    ep_rew_mean          | 1.45e+03   |
| time/                   |            |
|    fps                  | 160        |
|    iterations           | 282        |
|    time_elapsed         | 3607       |
|    total_timesteps      | 577536     |
| train/                  |            |
|    approx_kl            | 0.11176255 |
|    clip_fraction        | 0.574      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.81       |
|    explained_variance   | 0.97       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0472    |
|    n_updates            | 2810       |
|    policy_gradient_loss | -0.04      |
|    std                  | 0.133      |
|    value_loss           | 0.0126     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 792         |
|    ep_rew_mean          | 1.44e+03    |
| time/                   |             |
|    fps                  | 160         |
|    iterations           | 283         |
|    time_elapsed         | 3616        |
|    total_timesteps      | 579584      |
| train/                  |             |
|    approx_kl            | 0.108673275 |
|    clip_fraction        | 0.59        |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.83        |
|    explained_variance   | 0.526       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0676     |
|    n_updates            | 2820        |
|    policy_gradient_loss | -0.0406     |
|    std                  | 0.132       |
|    value_loss           | 0.00945     |
-----------------------------------------
Eval num_timesteps=580000, episode_reward=1652.73 +/- 765.32
Episode length: 797.84 +/- 291.07
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 798        |
|    mean_reward          | 1.65e+03   |
| time/                   |            |
|    total_timesteps      | 580000     |
| train/                  |            |
|    approx_kl            | 0.10355903 |
|    clip_fraction        | 0.55       |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.85       |
|    explained_variance   | 0.952      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0191    |
|    n_updates            | 2830       |
|    policy_gradient_loss | -0.0348    |
|    std                  | 0.132      |
|    value_loss           | 0.0103     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 788      |
|    ep_rew_mean     | 1.44e+03 |
| time/              |          |
|    fps             | 159      |
|    iterations      | 284      |
|    time_elapsed    | 3645     |
|    total_timesteps | 581632   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 798        |
|    ep_rew_mean          | 1.44e+03   |
| time/                   |            |
|    fps                  | 159        |
|    iterations           | 285        |
|    time_elapsed         | 3654       |
|    total_timesteps      | 583680     |
| train/                  |            |
|    approx_kl            | 0.10448387 |
|    clip_fraction        | 0.566      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.88       |
|    explained_variance   | 0.879      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0547    |
|    n_updates            | 2840       |
|    policy_gradient_loss | -0.0349    |
|    std                  | 0.132      |
|    value_loss           | 0.043      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 805       |
|    ep_rew_mean          | 1.44e+03  |
| time/                   |           |
|    fps                  | 159       |
|    iterations           | 286       |
|    time_elapsed         | 3664      |
|    total_timesteps      | 585728    |
| train/                  |           |
|    approx_kl            | 0.1160806 |
|    clip_fraction        | 0.536     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.91      |
|    explained_variance   | 0.929     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0232   |
|    n_updates            | 2850      |
|    policy_gradient_loss | -0.0287   |
|    std                  | 0.131     |
|    value_loss           | 0.019     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 799         |
|    ep_rew_mean          | 1.44e+03    |
| time/                   |             |
|    fps                  | 160         |
|    iterations           | 287         |
|    time_elapsed         | 3673        |
|    total_timesteps      | 587776      |
| train/                  |             |
|    approx_kl            | 0.116962224 |
|    clip_fraction        | 0.521       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.98        |
|    explained_variance   | 0.929       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.032      |
|    n_updates            | 2860        |
|    policy_gradient_loss | -0.0325     |
|    std                  | 0.13        |
|    value_loss           | 0.0313      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 798        |
|    ep_rew_mean          | 1.43e+03   |
| time/                   |            |
|    fps                  | 160        |
|    iterations           | 288        |
|    time_elapsed         | 3682       |
|    total_timesteps      | 589824     |
| train/                  |            |
|    approx_kl            | 0.10810241 |
|    clip_fraction        | 0.593      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.99       |
|    explained_variance   | 0.879      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.036     |
|    n_updates            | 2870       |
|    policy_gradient_loss | -0.0327    |
|    std                  | 0.13       |
|    value_loss           | 0.0303     |
----------------------------------------
Eval num_timesteps=590000, episode_reward=2038.27 +/- 866.88
Episode length: 848.72 +/- 346.94
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 849         |
|    mean_reward          | 2.04e+03    |
| time/                   |             |
|    total_timesteps      | 590000      |
| train/                  |             |
|    approx_kl            | 0.102834724 |
|    clip_fraction        | 0.564       |
|    clip_range           | 0.2         |
|    entropy_loss         | 5.03        |
|    explained_variance   | 0.916       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.063      |
|    n_updates            | 2880        |
|    policy_gradient_loss | -0.0283     |
|    std                  | 0.129       |
|    value_loss           | 0.0403      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 793      |
|    ep_rew_mean     | 1.45e+03 |
| time/              |          |
|    fps             | 159      |
|    iterations      | 289      |
|    time_elapsed    | 3712     |
|    total_timesteps | 591872   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 790        |
|    ep_rew_mean          | 1.45e+03   |
| time/                   |            |
|    fps                  | 159        |
|    iterations           | 290        |
|    time_elapsed         | 3721       |
|    total_timesteps      | 593920     |
| train/                  |            |
|    approx_kl            | 0.10559607 |
|    clip_fraction        | 0.57       |
|    clip_range           | 0.2        |
|    entropy_loss         | 5.1        |
|    explained_variance   | 0.383      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0225    |
|    n_updates            | 2890       |
|    policy_gradient_loss | -0.0324    |
|    std                  | 0.128      |
|    value_loss           | 0.0348     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 795        |
|    ep_rew_mean          | 1.46e+03   |
| time/                   |            |
|    fps                  | 159        |
|    iterations           | 291        |
|    time_elapsed         | 3730       |
|    total_timesteps      | 595968     |
| train/                  |            |
|    approx_kl            | 0.12971658 |
|    clip_fraction        | 0.6        |
|    clip_range           | 0.2        |
|    entropy_loss         | 5.14       |
|    explained_variance   | 0.664      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0658    |
|    n_updates            | 2900       |
|    policy_gradient_loss | -0.0383    |
|    std                  | 0.127      |
|    value_loss           | 0.0383     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 796        |
|    ep_rew_mean          | 1.45e+03   |
| time/                   |            |
|    fps                  | 159        |
|    iterations           | 292        |
|    time_elapsed         | 3740       |
|    total_timesteps      | 598016     |
| train/                  |            |
|    approx_kl            | 0.12032196 |
|    clip_fraction        | 0.578      |
|    clip_range           | 0.2        |
|    entropy_loss         | 5.17       |
|    explained_variance   | 0.841      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0259    |
|    n_updates            | 2910       |
|    policy_gradient_loss | -0.0279    |
|    std                  | 0.127      |
|    value_loss           | 0.0317     |
----------------------------------------
Eval num_timesteps=600000, episode_reward=1754.89 +/- 694.75
Episode length: 779.80 +/- 283.63
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 780        |
|    mean_reward          | 1.75e+03   |
| time/                   |            |
|    total_timesteps      | 600000     |
| train/                  |            |
|    approx_kl            | 0.11571715 |
|    clip_fraction        | 0.592      |
|    clip_range           | 0.2        |
|    entropy_loss         | 5.24       |
|    explained_variance   | 0.943      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0173    |
|    n_updates            | 2920       |
|    policy_gradient_loss | -0.0255    |
|    std                  | 0.126      |
|    value_loss           | 0.0301     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 796      |
|    ep_rew_mean     | 1.46e+03 |
| time/              |          |
|    fps             | 159      |
|    iterations      | 293      |
|    time_elapsed    | 3767     |
|    total_timesteps | 600064   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 808        |
|    ep_rew_mean          | 1.48e+03   |
| time/                   |            |
|    fps                  | 159        |
|    iterations           | 294        |
|    time_elapsed         | 3776       |
|    total_timesteps      | 602112     |
| train/                  |            |
|    approx_kl            | 0.13129699 |
|    clip_fraction        | 0.611      |
|    clip_range           | 0.2        |
|    entropy_loss         | 5.27       |
|    explained_variance   | 0.881      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0327    |
|    n_updates            | 2930       |
|    policy_gradient_loss | -0.0394    |
|    std                  | 0.126      |
|    value_loss           | 0.0187     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 809        |
|    ep_rew_mean          | 1.49e+03   |
| time/                   |            |
|    fps                  | 159        |
|    iterations           | 295        |
|    time_elapsed         | 3786       |
|    total_timesteps      | 604160     |
| train/                  |            |
|    approx_kl            | 0.11263265 |
|    clip_fraction        | 0.588      |
|    clip_range           | 0.2        |
|    entropy_loss         | 5.29       |
|    explained_variance   | 0.884      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0522    |
|    n_updates            | 2940       |
|    policy_gradient_loss | -0.0374    |
|    std                  | 0.125      |
|    value_loss           | 0.00622    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 809        |
|    ep_rew_mean          | 1.51e+03   |
| time/                   |            |
|    fps                  | 159        |
|    iterations           | 296        |
|    time_elapsed         | 3795       |
|    total_timesteps      | 606208     |
| train/                  |            |
|    approx_kl            | 0.11375305 |
|    clip_fraction        | 0.579      |
|    clip_range           | 0.2        |
|    entropy_loss         | 5.32       |
|    explained_variance   | 0.342      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0429    |
|    n_updates            | 2950       |
|    policy_gradient_loss | -0.0387    |
|    std                  | 0.124      |
|    value_loss           | 0.0158     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 816        |
|    ep_rew_mean          | 1.54e+03   |
| time/                   |            |
|    fps                  | 159        |
|    iterations           | 297        |
|    time_elapsed         | 3804       |
|    total_timesteps      | 608256     |
| train/                  |            |
|    approx_kl            | 0.11999399 |
|    clip_fraction        | 0.604      |
|    clip_range           | 0.2        |
|    entropy_loss         | 5.36       |
|    explained_variance   | 0.955      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0834    |
|    n_updates            | 2960       |
|    policy_gradient_loss | -0.0409    |
|    std                  | 0.124      |
|    value_loss           | 0.0131     |
----------------------------------------
Eval num_timesteps=610000, episode_reward=2344.27 +/- 551.33
Episode length: 970.96 +/- 99.19
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 971       |
|    mean_reward          | 2.34e+03  |
| time/                   |           |
|    total_timesteps      | 610000    |
| train/                  |           |
|    approx_kl            | 0.1271672 |
|    clip_fraction        | 0.584     |
|    clip_range           | 0.2       |
|    entropy_loss         | 5.39      |
|    explained_variance   | 0.398     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0945   |
|    n_updates            | 2970      |
|    policy_gradient_loss | -0.0448   |
|    std                  | 0.123     |
|    value_loss           | 0.00572   |
---------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 816      |
|    ep_rew_mean     | 1.55e+03 |
| time/              |          |
|    fps             | 159      |
|    iterations      | 298      |
|    time_elapsed    | 3833     |
|    total_timesteps | 610304   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 816        |
|    ep_rew_mean          | 1.55e+03   |
| time/                   |            |
|    fps                  | 159        |
|    iterations           | 299        |
|    time_elapsed         | 3843       |
|    total_timesteps      | 612352     |
| train/                  |            |
|    approx_kl            | 0.10930331 |
|    clip_fraction        | 0.597      |
|    clip_range           | 0.2        |
|    entropy_loss         | 5.43       |
|    explained_variance   | 0.56       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0161    |
|    n_updates            | 2980       |
|    policy_gradient_loss | -0.0296    |
|    std                  | 0.123      |
|    value_loss           | 0.0379     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 826        |
|    ep_rew_mean          | 1.6e+03    |
| time/                   |            |
|    fps                  | 159        |
|    iterations           | 300        |
|    time_elapsed         | 3852       |
|    total_timesteps      | 614400     |
| train/                  |            |
|    approx_kl            | 0.13207662 |
|    clip_fraction        | 0.61       |
|    clip_range           | 0.2        |
|    entropy_loss         | 5.45       |
|    explained_variance   | 0.488      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0481    |
|    n_updates            | 2990       |
|    policy_gradient_loss | -0.0393    |
|    std                  | 0.123      |
|    value_loss           | 0.0116     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 842       |
|    ep_rew_mean          | 1.64e+03  |
| time/                   |           |
|    fps                  | 159       |
|    iterations           | 301       |
|    time_elapsed         | 3861      |
|    total_timesteps      | 616448    |
| train/                  |           |
|    approx_kl            | 0.1258659 |
|    clip_fraction        | 0.596     |
|    clip_range           | 0.2       |
|    entropy_loss         | 5.43      |
|    explained_variance   | 0.319     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.074    |
|    n_updates            | 3000      |
|    policy_gradient_loss | -0.043    |
|    std                  | 0.123     |
|    value_loss           | 0.00559   |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 849        |
|    ep_rew_mean          | 1.64e+03   |
| time/                   |            |
|    fps                  | 159        |
|    iterations           | 302        |
|    time_elapsed         | 3871       |
|    total_timesteps      | 618496     |
| train/                  |            |
|    approx_kl            | 0.10974854 |
|    clip_fraction        | 0.605      |
|    clip_range           | 0.2        |
|    entropy_loss         | 5.45       |
|    explained_variance   | 0.253      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0567    |
|    n_updates            | 3010       |
|    policy_gradient_loss | -0.0259    |
|    std                  | 0.123      |
|    value_loss           | 0.0279     |
----------------------------------------
Eval num_timesteps=620000, episode_reward=2055.23 +/- 814.81
Episode length: 880.92 +/- 266.23
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 881        |
|    mean_reward          | 2.06e+03   |
| time/                   |            |
|    total_timesteps      | 620000     |
| train/                  |            |
|    approx_kl            | 0.13052952 |
|    clip_fraction        | 0.583      |
|    clip_range           | 0.2        |
|    entropy_loss         | 5.46       |
|    explained_variance   | 0.967      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0589    |
|    n_updates            | 3020       |
|    policy_gradient_loss | -0.0299    |
|    std                  | 0.122      |
|    value_loss           | 0.0131     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 849      |
|    ep_rew_mean     | 1.65e+03 |
| time/              |          |
|    fps             | 159      |
|    iterations      | 303      |
|    time_elapsed    | 3900     |
|    total_timesteps | 620544   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 851       |
|    ep_rew_mean          | 1.66e+03  |
| time/                   |           |
|    fps                  | 159       |
|    iterations           | 304       |
|    time_elapsed         | 3909      |
|    total_timesteps      | 622592    |
| train/                  |           |
|    approx_kl            | 0.1278106 |
|    clip_fraction        | 0.605     |
|    clip_range           | 0.2       |
|    entropy_loss         | 5.45      |
|    explained_variance   | 0.467     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0655   |
|    n_updates            | 3030      |
|    policy_gradient_loss | -0.039    |
|    std                  | 0.123     |
|    value_loss           | 0.00892   |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 845        |
|    ep_rew_mean          | 1.65e+03   |
| time/                   |            |
|    fps                  | 159        |
|    iterations           | 305        |
|    time_elapsed         | 3919       |
|    total_timesteps      | 624640     |
| train/                  |            |
|    approx_kl            | 0.09865253 |
|    clip_fraction        | 0.6        |
|    clip_range           | 0.2        |
|    entropy_loss         | 5.46       |
|    explained_variance   | 0.454      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0205    |
|    n_updates            | 3040       |
|    policy_gradient_loss | -0.035     |
|    std                  | 0.123      |
|    value_loss           | 0.0255     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 851         |
|    ep_rew_mean          | 1.66e+03    |
| time/                   |             |
|    fps                  | 159         |
|    iterations           | 306         |
|    time_elapsed         | 3928        |
|    total_timesteps      | 626688      |
| train/                  |             |
|    approx_kl            | 0.110038996 |
|    clip_fraction        | 0.603       |
|    clip_range           | 0.2         |
|    entropy_loss         | 5.46        |
|    explained_variance   | 0.343       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0395     |
|    n_updates            | 3050        |
|    policy_gradient_loss | -0.0302     |
|    std                  | 0.123       |
|    value_loss           | 0.0253      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 838         |
|    ep_rew_mean          | 1.64e+03    |
| time/                   |             |
|    fps                  | 159         |
|    iterations           | 307         |
|    time_elapsed         | 3937        |
|    total_timesteps      | 628736      |
| train/                  |             |
|    approx_kl            | 0.100675195 |
|    clip_fraction        | 0.566       |
|    clip_range           | 0.2         |
|    entropy_loss         | 5.48        |
|    explained_variance   | 0.943       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00641     |
|    n_updates            | 3060        |
|    policy_gradient_loss | -0.0302     |
|    std                  | 0.122       |
|    value_loss           | 0.026       |
-----------------------------------------
Eval num_timesteps=630000, episode_reward=1943.43 +/- 964.52
Episode length: 854.32 +/- 319.41
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 854        |
|    mean_reward          | 1.94e+03   |
| time/                   |            |
|    total_timesteps      | 630000     |
| train/                  |            |
|    approx_kl            | 0.11842044 |
|    clip_fraction        | 0.604      |
|    clip_range           | 0.2        |
|    entropy_loss         | 5.51       |
|    explained_variance   | 0.229      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0484    |
|    n_updates            | 3070       |
|    policy_gradient_loss | -0.0268    |
|    std                  | 0.122      |
|    value_loss           | 0.0451     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 843      |
|    ep_rew_mean     | 1.64e+03 |
| time/              |          |
|    fps             | 159      |
|    iterations      | 308      |
|    time_elapsed    | 3967     |
|    total_timesteps | 630784   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 841        |
|    ep_rew_mean          | 1.64e+03   |
| time/                   |            |
|    fps                  | 159        |
|    iterations           | 309        |
|    time_elapsed         | 3976       |
|    total_timesteps      | 632832     |
| train/                  |            |
|    approx_kl            | 0.11569892 |
|    clip_fraction        | 0.595      |
|    clip_range           | 0.2        |
|    entropy_loss         | 5.56       |
|    explained_variance   | 0.977      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0473    |
|    n_updates            | 3080       |
|    policy_gradient_loss | -0.0307    |
|    std                  | 0.121      |
|    value_loss           | 0.00767    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 835        |
|    ep_rew_mean          | 1.64e+03   |
| time/                   |            |
|    fps                  | 159        |
|    iterations           | 310        |
|    time_elapsed         | 3985       |
|    total_timesteps      | 634880     |
| train/                  |            |
|    approx_kl            | 0.10632387 |
|    clip_fraction        | 0.6        |
|    clip_range           | 0.2        |
|    entropy_loss         | 5.62       |
|    explained_variance   | 0.414      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0637    |
|    n_updates            | 3090       |
|    policy_gradient_loss | -0.0251    |
|    std                  | 0.12       |
|    value_loss           | 0.0267     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 848        |
|    ep_rew_mean          | 1.67e+03   |
| time/                   |            |
|    fps                  | 159        |
|    iterations           | 311        |
|    time_elapsed         | 3994       |
|    total_timesteps      | 636928     |
| train/                  |            |
|    approx_kl            | 0.11465751 |
|    clip_fraction        | 0.607      |
|    clip_range           | 0.2        |
|    entropy_loss         | 5.66       |
|    explained_variance   | 0.4        |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0696    |
|    n_updates            | 3100       |
|    policy_gradient_loss | -0.032     |
|    std                  | 0.119      |
|    value_loss           | 0.0205     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 844         |
|    ep_rew_mean          | 1.64e+03    |
| time/                   |             |
|    fps                  | 159         |
|    iterations           | 312         |
|    time_elapsed         | 4004        |
|    total_timesteps      | 638976      |
| train/                  |             |
|    approx_kl            | 0.121259525 |
|    clip_fraction        | 0.597       |
|    clip_range           | 0.2         |
|    entropy_loss         | 5.67        |
|    explained_variance   | 0.965       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0362     |
|    n_updates            | 3110        |
|    policy_gradient_loss | -0.0324     |
|    std                  | 0.119       |
|    value_loss           | 0.0142      |
-----------------------------------------
Eval num_timesteps=640000, episode_reward=2125.59 +/- 844.75
Episode length: 874.24 +/- 262.46
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 874        |
|    mean_reward          | 2.13e+03   |
| time/                   |            |
|    total_timesteps      | 640000     |
| train/                  |            |
|    approx_kl            | 0.11545128 |
|    clip_fraction        | 0.553      |
|    clip_range           | 0.2        |
|    entropy_loss         | 5.71       |
|    explained_variance   | 0.951      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0524    |
|    n_updates            | 3120       |
|    policy_gradient_loss | -0.026     |
|    std                  | 0.118      |
|    value_loss           | 0.016      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 839      |
|    ep_rew_mean     | 1.64e+03 |
| time/              |          |
|    fps             | 158      |
|    iterations      | 313      |
|    time_elapsed    | 4035     |
|    total_timesteps | 641024   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 840        |
|    ep_rew_mean          | 1.65e+03   |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 314        |
|    time_elapsed         | 4045       |
|    total_timesteps      | 643072     |
| train/                  |            |
|    approx_kl            | 0.12375866 |
|    clip_fraction        | 0.61       |
|    clip_range           | 0.2        |
|    entropy_loss         | 5.75       |
|    explained_variance   | 0.142      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0271    |
|    n_updates            | 3130       |
|    policy_gradient_loss | -0.0296    |
|    std                  | 0.118      |
|    value_loss           | 0.03       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 840        |
|    ep_rew_mean          | 1.64e+03   |
| time/                   |            |
|    fps                  | 159        |
|    iterations           | 315        |
|    time_elapsed         | 4055       |
|    total_timesteps      | 645120     |
| train/                  |            |
|    approx_kl            | 0.11857265 |
|    clip_fraction        | 0.614      |
|    clip_range           | 0.2        |
|    entropy_loss         | 5.76       |
|    explained_variance   | 0.792      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.056     |
|    n_updates            | 3140       |
|    policy_gradient_loss | -0.0297    |
|    std                  | 0.118      |
|    value_loss           | 0.0134     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 847        |
|    ep_rew_mean          | 1.66e+03   |
| time/                   |            |
|    fps                  | 159        |
|    iterations           | 316        |
|    time_elapsed         | 4064       |
|    total_timesteps      | 647168     |
| train/                  |            |
|    approx_kl            | 0.12461664 |
|    clip_fraction        | 0.598      |
|    clip_range           | 0.2        |
|    entropy_loss         | 5.78       |
|    explained_variance   | 0.978      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0311    |
|    n_updates            | 3150       |
|    policy_gradient_loss | -0.0386    |
|    std                  | 0.118      |
|    value_loss           | 0.0107     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 830        |
|    ep_rew_mean          | 1.64e+03   |
| time/                   |            |
|    fps                  | 159        |
|    iterations           | 317        |
|    time_elapsed         | 4073       |
|    total_timesteps      | 649216     |
| train/                  |            |
|    approx_kl            | 0.12903063 |
|    clip_fraction        | 0.61       |
|    clip_range           | 0.2        |
|    entropy_loss         | 5.8        |
|    explained_variance   | 0.422      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0624    |
|    n_updates            | 3160       |
|    policy_gradient_loss | -0.0368    |
|    std                  | 0.117      |
|    value_loss           | 0.00631    |
----------------------------------------
Eval num_timesteps=650000, episode_reward=2645.83 +/- 519.47
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 2.65e+03   |
| time/                   |            |
|    total_timesteps      | 650000     |
| train/                  |            |
|    approx_kl            | 0.10754836 |
|    clip_fraction        | 0.609      |
|    clip_range           | 0.2        |
|    entropy_loss         | 5.81       |
|    explained_variance   | 0.47       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0336    |
|    n_updates            | 3170       |
|    policy_gradient_loss | -0.0211    |
|    std                  | 0.117      |
|    value_loss           | 0.0344     |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 830      |
|    ep_rew_mean     | 1.67e+03 |
| time/              |          |
|    fps             | 158      |
|    iterations      | 318      |
|    time_elapsed    | 4103     |
|    total_timesteps | 651264   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 830        |
|    ep_rew_mean          | 1.66e+03   |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 319        |
|    time_elapsed         | 4112       |
|    total_timesteps      | 653312     |
| train/                  |            |
|    approx_kl            | 0.11630786 |
|    clip_fraction        | 0.62       |
|    clip_range           | 0.2        |
|    entropy_loss         | 5.81       |
|    explained_variance   | 0.525      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.056     |
|    n_updates            | 3180       |
|    policy_gradient_loss | -0.0241    |
|    std                  | 0.118      |
|    value_loss           | 0.0119     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 825        |
|    ep_rew_mean          | 1.66e+03   |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 320        |
|    time_elapsed         | 4122       |
|    total_timesteps      | 655360     |
| train/                  |            |
|    approx_kl            | 0.34187704 |
|    clip_fraction        | 0.633      |
|    clip_range           | 0.2        |
|    entropy_loss         | 5.82       |
|    explained_variance   | 0.968      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0543    |
|    n_updates            | 3190       |
|    policy_gradient_loss | -0.0237    |
|    std                  | 0.117      |
|    value_loss           | 0.00997    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 829        |
|    ep_rew_mean          | 1.68e+03   |
| time/                   |            |
|    fps                  | 159        |
|    iterations           | 321        |
|    time_elapsed         | 4131       |
|    total_timesteps      | 657408     |
| train/                  |            |
|    approx_kl            | 0.11113757 |
|    clip_fraction        | 0.593      |
|    clip_range           | 0.2        |
|    entropy_loss         | 5.86       |
|    explained_variance   | 0.919      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0638    |
|    n_updates            | 3200       |
|    policy_gradient_loss | -0.0246    |
|    std                  | 0.116      |
|    value_loss           | 0.0343     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 829         |
|    ep_rew_mean          | 1.66e+03    |
| time/                   |             |
|    fps                  | 159         |
|    iterations           | 322         |
|    time_elapsed         | 4141        |
|    total_timesteps      | 659456      |
| train/                  |             |
|    approx_kl            | 0.111268625 |
|    clip_fraction        | 0.595       |
|    clip_range           | 0.2         |
|    entropy_loss         | 5.91        |
|    explained_variance   | 0.907       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0409     |
|    n_updates            | 3210        |
|    policy_gradient_loss | -0.0253     |
|    std                  | 0.116       |
|    value_loss           | 0.0434      |
-----------------------------------------
Eval num_timesteps=660000, episode_reward=2740.12 +/- 636.44
Episode length: 953.72 +/- 188.87
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 954         |
|    mean_reward          | 2.74e+03    |
| time/                   |             |
|    total_timesteps      | 660000      |
| train/                  |             |
|    approx_kl            | 0.109918386 |
|    clip_fraction        | 0.58        |
|    clip_range           | 0.2         |
|    entropy_loss         | 5.95        |
|    explained_variance   | 0.977       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0454     |
|    n_updates            | 3220        |
|    policy_gradient_loss | -0.0292     |
|    std                  | 0.115       |
|    value_loss           | 0.00806     |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 829      |
|    ep_rew_mean     | 1.66e+03 |
| time/              |          |
|    fps             | 158      |
|    iterations      | 323      |
|    time_elapsed    | 4170     |
|    total_timesteps | 661504   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 827        |
|    ep_rew_mean          | 1.69e+03   |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 324        |
|    time_elapsed         | 4179       |
|    total_timesteps      | 663552     |
| train/                  |            |
|    approx_kl            | 0.13167411 |
|    clip_fraction        | 0.614      |
|    clip_range           | 0.2        |
|    entropy_loss         | 5.96       |
|    explained_variance   | 0.961      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0425    |
|    n_updates            | 3230       |
|    policy_gradient_loss | -0.0321    |
|    std                  | 0.115      |
|    value_loss           | 0.0169     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 837        |
|    ep_rew_mean          | 1.72e+03   |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 325        |
|    time_elapsed         | 4189       |
|    total_timesteps      | 665600     |
| train/                  |            |
|    approx_kl            | 0.12296937 |
|    clip_fraction        | 0.617      |
|    clip_range           | 0.2        |
|    entropy_loss         | 5.99       |
|    explained_variance   | 0.505      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0519    |
|    n_updates            | 3240       |
|    policy_gradient_loss | -0.0287    |
|    std                  | 0.115      |
|    value_loss           | 0.0254     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 838        |
|    ep_rew_mean          | 1.75e+03   |
| time/                   |            |
|    fps                  | 159        |
|    iterations           | 326        |
|    time_elapsed         | 4198       |
|    total_timesteps      | 667648     |
| train/                  |            |
|    approx_kl            | 0.13587958 |
|    clip_fraction        | 0.613      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.01       |
|    explained_variance   | 0.746      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0535    |
|    n_updates            | 3250       |
|    policy_gradient_loss | -0.0308    |
|    std                  | 0.114      |
|    value_loss           | 0.0123     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 834        |
|    ep_rew_mean          | 1.74e+03   |
| time/                   |            |
|    fps                  | 159        |
|    iterations           | 327        |
|    time_elapsed         | 4207       |
|    total_timesteps      | 669696     |
| train/                  |            |
|    approx_kl            | 0.12520218 |
|    clip_fraction        | 0.609      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.04       |
|    explained_variance   | 0.892      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0125    |
|    n_updates            | 3260       |
|    policy_gradient_loss | -0.0279    |
|    std                  | 0.114      |
|    value_loss           | 0.0302     |
----------------------------------------
Eval num_timesteps=670000, episode_reward=2925.39 +/- 181.28
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 2.93e+03   |
| time/                   |            |
|    total_timesteps      | 670000     |
| train/                  |            |
|    approx_kl            | 0.13186839 |
|    clip_fraction        | 0.6        |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.07       |
|    explained_variance   | 0.966      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0388    |
|    n_updates            | 3270       |
|    policy_gradient_loss | -0.0304    |
|    std                  | 0.113      |
|    value_loss           | 0.0213     |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 840      |
|    ep_rew_mean     | 1.75e+03 |
| time/              |          |
|    fps             | 158      |
|    iterations      | 328      |
|    time_elapsed    | 4237     |
|    total_timesteps | 671744   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 849        |
|    ep_rew_mean          | 1.78e+03   |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 329        |
|    time_elapsed         | 4246       |
|    total_timesteps      | 673792     |
| train/                  |            |
|    approx_kl            | 0.11638038 |
|    clip_fraction        | 0.592      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.09       |
|    explained_variance   | 0.976      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0814    |
|    n_updates            | 3280       |
|    policy_gradient_loss | -0.0207    |
|    std                  | 0.113      |
|    value_loss           | 0.0147     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 851        |
|    ep_rew_mean          | 1.81e+03   |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 330        |
|    time_elapsed         | 4256       |
|    total_timesteps      | 675840     |
| train/                  |            |
|    approx_kl            | 0.12649037 |
|    clip_fraction        | 0.619      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.11       |
|    explained_variance   | 0.363      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0457    |
|    n_updates            | 3290       |
|    policy_gradient_loss | -0.0309    |
|    std                  | 0.113      |
|    value_loss           | 0.00784    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 856        |
|    ep_rew_mean          | 1.83e+03   |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 331        |
|    time_elapsed         | 4265       |
|    total_timesteps      | 677888     |
| train/                  |            |
|    approx_kl            | 0.13851446 |
|    clip_fraction        | 0.617      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.15       |
|    explained_variance   | 0.4        |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0478    |
|    n_updates            | 3300       |
|    policy_gradient_loss | -0.0206    |
|    std                  | 0.112      |
|    value_loss           | 0.00671    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 867        |
|    ep_rew_mean          | 1.86e+03   |
| time/                   |            |
|    fps                  | 159        |
|    iterations           | 332        |
|    time_elapsed         | 4274       |
|    total_timesteps      | 679936     |
| train/                  |            |
|    approx_kl            | 0.11518425 |
|    clip_fraction        | 0.608      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.18       |
|    explained_variance   | 0.571      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0691    |
|    n_updates            | 3310       |
|    policy_gradient_loss | -0.0297    |
|    std                  | 0.112      |
|    value_loss           | 0.00501    |
----------------------------------------
Eval num_timesteps=680000, episode_reward=2789.67 +/- 530.10
Episode length: 980.40 +/- 96.02
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 980        |
|    mean_reward          | 2.79e+03   |
| time/                   |            |
|    total_timesteps      | 680000     |
| train/                  |            |
|    approx_kl            | 0.11740719 |
|    clip_fraction        | 0.608      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.21       |
|    explained_variance   | 0.576      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0484    |
|    n_updates            | 3320       |
|    policy_gradient_loss | -0.0332    |
|    std                  | 0.111      |
|    value_loss           | 0.00689    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 859      |
|    ep_rew_mean     | 1.86e+03 |
| time/              |          |
|    fps             | 158      |
|    iterations      | 333      |
|    time_elapsed    | 4304     |
|    total_timesteps | 681984   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 863        |
|    ep_rew_mean          | 1.89e+03   |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 334        |
|    time_elapsed         | 4314       |
|    total_timesteps      | 684032     |
| train/                  |            |
|    approx_kl            | 0.14356889 |
|    clip_fraction        | 0.634      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.24       |
|    explained_variance   | 0.388      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00702   |
|    n_updates            | 3330       |
|    policy_gradient_loss | -0.0191    |
|    std                  | 0.111      |
|    value_loss           | 0.0269     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 863        |
|    ep_rew_mean          | 1.9e+03    |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 335        |
|    time_elapsed         | 4323       |
|    total_timesteps      | 686080     |
| train/                  |            |
|    approx_kl            | 0.12659839 |
|    clip_fraction        | 0.622      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.25       |
|    explained_variance   | 0.402      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0461    |
|    n_updates            | 3340       |
|    policy_gradient_loss | -0.0225    |
|    std                  | 0.111      |
|    value_loss           | 0.0268     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 863        |
|    ep_rew_mean          | 1.92e+03   |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 336        |
|    time_elapsed         | 4332       |
|    total_timesteps      | 688128     |
| train/                  |            |
|    approx_kl            | 0.14755583 |
|    clip_fraction        | 0.64       |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.27       |
|    explained_variance   | 0.844      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0701    |
|    n_updates            | 3350       |
|    policy_gradient_loss | -0.0233    |
|    std                  | 0.111      |
|    value_loss           | 0.019      |
----------------------------------------
Eval num_timesteps=690000, episode_reward=3040.20 +/- 63.43
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 3.04e+03   |
| time/                   |            |
|    total_timesteps      | 690000     |
| train/                  |            |
|    approx_kl            | 0.11000456 |
|    clip_fraction        | 0.61       |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.29       |
|    explained_variance   | 0.974      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0124    |
|    n_updates            | 3360       |
|    policy_gradient_loss | -0.0231    |
|    std                  | 0.11       |
|    value_loss           | 0.0126     |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 863      |
|    ep_rew_mean     | 1.91e+03 |
| time/              |          |
|    fps             | 158      |
|    iterations      | 337      |
|    time_elapsed    | 4362     |
|    total_timesteps | 690176   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 873       |
|    ep_rew_mean          | 1.95e+03  |
| time/                   |           |
|    fps                  | 158       |
|    iterations           | 338       |
|    time_elapsed         | 4371      |
|    total_timesteps      | 692224    |
| train/                  |           |
|    approx_kl            | 0.1269375 |
|    clip_fraction        | 0.601     |
|    clip_range           | 0.2       |
|    entropy_loss         | 6.31      |
|    explained_variance   | 0.974     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.00724   |
|    n_updates            | 3370      |
|    policy_gradient_loss | -0.0238   |
|    std                  | 0.11      |
|    value_loss           | 0.00984   |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 873        |
|    ep_rew_mean          | 1.96e+03   |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 339        |
|    time_elapsed         | 4380       |
|    total_timesteps      | 694272     |
| train/                  |            |
|    approx_kl            | 0.14461172 |
|    clip_fraction        | 0.625      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.34       |
|    explained_variance   | 0.312      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0642    |
|    n_updates            | 3380       |
|    policy_gradient_loss | -0.0329    |
|    std                  | 0.11       |
|    value_loss           | 0.00532    |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 879         |
|    ep_rew_mean          | 1.99e+03    |
| time/                   |             |
|    fps                  | 158         |
|    iterations           | 340         |
|    time_elapsed         | 4390        |
|    total_timesteps      | 696320      |
| train/                  |             |
|    approx_kl            | 0.124556586 |
|    clip_fraction        | 0.615       |
|    clip_range           | 0.2         |
|    entropy_loss         | 6.37        |
|    explained_variance   | 0.496       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0686     |
|    n_updates            | 3390        |
|    policy_gradient_loss | -0.0274     |
|    std                  | 0.109       |
|    value_loss           | 0.00453     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 887         |
|    ep_rew_mean          | 2.02e+03    |
| time/                   |             |
|    fps                  | 158         |
|    iterations           | 341         |
|    time_elapsed         | 4399        |
|    total_timesteps      | 698368      |
| train/                  |             |
|    approx_kl            | 0.110885486 |
|    clip_fraction        | 0.61        |
|    clip_range           | 0.2         |
|    entropy_loss         | 6.37        |
|    explained_variance   | 0.388       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0349     |
|    n_updates            | 3400        |
|    policy_gradient_loss | -0.0198     |
|    std                  | 0.109       |
|    value_loss           | 0.0217      |
-----------------------------------------
Eval num_timesteps=700000, episode_reward=3205.65 +/- 55.13
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 3.21e+03   |
| time/                   |            |
|    total_timesteps      | 700000     |
| train/                  |            |
|    approx_kl            | 0.15597165 |
|    clip_fraction        | 0.634      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.39       |
|    explained_variance   | 0.276      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0539    |
|    n_updates            | 3410       |
|    policy_gradient_loss | -0.0309    |
|    std                  | 0.109      |
|    value_loss           | 0.00743    |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 887      |
|    ep_rew_mean     | 2.03e+03 |
| time/              |          |
|    fps             | 158      |
|    iterations      | 342      |
|    time_elapsed    | 4429     |
|    total_timesteps | 700416   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 887        |
|    ep_rew_mean          | 2.04e+03   |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 343        |
|    time_elapsed         | 4438       |
|    total_timesteps      | 702464     |
| train/                  |            |
|    approx_kl            | 0.13820764 |
|    clip_fraction        | 0.611      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.42       |
|    explained_variance   | 0.378      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00176   |
|    n_updates            | 3420       |
|    policy_gradient_loss | -0.0227    |
|    std                  | 0.109      |
|    value_loss           | 0.00307    |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 888       |
|    ep_rew_mean          | 2.06e+03  |
| time/                   |           |
|    fps                  | 158       |
|    iterations           | 344       |
|    time_elapsed         | 4447      |
|    total_timesteps      | 704512    |
| train/                  |           |
|    approx_kl            | 0.1599805 |
|    clip_fraction        | 0.636     |
|    clip_range           | 0.2       |
|    entropy_loss         | 6.44      |
|    explained_variance   | 0.535     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0587   |
|    n_updates            | 3430      |
|    policy_gradient_loss | -0.0309   |
|    std                  | 0.108     |
|    value_loss           | 0.00477   |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 888        |
|    ep_rew_mean          | 2.07e+03   |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 345        |
|    time_elapsed         | 4457       |
|    total_timesteps      | 706560     |
| train/                  |            |
|    approx_kl            | 0.13912007 |
|    clip_fraction        | 0.602      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.47       |
|    explained_variance   | 0.541      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0364    |
|    n_updates            | 3440       |
|    policy_gradient_loss | -0.0348    |
|    std                  | 0.108      |
|    value_loss           | 0.0045     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 888        |
|    ep_rew_mean          | 2.09e+03   |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 346        |
|    time_elapsed         | 4466       |
|    total_timesteps      | 708608     |
| train/                  |            |
|    approx_kl            | 0.12994716 |
|    clip_fraction        | 0.619      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.51       |
|    explained_variance   | 0.603      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0448    |
|    n_updates            | 3450       |
|    policy_gradient_loss | -0.0284    |
|    std                  | 0.107      |
|    value_loss           | 0.00526    |
----------------------------------------
Eval num_timesteps=710000, episode_reward=2791.75 +/- 890.67
Episode length: 897.68 +/- 282.06
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 898        |
|    mean_reward          | 2.79e+03   |
| time/                   |            |
|    total_timesteps      | 710000     |
| train/                  |            |
|    approx_kl            | 0.13556269 |
|    clip_fraction        | 0.615      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.55       |
|    explained_variance   | 0.586      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0201    |
|    n_updates            | 3460       |
|    policy_gradient_loss | -0.0247    |
|    std                  | 0.107      |
|    value_loss           | 0.00347    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 888      |
|    ep_rew_mean     | 2.1e+03  |
| time/              |          |
|    fps             | 158      |
|    iterations      | 347      |
|    time_elapsed    | 4496     |
|    total_timesteps | 710656   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 894        |
|    ep_rew_mean          | 2.12e+03   |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 348        |
|    time_elapsed         | 4505       |
|    total_timesteps      | 712704     |
| train/                  |            |
|    approx_kl            | 0.13675448 |
|    clip_fraction        | 0.622      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.58       |
|    explained_variance   | 0.511      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0542    |
|    n_updates            | 3470       |
|    policy_gradient_loss | -0.0274    |
|    std                  | 0.106      |
|    value_loss           | 0.00595    |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 900         |
|    ep_rew_mean          | 2.13e+03    |
| time/                   |             |
|    fps                  | 158         |
|    iterations           | 349         |
|    time_elapsed         | 4514        |
|    total_timesteps      | 714752      |
| train/                  |             |
|    approx_kl            | 0.113607176 |
|    clip_fraction        | 0.602       |
|    clip_range           | 0.2         |
|    entropy_loss         | 6.62        |
|    explained_variance   | 0.955       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0451     |
|    n_updates            | 3480        |
|    policy_gradient_loss | -0.0147     |
|    std                  | 0.106       |
|    value_loss           | 0.0335      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 904        |
|    ep_rew_mean          | 2.15e+03   |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 350        |
|    time_elapsed         | 4524       |
|    total_timesteps      | 716800     |
| train/                  |            |
|    approx_kl            | 0.16794938 |
|    clip_fraction        | 0.641      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.64       |
|    explained_variance   | 0.971      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0497    |
|    n_updates            | 3490       |
|    policy_gradient_loss | -0.019     |
|    std                  | 0.106      |
|    value_loss           | 0.00399    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 916        |
|    ep_rew_mean          | 2.19e+03   |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 351        |
|    time_elapsed         | 4533       |
|    total_timesteps      | 718848     |
| train/                  |            |
|    approx_kl            | 0.22475584 |
|    clip_fraction        | 0.621      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.68       |
|    explained_variance   | 0.975      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00872   |
|    n_updates            | 3500       |
|    policy_gradient_loss | 0.00778    |
|    std                  | 0.105      |
|    value_loss           | 0.00764    |
----------------------------------------
Eval num_timesteps=720000, episode_reward=3298.81 +/- 59.31
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 3.3e+03    |
| time/                   |            |
|    total_timesteps      | 720000     |
| train/                  |            |
|    approx_kl            | 0.15405908 |
|    clip_fraction        | 0.635      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.68       |
|    explained_variance   | 0.72       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0198     |
|    n_updates            | 3510       |
|    policy_gradient_loss | -0.017     |
|    std                  | 0.105      |
|    value_loss           | 0.0297     |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 916      |
|    ep_rew_mean     | 2.21e+03 |
| time/              |          |
|    fps             | 157      |
|    iterations      | 352      |
|    time_elapsed    | 4563     |
|    total_timesteps | 720896   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 919        |
|    ep_rew_mean          | 2.23e+03   |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 353        |
|    time_elapsed         | 4572       |
|    total_timesteps      | 722944     |
| train/                  |            |
|    approx_kl            | 0.12824449 |
|    clip_fraction        | 0.628      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.69       |
|    explained_variance   | 0.501      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0659    |
|    n_updates            | 3520       |
|    policy_gradient_loss | -0.0238    |
|    std                  | 0.105      |
|    value_loss           | 0.00518    |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 919         |
|    ep_rew_mean          | 2.24e+03    |
| time/                   |             |
|    fps                  | 158         |
|    iterations           | 354         |
|    time_elapsed         | 4581        |
|    total_timesteps      | 724992      |
| train/                  |             |
|    approx_kl            | 0.124354266 |
|    clip_fraction        | 0.632       |
|    clip_range           | 0.2         |
|    entropy_loss         | 6.67        |
|    explained_variance   | 0.592       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0357     |
|    n_updates            | 3530        |
|    policy_gradient_loss | -0.0291     |
|    std                  | 0.105       |
|    value_loss           | 0.00679     |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 922        |
|    ep_rew_mean          | 2.26e+03   |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 355        |
|    time_elapsed         | 4591       |
|    total_timesteps      | 727040     |
| train/                  |            |
|    approx_kl            | 0.13055065 |
|    clip_fraction        | 0.624      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.69       |
|    explained_variance   | 0.6        |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0789    |
|    n_updates            | 3540       |
|    policy_gradient_loss | -0.0304    |
|    std                  | 0.105      |
|    value_loss           | 0.00414    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 922        |
|    ep_rew_mean          | 2.28e+03   |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 356        |
|    time_elapsed         | 4600       |
|    total_timesteps      | 729088     |
| train/                  |            |
|    approx_kl            | 0.13075204 |
|    clip_fraction        | 0.622      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.69       |
|    explained_variance   | 0.72       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0749    |
|    n_updates            | 3550       |
|    policy_gradient_loss | -0.0177    |
|    std                  | 0.105      |
|    value_loss           | 0.0155     |
----------------------------------------
Eval num_timesteps=730000, episode_reward=3289.47 +/- 227.79
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 3.29e+03   |
| time/                   |            |
|    total_timesteps      | 730000     |
| train/                  |            |
|    approx_kl            | 0.14477795 |
|    clip_fraction        | 0.639      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.69       |
|    explained_variance   | 0.362      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0553    |
|    n_updates            | 3560       |
|    policy_gradient_loss | -0.0222    |
|    std                  | 0.105      |
|    value_loss           | 0.00758    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 926      |
|    ep_rew_mean     | 2.31e+03 |
| time/              |          |
|    fps             | 157      |
|    iterations      | 357      |
|    time_elapsed    | 4630     |
|    total_timesteps | 731136   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 925        |
|    ep_rew_mean          | 2.34e+03   |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 358        |
|    time_elapsed         | 4639       |
|    total_timesteps      | 733184     |
| train/                  |            |
|    approx_kl            | 0.13249098 |
|    clip_fraction        | 0.624      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.67       |
|    explained_variance   | 0.6        |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0514    |
|    n_updates            | 3570       |
|    policy_gradient_loss | -0.0281    |
|    std                  | 0.105      |
|    value_loss           | 0.00792    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 920        |
|    ep_rew_mean          | 2.34e+03   |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 359        |
|    time_elapsed         | 4648       |
|    total_timesteps      | 735232     |
| train/                  |            |
|    approx_kl            | 0.13811111 |
|    clip_fraction        | 0.631      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.7        |
|    explained_variance   | 0.549      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00726    |
|    n_updates            | 3580       |
|    policy_gradient_loss | -0.0164    |
|    std                  | 0.105      |
|    value_loss           | 0.0258     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 920        |
|    ep_rew_mean          | 2.36e+03   |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 360        |
|    time_elapsed         | 4658       |
|    total_timesteps      | 737280     |
| train/                  |            |
|    approx_kl            | 0.13439745 |
|    clip_fraction        | 0.618      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.73       |
|    explained_variance   | 0.716      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0581    |
|    n_updates            | 3590       |
|    policy_gradient_loss | -0.0214    |
|    std                  | 0.104      |
|    value_loss           | 0.0151     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 920         |
|    ep_rew_mean          | 2.36e+03    |
| time/                   |             |
|    fps                  | 158         |
|    iterations           | 361         |
|    time_elapsed         | 4667        |
|    total_timesteps      | 739328      |
| train/                  |             |
|    approx_kl            | 0.124893345 |
|    clip_fraction        | 0.615       |
|    clip_range           | 0.2         |
|    entropy_loss         | 6.74        |
|    explained_variance   | 0.538       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0469     |
|    n_updates            | 3600        |
|    policy_gradient_loss | -0.0236     |
|    std                  | 0.104       |
|    value_loss           | 0.00912     |
-----------------------------------------
Eval num_timesteps=740000, episode_reward=3284.35 +/- 500.70
Episode length: 1000.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 1e+03       |
|    mean_reward          | 3.28e+03    |
| time/                   |             |
|    total_timesteps      | 740000      |
| train/                  |             |
|    approx_kl            | 0.121664256 |
|    clip_fraction        | 0.631       |
|    clip_range           | 0.2         |
|    entropy_loss         | 6.75        |
|    explained_variance   | 0.965       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0125     |
|    n_updates            | 3610        |
|    policy_gradient_loss | -0.0159     |
|    std                  | 0.104       |
|    value_loss           | 0.0264      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 929      |
|    ep_rew_mean     | 2.38e+03 |
| time/              |          |
|    fps             | 157      |
|    iterations      | 362      |
|    time_elapsed    | 4697     |
|    total_timesteps | 741376   |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 937      |
|    ep_rew_mean          | 2.42e+03 |
| time/                   |          |
|    fps                  | 157      |
|    iterations           | 363      |
|    time_elapsed         | 4706     |
|    total_timesteps      | 743424   |
| train/                  |          |
|    approx_kl            | 0.133202 |
|    clip_fraction        | 0.619    |
|    clip_range           | 0.2      |
|    entropy_loss         | 6.77     |
|    explained_variance   | 0.96     |
|    learning_rate        | 0.0003   |
|    loss                 | 0.00656  |
|    n_updates            | 3620     |
|    policy_gradient_loss | -0.0218  |
|    std                  | 0.104    |
|    value_loss           | 0.00492  |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 937       |
|    ep_rew_mean          | 2.44e+03  |
| time/                   |           |
|    fps                  | 158       |
|    iterations           | 364       |
|    time_elapsed         | 4715      |
|    total_timesteps      | 745472    |
| train/                  |           |
|    approx_kl            | 0.1256586 |
|    clip_fraction        | 0.605     |
|    clip_range           | 0.2       |
|    entropy_loss         | 6.8       |
|    explained_variance   | 0.574     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0631   |
|    n_updates            | 3630      |
|    policy_gradient_loss | -0.0272   |
|    std                  | 0.104     |
|    value_loss           | 0.00733   |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 937        |
|    ep_rew_mean          | 2.46e+03   |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 365        |
|    time_elapsed         | 4725       |
|    total_timesteps      | 747520     |
| train/                  |            |
|    approx_kl            | 0.12935457 |
|    clip_fraction        | 0.642      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.81       |
|    explained_variance   | 0.596      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0363    |
|    n_updates            | 3640       |
|    policy_gradient_loss | -0.0225    |
|    std                  | 0.104      |
|    value_loss           | 0.00623    |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 942       |
|    ep_rew_mean          | 2.48e+03  |
| time/                   |           |
|    fps                  | 158       |
|    iterations           | 366       |
|    time_elapsed         | 4734      |
|    total_timesteps      | 749568    |
| train/                  |           |
|    approx_kl            | 0.1344989 |
|    clip_fraction        | 0.635     |
|    clip_range           | 0.2       |
|    entropy_loss         | 6.82      |
|    explained_variance   | 0.979     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0398   |
|    n_updates            | 3650      |
|    policy_gradient_loss | -0.0185   |
|    std                  | 0.103     |
|    value_loss           | 0.0156    |
---------------------------------------
Eval num_timesteps=750000, episode_reward=3492.25 +/- 86.67
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 3.49e+03   |
| time/                   |            |
|    total_timesteps      | 750000     |
| train/                  |            |
|    approx_kl            | 0.14110701 |
|    clip_fraction        | 0.636      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.86       |
|    explained_variance   | 0.235      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.044     |
|    n_updates            | 3660       |
|    policy_gradient_loss | -0.0232    |
|    std                  | 0.103      |
|    value_loss           | 0.00635    |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 946      |
|    ep_rew_mean     | 2.51e+03 |
| time/              |          |
|    fps             | 157      |
|    iterations      | 367      |
|    time_elapsed    | 4764     |
|    total_timesteps | 751616   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 946         |
|    ep_rew_mean          | 2.55e+03    |
| time/                   |             |
|    fps                  | 157         |
|    iterations           | 368         |
|    time_elapsed         | 4775        |
|    total_timesteps      | 753664      |
| train/                  |             |
|    approx_kl            | 0.117694676 |
|    clip_fraction        | 0.622       |
|    clip_range           | 0.2         |
|    entropy_loss         | 6.87        |
|    explained_variance   | 0.569       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0871     |
|    n_updates            | 3670        |
|    policy_gradient_loss | -0.0242     |
|    std                  | 0.103       |
|    value_loss           | 0.00393     |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 946        |
|    ep_rew_mean          | 2.56e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 369        |
|    time_elapsed         | 4784       |
|    total_timesteps      | 755712     |
| train/                  |            |
|    approx_kl            | 0.12038874 |
|    clip_fraction        | 0.639      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.87       |
|    explained_variance   | 0.515      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0548    |
|    n_updates            | 3680       |
|    policy_gradient_loss | -0.0247    |
|    std                  | 0.103      |
|    value_loss           | 0.00612    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 947        |
|    ep_rew_mean          | 2.58e+03   |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 370        |
|    time_elapsed         | 4793       |
|    total_timesteps      | 757760     |
| train/                  |            |
|    approx_kl            | 0.13678654 |
|    clip_fraction        | 0.621      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.9        |
|    explained_variance   | 0.984      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0253    |
|    n_updates            | 3690       |
|    policy_gradient_loss | -0.02      |
|    std                  | 0.102      |
|    value_loss           | 0.0112     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 947        |
|    ep_rew_mean          | 2.59e+03   |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 371        |
|    time_elapsed         | 4803       |
|    total_timesteps      | 759808     |
| train/                  |            |
|    approx_kl            | 0.14626326 |
|    clip_fraction        | 0.634      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.92       |
|    explained_variance   | 0.589      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0536    |
|    n_updates            | 3700       |
|    policy_gradient_loss | -0.0247    |
|    std                  | 0.102      |
|    value_loss           | 0.00658    |
----------------------------------------
Eval num_timesteps=760000, episode_reward=3544.15 +/- 97.39
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 3.54e+03   |
| time/                   |            |
|    total_timesteps      | 760000     |
| train/                  |            |
|    approx_kl            | 0.15187155 |
|    clip_fraction        | 0.632      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.93       |
|    explained_variance   | 0.61       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0654    |
|    n_updates            | 3710       |
|    policy_gradient_loss | -0.0301    |
|    std                  | 0.102      |
|    value_loss           | 0.00438    |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 947      |
|    ep_rew_mean     | 2.61e+03 |
| time/              |          |
|    fps             | 157      |
|    iterations      | 372      |
|    time_elapsed    | 4832     |
|    total_timesteps | 761856   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 956        |
|    ep_rew_mean          | 2.65e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 373        |
|    time_elapsed         | 4841       |
|    total_timesteps      | 763904     |
| train/                  |            |
|    approx_kl            | 0.13642825 |
|    clip_fraction        | 0.628      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.94       |
|    explained_variance   | 0.649      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0667    |
|    n_updates            | 3720       |
|    policy_gradient_loss | -0.0244    |
|    std                  | 0.102      |
|    value_loss           | 0.00397    |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 965       |
|    ep_rew_mean          | 2.71e+03  |
| time/                   |           |
|    fps                  | 157       |
|    iterations           | 374       |
|    time_elapsed         | 4851      |
|    total_timesteps      | 765952    |
| train/                  |           |
|    approx_kl            | 0.1543931 |
|    clip_fraction        | 0.628     |
|    clip_range           | 0.2       |
|    entropy_loss         | 6.94      |
|    explained_variance   | 0.538     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0589   |
|    n_updates            | 3730      |
|    policy_gradient_loss | -0.0161   |
|    std                  | 0.102     |
|    value_loss           | 0.00433   |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 965        |
|    ep_rew_mean          | 2.74e+03   |
| time/                   |            |
|    fps                  | 158        |
|    iterations           | 375        |
|    time_elapsed         | 4860       |
|    total_timesteps      | 768000     |
| train/                  |            |
|    approx_kl            | 0.11947021 |
|    clip_fraction        | 0.623      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.94       |
|    explained_variance   | 0.64       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.094     |
|    n_updates            | 3740       |
|    policy_gradient_loss | -0.0188    |
|    std                  | 0.102      |
|    value_loss           | 0.00594    |
----------------------------------------
Eval num_timesteps=770000, episode_reward=3611.78 +/- 107.19
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 3.61e+03   |
| time/                   |            |
|    total_timesteps      | 770000     |
| train/                  |            |
|    approx_kl            | 0.12901591 |
|    clip_fraction        | 0.633      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.96       |
|    explained_variance   | 0.575      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0705    |
|    n_updates            | 3750       |
|    policy_gradient_loss | -0.0199    |
|    std                  | 0.102      |
|    value_loss           | 0.00529    |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 965      |
|    ep_rew_mean     | 2.75e+03 |
| time/              |          |
|    fps             | 157      |
|    iterations      | 376      |
|    time_elapsed    | 4890     |
|    total_timesteps | 770048   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 965        |
|    ep_rew_mean          | 2.77e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 377        |
|    time_elapsed         | 4899       |
|    total_timesteps      | 772096     |
| train/                  |            |
|    approx_kl            | 0.13531196 |
|    clip_fraction        | 0.622      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.96       |
|    explained_variance   | 0.703      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0531    |
|    n_updates            | 3760       |
|    policy_gradient_loss | -0.0218    |
|    std                  | 0.102      |
|    value_loss           | 0.00332    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 965        |
|    ep_rew_mean          | 2.76e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 378        |
|    time_elapsed         | 4909       |
|    total_timesteps      | 774144     |
| train/                  |            |
|    approx_kl            | 0.13999955 |
|    clip_fraction        | 0.624      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.97       |
|    explained_variance   | 0.589      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0525    |
|    n_updates            | 3770       |
|    policy_gradient_loss | -0.0158    |
|    std                  | 0.102      |
|    value_loss           | 0.00297    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 965        |
|    ep_rew_mean          | 2.78e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 379        |
|    time_elapsed         | 4918       |
|    total_timesteps      | 776192     |
| train/                  |            |
|    approx_kl            | 0.15326262 |
|    clip_fraction        | 0.61       |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.99       |
|    explained_variance   | 0.986      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0164    |
|    n_updates            | 3780       |
|    policy_gradient_loss | -0.0178    |
|    std                  | 0.101      |
|    value_loss           | 0.0118     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 972        |
|    ep_rew_mean          | 2.81e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 380        |
|    time_elapsed         | 4927       |
|    total_timesteps      | 778240     |
| train/                  |            |
|    approx_kl            | 0.14093208 |
|    clip_fraction        | 0.63       |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.01       |
|    explained_variance   | 0.614      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0531    |
|    n_updates            | 3790       |
|    policy_gradient_loss | -0.0257    |
|    std                  | 0.101      |
|    value_loss           | 0.00357    |
----------------------------------------
Eval num_timesteps=780000, episode_reward=3691.07 +/- 58.80
Episode length: 1000.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 1e+03     |
|    mean_reward          | 3.69e+03  |
| time/                   |           |
|    total_timesteps      | 780000    |
| train/                  |           |
|    approx_kl            | 0.1436302 |
|    clip_fraction        | 0.626     |
|    clip_range           | 0.2       |
|    entropy_loss         | 7.03      |
|    explained_variance   | 0.672     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0153   |
|    n_updates            | 3800      |
|    policy_gradient_loss | -0.0163   |
|    std                  | 0.1       |
|    value_loss           | 0.00526   |
---------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 972      |
|    ep_rew_mean     | 2.83e+03 |
| time/              |          |
|    fps             | 157      |
|    iterations      | 381      |
|    time_elapsed    | 4956     |
|    total_timesteps | 780288   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 980        |
|    ep_rew_mean          | 2.86e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 382        |
|    time_elapsed         | 4965       |
|    total_timesteps      | 782336     |
| train/                  |            |
|    approx_kl            | 0.14933261 |
|    clip_fraction        | 0.646      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.03       |
|    explained_variance   | 0.71       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0521    |
|    n_updates            | 3810       |
|    policy_gradient_loss | -0.0163    |
|    std                  | 0.101      |
|    value_loss           | 0.00297    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 980        |
|    ep_rew_mean          | 2.88e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 383        |
|    time_elapsed         | 4975       |
|    total_timesteps      | 784384     |
| train/                  |            |
|    approx_kl            | 0.13154347 |
|    clip_fraction        | 0.643      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.02       |
|    explained_variance   | 0.692      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0412    |
|    n_updates            | 3820       |
|    policy_gradient_loss | -0.0187    |
|    std                  | 0.101      |
|    value_loss           | 0.00724    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 980        |
|    ep_rew_mean          | 2.9e+03    |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 384        |
|    time_elapsed         | 4984       |
|    total_timesteps      | 786432     |
| train/                  |            |
|    approx_kl            | 0.13065344 |
|    clip_fraction        | 0.62       |
|    clip_range           | 0.2        |
|    entropy_loss         | 7          |
|    explained_variance   | 0.96       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00142    |
|    n_updates            | 3830       |
|    policy_gradient_loss | -0.021     |
|    std                  | 0.101      |
|    value_loss           | 0.0155     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 980        |
|    ep_rew_mean          | 2.92e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 385        |
|    time_elapsed         | 4993       |
|    total_timesteps      | 788480     |
| train/                  |            |
|    approx_kl            | 0.14335318 |
|    clip_fraction        | 0.662      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7          |
|    explained_variance   | 0.774      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0807    |
|    n_updates            | 3840       |
|    policy_gradient_loss | -0.0212    |
|    std                  | 0.101      |
|    value_loss           | 0.00641    |
----------------------------------------
Eval num_timesteps=790000, episode_reward=3780.61 +/- 102.64
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 3.78e+03   |
| time/                   |            |
|    total_timesteps      | 790000     |
| train/                  |            |
|    approx_kl            | 0.14736304 |
|    clip_fraction        | 0.628      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.99       |
|    explained_variance   | 0.704      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0758    |
|    n_updates            | 3850       |
|    policy_gradient_loss | -0.0214    |
|    std                  | 0.102      |
|    value_loss           | 0.00311    |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 980      |
|    ep_rew_mean     | 2.93e+03 |
| time/              |          |
|    fps             | 157      |
|    iterations      | 386      |
|    time_elapsed    | 5022     |
|    total_timesteps | 790528   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 980        |
|    ep_rew_mean          | 2.94e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 387        |
|    time_elapsed         | 5032       |
|    total_timesteps      | 792576     |
| train/                  |            |
|    approx_kl            | 0.11885443 |
|    clip_fraction        | 0.64       |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.96       |
|    explained_variance   | 0.645      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0389    |
|    n_updates            | 3860       |
|    policy_gradient_loss | -0.0202    |
|    std                  | 0.102      |
|    value_loss           | 0.00363    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 982        |
|    ep_rew_mean          | 2.96e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 388        |
|    time_elapsed         | 5041       |
|    total_timesteps      | 794624     |
| train/                  |            |
|    approx_kl            | 0.13382241 |
|    clip_fraction        | 0.615      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.97       |
|    explained_variance   | 0.701      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0756    |
|    n_updates            | 3870       |
|    policy_gradient_loss | -0.0197    |
|    std                  | 0.101      |
|    value_loss           | 0.00425    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 982        |
|    ep_rew_mean          | 2.98e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 389        |
|    time_elapsed         | 5050       |
|    total_timesteps      | 796672     |
| train/                  |            |
|    approx_kl            | 0.16605467 |
|    clip_fraction        | 0.641      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.99       |
|    explained_variance   | 0.773      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0719    |
|    n_updates            | 3880       |
|    policy_gradient_loss | -0.0217    |
|    std                  | 0.101      |
|    value_loss           | 0.00454    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 982        |
|    ep_rew_mean          | 2.98e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 390        |
|    time_elapsed         | 5059       |
|    total_timesteps      | 798720     |
| train/                  |            |
|    approx_kl            | 0.14270645 |
|    clip_fraction        | 0.631      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.98       |
|    explained_variance   | 0.655      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0579    |
|    n_updates            | 3890       |
|    policy_gradient_loss | -0.0225    |
|    std                  | 0.102      |
|    value_loss           | 0.00428    |
----------------------------------------
Eval num_timesteps=800000, episode_reward=3704.38 +/- 558.33
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 3.7e+03    |
| time/                   |            |
|    total_timesteps      | 800000     |
| train/                  |            |
|    approx_kl            | 0.16185313 |
|    clip_fraction        | 0.638      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.96       |
|    explained_variance   | 0.674      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0639    |
|    n_updates            | 3900       |
|    policy_gradient_loss | -0.023     |
|    std                  | 0.102      |
|    value_loss           | 0.00404    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 982      |
|    ep_rew_mean     | 3e+03    |
| time/              |          |
|    fps             | 157      |
|    iterations      | 391      |
|    time_elapsed    | 5088     |
|    total_timesteps | 800768   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 982        |
|    ep_rew_mean          | 3.01e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 392        |
|    time_elapsed         | 5098       |
|    total_timesteps      | 802816     |
| train/                  |            |
|    approx_kl            | 0.12187238 |
|    clip_fraction        | 0.617      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.94       |
|    explained_variance   | 0.653      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.07      |
|    n_updates            | 3910       |
|    policy_gradient_loss | -0.0228    |
|    std                  | 0.102      |
|    value_loss           | 0.00658    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 982        |
|    ep_rew_mean          | 3.02e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 393        |
|    time_elapsed         | 5107       |
|    total_timesteps      | 804864     |
| train/                  |            |
|    approx_kl            | 0.15652058 |
|    clip_fraction        | 0.638      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.95       |
|    explained_variance   | 0.622      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0635    |
|    n_updates            | 3920       |
|    policy_gradient_loss | -0.0205    |
|    std                  | 0.102      |
|    value_loss           | 0.00341    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 982        |
|    ep_rew_mean          | 3e+03      |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 394        |
|    time_elapsed         | 5116       |
|    total_timesteps      | 806912     |
| train/                  |            |
|    approx_kl            | 0.13539416 |
|    clip_fraction        | 0.628      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.96       |
|    explained_variance   | 0.643      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0282    |
|    n_updates            | 3930       |
|    policy_gradient_loss | -0.0237    |
|    std                  | 0.101      |
|    value_loss           | 0.00427    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 982        |
|    ep_rew_mean          | 3.01e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 395        |
|    time_elapsed         | 5126       |
|    total_timesteps      | 808960     |
| train/                  |            |
|    approx_kl            | 0.10871113 |
|    clip_fraction        | 0.562      |
|    clip_range           | 0.2        |
|    entropy_loss         | 6.97       |
|    explained_variance   | 0.975      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00545   |
|    n_updates            | 3940       |
|    policy_gradient_loss | -0.0156    |
|    std                  | 0.101      |
|    value_loss           | 0.0207     |
----------------------------------------
Eval num_timesteps=810000, episode_reward=3598.82 +/- 825.87
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 3.6e+03    |
| time/                   |            |
|    total_timesteps      | 810000     |
| train/                  |            |
|    approx_kl            | 0.15901648 |
|    clip_fraction        | 0.641      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.03       |
|    explained_variance   | -0.129     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0377    |
|    n_updates            | 3950       |
|    policy_gradient_loss | -0.0199    |
|    std                  | 0.1        |
|    value_loss           | 0.00711    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 986      |
|    ep_rew_mean     | 3.04e+03 |
| time/              |          |
|    fps             | 157      |
|    iterations      | 396      |
|    time_elapsed    | 5155     |
|    total_timesteps | 811008   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 986        |
|    ep_rew_mean          | 3.07e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 397        |
|    time_elapsed         | 5165       |
|    total_timesteps      | 813056     |
| train/                  |            |
|    approx_kl            | 0.13155234 |
|    clip_fraction        | 0.614      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.07       |
|    explained_variance   | 0.573      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0267    |
|    n_updates            | 3960       |
|    policy_gradient_loss | -0.0254    |
|    std                  | 0.1        |
|    value_loss           | 0.00488    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 986        |
|    ep_rew_mean          | 3.08e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 398        |
|    time_elapsed         | 5174       |
|    total_timesteps      | 815104     |
| train/                  |            |
|    approx_kl            | 0.14295653 |
|    clip_fraction        | 0.652      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.07       |
|    explained_variance   | 0.479      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00549   |
|    n_updates            | 3970       |
|    policy_gradient_loss | -0.0184    |
|    std                  | 0.1        |
|    value_loss           | 0.00538    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 986        |
|    ep_rew_mean          | 3.11e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 399        |
|    time_elapsed         | 5183       |
|    total_timesteps      | 817152     |
| train/                  |            |
|    approx_kl            | 0.13069035 |
|    clip_fraction        | 0.621      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.08       |
|    explained_variance   | 0.612      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0469    |
|    n_updates            | 3980       |
|    policy_gradient_loss | -0.0273    |
|    std                  | 0.0999     |
|    value_loss           | 0.00343    |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 986       |
|    ep_rew_mean          | 3.11e+03  |
| time/                   |           |
|    fps                  | 157       |
|    iterations           | 400       |
|    time_elapsed         | 5193      |
|    total_timesteps      | 819200    |
| train/                  |           |
|    approx_kl            | 0.1925357 |
|    clip_fraction        | 0.635     |
|    clip_range           | 0.2       |
|    entropy_loss         | 7.09      |
|    explained_variance   | 0.741     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0585   |
|    n_updates            | 3990      |
|    policy_gradient_loss | -0.0197   |
|    std                  | 0.0998    |
|    value_loss           | 0.00544   |
---------------------------------------
Eval num_timesteps=820000, episode_reward=3626.91 +/- 647.20
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 3.63e+03   |
| time/                   |            |
|    total_timesteps      | 820000     |
| train/                  |            |
|    approx_kl            | 0.14963597 |
|    clip_fraction        | 0.631      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.1        |
|    explained_variance   | 0.692      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0407    |
|    n_updates            | 4000       |
|    policy_gradient_loss | -0.0223    |
|    std                  | 0.1        |
|    value_loss           | 0.00362    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 986      |
|    ep_rew_mean     | 3.13e+03 |
| time/              |          |
|    fps             | 157      |
|    iterations      | 401      |
|    time_elapsed    | 5225     |
|    total_timesteps | 821248   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 986        |
|    ep_rew_mean          | 3.14e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 402        |
|    time_elapsed         | 5234       |
|    total_timesteps      | 823296     |
| train/                  |            |
|    approx_kl            | 0.14209735 |
|    clip_fraction        | 0.626      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.11       |
|    explained_variance   | 0.687      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0452    |
|    n_updates            | 4010       |
|    policy_gradient_loss | -0.0282    |
|    std                  | 0.0995     |
|    value_loss           | 0.00413    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 986        |
|    ep_rew_mean          | 3.15e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 403        |
|    time_elapsed         | 5244       |
|    total_timesteps      | 825344     |
| train/                  |            |
|    approx_kl            | 0.17116892 |
|    clip_fraction        | 0.646      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.14       |
|    explained_variance   | 0.688      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0251    |
|    n_updates            | 4020       |
|    policy_gradient_loss | -0.0172    |
|    std                  | 0.0992     |
|    value_loss           | 0.00391    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 989        |
|    ep_rew_mean          | 3.17e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 404        |
|    time_elapsed         | 5253       |
|    total_timesteps      | 827392     |
| train/                  |            |
|    approx_kl            | 0.15167978 |
|    clip_fraction        | 0.653      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.14       |
|    explained_variance   | 0.734      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00171    |
|    n_updates            | 4030       |
|    policy_gradient_loss | -0.0106    |
|    std                  | 0.0995     |
|    value_loss           | 0.00378    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 989        |
|    ep_rew_mean          | 3.19e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 405        |
|    time_elapsed         | 5262       |
|    total_timesteps      | 829440     |
| train/                  |            |
|    approx_kl            | 0.15335701 |
|    clip_fraction        | 0.642      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.13       |
|    explained_variance   | 0.671      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.066     |
|    n_updates            | 4040       |
|    policy_gradient_loss | -0.0225    |
|    std                  | 0.0995     |
|    value_loss           | 0.00481    |
----------------------------------------
Eval num_timesteps=830000, episode_reward=3935.26 +/- 105.76
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 3.94e+03   |
| time/                   |            |
|    total_timesteps      | 830000     |
| train/                  |            |
|    approx_kl            | 0.14387763 |
|    clip_fraction        | 0.632      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.15       |
|    explained_variance   | 0.768      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0446    |
|    n_updates            | 4050       |
|    policy_gradient_loss | -0.0256    |
|    std                  | 0.0991     |
|    value_loss           | 0.00416    |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 995      |
|    ep_rew_mean     | 3.19e+03 |
| time/              |          |
|    fps             | 157      |
|    iterations      | 406      |
|    time_elapsed    | 5292     |
|    total_timesteps | 831488   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 995        |
|    ep_rew_mean          | 3.2e+03    |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 407        |
|    time_elapsed         | 5301       |
|    total_timesteps      | 833536     |
| train/                  |            |
|    approx_kl            | 0.15774044 |
|    clip_fraction        | 0.64       |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.17       |
|    explained_variance   | 0.99       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0453    |
|    n_updates            | 4060       |
|    policy_gradient_loss | -0.0187    |
|    std                  | 0.0988     |
|    value_loss           | 0.00643    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | 3.24e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 408        |
|    time_elapsed         | 5311       |
|    total_timesteps      | 835584     |
| train/                  |            |
|    approx_kl            | 0.15669818 |
|    clip_fraction        | 0.642      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.18       |
|    explained_variance   | 0.578      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0606    |
|    n_updates            | 4070       |
|    policy_gradient_loss | -0.0238    |
|    std                  | 0.0988     |
|    value_loss           | 0.00845    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | 3.25e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 409        |
|    time_elapsed         | 5320       |
|    total_timesteps      | 837632     |
| train/                  |            |
|    approx_kl            | 0.13289958 |
|    clip_fraction        | 0.626      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.2        |
|    explained_variance   | 0.626      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0646    |
|    n_updates            | 4080       |
|    policy_gradient_loss | -0.0196    |
|    std                  | 0.0984     |
|    value_loss           | 0.00625    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | 3.28e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 410        |
|    time_elapsed         | 5329       |
|    total_timesteps      | 839680     |
| train/                  |            |
|    approx_kl            | 0.15581696 |
|    clip_fraction        | 0.627      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.22       |
|    explained_variance   | 0.659      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0127    |
|    n_updates            | 4090       |
|    policy_gradient_loss | -0.0271    |
|    std                  | 0.0983     |
|    value_loss           | 0.00497    |
----------------------------------------
Eval num_timesteps=840000, episode_reward=3948.33 +/- 90.84
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 3.95e+03   |
| time/                   |            |
|    total_timesteps      | 840000     |
| train/                  |            |
|    approx_kl            | 0.13866025 |
|    clip_fraction        | 0.64       |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.24       |
|    explained_variance   | 0.685      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0423    |
|    n_updates            | 4100       |
|    policy_gradient_loss | -0.0163    |
|    std                  | 0.0981     |
|    value_loss           | 0.00477    |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 3.27e+03 |
| time/              |          |
|    fps             | 157      |
|    iterations      | 411      |
|    time_elapsed    | 5359     |
|    total_timesteps | 841728   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | 3.28e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 412        |
|    time_elapsed         | 5368       |
|    total_timesteps      | 843776     |
| train/                  |            |
|    approx_kl            | 0.13223526 |
|    clip_fraction        | 0.628      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.22       |
|    explained_variance   | 0.986      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0678    |
|    n_updates            | 4110       |
|    policy_gradient_loss | -0.00973   |
|    std                  | 0.0985     |
|    value_loss           | 0.0106     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | 3.29e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 413        |
|    time_elapsed         | 5378       |
|    total_timesteps      | 845824     |
| train/                  |            |
|    approx_kl            | 0.14337331 |
|    clip_fraction        | 0.637      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.2        |
|    explained_variance   | 0.662      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0772    |
|    n_updates            | 4120       |
|    policy_gradient_loss | -0.0162    |
|    std                  | 0.0986     |
|    value_loss           | 0.00396    |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 1e+03     |
|    ep_rew_mean          | 3.3e+03   |
| time/                   |           |
|    fps                  | 157       |
|    iterations           | 414       |
|    time_elapsed         | 5387      |
|    total_timesteps      | 847872    |
| train/                  |           |
|    approx_kl            | 0.1385587 |
|    clip_fraction        | 0.653     |
|    clip_range           | 0.2       |
|    entropy_loss         | 7.2       |
|    explained_variance   | 0.941     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0822   |
|    n_updates            | 4130      |
|    policy_gradient_loss | -0.0194   |
|    std                  | 0.0984    |
|    value_loss           | 0.0162    |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | 3.29e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 415        |
|    time_elapsed         | 5396       |
|    total_timesteps      | 849920     |
| train/                  |            |
|    approx_kl            | 0.15639916 |
|    clip_fraction        | 0.635      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.21       |
|    explained_variance   | 0.961      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0618    |
|    n_updates            | 4140       |
|    policy_gradient_loss | -0.0169    |
|    std                  | 0.0982     |
|    value_loss           | 0.0166     |
----------------------------------------
Eval num_timesteps=850000, episode_reward=3694.66 +/- 745.95
Episode length: 961.56 +/- 188.32
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 962        |
|    mean_reward          | 3.69e+03   |
| time/                   |            |
|    total_timesteps      | 850000     |
| train/                  |            |
|    approx_kl            | 0.15805537 |
|    clip_fraction        | 0.638      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.23       |
|    explained_variance   | 0.992      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0306    |
|    n_updates            | 4150       |
|    policy_gradient_loss | -0.0249    |
|    std                  | 0.0982     |
|    value_loss           | 0.00574    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 3.29e+03 |
| time/              |          |
|    fps             | 157      |
|    iterations      | 416      |
|    time_elapsed    | 5426     |
|    total_timesteps | 851968   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | 3.29e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 417        |
|    time_elapsed         | 5435       |
|    total_timesteps      | 854016     |
| train/                  |            |
|    approx_kl            | 0.16276228 |
|    clip_fraction        | 0.649      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.21       |
|    explained_variance   | 0.565      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0169     |
|    n_updates            | 4160       |
|    policy_gradient_loss | -0.0164    |
|    std                  | 0.0983     |
|    value_loss           | 0.0063     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | 3.29e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 418        |
|    time_elapsed         | 5445       |
|    total_timesteps      | 856064     |
| train/                  |            |
|    approx_kl            | 0.17095189 |
|    clip_fraction        | 0.66       |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.22       |
|    explained_variance   | 0.515      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0278    |
|    n_updates            | 4170       |
|    policy_gradient_loss | -0.0152    |
|    std                  | 0.0981     |
|    value_loss           | 0.00944    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 990        |
|    ep_rew_mean          | 3.26e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 419        |
|    time_elapsed         | 5454       |
|    total_timesteps      | 858112     |
| train/                  |            |
|    approx_kl            | 0.10950473 |
|    clip_fraction        | 0.608      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.25       |
|    explained_variance   | 0.975      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.012     |
|    n_updates            | 4180       |
|    policy_gradient_loss | -0.0181    |
|    std                  | 0.0976     |
|    value_loss           | 0.0206     |
----------------------------------------
Eval num_timesteps=860000, episode_reward=3625.15 +/- 835.11
Episode length: 972.80 +/- 133.25
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 973       |
|    mean_reward          | 3.63e+03  |
| time/                   |           |
|    total_timesteps      | 860000    |
| train/                  |           |
|    approx_kl            | 0.1571542 |
|    clip_fraction        | 0.645     |
|    clip_range           | 0.2       |
|    entropy_loss         | 7.29      |
|    explained_variance   | 0.466     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0166   |
|    n_updates            | 4190      |
|    policy_gradient_loss | -0.0196   |
|    std                  | 0.0971    |
|    value_loss           | 0.0255    |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 990      |
|    ep_rew_mean     | 3.27e+03 |
| time/              |          |
|    fps             | 156      |
|    iterations      | 420      |
|    time_elapsed    | 5483     |
|    total_timesteps | 860160   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 990       |
|    ep_rew_mean          | 3.27e+03  |
| time/                   |           |
|    fps                  | 156       |
|    iterations           | 421       |
|    time_elapsed         | 5493      |
|    total_timesteps      | 862208    |
| train/                  |           |
|    approx_kl            | 0.1551562 |
|    clip_fraction        | 0.647     |
|    clip_range           | 0.2       |
|    entropy_loss         | 7.32      |
|    explained_variance   | 0.536     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0473   |
|    n_updates            | 4200      |
|    policy_gradient_loss | -0.0279   |
|    std                  | 0.0969    |
|    value_loss           | 0.00804   |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 988        |
|    ep_rew_mean          | 3.26e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 422        |
|    time_elapsed         | 5502       |
|    total_timesteps      | 864256     |
| train/                  |            |
|    approx_kl            | 0.14388582 |
|    clip_fraction        | 0.653      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.34       |
|    explained_variance   | 0.951      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0414    |
|    n_updates            | 4210       |
|    policy_gradient_loss | -0.0168    |
|    std                  | 0.0966     |
|    value_loss           | 0.0146     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 988        |
|    ep_rew_mean          | 3.27e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 423        |
|    time_elapsed         | 5511       |
|    total_timesteps      | 866304     |
| train/                  |            |
|    approx_kl            | 0.12050867 |
|    clip_fraction        | 0.648      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.37       |
|    explained_variance   | 0.919      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00895   |
|    n_updates            | 4220       |
|    policy_gradient_loss | -0.0166    |
|    std                  | 0.0961     |
|    value_loss           | 0.0337     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 982        |
|    ep_rew_mean          | 3.26e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 424        |
|    time_elapsed         | 5520       |
|    total_timesteps      | 868352     |
| train/                  |            |
|    approx_kl            | 0.16138688 |
|    clip_fraction        | 0.663      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.39       |
|    explained_variance   | 0.884      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.039     |
|    n_updates            | 4230       |
|    policy_gradient_loss | -0.0161    |
|    std                  | 0.0964     |
|    value_loss           | 0.02       |
----------------------------------------
Eval num_timesteps=870000, episode_reward=3463.93 +/- 1159.13
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 3.46e+03   |
| time/                   |            |
|    total_timesteps      | 870000     |
| train/                  |            |
|    approx_kl            | 0.13800485 |
|    clip_fraction        | 0.646      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.38       |
|    explained_variance   | 0.391      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00499   |
|    n_updates            | 4240       |
|    policy_gradient_loss | -0.00709   |
|    std                  | 0.0962     |
|    value_loss           | 0.0303     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 982      |
|    ep_rew_mean     | 3.27e+03 |
| time/              |          |
|    fps             | 156      |
|    iterations      | 425      |
|    time_elapsed    | 5550     |
|    total_timesteps | 870400   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 973        |
|    ep_rew_mean          | 3.26e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 426        |
|    time_elapsed         | 5559       |
|    total_timesteps      | 872448     |
| train/                  |            |
|    approx_kl            | 0.15551561 |
|    clip_fraction        | 0.658      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.38       |
|    explained_variance   | 0.295      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00214    |
|    n_updates            | 4250       |
|    policy_gradient_loss | -0.0171    |
|    std                  | 0.0963     |
|    value_loss           | 0.00809    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 973        |
|    ep_rew_mean          | 3.27e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 427        |
|    time_elapsed         | 5568       |
|    total_timesteps      | 874496     |
| train/                  |            |
|    approx_kl            | 0.11900739 |
|    clip_fraction        | 0.654      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.38       |
|    explained_variance   | 0.411      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0766    |
|    n_updates            | 4260       |
|    policy_gradient_loss | -0.00884   |
|    std                  | 0.0962     |
|    value_loss           | 0.0254     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 973       |
|    ep_rew_mean          | 3.25e+03  |
| time/                   |           |
|    fps                  | 157       |
|    iterations           | 428       |
|    time_elapsed         | 5578      |
|    total_timesteps      | 876544    |
| train/                  |           |
|    approx_kl            | 0.1638923 |
|    clip_fraction        | 0.653     |
|    clip_range           | 0.2       |
|    entropy_loss         | 7.35      |
|    explained_variance   | 0.945     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0212   |
|    n_updates            | 4270      |
|    policy_gradient_loss | -0.0162   |
|    std                  | 0.0969    |
|    value_loss           | 0.0207    |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 966       |
|    ep_rew_mean          | 3.23e+03  |
| time/                   |           |
|    fps                  | 157       |
|    iterations           | 429       |
|    time_elapsed         | 5587      |
|    total_timesteps      | 878592    |
| train/                  |           |
|    approx_kl            | 2.3262067 |
|    clip_fraction        | 0.697     |
|    clip_range           | 0.2       |
|    entropy_loss         | 7.36      |
|    explained_variance   | 0.963     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0939   |
|    n_updates            | 4280      |
|    policy_gradient_loss | -0.00943  |
|    std                  | 0.0961    |
|    value_loss           | 0.00529   |
---------------------------------------
Eval num_timesteps=880000, episode_reward=3836.81 +/- 679.26
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 3.84e+03   |
| time/                   |            |
|    total_timesteps      | 880000     |
| train/                  |            |
|    approx_kl            | 0.13923456 |
|    clip_fraction        | 0.643      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.42       |
|    explained_variance   | 0.403      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0442    |
|    n_updates            | 4290       |
|    policy_gradient_loss | -0.0141    |
|    std                  | 0.0957     |
|    value_loss           | 0.0266     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 966      |
|    ep_rew_mean     | 3.24e+03 |
| time/              |          |
|    fps             | 156      |
|    iterations      | 430      |
|    time_elapsed    | 5617     |
|    total_timesteps | 880640   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 966        |
|    ep_rew_mean          | 3.23e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 431        |
|    time_elapsed         | 5626       |
|    total_timesteps      | 882688     |
| train/                  |            |
|    approx_kl            | 0.16126044 |
|    clip_fraction        | 0.658      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.43       |
|    explained_variance   | 0.458      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0813    |
|    n_updates            | 4300       |
|    policy_gradient_loss | -0.0176    |
|    std                  | 0.0958     |
|    value_loss           | 0.00385    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 966        |
|    ep_rew_mean          | 3.24e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 432        |
|    time_elapsed         | 5635       |
|    total_timesteps      | 884736     |
| train/                  |            |
|    approx_kl            | 0.13531926 |
|    clip_fraction        | 0.635      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.42       |
|    explained_variance   | 0.975      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0309    |
|    n_updates            | 4310       |
|    policy_gradient_loss | -0.0117    |
|    std                  | 0.0957     |
|    value_loss           | 0.0241     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 966        |
|    ep_rew_mean          | 3.24e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 433        |
|    time_elapsed         | 5644       |
|    total_timesteps      | 886784     |
| train/                  |            |
|    approx_kl            | 0.17822269 |
|    clip_fraction        | 0.675      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.43       |
|    explained_variance   | 0.101      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.063     |
|    n_updates            | 4320       |
|    policy_gradient_loss | -0.0205    |
|    std                  | 0.096      |
|    value_loss           | 0.00538    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 966        |
|    ep_rew_mean          | 3.25e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 434        |
|    time_elapsed         | 5654       |
|    total_timesteps      | 888832     |
| train/                  |            |
|    approx_kl            | 0.16270281 |
|    clip_fraction        | 0.637      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.41       |
|    explained_variance   | 0.591      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0744    |
|    n_updates            | 4330       |
|    policy_gradient_loss | -0.0303    |
|    std                  | 0.0958     |
|    value_loss           | 0.00552    |
----------------------------------------
Eval num_timesteps=890000, episode_reward=3561.76 +/- 1087.31
Episode length: 961.28 +/- 189.69
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 961        |
|    mean_reward          | 3.56e+03   |
| time/                   |            |
|    total_timesteps      | 890000     |
| train/                  |            |
|    approx_kl            | 0.15487982 |
|    clip_fraction        | 0.651      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.43       |
|    explained_variance   | 0.966      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0561    |
|    n_updates            | 4340       |
|    policy_gradient_loss | -0.0162    |
|    std                  | 0.0957     |
|    value_loss           | 0.0166     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 966      |
|    ep_rew_mean     | 3.24e+03 |
| time/              |          |
|    fps             | 156      |
|    iterations      | 435      |
|    time_elapsed    | 5683     |
|    total_timesteps | 890880   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 966        |
|    ep_rew_mean          | 3.25e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 436        |
|    time_elapsed         | 5692       |
|    total_timesteps      | 892928     |
| train/                  |            |
|    approx_kl            | 0.15975587 |
|    clip_fraction        | 0.647      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.44       |
|    explained_variance   | 0.988      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00561   |
|    n_updates            | 4350       |
|    policy_gradient_loss | -0.0103    |
|    std                  | 0.0957     |
|    value_loss           | 0.00465    |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 966       |
|    ep_rew_mean          | 3.23e+03  |
| time/                   |           |
|    fps                  | 156       |
|    iterations           | 437       |
|    time_elapsed         | 5702      |
|    total_timesteps      | 894976    |
| train/                  |           |
|    approx_kl            | 0.1387137 |
|    clip_fraction        | 0.663     |
|    clip_range           | 0.2       |
|    entropy_loss         | 7.41      |
|    explained_variance   | 0.974     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0159   |
|    n_updates            | 4360      |
|    policy_gradient_loss | -0.0188   |
|    std                  | 0.0961    |
|    value_loss           | 0.0188    |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 966       |
|    ep_rew_mean          | 3.24e+03  |
| time/                   |           |
|    fps                  | 157       |
|    iterations           | 438       |
|    time_elapsed         | 5711      |
|    total_timesteps      | 897024    |
| train/                  |           |
|    approx_kl            | 0.1564526 |
|    clip_fraction        | 0.638     |
|    clip_range           | 0.2       |
|    entropy_loss         | 7.4       |
|    explained_variance   | 0.973     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0192   |
|    n_updates            | 4370      |
|    policy_gradient_loss | -0.0256   |
|    std                  | 0.0961    |
|    value_loss           | 0.00756   |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 966        |
|    ep_rew_mean          | 3.24e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 439        |
|    time_elapsed         | 5720       |
|    total_timesteps      | 899072     |
| train/                  |            |
|    approx_kl            | 0.13679215 |
|    clip_fraction        | 0.622      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.41       |
|    explained_variance   | 0.893      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0383    |
|    n_updates            | 4380       |
|    policy_gradient_loss | -0.0209    |
|    std                  | 0.0958     |
|    value_loss           | 0.014      |
----------------------------------------
Eval num_timesteps=900000, episode_reward=3846.05 +/- 624.22
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 3.85e+03   |
| time/                   |            |
|    total_timesteps      | 900000     |
| train/                  |            |
|    approx_kl            | 0.14735681 |
|    clip_fraction        | 0.64       |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.43       |
|    explained_variance   | 0.552      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0113    |
|    n_updates            | 4390       |
|    policy_gradient_loss | -0.021     |
|    std                  | 0.0958     |
|    value_loss           | 0.00649    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 966      |
|    ep_rew_mean     | 3.25e+03 |
| time/              |          |
|    fps             | 156      |
|    iterations      | 440      |
|    time_elapsed    | 5750     |
|    total_timesteps | 901120   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 966        |
|    ep_rew_mean          | 3.29e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 441        |
|    time_elapsed         | 5759       |
|    total_timesteps      | 903168     |
| train/                  |            |
|    approx_kl            | 0.13898851 |
|    clip_fraction        | 0.624      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.43       |
|    explained_variance   | 0.533      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0479    |
|    n_updates            | 4400       |
|    policy_gradient_loss | -0.0154    |
|    std                  | 0.0957     |
|    value_loss           | 0.00573    |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 966       |
|    ep_rew_mean          | 3.3e+03   |
| time/                   |           |
|    fps                  | 156       |
|    iterations           | 442       |
|    time_elapsed         | 5768      |
|    total_timesteps      | 905216    |
| train/                  |           |
|    approx_kl            | 0.1437734 |
|    clip_fraction        | 0.648     |
|    clip_range           | 0.2       |
|    entropy_loss         | 7.43      |
|    explained_variance   | 0.638     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0521   |
|    n_updates            | 4410      |
|    policy_gradient_loss | -0.0213   |
|    std                  | 0.0958    |
|    value_loss           | 0.00497   |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 966        |
|    ep_rew_mean          | 3.28e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 443        |
|    time_elapsed         | 5778       |
|    total_timesteps      | 907264     |
| train/                  |            |
|    approx_kl            | 0.17074125 |
|    clip_fraction        | 0.644      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.43       |
|    explained_variance   | 0.554      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0522    |
|    n_updates            | 4420       |
|    policy_gradient_loss | -0.0183    |
|    std                  | 0.096      |
|    value_loss           | 0.00357    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 966        |
|    ep_rew_mean          | 3.29e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 444        |
|    time_elapsed         | 5787       |
|    total_timesteps      | 909312     |
| train/                  |            |
|    approx_kl            | 0.89027643 |
|    clip_fraction        | 0.684      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.43       |
|    explained_variance   | 0.964      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0316    |
|    n_updates            | 4430       |
|    policy_gradient_loss | -0.0227    |
|    std                  | 0.0954     |
|    value_loss           | 0.0214     |
----------------------------------------
Eval num_timesteps=910000, episode_reward=3697.91 +/- 942.96
Episode length: 950.16 +/- 195.16
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 950        |
|    mean_reward          | 3.7e+03    |
| time/                   |            |
|    total_timesteps      | 910000     |
| train/                  |            |
|    approx_kl            | 0.16345808 |
|    clip_fraction        | 0.658      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.47       |
|    explained_variance   | 0.438      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0568    |
|    n_updates            | 4440       |
|    policy_gradient_loss | -0.0206    |
|    std                  | 0.0951     |
|    value_loss           | 0.00641    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 966      |
|    ep_rew_mean     | 3.3e+03  |
| time/              |          |
|    fps             | 156      |
|    iterations      | 445      |
|    time_elapsed    | 5816     |
|    total_timesteps | 911360   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 966        |
|    ep_rew_mean          | 3.3e+03    |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 446        |
|    time_elapsed         | 5827       |
|    total_timesteps      | 913408     |
| train/                  |            |
|    approx_kl            | 0.13466623 |
|    clip_fraction        | 0.632      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.49       |
|    explained_variance   | 0.565      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0879    |
|    n_updates            | 4450       |
|    policy_gradient_loss | -0.0185    |
|    std                  | 0.0951     |
|    value_loss           | 0.00491    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 966        |
|    ep_rew_mean          | 3.28e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 447        |
|    time_elapsed         | 5837       |
|    total_timesteps      | 915456     |
| train/                  |            |
|    approx_kl            | 0.14585584 |
|    clip_fraction        | 0.638      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.5        |
|    explained_variance   | 0.967      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.022     |
|    n_updates            | 4460       |
|    policy_gradient_loss | -0.0152    |
|    std                  | 0.0947     |
|    value_loss           | 0.0154     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 966        |
|    ep_rew_mean          | 3.29e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 448        |
|    time_elapsed         | 5846       |
|    total_timesteps      | 917504     |
| train/                  |            |
|    approx_kl            | 0.14626023 |
|    clip_fraction        | 0.656      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.5        |
|    explained_variance   | 0.998      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.015     |
|    n_updates            | 4470       |
|    policy_gradient_loss | -0.00792   |
|    std                  | 0.0952     |
|    value_loss           | 0.00236    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 966        |
|    ep_rew_mean          | 3.29e+03   |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 449        |
|    time_elapsed         | 5856       |
|    total_timesteps      | 919552     |
| train/                  |            |
|    approx_kl            | 0.15275447 |
|    clip_fraction        | 0.639      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.47       |
|    explained_variance   | 0.617      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0464    |
|    n_updates            | 4480       |
|    policy_gradient_loss | -0.0143    |
|    std                  | 0.0952     |
|    value_loss           | 0.00408    |
----------------------------------------
Eval num_timesteps=920000, episode_reward=3913.75 +/- 487.19
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 3.91e+03   |
| time/                   |            |
|    total_timesteps      | 920000     |
| train/                  |            |
|    approx_kl            | 0.16405149 |
|    clip_fraction        | 0.641      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.48       |
|    explained_variance   | 0.621      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0296     |
|    n_updates            | 4490       |
|    policy_gradient_loss | -0.0144    |
|    std                  | 0.0951     |
|    value_loss           | 0.00458    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 966      |
|    ep_rew_mean     | 3.29e+03 |
| time/              |          |
|    fps             | 156      |
|    iterations      | 450      |
|    time_elapsed    | 5886     |
|    total_timesteps | 921600   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 966        |
|    ep_rew_mean          | 3.3e+03    |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 451        |
|    time_elapsed         | 5895       |
|    total_timesteps      | 923648     |
| train/                  |            |
|    approx_kl            | 0.14758548 |
|    clip_fraction        | 0.636      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.47       |
|    explained_variance   | 0.537      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0595    |
|    n_updates            | 4500       |
|    policy_gradient_loss | -0.0238    |
|    std                  | 0.0955     |
|    value_loss           | 0.00546    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 966        |
|    ep_rew_mean          | 3.27e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 452        |
|    time_elapsed         | 5904       |
|    total_timesteps      | 925696     |
| train/                  |            |
|    approx_kl            | 0.16330495 |
|    clip_fraction        | 0.651      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.47       |
|    explained_variance   | 0.629      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0684    |
|    n_updates            | 4510       |
|    policy_gradient_loss | -0.0264    |
|    std                  | 0.0951     |
|    value_loss           | 0.0047     |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 966      |
|    ep_rew_mean          | 3.28e+03 |
| time/                   |          |
|    fps                  | 156      |
|    iterations           | 453      |
|    time_elapsed         | 5914     |
|    total_timesteps      | 927744   |
| train/                  |          |
|    approx_kl            | 0.141732 |
|    clip_fraction        | 0.615    |
|    clip_range           | 0.2      |
|    entropy_loss         | 7.49     |
|    explained_variance   | 0.977    |
|    learning_rate        | 0.0003   |
|    loss                 | -0.0331  |
|    n_updates            | 4520     |
|    policy_gradient_loss | -0.00842 |
|    std                  | 0.0951   |
|    value_loss           | 0.0171   |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 966        |
|    ep_rew_mean          | 3.28e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 454        |
|    time_elapsed         | 5923       |
|    total_timesteps      | 929792     |
| train/                  |            |
|    approx_kl            | 0.17948115 |
|    clip_fraction        | 0.646      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.49       |
|    explained_variance   | 0.987      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0211    |
|    n_updates            | 4530       |
|    policy_gradient_loss | -0.0193    |
|    std                  | 0.0952     |
|    value_loss           | 0.00688    |
----------------------------------------
Eval num_timesteps=930000, episode_reward=3966.36 +/- 324.38
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 3.97e+03   |
| time/                   |            |
|    total_timesteps      | 930000     |
| train/                  |            |
|    approx_kl            | 0.14753518 |
|    clip_fraction        | 0.642      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.5        |
|    explained_variance   | 0.642      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00311   |
|    n_updates            | 4540       |
|    policy_gradient_loss | -0.0214    |
|    std                  | 0.0946     |
|    value_loss           | 0.00465    |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 966      |
|    ep_rew_mean     | 3.27e+03 |
| time/              |          |
|    fps             | 156      |
|    iterations      | 455      |
|    time_elapsed    | 5953     |
|    total_timesteps | 931840   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 966       |
|    ep_rew_mean          | 3.27e+03  |
| time/                   |           |
|    fps                  | 156       |
|    iterations           | 456       |
|    time_elapsed         | 5963      |
|    total_timesteps      | 933888    |
| train/                  |           |
|    approx_kl            | 0.1743102 |
|    clip_fraction        | 0.651     |
|    clip_range           | 0.2       |
|    entropy_loss         | 7.54      |
|    explained_variance   | 0.98      |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0201   |
|    n_updates            | 4550      |
|    policy_gradient_loss | -0.0179   |
|    std                  | 0.0944    |
|    value_loss           | 0.013     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 966        |
|    ep_rew_mean          | 3.26e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 457        |
|    time_elapsed         | 5972       |
|    total_timesteps      | 935936     |
| train/                  |            |
|    approx_kl            | 0.16060367 |
|    clip_fraction        | 0.657      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.54       |
|    explained_variance   | 0.98       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0408     |
|    n_updates            | 4560       |
|    policy_gradient_loss | -0.0147    |
|    std                  | 0.0946     |
|    value_loss           | 0.0133     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 966       |
|    ep_rew_mean          | 3.26e+03  |
| time/                   |           |
|    fps                  | 156       |
|    iterations           | 458       |
|    time_elapsed         | 5981      |
|    total_timesteps      | 937984    |
| train/                  |           |
|    approx_kl            | 0.1534012 |
|    clip_fraction        | 0.676     |
|    clip_range           | 0.2       |
|    entropy_loss         | 7.52      |
|    explained_variance   | 0.936     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0221   |
|    n_updates            | 4570      |
|    policy_gradient_loss | -0.0103   |
|    std                  | 0.0947    |
|    value_loss           | 0.0252    |
---------------------------------------
Eval num_timesteps=940000, episode_reward=3899.10 +/- 656.43
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 3.9e+03    |
| time/                   |            |
|    total_timesteps      | 940000     |
| train/                  |            |
|    approx_kl            | 0.17240869 |
|    clip_fraction        | 0.663      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.52       |
|    explained_variance   | 0.969      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0393    |
|    n_updates            | 4580       |
|    policy_gradient_loss | -0.0248    |
|    std                  | 0.0946     |
|    value_loss           | 0.00678    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 966      |
|    ep_rew_mean     | 3.28e+03 |
| time/              |          |
|    fps             | 156      |
|    iterations      | 459      |
|    time_elapsed    | 6011     |
|    total_timesteps | 940032   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 966       |
|    ep_rew_mean          | 3.26e+03  |
| time/                   |           |
|    fps                  | 156       |
|    iterations           | 460       |
|    time_elapsed         | 6021      |
|    total_timesteps      | 942080    |
| train/                  |           |
|    approx_kl            | 0.1512054 |
|    clip_fraction        | 0.644     |
|    clip_range           | 0.2       |
|    entropy_loss         | 7.53      |
|    explained_variance   | 0.982     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0203   |
|    n_updates            | 4590      |
|    policy_gradient_loss | -0.0209   |
|    std                  | 0.0944    |
|    value_loss           | 0.0145    |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 966        |
|    ep_rew_mean          | 3.27e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 461        |
|    time_elapsed         | 6030       |
|    total_timesteps      | 944128     |
| train/                  |            |
|    approx_kl            | 0.13313147 |
|    clip_fraction        | 0.63       |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.53       |
|    explained_variance   | 0.985      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.037     |
|    n_updates            | 4600       |
|    policy_gradient_loss | -0.0182    |
|    std                  | 0.0943     |
|    value_loss           | 0.0123     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 966        |
|    ep_rew_mean          | 3.3e+03    |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 462        |
|    time_elapsed         | 6040       |
|    total_timesteps      | 946176     |
| train/                  |            |
|    approx_kl            | 0.13976938 |
|    clip_fraction        | 0.631      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.53       |
|    explained_variance   | 0.613      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0797    |
|    n_updates            | 4610       |
|    policy_gradient_loss | -0.0211    |
|    std                  | 0.0946     |
|    value_loss           | 0.00473    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 966        |
|    ep_rew_mean          | 3.31e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 463        |
|    time_elapsed         | 6049       |
|    total_timesteps      | 948224     |
| train/                  |            |
|    approx_kl            | 0.13612226 |
|    clip_fraction        | 0.643      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.53       |
|    explained_variance   | 0.639      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.044     |
|    n_updates            | 4620       |
|    policy_gradient_loss | -0.0195    |
|    std                  | 0.0945     |
|    value_loss           | 0.00318    |
----------------------------------------
Eval num_timesteps=950000, episode_reward=4179.34 +/- 96.42
Episode length: 1000.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 1e+03     |
|    mean_reward          | 4.18e+03  |
| time/                   |           |
|    total_timesteps      | 950000    |
| train/                  |           |
|    approx_kl            | 0.1644506 |
|    clip_fraction        | 0.647     |
|    clip_range           | 0.2       |
|    entropy_loss         | 7.53      |
|    explained_variance   | 0.629     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.02     |
|    n_updates            | 4630      |
|    policy_gradient_loss | -0.0196   |
|    std                  | 0.0944    |
|    value_loss           | 0.00403   |
---------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 966      |
|    ep_rew_mean     | 3.32e+03 |
| time/              |          |
|    fps             | 156      |
|    iterations      | 464      |
|    time_elapsed    | 6079     |
|    total_timesteps | 950272   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 966        |
|    ep_rew_mean          | 3.36e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 465        |
|    time_elapsed         | 6088       |
|    total_timesteps      | 952320     |
| train/                  |            |
|    approx_kl            | 0.16014045 |
|    clip_fraction        | 0.636      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.54       |
|    explained_variance   | 0.702      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0145    |
|    n_updates            | 4640       |
|    policy_gradient_loss | -0.0218    |
|    std                  | 0.0944     |
|    value_loss           | 0.0039     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 976       |
|    ep_rew_mean          | 3.4e+03   |
| time/                   |           |
|    fps                  | 156       |
|    iterations           | 466       |
|    time_elapsed         | 6097      |
|    total_timesteps      | 954368    |
| train/                  |           |
|    approx_kl            | 0.1664376 |
|    clip_fraction        | 0.645     |
|    clip_range           | 0.2       |
|    entropy_loss         | 7.53      |
|    explained_variance   | 0.635     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0502   |
|    n_updates            | 4650      |
|    policy_gradient_loss | -0.0151   |
|    std                  | 0.0946    |
|    value_loss           | 0.00499   |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 976        |
|    ep_rew_mean          | 3.38e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 467        |
|    time_elapsed         | 6107       |
|    total_timesteps      | 956416     |
| train/                  |            |
|    approx_kl            | 0.20528227 |
|    clip_fraction        | 0.662      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.53       |
|    explained_variance   | 0.599      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0324    |
|    n_updates            | 4660       |
|    policy_gradient_loss | -0.0177    |
|    std                  | 0.0946     |
|    value_loss           | 0.0039     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 976        |
|    ep_rew_mean          | 3.37e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 468        |
|    time_elapsed         | 6116       |
|    total_timesteps      | 958464     |
| train/                  |            |
|    approx_kl            | 0.22124231 |
|    clip_fraction        | 0.664      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.54       |
|    explained_variance   | 0.95       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0171    |
|    n_updates            | 4670       |
|    policy_gradient_loss | -0.0142    |
|    std                  | 0.0943     |
|    value_loss           | 0.0143     |
----------------------------------------
Eval num_timesteps=960000, episode_reward=3926.62 +/- 884.55
Episode length: 968.16 +/- 155.98
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 968       |
|    mean_reward          | 3.93e+03  |
| time/                   |           |
|    total_timesteps      | 960000    |
| train/                  |           |
|    approx_kl            | 0.1652785 |
|    clip_fraction        | 0.635     |
|    clip_range           | 0.2       |
|    entropy_loss         | 7.55      |
|    explained_variance   | 0.987     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.00619  |
|    n_updates            | 4680      |
|    policy_gradient_loss | -0.0136   |
|    std                  | 0.0942    |
|    value_loss           | 0.00966   |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 976      |
|    ep_rew_mean     | 3.39e+03 |
| time/              |          |
|    fps             | 156      |
|    iterations      | 469      |
|    time_elapsed    | 6146     |
|    total_timesteps | 960512   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 979        |
|    ep_rew_mean          | 3.4e+03    |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 470        |
|    time_elapsed         | 6155       |
|    total_timesteps      | 962560     |
| train/                  |            |
|    approx_kl            | 0.17205901 |
|    clip_fraction        | 0.665      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.56       |
|    explained_variance   | 0.963      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0444    |
|    n_updates            | 4690       |
|    policy_gradient_loss | -0.0102    |
|    std                  | 0.0942     |
|    value_loss           | 0.0164     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 979       |
|    ep_rew_mean          | 3.41e+03  |
| time/                   |           |
|    fps                  | 156       |
|    iterations           | 471       |
|    time_elapsed         | 6164      |
|    total_timesteps      | 964608    |
| train/                  |           |
|    approx_kl            | 0.2116986 |
|    clip_fraction        | 0.676     |
|    clip_range           | 0.2       |
|    entropy_loss         | 7.57      |
|    explained_variance   | 0.161     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0378   |
|    n_updates            | 4700      |
|    policy_gradient_loss | -0.0209   |
|    std                  | 0.0941    |
|    value_loss           | 0.00429   |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 984       |
|    ep_rew_mean          | 3.42e+03  |
| time/                   |           |
|    fps                  | 156       |
|    iterations           | 472       |
|    time_elapsed         | 6174      |
|    total_timesteps      | 966656    |
| train/                  |           |
|    approx_kl            | 0.1625709 |
|    clip_fraction        | 0.653     |
|    clip_range           | 0.2       |
|    entropy_loss         | 7.56      |
|    explained_variance   | 0.606     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.042    |
|    n_updates            | 4710      |
|    policy_gradient_loss | -0.0163   |
|    std                  | 0.0942    |
|    value_loss           | 0.00341   |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 984        |
|    ep_rew_mean          | 3.39e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 473        |
|    time_elapsed         | 6183       |
|    total_timesteps      | 968704     |
| train/                  |            |
|    approx_kl            | 0.15630938 |
|    clip_fraction        | 0.629      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.58       |
|    explained_variance   | 0.965      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0486    |
|    n_updates            | 4720       |
|    policy_gradient_loss | -0.0177    |
|    std                  | 0.0936     |
|    value_loss           | 0.029      |
----------------------------------------
Eval num_timesteps=970000, episode_reward=3852.59 +/- 937.38
Episode length: 955.96 +/- 171.42
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 956       |
|    mean_reward          | 3.85e+03  |
| time/                   |           |
|    total_timesteps      | 970000    |
| train/                  |           |
|    approx_kl            | 0.1605441 |
|    clip_fraction        | 0.648     |
|    clip_range           | 0.2       |
|    entropy_loss         | 7.62      |
|    explained_variance   | 0.975     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0634   |
|    n_updates            | 4730      |
|    policy_gradient_loss | -0.02     |
|    std                  | 0.0934    |
|    value_loss           | 0.00783   |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 984      |
|    ep_rew_mean     | 3.4e+03  |
| time/              |          |
|    fps             | 156      |
|    iterations      | 474      |
|    time_elapsed    | 6213     |
|    total_timesteps | 970752   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 993        |
|    ep_rew_mean          | 3.43e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 475        |
|    time_elapsed         | 6222       |
|    total_timesteps      | 972800     |
| train/                  |            |
|    approx_kl            | 0.15429102 |
|    clip_fraction        | 0.657      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.62       |
|    explained_variance   | 0.698      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0702    |
|    n_updates            | 4740       |
|    policy_gradient_loss | -0.0227    |
|    std                  | 0.0934     |
|    value_loss           | 0.00428    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 989        |
|    ep_rew_mean          | 3.42e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 476        |
|    time_elapsed         | 6232       |
|    total_timesteps      | 974848     |
| train/                  |            |
|    approx_kl            | 0.14962876 |
|    clip_fraction        | 0.626      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.62       |
|    explained_variance   | 0.987      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0547    |
|    n_updates            | 4750       |
|    policy_gradient_loss | -0.0217    |
|    std                  | 0.0933     |
|    value_loss           | 0.0111     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 996        |
|    ep_rew_mean          | 3.45e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 477        |
|    time_elapsed         | 6241       |
|    total_timesteps      | 976896     |
| train/                  |            |
|    approx_kl            | 0.15517844 |
|    clip_fraction        | 0.671      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.62       |
|    explained_variance   | 0.955      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00113    |
|    n_updates            | 4760       |
|    policy_gradient_loss | -0.0149    |
|    std                  | 0.0934     |
|    value_loss           | 0.019      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 996        |
|    ep_rew_mean          | 3.43e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 478        |
|    time_elapsed         | 6250       |
|    total_timesteps      | 978944     |
| train/                  |            |
|    approx_kl            | 0.16748722 |
|    clip_fraction        | 0.662      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.6        |
|    explained_variance   | 0.446      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0291    |
|    n_updates            | 4770       |
|    policy_gradient_loss | -0.0126    |
|    std                  | 0.0939     |
|    value_loss           | 0.00948    |
----------------------------------------
Eval num_timesteps=980000, episode_reward=4068.69 +/- 294.71
Episode length: 1000.00 +/- 0.00
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 1e+03    |
|    mean_reward          | 4.07e+03 |
| time/                   |          |
|    total_timesteps      | 980000   |
| train/                  |          |
|    approx_kl            | 0.178142 |
|    clip_fraction        | 0.634    |
|    clip_range           | 0.2      |
|    entropy_loss         | 7.59     |
|    explained_variance   | 0.983    |
|    learning_rate        | 0.0003   |
|    loss                 | -0.0166  |
|    n_updates            | 4780     |
|    policy_gradient_loss | -0.0176  |
|    std                  | 0.0937   |
|    value_loss           | 0.0143   |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 996      |
|    ep_rew_mean     | 3.44e+03 |
| time/              |          |
|    fps             | 156      |
|    iterations      | 479      |
|    time_elapsed    | 6280     |
|    total_timesteps | 980992   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 996        |
|    ep_rew_mean          | 3.45e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 480        |
|    time_elapsed         | 6289       |
|    total_timesteps      | 983040     |
| train/                  |            |
|    approx_kl            | 0.16523497 |
|    clip_fraction        | 0.668      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.59       |
|    explained_variance   | 0.403      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0546    |
|    n_updates            | 4790       |
|    policy_gradient_loss | -0.0164    |
|    std                  | 0.0938     |
|    value_loss           | 0.00655    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 996        |
|    ep_rew_mean          | 3.45e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 481        |
|    time_elapsed         | 6298       |
|    total_timesteps      | 985088     |
| train/                  |            |
|    approx_kl            | 0.14037612 |
|    clip_fraction        | 0.644      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.57       |
|    explained_variance   | 0.661      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0516    |
|    n_updates            | 4800       |
|    policy_gradient_loss | -0.0305    |
|    std                  | 0.094      |
|    value_loss           | 0.00605    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 996        |
|    ep_rew_mean          | 3.45e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 482        |
|    time_elapsed         | 6308       |
|    total_timesteps      | 987136     |
| train/                  |            |
|    approx_kl            | 0.12534928 |
|    clip_fraction        | 0.637      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.55       |
|    explained_variance   | 0.728      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0275    |
|    n_updates            | 4810       |
|    policy_gradient_loss | -0.0201    |
|    std                  | 0.0943     |
|    value_loss           | 0.00394    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 996        |
|    ep_rew_mean          | 3.47e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 483        |
|    time_elapsed         | 6317       |
|    total_timesteps      | 989184     |
| train/                  |            |
|    approx_kl            | 0.14658496 |
|    clip_fraction        | 0.645      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.53       |
|    explained_variance   | 0.685      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0341    |
|    n_updates            | 4820       |
|    policy_gradient_loss | -0.0244    |
|    std                  | 0.0945     |
|    value_loss           | 0.00425    |
----------------------------------------
Eval num_timesteps=990000, episode_reward=3831.61 +/- 737.87
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 3.83e+03   |
| time/                   |            |
|    total_timesteps      | 990000     |
| train/                  |            |
|    approx_kl            | 0.14829336 |
|    clip_fraction        | 0.652      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.53       |
|    explained_variance   | 0.624      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0694    |
|    n_updates            | 4830       |
|    policy_gradient_loss | -0.0269    |
|    std                  | 0.0945     |
|    value_loss           | 0.00358    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 996      |
|    ep_rew_mean     | 3.47e+03 |
| time/              |          |
|    fps             | 156      |
|    iterations      | 484      |
|    time_elapsed    | 6347     |
|    total_timesteps | 991232   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 996       |
|    ep_rew_mean          | 3.49e+03  |
| time/                   |           |
|    fps                  | 156       |
|    iterations           | 485       |
|    time_elapsed         | 6356      |
|    total_timesteps      | 993280    |
| train/                  |           |
|    approx_kl            | 0.1380647 |
|    clip_fraction        | 0.631     |
|    clip_range           | 0.2       |
|    entropy_loss         | 7.55      |
|    explained_variance   | 0.643     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0505   |
|    n_updates            | 4840      |
|    policy_gradient_loss | -0.0264   |
|    std                  | 0.0942    |
|    value_loss           | 0.005     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 996        |
|    ep_rew_mean          | 3.49e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 486        |
|    time_elapsed         | 6365       |
|    total_timesteps      | 995328     |
| train/                  |            |
|    approx_kl            | 0.13883564 |
|    clip_fraction        | 0.642      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.56       |
|    explained_variance   | 0.671      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0555    |
|    n_updates            | 4850       |
|    policy_gradient_loss | -0.0259    |
|    std                  | 0.0939     |
|    value_loss           | 0.00433    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 993        |
|    ep_rew_mean          | 3.49e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 487        |
|    time_elapsed         | 6374       |
|    total_timesteps      | 997376     |
| train/                  |            |
|    approx_kl            | 0.15949053 |
|    clip_fraction        | 0.649      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.59       |
|    explained_variance   | 0.616      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0603    |
|    n_updates            | 4860       |
|    policy_gradient_loss | -0.0282    |
|    std                  | 0.0934     |
|    value_loss           | 0.00538    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 993        |
|    ep_rew_mean          | 3.49e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 488        |
|    time_elapsed         | 6384       |
|    total_timesteps      | 999424     |
| train/                  |            |
|    approx_kl            | 0.15094459 |
|    clip_fraction        | 0.632      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.62       |
|    explained_variance   | 0.421      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0149    |
|    n_updates            | 4870       |
|    policy_gradient_loss | -0.0247    |
|    std                  | 0.0934     |
|    value_loss           | 0.02       |
----------------------------------------
Eval num_timesteps=1000000, episode_reward=3706.15 +/- 1005.99
Episode length: 1000.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 1e+03     |
|    mean_reward          | 3.71e+03  |
| time/                   |           |
|    total_timesteps      | 1000000   |
| train/                  |           |
|    approx_kl            | 0.1686896 |
|    clip_fraction        | 0.653     |
|    clip_range           | 0.2       |
|    entropy_loss         | 7.65      |
|    explained_variance   | 0.503     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0724   |
|    n_updates            | 4880      |
|    policy_gradient_loss | -0.0268   |
|    std                  | 0.0929    |
|    value_loss           | 0.00695   |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 993      |
|    ep_rew_mean     | 3.49e+03 |
| time/              |          |
|    fps             | 156      |
|    iterations      | 489      |
|    time_elapsed    | 6413     |
|    total_timesteps | 1001472  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 993        |
|    ep_rew_mean          | 3.49e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 490        |
|    time_elapsed         | 6423       |
|    total_timesteps      | 1003520    |
| train/                  |            |
|    approx_kl            | 0.17079827 |
|    clip_fraction        | 0.652      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.66       |
|    explained_variance   | 0.57       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0544    |
|    n_updates            | 4890       |
|    policy_gradient_loss | -0.0275    |
|    std                  | 0.0931     |
|    value_loss           | 0.0047     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 993        |
|    ep_rew_mean          | 3.51e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 491        |
|    time_elapsed         | 6432       |
|    total_timesteps      | 1005568    |
| train/                  |            |
|    approx_kl            | 0.15423253 |
|    clip_fraction        | 0.656      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.64       |
|    explained_variance   | 0.579      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.085     |
|    n_updates            | 4900       |
|    policy_gradient_loss | -0.0237    |
|    std                  | 0.0934     |
|    value_loss           | 0.00723    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 993        |
|    ep_rew_mean          | 3.51e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 492        |
|    time_elapsed         | 6441       |
|    total_timesteps      | 1007616    |
| train/                  |            |
|    approx_kl            | 0.13482966 |
|    clip_fraction        | 0.641      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.62       |
|    explained_variance   | 0.518      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0709    |
|    n_updates            | 4910       |
|    policy_gradient_loss | -0.0166    |
|    std                  | 0.0933     |
|    value_loss           | 0.00629    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 993        |
|    ep_rew_mean          | 3.5e+03    |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 493        |
|    time_elapsed         | 6451       |
|    total_timesteps      | 1009664    |
| train/                  |            |
|    approx_kl            | 0.14982972 |
|    clip_fraction        | 0.628      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.62       |
|    explained_variance   | 0.962      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0422    |
|    n_updates            | 4920       |
|    policy_gradient_loss | -0.0229    |
|    std                  | 0.0934     |
|    value_loss           | 0.0186     |
----------------------------------------
Eval num_timesteps=1010000, episode_reward=3474.07 +/- 1186.84
Episode length: 928.68 +/- 240.21
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 929        |
|    mean_reward          | 3.47e+03   |
| time/                   |            |
|    total_timesteps      | 1010000    |
| train/                  |            |
|    approx_kl            | 0.16136783 |
|    clip_fraction        | 0.655      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.6        |
|    explained_variance   | 0.965      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.021     |
|    n_updates            | 4930       |
|    policy_gradient_loss | -0.0214    |
|    std                  | 0.0938     |
|    value_loss           | 0.0238     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 993      |
|    ep_rew_mean     | 3.5e+03  |
| time/              |          |
|    fps             | 156      |
|    iterations      | 494      |
|    time_elapsed    | 6484     |
|    total_timesteps | 1011712  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 986        |
|    ep_rew_mean          | 3.51e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 495        |
|    time_elapsed         | 6495       |
|    total_timesteps      | 1013760    |
| train/                  |            |
|    approx_kl            | 0.14011168 |
|    clip_fraction        | 0.658      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.57       |
|    explained_variance   | 0.404      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0456    |
|    n_updates            | 4940       |
|    policy_gradient_loss | -0.0209    |
|    std                  | 0.094      |
|    value_loss           | 0.00673    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 986        |
|    ep_rew_mean          | 3.51e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 496        |
|    time_elapsed         | 6504       |
|    total_timesteps      | 1015808    |
| train/                  |            |
|    approx_kl            | 0.16275243 |
|    clip_fraction        | 0.654      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.58       |
|    explained_variance   | 0.528      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.000983   |
|    n_updates            | 4950       |
|    policy_gradient_loss | -0.0174    |
|    std                  | 0.0938     |
|    value_loss           | 0.027      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 986        |
|    ep_rew_mean          | 3.51e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 497        |
|    time_elapsed         | 6514       |
|    total_timesteps      | 1017856    |
| train/                  |            |
|    approx_kl            | 0.14239001 |
|    clip_fraction        | 0.642      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.59       |
|    explained_variance   | 0.56       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.099     |
|    n_updates            | 4960       |
|    policy_gradient_loss | -0.0266    |
|    std                  | 0.0939     |
|    value_loss           | 0.00512    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 986        |
|    ep_rew_mean          | 3.51e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 498        |
|    time_elapsed         | 6523       |
|    total_timesteps      | 1019904    |
| train/                  |            |
|    approx_kl            | 0.17096236 |
|    clip_fraction        | 0.657      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.58       |
|    explained_variance   | 0.513      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0471    |
|    n_updates            | 4970       |
|    policy_gradient_loss | -0.0245    |
|    std                  | 0.0939     |
|    value_loss           | 0.0061     |
----------------------------------------
Eval num_timesteps=1020000, episode_reward=4092.97 +/- 570.27
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 4.09e+03   |
| time/                   |            |
|    total_timesteps      | 1020000    |
| train/                  |            |
|    approx_kl            | 0.17308566 |
|    clip_fraction        | 0.655      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.57       |
|    explained_variance   | 0.625      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0789    |
|    n_updates            | 4980       |
|    policy_gradient_loss | -0.0255    |
|    std                  | 0.0941     |
|    value_loss           | 0.00656    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 986      |
|    ep_rew_mean     | 3.51e+03 |
| time/              |          |
|    fps             | 155      |
|    iterations      | 499      |
|    time_elapsed    | 6552     |
|    total_timesteps | 1021952  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 985        |
|    ep_rew_mean          | 3.54e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 500        |
|    time_elapsed         | 6562       |
|    total_timesteps      | 1024000    |
| train/                  |            |
|    approx_kl            | 0.14178304 |
|    clip_fraction        | 0.646      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.56       |
|    explained_variance   | 0.59       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0782    |
|    n_updates            | 4990       |
|    policy_gradient_loss | -0.0236    |
|    std                  | 0.0943     |
|    value_loss           | 0.00569    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 985        |
|    ep_rew_mean          | 3.56e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 501        |
|    time_elapsed         | 6571       |
|    total_timesteps      | 1026048    |
| train/                  |            |
|    approx_kl            | 0.14589654 |
|    clip_fraction        | 0.637      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.55       |
|    explained_variance   | 0.455      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.061     |
|    n_updates            | 5000       |
|    policy_gradient_loss | -0.0248    |
|    std                  | 0.0941     |
|    value_loss           | 0.0143     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 976        |
|    ep_rew_mean          | 3.51e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 502        |
|    time_elapsed         | 6581       |
|    total_timesteps      | 1028096    |
| train/                  |            |
|    approx_kl            | 0.14629322 |
|    clip_fraction        | 0.649      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.56       |
|    explained_variance   | 0.491      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0392    |
|    n_updates            | 5010       |
|    policy_gradient_loss | -0.0287    |
|    std                  | 0.0943     |
|    value_loss           | 0.00407    |
----------------------------------------
Eval num_timesteps=1030000, episode_reward=4051.74 +/- 696.62
Episode length: 999.04 +/- 4.70
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 999        |
|    mean_reward          | 4.05e+03   |
| time/                   |            |
|    total_timesteps      | 1030000    |
| train/                  |            |
|    approx_kl            | 0.15325029 |
|    clip_fraction        | 0.649      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.53       |
|    explained_variance   | 0.964      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0211    |
|    n_updates            | 5020       |
|    policy_gradient_loss | -0.0158    |
|    std                  | 0.0945     |
|    value_loss           | 0.0281     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 976      |
|    ep_rew_mean     | 3.53e+03 |
| time/              |          |
|    fps             | 155      |
|    iterations      | 503      |
|    time_elapsed    | 6610     |
|    total_timesteps | 1030144  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 972        |
|    ep_rew_mean          | 3.51e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 504        |
|    time_elapsed         | 6620       |
|    total_timesteps      | 1032192    |
| train/                  |            |
|    approx_kl            | 0.17231219 |
|    clip_fraction        | 0.655      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.56       |
|    explained_variance   | 0.958      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0246    |
|    n_updates            | 5030       |
|    policy_gradient_loss | -0.0203    |
|    std                  | 0.0939     |
|    value_loss           | 0.0119     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 972        |
|    ep_rew_mean          | 3.52e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 505        |
|    time_elapsed         | 6629       |
|    total_timesteps      | 1034240    |
| train/                  |            |
|    approx_kl            | 0.14571741 |
|    clip_fraction        | 0.646      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.6        |
|    explained_variance   | 0.96       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0227    |
|    n_updates            | 5040       |
|    policy_gradient_loss | -0.0154    |
|    std                  | 0.0937     |
|    value_loss           | 0.0246     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 972        |
|    ep_rew_mean          | 3.52e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 506        |
|    time_elapsed         | 6638       |
|    total_timesteps      | 1036288    |
| train/                  |            |
|    approx_kl            | 0.18060577 |
|    clip_fraction        | 0.644      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.61       |
|    explained_variance   | 0.064      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0132    |
|    n_updates            | 5050       |
|    policy_gradient_loss | -0.0241    |
|    std                  | 0.0936     |
|    value_loss           | 0.006      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 972        |
|    ep_rew_mean          | 3.55e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 507        |
|    time_elapsed         | 6648       |
|    total_timesteps      | 1038336    |
| train/                  |            |
|    approx_kl            | 0.15577146 |
|    clip_fraction        | 0.644      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.63       |
|    explained_variance   | 0.597      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0153    |
|    n_updates            | 5060       |
|    policy_gradient_loss | -0.0308    |
|    std                  | 0.0931     |
|    value_loss           | 0.00378    |
----------------------------------------
Eval num_timesteps=1040000, episode_reward=4124.68 +/- 507.86
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 4.12e+03   |
| time/                   |            |
|    total_timesteps      | 1040000    |
| train/                  |            |
|    approx_kl            | 0.17136586 |
|    clip_fraction        | 0.661      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.67       |
|    explained_variance   | 0.958      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0449    |
|    n_updates            | 5070       |
|    policy_gradient_loss | -0.018     |
|    std                  | 0.0927     |
|    value_loss           | 0.0122     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 972      |
|    ep_rew_mean     | 3.55e+03 |
| time/              |          |
|    fps             | 155      |
|    iterations      | 508      |
|    time_elapsed    | 6677     |
|    total_timesteps | 1040384  |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 972       |
|    ep_rew_mean          | 3.54e+03  |
| time/                   |           |
|    fps                  | 155       |
|    iterations           | 509       |
|    time_elapsed         | 6687      |
|    total_timesteps      | 1042432   |
| train/                  |           |
|    approx_kl            | 0.1749095 |
|    clip_fraction        | 0.657     |
|    clip_range           | 0.2       |
|    entropy_loss         | 7.69      |
|    explained_variance   | 0.924     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.046    |
|    n_updates            | 5080      |
|    policy_gradient_loss | -0.0174   |
|    std                  | 0.0926    |
|    value_loss           | 0.0137    |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 972        |
|    ep_rew_mean          | 3.51e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 510        |
|    time_elapsed         | 6696       |
|    total_timesteps      | 1044480    |
| train/                  |            |
|    approx_kl            | 0.15916845 |
|    clip_fraction        | 0.676      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.69       |
|    explained_variance   | 0.976      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.027     |
|    n_updates            | 5090       |
|    policy_gradient_loss | -0.0118    |
|    std                  | 0.0928     |
|    value_loss           | 0.0121     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 972       |
|    ep_rew_mean          | 3.52e+03  |
| time/                   |           |
|    fps                  | 156       |
|    iterations           | 511       |
|    time_elapsed         | 6706      |
|    total_timesteps      | 1046528   |
| train/                  |           |
|    approx_kl            | 0.1588344 |
|    clip_fraction        | 0.661     |
|    clip_range           | 0.2       |
|    entropy_loss         | 7.7       |
|    explained_variance   | 0.982     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0376   |
|    n_updates            | 5100      |
|    policy_gradient_loss | -0.0116   |
|    std                  | 0.0925    |
|    value_loss           | 0.0153    |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 972        |
|    ep_rew_mean          | 3.51e+03   |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 512        |
|    time_elapsed         | 6715       |
|    total_timesteps      | 1048576    |
| train/                  |            |
|    approx_kl            | 0.20088825 |
|    clip_fraction        | 0.675      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.72       |
|    explained_variance   | -0.167     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0173    |
|    n_updates            | 5110       |
|    policy_gradient_loss | -0.0184    |
|    std                  | 0.0923     |
|    value_loss           | 0.0073     |
----------------------------------------
Eval num_timesteps=1050000, episode_reward=4041.70 +/- 608.11
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 4.04e+03   |
| time/                   |            |
|    total_timesteps      | 1050000    |
| train/                  |            |
|    approx_kl            | 0.15465298 |
|    clip_fraction        | 0.639      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.72       |
|    explained_variance   | 0.613      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.118     |
|    n_updates            | 5120       |
|    policy_gradient_loss | -0.0188    |
|    std                  | 0.0923     |
|    value_loss           | 0.00407    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 970      |
|    ep_rew_mean     | 3.51e+03 |
| time/              |          |
|    fps             | 155      |
|    iterations      | 513      |
|    time_elapsed    | 6745     |
|    total_timesteps | 1050624  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 970        |
|    ep_rew_mean          | 3.51e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 514        |
|    time_elapsed         | 6754       |
|    total_timesteps      | 1052672    |
| train/                  |            |
|    approx_kl            | 0.15677673 |
|    clip_fraction        | 0.661      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.74       |
|    explained_variance   | 0.416      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0425     |
|    n_updates            | 5130       |
|    policy_gradient_loss | -0.0125    |
|    std                  | 0.092      |
|    value_loss           | 0.0166     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 970        |
|    ep_rew_mean          | 3.55e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 515        |
|    time_elapsed         | 6763       |
|    total_timesteps      | 1054720    |
| train/                  |            |
|    approx_kl            | 0.16723739 |
|    clip_fraction        | 0.678      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.72       |
|    explained_variance   | 0.399      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0463    |
|    n_updates            | 5140       |
|    policy_gradient_loss | -0.02      |
|    std                  | 0.0925     |
|    value_loss           | 0.00416    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 970        |
|    ep_rew_mean          | 3.55e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 516        |
|    time_elapsed         | 6775       |
|    total_timesteps      | 1056768    |
| train/                  |            |
|    approx_kl            | 0.15926725 |
|    clip_fraction        | 0.64       |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.68       |
|    explained_variance   | 0.583      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0715    |
|    n_updates            | 5150       |
|    policy_gradient_loss | -0.0237    |
|    std                  | 0.0929     |
|    value_loss           | 0.00317    |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 970       |
|    ep_rew_mean          | 3.54e+03  |
| time/                   |           |
|    fps                  | 156       |
|    iterations           | 517       |
|    time_elapsed         | 6784      |
|    total_timesteps      | 1058816   |
| train/                  |           |
|    approx_kl            | 0.2026875 |
|    clip_fraction        | 0.655     |
|    clip_range           | 0.2       |
|    entropy_loss         | 7.68      |
|    explained_variance   | 0.903     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0152   |
|    n_updates            | 5160      |
|    policy_gradient_loss | -0.013    |
|    std                  | 0.0928    |
|    value_loss           | 0.0289    |
---------------------------------------
Eval num_timesteps=1060000, episode_reward=4184.64 +/- 327.27
Episode length: 986.92 +/- 64.08
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 987        |
|    mean_reward          | 4.18e+03   |
| time/                   |            |
|    total_timesteps      | 1060000    |
| train/                  |            |
|    approx_kl            | 0.16643718 |
|    clip_fraction        | 0.651      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.7        |
|    explained_variance   | 0.982      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0308    |
|    n_updates            | 5170       |
|    policy_gradient_loss | -0.0186    |
|    std                  | 0.0925     |
|    value_loss           | 0.0143     |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 970      |
|    ep_rew_mean     | 3.49e+03 |
| time/              |          |
|    fps             | 155      |
|    iterations      | 518      |
|    time_elapsed    | 6814     |
|    total_timesteps | 1060864  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 970        |
|    ep_rew_mean          | 3.49e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 519        |
|    time_elapsed         | 6826       |
|    total_timesteps      | 1062912    |
| train/                  |            |
|    approx_kl            | 0.14611433 |
|    clip_fraction        | 0.604      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.73       |
|    explained_variance   | 0.986      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0348    |
|    n_updates            | 5180       |
|    policy_gradient_loss | -0.0203    |
|    std                  | 0.0919     |
|    value_loss           | 0.00811    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 970        |
|    ep_rew_mean          | 3.5e+03    |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 520        |
|    time_elapsed         | 6835       |
|    total_timesteps      | 1064960    |
| train/                  |            |
|    approx_kl            | 0.17671075 |
|    clip_fraction        | 0.674      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.75       |
|    explained_variance   | 0.958      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0213    |
|    n_updates            | 5190       |
|    policy_gradient_loss | -0.0153    |
|    std                  | 0.092      |
|    value_loss           | 0.0287     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 970        |
|    ep_rew_mean          | 3.48e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 521        |
|    time_elapsed         | 6844       |
|    total_timesteps      | 1067008    |
| train/                  |            |
|    approx_kl            | 0.16560397 |
|    clip_fraction        | 0.653      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.76       |
|    explained_variance   | 0.962      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0592    |
|    n_updates            | 5200       |
|    policy_gradient_loss | -0.0184    |
|    std                  | 0.092      |
|    value_loss           | 0.00636    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 970        |
|    ep_rew_mean          | 3.48e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 522        |
|    time_elapsed         | 6854       |
|    total_timesteps      | 1069056    |
| train/                  |            |
|    approx_kl            | 0.14661121 |
|    clip_fraction        | 0.627      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.75       |
|    explained_variance   | 0.977      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0262    |
|    n_updates            | 5210       |
|    policy_gradient_loss | -0.0152    |
|    std                  | 0.0921     |
|    value_loss           | 0.0136     |
----------------------------------------
Eval num_timesteps=1070000, episode_reward=3495.86 +/- 1404.86
Episode length: 901.72 +/- 266.58
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 902      |
|    mean_reward          | 3.5e+03  |
| time/                   |          |
|    total_timesteps      | 1070000  |
| train/                  |          |
|    approx_kl            | 0.159901 |
|    clip_fraction        | 0.662    |
|    clip_range           | 0.2      |
|    entropy_loss         | 7.76     |
|    explained_variance   | 0.304    |
|    learning_rate        | 0.0003   |
|    loss                 | -0.0412  |
|    n_updates            | 5220     |
|    policy_gradient_loss | -0.0172  |
|    std                  | 0.0917   |
|    value_loss           | 0.00506  |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 970      |
|    ep_rew_mean     | 3.49e+03 |
| time/              |          |
|    fps             | 155      |
|    iterations      | 523      |
|    time_elapsed    | 6883     |
|    total_timesteps | 1071104  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 974        |
|    ep_rew_mean          | 3.51e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 524        |
|    time_elapsed         | 6892       |
|    total_timesteps      | 1073152    |
| train/                  |            |
|    approx_kl            | 0.22106344 |
|    clip_fraction        | 0.699      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.77       |
|    explained_variance   | 0.981      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0241    |
|    n_updates            | 5230       |
|    policy_gradient_loss | -0.01      |
|    std                  | 0.0919     |
|    value_loss           | 0.0124     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 974        |
|    ep_rew_mean          | 3.51e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 525        |
|    time_elapsed         | 6902       |
|    total_timesteps      | 1075200    |
| train/                  |            |
|    approx_kl            | 0.16223457 |
|    clip_fraction        | 0.658      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.8        |
|    explained_variance   | 0.961      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0259    |
|    n_updates            | 5240       |
|    policy_gradient_loss | -0.0172    |
|    std                  | 0.0913     |
|    value_loss           | 0.0126     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 974        |
|    ep_rew_mean          | 3.52e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 526        |
|    time_elapsed         | 6911       |
|    total_timesteps      | 1077248    |
| train/                  |            |
|    approx_kl            | 0.13861927 |
|    clip_fraction        | 0.644      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.83       |
|    explained_variance   | 0.983      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0213    |
|    n_updates            | 5250       |
|    policy_gradient_loss | -0.0146    |
|    std                  | 0.0911     |
|    value_loss           | 0.0155     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 965        |
|    ep_rew_mean          | 3.49e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 527        |
|    time_elapsed         | 6921       |
|    total_timesteps      | 1079296    |
| train/                  |            |
|    approx_kl            | 0.17935655 |
|    clip_fraction        | 0.658      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.84       |
|    explained_variance   | 0.522      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0273    |
|    n_updates            | 5260       |
|    policy_gradient_loss | -0.0195    |
|    std                  | 0.091      |
|    value_loss           | 0.0039     |
----------------------------------------
Eval num_timesteps=1080000, episode_reward=3886.26 +/- 1053.17
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 3.89e+03   |
| time/                   |            |
|    total_timesteps      | 1080000    |
| train/                  |            |
|    approx_kl            | 0.15100941 |
|    clip_fraction        | 0.666      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.83       |
|    explained_variance   | 0.502      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.000965   |
|    n_updates            | 5270       |
|    policy_gradient_loss | -0.00497   |
|    std                  | 0.0911     |
|    value_loss           | 0.0256     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 956      |
|    ep_rew_mean     | 3.46e+03 |
| time/              |          |
|    fps             | 155      |
|    iterations      | 528      |
|    time_elapsed    | 6950     |
|    total_timesteps | 1081344  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 956        |
|    ep_rew_mean          | 3.46e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 529        |
|    time_elapsed         | 6959       |
|    total_timesteps      | 1083392    |
| train/                  |            |
|    approx_kl            | 0.18491682 |
|    clip_fraction        | 0.66       |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.82       |
|    explained_variance   | 0.443      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0622     |
|    n_updates            | 5280       |
|    policy_gradient_loss | -0.0085    |
|    std                  | 0.0913     |
|    value_loss           | 0.0179     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 956        |
|    ep_rew_mean          | 3.47e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 530        |
|    time_elapsed         | 6969       |
|    total_timesteps      | 1085440    |
| train/                  |            |
|    approx_kl            | 0.15241686 |
|    clip_fraction        | 0.66       |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.83       |
|    explained_variance   | 0.43       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0633    |
|    n_updates            | 5290       |
|    policy_gradient_loss | -0.0203    |
|    std                  | 0.0911     |
|    value_loss           | 0.00647    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 956        |
|    ep_rew_mean          | 3.47e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 531        |
|    time_elapsed         | 6979       |
|    total_timesteps      | 1087488    |
| train/                  |            |
|    approx_kl            | 0.15376405 |
|    clip_fraction        | 0.651      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.84       |
|    explained_variance   | 0.591      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0426    |
|    n_updates            | 5300       |
|    policy_gradient_loss | -0.0216    |
|    std                  | 0.091      |
|    value_loss           | 0.00483    |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 956      |
|    ep_rew_mean          | 3.47e+03 |
| time/                   |          |
|    fps                  | 155      |
|    iterations           | 532      |
|    time_elapsed         | 6990     |
|    total_timesteps      | 1089536  |
| train/                  |          |
|    approx_kl            | 0.151749 |
|    clip_fraction        | 0.642    |
|    clip_range           | 0.2      |
|    entropy_loss         | 7.84     |
|    explained_variance   | 0.576    |
|    learning_rate        | 0.0003   |
|    loss                 | -0.0129  |
|    n_updates            | 5310     |
|    policy_gradient_loss | -0.0223  |
|    std                  | 0.0911   |
|    value_loss           | 0.00355  |
--------------------------------------
Eval num_timesteps=1090000, episode_reward=4149.23 +/- 486.65
Episode length: 980.20 +/- 97.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 980        |
|    mean_reward          | 4.15e+03   |
| time/                   |            |
|    total_timesteps      | 1090000    |
| train/                  |            |
|    approx_kl            | 0.14220569 |
|    clip_fraction        | 0.657      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.84       |
|    explained_variance   | 0.971      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0761    |
|    n_updates            | 5320       |
|    policy_gradient_loss | -0.0143    |
|    std                  | 0.0909     |
|    value_loss           | 0.0138     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 956      |
|    ep_rew_mean     | 3.48e+03 |
| time/              |          |
|    fps             | 155      |
|    iterations      | 533      |
|    time_elapsed    | 7019     |
|    total_timesteps | 1091584  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 959        |
|    ep_rew_mean          | 3.48e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 534        |
|    time_elapsed         | 7028       |
|    total_timesteps      | 1093632    |
| train/                  |            |
|    approx_kl            | 0.16709724 |
|    clip_fraction        | 0.671      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.85       |
|    explained_variance   | 0.275      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0116     |
|    n_updates            | 5330       |
|    policy_gradient_loss | -0.0125    |
|    std                  | 0.091      |
|    value_loss           | 0.00612    |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 959       |
|    ep_rew_mean          | 3.48e+03  |
| time/                   |           |
|    fps                  | 155       |
|    iterations           | 535       |
|    time_elapsed         | 7037      |
|    total_timesteps      | 1095680   |
| train/                  |           |
|    approx_kl            | 1.3575807 |
|    clip_fraction        | 0.673     |
|    clip_range           | 0.2       |
|    entropy_loss         | 7.86      |
|    explained_variance   | 0.661     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0801   |
|    n_updates            | 5340      |
|    policy_gradient_loss | -0.0538   |
|    std                  | 0.0903    |
|    value_loss           | 0.00484   |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 959        |
|    ep_rew_mean          | 3.49e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 536        |
|    time_elapsed         | 7047       |
|    total_timesteps      | 1097728    |
| train/                  |            |
|    approx_kl            | 0.18644994 |
|    clip_fraction        | 0.663      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.9        |
|    explained_variance   | 0.26       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0352    |
|    n_updates            | 5350       |
|    policy_gradient_loss | -0.019     |
|    std                  | 0.0905     |
|    value_loss           | 0.0041     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 959        |
|    ep_rew_mean          | 3.49e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 537        |
|    time_elapsed         | 7056       |
|    total_timesteps      | 1099776    |
| train/                  |            |
|    approx_kl            | 0.17342833 |
|    clip_fraction        | 0.649      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.87       |
|    explained_variance   | 0.607      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0497    |
|    n_updates            | 5360       |
|    policy_gradient_loss | -0.0239    |
|    std                  | 0.0907     |
|    value_loss           | 0.00471    |
----------------------------------------
Eval num_timesteps=1100000, episode_reward=4100.43 +/- 718.23
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 4.1e+03    |
| time/                   |            |
|    total_timesteps      | 1100000    |
| train/                  |            |
|    approx_kl            | 0.13720562 |
|    clip_fraction        | 0.64       |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.88       |
|    explained_variance   | 0.66       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0759    |
|    n_updates            | 5370       |
|    policy_gradient_loss | -0.0184    |
|    std                  | 0.0904     |
|    value_loss           | 0.00307    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 959      |
|    ep_rew_mean     | 3.5e+03  |
| time/              |          |
|    fps             | 155      |
|    iterations      | 538      |
|    time_elapsed    | 7086     |
|    total_timesteps | 1101824  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 959        |
|    ep_rew_mean          | 3.5e+03    |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 539        |
|    time_elapsed         | 7096       |
|    total_timesteps      | 1103872    |
| train/                  |            |
|    approx_kl            | 0.18890217 |
|    clip_fraction        | 0.67       |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.9        |
|    explained_variance   | 0.622      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0179    |
|    n_updates            | 5380       |
|    policy_gradient_loss | -0.0257    |
|    std                  | 0.0903     |
|    value_loss           | 0.00352    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 952        |
|    ep_rew_mean          | 3.48e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 540        |
|    time_elapsed         | 7105       |
|    total_timesteps      | 1105920    |
| train/                  |            |
|    approx_kl            | 0.15835303 |
|    clip_fraction        | 0.652      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.91       |
|    explained_variance   | 0.975      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.034     |
|    n_updates            | 5390       |
|    policy_gradient_loss | -0.0183    |
|    std                  | 0.0901     |
|    value_loss           | 0.0135     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 952        |
|    ep_rew_mean          | 3.49e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 541        |
|    time_elapsed         | 7114       |
|    total_timesteps      | 1107968    |
| train/                  |            |
|    approx_kl            | 0.17343943 |
|    clip_fraction        | 0.656      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.92       |
|    explained_variance   | 0.465      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0145    |
|    n_updates            | 5400       |
|    policy_gradient_loss | -0.00788   |
|    std                  | 0.09       |
|    value_loss           | 0.0232     |
----------------------------------------
Eval num_timesteps=1110000, episode_reward=4206.57 +/- 259.82
Episode length: 988.48 +/- 56.44
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 988        |
|    mean_reward          | 4.21e+03   |
| time/                   |            |
|    total_timesteps      | 1110000    |
| train/                  |            |
|    approx_kl            | 0.17266916 |
|    clip_fraction        | 0.666      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.91       |
|    explained_variance   | 0.209      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0565    |
|    n_updates            | 5410       |
|    policy_gradient_loss | -0.0158    |
|    std                  | 0.0903     |
|    value_loss           | 0.00408    |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 958      |
|    ep_rew_mean     | 3.52e+03 |
| time/              |          |
|    fps             | 155      |
|    iterations      | 542      |
|    time_elapsed    | 7144     |
|    total_timesteps | 1110016  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 958        |
|    ep_rew_mean          | 3.52e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 543        |
|    time_elapsed         | 7155       |
|    total_timesteps      | 1112064    |
| train/                  |            |
|    approx_kl            | 0.15624064 |
|    clip_fraction        | 0.652      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.9        |
|    explained_variance   | 0.595      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0715    |
|    n_updates            | 5420       |
|    policy_gradient_loss | -0.0211    |
|    std                  | 0.0903     |
|    value_loss           | 0.00384    |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 958       |
|    ep_rew_mean          | 3.52e+03  |
| time/                   |           |
|    fps                  | 155       |
|    iterations           | 544       |
|    time_elapsed         | 7165      |
|    total_timesteps      | 1114112   |
| train/                  |           |
|    approx_kl            | 0.1605828 |
|    clip_fraction        | 0.645     |
|    clip_range           | 0.2       |
|    entropy_loss         | 7.9       |
|    explained_variance   | 0.949     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0366   |
|    n_updates            | 5430      |
|    policy_gradient_loss | -0.0161   |
|    std                  | 0.0902    |
|    value_loss           | 0.00968   |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 958        |
|    ep_rew_mean          | 3.53e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 545        |
|    time_elapsed         | 7174       |
|    total_timesteps      | 1116160    |
| train/                  |            |
|    approx_kl            | 0.17194256 |
|    clip_fraction        | 0.662      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.89       |
|    explained_variance   | 0.266      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0706    |
|    n_updates            | 5440       |
|    policy_gradient_loss | -0.0228    |
|    std                  | 0.0906     |
|    value_loss           | 0.005      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 958        |
|    ep_rew_mean          | 3.5e+03    |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 546        |
|    time_elapsed         | 7183       |
|    total_timesteps      | 1118208    |
| train/                  |            |
|    approx_kl            | 0.17637059 |
|    clip_fraction        | 0.669      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.87       |
|    explained_variance   | 0.98       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0426    |
|    n_updates            | 5450       |
|    policy_gradient_loss | -0.0157    |
|    std                  | 0.0905     |
|    value_loss           | 0.0131     |
----------------------------------------
Eval num_timesteps=1120000, episode_reward=3895.05 +/- 831.45
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 3.9e+03    |
| time/                   |            |
|    total_timesteps      | 1120000    |
| train/                  |            |
|    approx_kl            | 0.17750387 |
|    clip_fraction        | 0.647      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.91       |
|    explained_variance   | 0.976      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0155    |
|    n_updates            | 5460       |
|    policy_gradient_loss | -0.0171    |
|    std                  | 0.0899     |
|    value_loss           | 0.0125     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 959      |
|    ep_rew_mean     | 3.5e+03  |
| time/              |          |
|    fps             | 155      |
|    iterations      | 547      |
|    time_elapsed    | 7213     |
|    total_timesteps | 1120256  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 959        |
|    ep_rew_mean          | 3.5e+03    |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 548        |
|    time_elapsed         | 7222       |
|    total_timesteps      | 1122304    |
| train/                  |            |
|    approx_kl            | 0.17367928 |
|    clip_fraction        | 0.682      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.93       |
|    explained_variance   | 0.26       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0476    |
|    n_updates            | 5470       |
|    policy_gradient_loss | -0.0252    |
|    std                  | 0.0901     |
|    value_loss           | 0.0051     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 963        |
|    ep_rew_mean          | 3.54e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 549        |
|    time_elapsed         | 7231       |
|    total_timesteps      | 1124352    |
| train/                  |            |
|    approx_kl            | 0.16820943 |
|    clip_fraction        | 0.669      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.93       |
|    explained_variance   | 0.57       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0718    |
|    n_updates            | 5480       |
|    policy_gradient_loss | -0.0226    |
|    std                  | 0.0899     |
|    value_loss           | 0.00422    |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 963       |
|    ep_rew_mean          | 3.55e+03  |
| time/                   |           |
|    fps                  | 155       |
|    iterations           | 550       |
|    time_elapsed         | 7241      |
|    total_timesteps      | 1126400   |
| train/                  |           |
|    approx_kl            | 0.1757336 |
|    clip_fraction        | 0.661     |
|    clip_range           | 0.2       |
|    entropy_loss         | 7.96      |
|    explained_variance   | 0.444     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0338   |
|    n_updates            | 5490      |
|    policy_gradient_loss | -0.0145   |
|    std                  | 0.0894    |
|    value_loss           | 0.0211    |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 967        |
|    ep_rew_mean          | 3.59e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 551        |
|    time_elapsed         | 7250       |
|    total_timesteps      | 1128448    |
| train/                  |            |
|    approx_kl            | 0.19050705 |
|    clip_fraction        | 0.664      |
|    clip_range           | 0.2        |
|    entropy_loss         | 7.98       |
|    explained_variance   | 0.517      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0727    |
|    n_updates            | 5500       |
|    policy_gradient_loss | -0.0179    |
|    std                  | 0.0892     |
|    value_loss           | 0.00435    |
----------------------------------------
Eval num_timesteps=1130000, episode_reward=4008.30 +/- 792.74
Episode length: 974.44 +/- 125.22
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 974        |
|    mean_reward          | 4.01e+03   |
| time/                   |            |
|    total_timesteps      | 1130000    |
| train/                  |            |
|    approx_kl            | 0.15709747 |
|    clip_fraction        | 0.65       |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.01       |
|    explained_variance   | 0.715      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0621    |
|    n_updates            | 5510       |
|    policy_gradient_loss | -0.0285    |
|    std                  | 0.0889     |
|    value_loss           | 0.00343    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 967      |
|    ep_rew_mean     | 3.59e+03 |
| time/              |          |
|    fps             | 155      |
|    iterations      | 552      |
|    time_elapsed    | 7279     |
|    total_timesteps | 1130496  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 967        |
|    ep_rew_mean          | 3.59e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 553        |
|    time_elapsed         | 7289       |
|    total_timesteps      | 1132544    |
| train/                  |            |
|    approx_kl            | 0.16183479 |
|    clip_fraction        | 0.653      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.01       |
|    explained_variance   | 0.667      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0452    |
|    n_updates            | 5520       |
|    policy_gradient_loss | -0.0228    |
|    std                  | 0.0891     |
|    value_loss           | 0.00307    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 967        |
|    ep_rew_mean          | 3.57e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 554        |
|    time_elapsed         | 7298       |
|    total_timesteps      | 1134592    |
| train/                  |            |
|    approx_kl            | 0.13990569 |
|    clip_fraction        | 0.641      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8          |
|    explained_variance   | 0.958      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.05      |
|    n_updates            | 5530       |
|    policy_gradient_loss | -0.0183    |
|    std                  | 0.0891     |
|    value_loss           | 0.0123     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 967        |
|    ep_rew_mean          | 3.58e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 555        |
|    time_elapsed         | 7307       |
|    total_timesteps      | 1136640    |
| train/                  |            |
|    approx_kl            | 0.21865667 |
|    clip_fraction        | 0.696      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.02       |
|    explained_variance   | 0.981      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00649    |
|    n_updates            | 5540       |
|    policy_gradient_loss | -0.00476   |
|    std                  | 0.0889     |
|    value_loss           | 0.00525    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 967        |
|    ep_rew_mean          | 3.6e+03    |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 556        |
|    time_elapsed         | 7317       |
|    total_timesteps      | 1138688    |
| train/                  |            |
|    approx_kl            | 0.14388715 |
|    clip_fraction        | 0.664      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.04       |
|    explained_variance   | 0.596      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0619    |
|    n_updates            | 5550       |
|    policy_gradient_loss | -0.0215    |
|    std                  | 0.0884     |
|    value_loss           | 0.00357    |
----------------------------------------
Eval num_timesteps=1140000, episode_reward=3995.84 +/- 779.95
Episode length: 956.76 +/- 151.14
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 957        |
|    mean_reward          | 4e+03      |
| time/                   |            |
|    total_timesteps      | 1140000    |
| train/                  |            |
|    approx_kl            | 0.16986102 |
|    clip_fraction        | 0.65       |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.06       |
|    explained_variance   | 0.696      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0566    |
|    n_updates            | 5560       |
|    policy_gradient_loss | -0.0172    |
|    std                  | 0.0886     |
|    value_loss           | 0.0027     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 967      |
|    ep_rew_mean     | 3.58e+03 |
| time/              |          |
|    fps             | 155      |
|    iterations      | 557      |
|    time_elapsed    | 7347     |
|    total_timesteps | 1140736  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 967        |
|    ep_rew_mean          | 3.58e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 558        |
|    time_elapsed         | 7356       |
|    total_timesteps      | 1142784    |
| train/                  |            |
|    approx_kl            | 0.14169246 |
|    clip_fraction        | 0.599      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.06       |
|    explained_variance   | 0.976      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0552    |
|    n_updates            | 5570       |
|    policy_gradient_loss | -0.0159    |
|    std                  | 0.0883     |
|    value_loss           | 0.0171     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 967        |
|    ep_rew_mean          | 3.55e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 559        |
|    time_elapsed         | 7365       |
|    total_timesteps      | 1144832    |
| train/                  |            |
|    approx_kl            | 0.16823876 |
|    clip_fraction        | 0.671      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.08       |
|    explained_variance   | 0.987      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0235    |
|    n_updates            | 5580       |
|    policy_gradient_loss | -0.0128    |
|    std                  | 0.0883     |
|    value_loss           | 0.0113     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 969        |
|    ep_rew_mean          | 3.56e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 560        |
|    time_elapsed         | 7374       |
|    total_timesteps      | 1146880    |
| train/                  |            |
|    approx_kl            | 0.20805521 |
|    clip_fraction        | 0.687      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.08       |
|    explained_variance   | 0.963      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0147    |
|    n_updates            | 5590       |
|    policy_gradient_loss | -0.012     |
|    std                  | 0.0884     |
|    value_loss           | 0.00588    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 969        |
|    ep_rew_mean          | 3.53e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 561        |
|    time_elapsed         | 7384       |
|    total_timesteps      | 1148928    |
| train/                  |            |
|    approx_kl            | 0.16839083 |
|    clip_fraction        | 0.676      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.05       |
|    explained_variance   | 0.688      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0165    |
|    n_updates            | 5600       |
|    policy_gradient_loss | -0.0205    |
|    std                  | 0.0887     |
|    value_loss           | 0.00466    |
----------------------------------------
Eval num_timesteps=1150000, episode_reward=3505.56 +/- 1286.62
Episode length: 964.52 +/- 173.82
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 965        |
|    mean_reward          | 3.51e+03   |
| time/                   |            |
|    total_timesteps      | 1150000    |
| train/                  |            |
|    approx_kl            | 0.16009045 |
|    clip_fraction        | 0.642      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.04       |
|    explained_variance   | 0.981      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00213   |
|    n_updates            | 5610       |
|    policy_gradient_loss | -0.0165    |
|    std                  | 0.0887     |
|    value_loss           | 0.0144     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 969      |
|    ep_rew_mean     | 3.53e+03 |
| time/              |          |
|    fps             | 155      |
|    iterations      | 562      |
|    time_elapsed    | 7414     |
|    total_timesteps | 1150976  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 963        |
|    ep_rew_mean          | 3.51e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 563        |
|    time_elapsed         | 7424       |
|    total_timesteps      | 1153024    |
| train/                  |            |
|    approx_kl            | 0.18021816 |
|    clip_fraction        | 0.646      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.04       |
|    explained_variance   | 0.215      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0502    |
|    n_updates            | 5620       |
|    policy_gradient_loss | -0.0152    |
|    std                  | 0.0889     |
|    value_loss           | 0.00485    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 963        |
|    ep_rew_mean          | 3.53e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 564        |
|    time_elapsed         | 7434       |
|    total_timesteps      | 1155072    |
| train/                  |            |
|    approx_kl            | 0.14809278 |
|    clip_fraction        | 0.645      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.03       |
|    explained_variance   | 0.532      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0702    |
|    n_updates            | 5630       |
|    policy_gradient_loss | -0.0173    |
|    std                  | 0.0887     |
|    value_loss           | 0.0234     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 963        |
|    ep_rew_mean          | 3.57e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 565        |
|    time_elapsed         | 7443       |
|    total_timesteps      | 1157120    |
| train/                  |            |
|    approx_kl            | 0.18901159 |
|    clip_fraction        | 0.684      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.04       |
|    explained_variance   | 0.48       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0502    |
|    n_updates            | 5640       |
|    policy_gradient_loss | -0.0151    |
|    std                  | 0.089      |
|    value_loss           | 0.0199     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 963        |
|    ep_rew_mean          | 3.57e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 566        |
|    time_elapsed         | 7453       |
|    total_timesteps      | 1159168    |
| train/                  |            |
|    approx_kl            | 0.18663985 |
|    clip_fraction        | 0.682      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.02       |
|    explained_variance   | 0.822      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0378    |
|    n_updates            | 5650       |
|    policy_gradient_loss | -0.012     |
|    std                  | 0.0892     |
|    value_loss           | 0.0157     |
----------------------------------------
Eval num_timesteps=1160000, episode_reward=3170.45 +/- 1101.19
Episode length: 958.56 +/- 143.58
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 959        |
|    mean_reward          | 3.17e+03   |
| time/                   |            |
|    total_timesteps      | 1160000    |
| train/                  |            |
|    approx_kl            | 0.15226659 |
|    clip_fraction        | 0.65       |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.02       |
|    explained_variance   | 0.975      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0343    |
|    n_updates            | 5660       |
|    policy_gradient_loss | -0.0133    |
|    std                  | 0.0888     |
|    value_loss           | 0.0209     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 963      |
|    ep_rew_mean     | 3.54e+03 |
| time/              |          |
|    fps             | 155      |
|    iterations      | 567      |
|    time_elapsed    | 7483     |
|    total_timesteps | 1161216  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 963        |
|    ep_rew_mean          | 3.53e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 568        |
|    time_elapsed         | 7493       |
|    total_timesteps      | 1163264    |
| train/                  |            |
|    approx_kl            | 0.17053661 |
|    clip_fraction        | 0.625      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.06       |
|    explained_variance   | 0.986      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0422    |
|    n_updates            | 5670       |
|    policy_gradient_loss | -0.0126    |
|    std                  | 0.0883     |
|    value_loss           | 0.0128     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 963        |
|    ep_rew_mean          | 3.48e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 569        |
|    time_elapsed         | 7502       |
|    total_timesteps      | 1165312    |
| train/                  |            |
|    approx_kl            | 0.13136168 |
|    clip_fraction        | 0.573      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.1        |
|    explained_variance   | 0.96       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0429    |
|    n_updates            | 5680       |
|    policy_gradient_loss | -0.0218    |
|    std                  | 0.088      |
|    value_loss           | 0.0163     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 963        |
|    ep_rew_mean          | 3.47e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 570        |
|    time_elapsed         | 7512       |
|    total_timesteps      | 1167360    |
| train/                  |            |
|    approx_kl            | 0.17885177 |
|    clip_fraction        | 0.668      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.11       |
|    explained_variance   | 0.977      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0409    |
|    n_updates            | 5690       |
|    policy_gradient_loss | -0.0151    |
|    std                  | 0.0882     |
|    value_loss           | 0.0156     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 963        |
|    ep_rew_mean          | 3.48e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 571        |
|    time_elapsed         | 7521       |
|    total_timesteps      | 1169408    |
| train/                  |            |
|    approx_kl            | 0.16481476 |
|    clip_fraction        | 0.648      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.08       |
|    explained_variance   | 0.969      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0261    |
|    n_updates            | 5700       |
|    policy_gradient_loss | -0.0132    |
|    std                  | 0.0883     |
|    value_loss           | 0.0221     |
----------------------------------------
Eval num_timesteps=1170000, episode_reward=3410.79 +/- 1229.07
Episode length: 943.36 +/- 173.92
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 943        |
|    mean_reward          | 3.41e+03   |
| time/                   |            |
|    total_timesteps      | 1170000    |
| train/                  |            |
|    approx_kl            | 0.19012687 |
|    clip_fraction        | 0.661      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.09       |
|    explained_variance   | 0.828      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0332    |
|    n_updates            | 5710       |
|    policy_gradient_loss | -0.0246    |
|    std                  | 0.0882     |
|    value_loss           | 0.00572    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 958      |
|    ep_rew_mean     | 3.48e+03 |
| time/              |          |
|    fps             | 155      |
|    iterations      | 572      |
|    time_elapsed    | 7551     |
|    total_timesteps | 1171456  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 958        |
|    ep_rew_mean          | 3.43e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 573        |
|    time_elapsed         | 7560       |
|    total_timesteps      | 1173504    |
| train/                  |            |
|    approx_kl            | 0.13980037 |
|    clip_fraction        | 0.624      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.1        |
|    explained_variance   | 0.961      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0142     |
|    n_updates            | 5720       |
|    policy_gradient_loss | -0.0201    |
|    std                  | 0.0879     |
|    value_loss           | 0.0169     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 958       |
|    ep_rew_mean          | 3.41e+03  |
| time/                   |           |
|    fps                  | 155       |
|    iterations           | 574       |
|    time_elapsed         | 7570      |
|    total_timesteps      | 1175552   |
| train/                  |           |
|    approx_kl            | 0.1868788 |
|    clip_fraction        | 0.658     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.13      |
|    explained_variance   | 0.972     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0783   |
|    n_updates            | 5730      |
|    policy_gradient_loss | -0.0199   |
|    std                  | 0.0876    |
|    value_loss           | 0.0181    |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 970        |
|    ep_rew_mean          | 3.44e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 575        |
|    time_elapsed         | 7579       |
|    total_timesteps      | 1177600    |
| train/                  |            |
|    approx_kl            | 0.18794042 |
|    clip_fraction        | 0.659      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.16       |
|    explained_variance   | 0.973      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0444    |
|    n_updates            | 5740       |
|    policy_gradient_loss | -0.00792   |
|    std                  | 0.0873     |
|    value_loss           | 0.0218     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 970        |
|    ep_rew_mean          | 3.44e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 576        |
|    time_elapsed         | 7589       |
|    total_timesteps      | 1179648    |
| train/                  |            |
|    approx_kl            | 0.16812198 |
|    clip_fraction        | 0.673      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.18       |
|    explained_variance   | 0.956      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.067     |
|    n_updates            | 5750       |
|    policy_gradient_loss | -0.00903   |
|    std                  | 0.0871     |
|    value_loss           | 0.0162     |
----------------------------------------
Eval num_timesteps=1180000, episode_reward=3514.84 +/- 1143.99
Episode length: 964.96 +/- 120.16
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 965        |
|    mean_reward          | 3.51e+03   |
| time/                   |            |
|    total_timesteps      | 1180000    |
| train/                  |            |
|    approx_kl            | 0.17559698 |
|    clip_fraction        | 0.67       |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.18       |
|    explained_variance   | 0.964      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0163    |
|    n_updates            | 5760       |
|    policy_gradient_loss | -0.013     |
|    std                  | 0.0874     |
|    value_loss           | 0.0152     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 963      |
|    ep_rew_mean     | 3.35e+03 |
| time/              |          |
|    fps             | 155      |
|    iterations      | 577      |
|    time_elapsed    | 7619     |
|    total_timesteps | 1181696  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 961        |
|    ep_rew_mean          | 3.34e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 578        |
|    time_elapsed         | 7628       |
|    total_timesteps      | 1183744    |
| train/                  |            |
|    approx_kl            | 0.13667248 |
|    clip_fraction        | 0.581      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.17       |
|    explained_variance   | 0.969      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0548    |
|    n_updates            | 5770       |
|    policy_gradient_loss | -0.0123    |
|    std                  | 0.0873     |
|    value_loss           | 0.0185     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 961        |
|    ep_rew_mean          | 3.34e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 579        |
|    time_elapsed         | 7638       |
|    total_timesteps      | 1185792    |
| train/                  |            |
|    approx_kl            | 0.18621625 |
|    clip_fraction        | 0.679      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.18       |
|    explained_variance   | 0.395      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00206   |
|    n_updates            | 5780       |
|    policy_gradient_loss | -0.0136    |
|    std                  | 0.0875     |
|    value_loss           | 0.0213     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 961        |
|    ep_rew_mean          | 3.34e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 580        |
|    time_elapsed         | 7647       |
|    total_timesteps      | 1187840    |
| train/                  |            |
|    approx_kl            | 0.16223644 |
|    clip_fraction        | 0.664      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.16       |
|    explained_variance   | 0.96       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.05      |
|    n_updates            | 5790       |
|    policy_gradient_loss | -0.0106    |
|    std                  | 0.0876     |
|    value_loss           | 0.0144     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 961        |
|    ep_rew_mean          | 3.35e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 581        |
|    time_elapsed         | 7657       |
|    total_timesteps      | 1189888    |
| train/                  |            |
|    approx_kl            | 0.18290436 |
|    clip_fraction        | 0.678      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.15       |
|    explained_variance   | 0.0396     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0553    |
|    n_updates            | 5800       |
|    policy_gradient_loss | -0.0215    |
|    std                  | 0.0877     |
|    value_loss           | 0.00486    |
----------------------------------------
Eval num_timesteps=1190000, episode_reward=4075.79 +/- 218.00
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 4.08e+03   |
| time/                   |            |
|    total_timesteps      | 1190000    |
| train/                  |            |
|    approx_kl            | 0.18165013 |
|    clip_fraction        | 0.671      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.17       |
|    explained_variance   | 0.592      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0372    |
|    n_updates            | 5810       |
|    policy_gradient_loss | -0.0181    |
|    std                  | 0.0871     |
|    value_loss           | 0.00351    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 961      |
|    ep_rew_mean     | 3.34e+03 |
| time/              |          |
|    fps             | 155      |
|    iterations      | 582      |
|    time_elapsed    | 7687     |
|    total_timesteps | 1191936  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 961        |
|    ep_rew_mean          | 3.34e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 583        |
|    time_elapsed         | 7697       |
|    total_timesteps      | 1193984    |
| train/                  |            |
|    approx_kl            | 0.16858587 |
|    clip_fraction        | 0.665      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.18       |
|    explained_variance   | 0.599      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0417    |
|    n_updates            | 5820       |
|    policy_gradient_loss | -0.0199    |
|    std                  | 0.0875     |
|    value_loss           | 0.00292    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 961        |
|    ep_rew_mean          | 3.33e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 584        |
|    time_elapsed         | 7706       |
|    total_timesteps      | 1196032    |
| train/                  |            |
|    approx_kl            | 0.15569746 |
|    clip_fraction        | 0.655      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.18       |
|    explained_variance   | 0.625      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0239    |
|    n_updates            | 5830       |
|    policy_gradient_loss | -0.0187    |
|    std                  | 0.0871     |
|    value_loss           | 0.00257    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 961        |
|    ep_rew_mean          | 3.31e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 585        |
|    time_elapsed         | 7716       |
|    total_timesteps      | 1198080    |
| train/                  |            |
|    approx_kl            | 0.20798923 |
|    clip_fraction        | 0.682      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.19       |
|    explained_variance   | 0.558      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0476    |
|    n_updates            | 5840       |
|    policy_gradient_loss | -0.0137    |
|    std                  | 0.0872     |
|    value_loss           | 0.00957    |
----------------------------------------
Eval num_timesteps=1200000, episode_reward=4109.43 +/- 95.31
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 4.11e+03   |
| time/                   |            |
|    total_timesteps      | 1200000    |
| train/                  |            |
|    approx_kl            | 0.16512707 |
|    clip_fraction        | 0.652      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.2        |
|    explained_variance   | 0.98       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0448    |
|    n_updates            | 5850       |
|    policy_gradient_loss | -0.0137    |
|    std                  | 0.0868     |
|    value_loss           | 0.0126     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 961      |
|    ep_rew_mean     | 3.29e+03 |
| time/              |          |
|    fps             | 154      |
|    iterations      | 586      |
|    time_elapsed    | 7747     |
|    total_timesteps | 1200128  |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 969       |
|    ep_rew_mean          | 3.32e+03  |
| time/                   |           |
|    fps                  | 154       |
|    iterations           | 587       |
|    time_elapsed         | 7756      |
|    total_timesteps      | 1202176   |
| train/                  |           |
|    approx_kl            | 0.6931578 |
|    clip_fraction        | 0.704     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.22      |
|    explained_variance   | 0.97      |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0493   |
|    n_updates            | 5860      |
|    policy_gradient_loss | -0.014    |
|    std                  | 0.087     |
|    value_loss           | 0.0043    |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 969        |
|    ep_rew_mean          | 3.32e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 588        |
|    time_elapsed         | 7766       |
|    total_timesteps      | 1204224    |
| train/                  |            |
|    approx_kl            | 0.16230348 |
|    clip_fraction        | 0.651      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.19       |
|    explained_variance   | 0.523      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0459    |
|    n_updates            | 5870       |
|    policy_gradient_loss | -0.019     |
|    std                  | 0.0872     |
|    value_loss           | 0.00263    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 969        |
|    ep_rew_mean          | 3.31e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 589        |
|    time_elapsed         | 7775       |
|    total_timesteps      | 1206272    |
| train/                  |            |
|    approx_kl            | 0.14908023 |
|    clip_fraction        | 0.641      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.2        |
|    explained_variance   | 0.672      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0129    |
|    n_updates            | 5880       |
|    policy_gradient_loss | -0.0164    |
|    std                  | 0.087      |
|    value_loss           | 0.00313    |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 969       |
|    ep_rew_mean          | 3.28e+03  |
| time/                   |           |
|    fps                  | 155       |
|    iterations           | 590       |
|    time_elapsed         | 7785      |
|    total_timesteps      | 1208320   |
| train/                  |           |
|    approx_kl            | 0.1468642 |
|    clip_fraction        | 0.663     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.21      |
|    explained_variance   | 0.607     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.00179  |
|    n_updates            | 5890      |
|    policy_gradient_loss | -0.0188   |
|    std                  | 0.0872    |
|    value_loss           | 0.00256   |
---------------------------------------
Eval num_timesteps=1210000, episode_reward=4003.51 +/- 248.73
Episode length: 987.36 +/- 61.92
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 987        |
|    mean_reward          | 4e+03      |
| time/                   |            |
|    total_timesteps      | 1210000    |
| train/                  |            |
|    approx_kl            | 0.14887597 |
|    clip_fraction        | 0.63       |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.2        |
|    explained_variance   | 0.98       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0125     |
|    n_updates            | 5900       |
|    policy_gradient_loss | -0.0137    |
|    std                  | 0.0869     |
|    value_loss           | 0.0115     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 969      |
|    ep_rew_mean     | 3.28e+03 |
| time/              |          |
|    fps             | 154      |
|    iterations      | 591      |
|    time_elapsed    | 7814     |
|    total_timesteps | 1210368  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 956        |
|    ep_rew_mean          | 3.25e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 592        |
|    time_elapsed         | 7824       |
|    total_timesteps      | 1212416    |
| train/                  |            |
|    approx_kl            | 0.18413706 |
|    clip_fraction        | 0.662      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.22       |
|    explained_variance   | 0.563      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.045     |
|    n_updates            | 5910       |
|    policy_gradient_loss | -0.0217    |
|    std                  | 0.0869     |
|    value_loss           | 0.0042     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 956        |
|    ep_rew_mean          | 3.24e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 593        |
|    time_elapsed         | 7833       |
|    total_timesteps      | 1214464    |
| train/                  |            |
|    approx_kl            | 0.14649676 |
|    clip_fraction        | 0.648      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.22       |
|    explained_variance   | 0.588      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00872   |
|    n_updates            | 5920       |
|    policy_gradient_loss | -0.0104    |
|    std                  | 0.0868     |
|    value_loss           | 0.0217     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 956        |
|    ep_rew_mean          | 3.21e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 594        |
|    time_elapsed         | 7843       |
|    total_timesteps      | 1216512    |
| train/                  |            |
|    approx_kl            | 0.15113163 |
|    clip_fraction        | 0.671      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.22       |
|    explained_variance   | 0.972      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00912   |
|    n_updates            | 5930       |
|    policy_gradient_loss | -0.0112    |
|    std                  | 0.0871     |
|    value_loss           | 0.0193     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 956       |
|    ep_rew_mean          | 3.21e+03  |
| time/                   |           |
|    fps                  | 155       |
|    iterations           | 595       |
|    time_elapsed         | 7852      |
|    total_timesteps      | 1218560   |
| train/                  |           |
|    approx_kl            | 3.8545387 |
|    clip_fraction        | 0.78      |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.21      |
|    explained_variance   | 0.986     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0448   |
|    n_updates            | 5940      |
|    policy_gradient_loss | -0.0232   |
|    std                  | 0.0868    |
|    value_loss           | 0.00591   |
---------------------------------------
Eval num_timesteps=1220000, episode_reward=3687.47 +/- 1000.56
Episode length: 964.68 +/- 173.03
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 965        |
|    mean_reward          | 3.69e+03   |
| time/                   |            |
|    total_timesteps      | 1220000    |
| train/                  |            |
|    approx_kl            | 0.17155313 |
|    clip_fraction        | 0.66       |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.24       |
|    explained_variance   | 0.432      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0672    |
|    n_updates            | 5950       |
|    policy_gradient_loss | -0.0191    |
|    std                  | 0.0867     |
|    value_loss           | 0.0028     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 961      |
|    ep_rew_mean     | 3.23e+03 |
| time/              |          |
|    fps             | 154      |
|    iterations      | 596      |
|    time_elapsed    | 7882     |
|    total_timesteps | 1220608  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 961        |
|    ep_rew_mean          | 3.23e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 597        |
|    time_elapsed         | 7891       |
|    total_timesteps      | 1222656    |
| train/                  |            |
|    approx_kl            | 0.15193015 |
|    clip_fraction        | 0.674      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.23       |
|    explained_variance   | 0.889      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.044     |
|    n_updates            | 5960       |
|    policy_gradient_loss | -0.016     |
|    std                  | 0.0866     |
|    value_loss           | 0.0129     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 961        |
|    ep_rew_mean          | 3.23e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 598        |
|    time_elapsed         | 7901       |
|    total_timesteps      | 1224704    |
| train/                  |            |
|    approx_kl            | 0.19263901 |
|    clip_fraction        | 0.662      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.23       |
|    explained_variance   | 0.304      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0425    |
|    n_updates            | 5970       |
|    policy_gradient_loss | -0.0144    |
|    std                  | 0.0869     |
|    value_loss           | 0.00324    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 961        |
|    ep_rew_mean          | 3.23e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 599        |
|    time_elapsed         | 7910       |
|    total_timesteps      | 1226752    |
| train/                  |            |
|    approx_kl            | 0.20053545 |
|    clip_fraction        | 0.671      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.22       |
|    explained_variance   | 0.501      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0569    |
|    n_updates            | 5980       |
|    policy_gradient_loss | -0.0218    |
|    std                  | 0.0868     |
|    value_loss           | 0.00275    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 961        |
|    ep_rew_mean          | 3.22e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 600        |
|    time_elapsed         | 7920       |
|    total_timesteps      | 1228800    |
| train/                  |            |
|    approx_kl            | 0.15911229 |
|    clip_fraction        | 0.668      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.22       |
|    explained_variance   | 0.481      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0425    |
|    n_updates            | 5990       |
|    policy_gradient_loss | -0.0157    |
|    std                  | 0.0869     |
|    value_loss           | 0.00389    |
----------------------------------------
Eval num_timesteps=1230000, episode_reward=4157.13 +/- 107.04
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 4.16e+03   |
| time/                   |            |
|    total_timesteps      | 1230000    |
| train/                  |            |
|    approx_kl            | 0.17635198 |
|    clip_fraction        | 0.639      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.22       |
|    explained_variance   | 0.624      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0332     |
|    n_updates            | 6000       |
|    policy_gradient_loss | -0.014     |
|    std                  | 0.0868     |
|    value_loss           | 0.00218    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 961      |
|    ep_rew_mean     | 3.24e+03 |
| time/              |          |
|    fps             | 154      |
|    iterations      | 601      |
|    time_elapsed    | 7949     |
|    total_timesteps | 1230848  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 961        |
|    ep_rew_mean          | 3.24e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 602        |
|    time_elapsed         | 7959       |
|    total_timesteps      | 1232896    |
| train/                  |            |
|    approx_kl            | 0.17876567 |
|    clip_fraction        | 0.661      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.22       |
|    explained_variance   | 0.678      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0282    |
|    n_updates            | 6010       |
|    policy_gradient_loss | -0.0161    |
|    std                  | 0.0869     |
|    value_loss           | 0.00724    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 961        |
|    ep_rew_mean          | 3.24e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 603        |
|    time_elapsed         | 7968       |
|    total_timesteps      | 1234944    |
| train/                  |            |
|    approx_kl            | 0.16372052 |
|    clip_fraction        | 0.661      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.21       |
|    explained_variance   | 0.494      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0711    |
|    n_updates            | 6020       |
|    policy_gradient_loss | -0.0191    |
|    std                  | 0.0871     |
|    value_loss           | 0.00314    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 961        |
|    ep_rew_mean          | 3.25e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 604        |
|    time_elapsed         | 7977       |
|    total_timesteps      | 1236992    |
| train/                  |            |
|    approx_kl            | 0.15965465 |
|    clip_fraction        | 0.669      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.23       |
|    explained_variance   | 0.772      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0279    |
|    n_updates            | 6030       |
|    policy_gradient_loss | -0.0145    |
|    std                  | 0.0865     |
|    value_loss           | 0.012      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 961       |
|    ep_rew_mean          | 3.27e+03  |
| time/                   |           |
|    fps                  | 155       |
|    iterations           | 605       |
|    time_elapsed         | 7987      |
|    total_timesteps      | 1239040   |
| train/                  |           |
|    approx_kl            | 0.1719378 |
|    clip_fraction        | 0.68      |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.25      |
|    explained_variance   | 0.98      |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0348   |
|    n_updates            | 6040      |
|    policy_gradient_loss | -0.0181   |
|    std                  | 0.0866    |
|    value_loss           | 0.00449   |
---------------------------------------
Eval num_timesteps=1240000, episode_reward=3990.38 +/- 571.36
Episode length: 973.52 +/- 129.72
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 974        |
|    mean_reward          | 3.99e+03   |
| time/                   |            |
|    total_timesteps      | 1240000    |
| train/                  |            |
|    approx_kl            | 0.16653205 |
|    clip_fraction        | 0.654      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.24       |
|    explained_variance   | 0.64       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.055     |
|    n_updates            | 6050       |
|    policy_gradient_loss | -0.02      |
|    std                  | 0.0864     |
|    value_loss           | 0.0046     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 961      |
|    ep_rew_mean     | 3.3e+03  |
| time/              |          |
|    fps             | 154      |
|    iterations      | 606      |
|    time_elapsed    | 8017     |
|    total_timesteps | 1241088  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 961        |
|    ep_rew_mean          | 3.3e+03    |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 607        |
|    time_elapsed         | 8026       |
|    total_timesteps      | 1243136    |
| train/                  |            |
|    approx_kl            | 0.19880849 |
|    clip_fraction        | 0.681      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.26       |
|    explained_variance   | 0.616      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0312    |
|    n_updates            | 6060       |
|    policy_gradient_loss | -0.0191    |
|    std                  | 0.0864     |
|    value_loss           | 0.00347    |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 961       |
|    ep_rew_mean          | 3.33e+03  |
| time/                   |           |
|    fps                  | 154       |
|    iterations           | 608       |
|    time_elapsed         | 8035      |
|    total_timesteps      | 1245184   |
| train/                  |           |
|    approx_kl            | 0.1639556 |
|    clip_fraction        | 0.646     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.27      |
|    explained_variance   | 0.644     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0642   |
|    n_updates            | 6070      |
|    policy_gradient_loss | -0.0276   |
|    std                  | 0.0863    |
|    value_loss           | 0.00367   |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 961      |
|    ep_rew_mean          | 3.32e+03 |
| time/                   |          |
|    fps                  | 155      |
|    iterations           | 609      |
|    time_elapsed         | 8045     |
|    total_timesteps      | 1247232  |
| train/                  |          |
|    approx_kl            | 0.175751 |
|    clip_fraction        | 0.676    |
|    clip_range           | 0.2      |
|    entropy_loss         | 8.27     |
|    explained_variance   | 0.618    |
|    learning_rate        | 0.0003   |
|    loss                 | -0.0778  |
|    n_updates            | 6080     |
|    policy_gradient_loss | -0.0119  |
|    std                  | 0.0864   |
|    value_loss           | 0.00206  |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 967        |
|    ep_rew_mean          | 3.34e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 610        |
|    time_elapsed         | 8054       |
|    total_timesteps      | 1249280    |
| train/                  |            |
|    approx_kl            | 0.15208104 |
|    clip_fraction        | 0.66       |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.24       |
|    explained_variance   | 0.6        |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00899   |
|    n_updates            | 6090       |
|    policy_gradient_loss | -0.0195    |
|    std                  | 0.0869     |
|    value_loss           | 0.00336    |
----------------------------------------
Eval num_timesteps=1250000, episode_reward=3777.77 +/- 1078.17
Episode length: 968.64 +/- 153.63
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 969        |
|    mean_reward          | 3.78e+03   |
| time/                   |            |
|    total_timesteps      | 1250000    |
| train/                  |            |
|    approx_kl            | 0.15286165 |
|    clip_fraction        | 0.656      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.21       |
|    explained_variance   | 0.628      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0158     |
|    n_updates            | 6100       |
|    policy_gradient_loss | -0.0237    |
|    std                  | 0.0871     |
|    value_loss           | 0.00268    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 967      |
|    ep_rew_mean     | 3.34e+03 |
| time/              |          |
|    fps             | 154      |
|    iterations      | 611      |
|    time_elapsed    | 8084     |
|    total_timesteps | 1251328  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 967        |
|    ep_rew_mean          | 3.34e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 612        |
|    time_elapsed         | 8093       |
|    total_timesteps      | 1253376    |
| train/                  |            |
|    approx_kl            | 0.17521116 |
|    clip_fraction        | 0.663      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.2        |
|    explained_variance   | 0.584      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0366    |
|    n_updates            | 6110       |
|    policy_gradient_loss | -0.0202    |
|    std                  | 0.0871     |
|    value_loss           | 0.00239    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 967        |
|    ep_rew_mean          | 3.36e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 613        |
|    time_elapsed         | 8103       |
|    total_timesteps      | 1255424    |
| train/                  |            |
|    approx_kl            | 0.16485974 |
|    clip_fraction        | 0.665      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.2        |
|    explained_variance   | 0.668      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0851    |
|    n_updates            | 6120       |
|    policy_gradient_loss | -0.0191    |
|    std                  | 0.0871     |
|    value_loss           | 0.00273    |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 967      |
|    ep_rew_mean          | 3.41e+03 |
| time/                   |          |
|    fps                  | 154      |
|    iterations           | 614      |
|    time_elapsed         | 8112     |
|    total_timesteps      | 1257472  |
| train/                  |          |
|    approx_kl            | 0.15917  |
|    clip_fraction        | 0.656    |
|    clip_range           | 0.2      |
|    entropy_loss         | 8.21     |
|    explained_variance   | 0.63     |
|    learning_rate        | 0.0003   |
|    loss                 | -0.0117  |
|    n_updates            | 6130     |
|    policy_gradient_loss | -0.0244  |
|    std                  | 0.0869   |
|    value_loss           | 0.00286  |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 967        |
|    ep_rew_mean          | 3.44e+03   |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 615        |
|    time_elapsed         | 8122       |
|    total_timesteps      | 1259520    |
| train/                  |            |
|    approx_kl            | 0.20064783 |
|    clip_fraction        | 0.67       |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.22       |
|    explained_variance   | 0.628      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0476    |
|    n_updates            | 6140       |
|    policy_gradient_loss | -0.0228    |
|    std                  | 0.0869     |
|    value_loss           | 0.00289    |
----------------------------------------
Eval num_timesteps=1260000, episode_reward=4158.34 +/- 97.49
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 4.16e+03   |
| time/                   |            |
|    total_timesteps      | 1260000    |
| train/                  |            |
|    approx_kl            | 0.16156825 |
|    clip_fraction        | 0.652      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.23       |
|    explained_variance   | 0.573      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0751    |
|    n_updates            | 6150       |
|    policy_gradient_loss | -0.0202    |
|    std                  | 0.0867     |
|    value_loss           | 0.00299    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 967      |
|    ep_rew_mean     | 3.49e+03 |
| time/              |          |
|    fps             | 154      |
|    iterations      | 616      |
|    time_elapsed    | 8155     |
|    total_timesteps | 1261568  |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 967       |
|    ep_rew_mean          | 3.5e+03   |
| time/                   |           |
|    fps                  | 154       |
|    iterations           | 617       |
|    time_elapsed         | 8164      |
|    total_timesteps      | 1263616   |
| train/                  |           |
|    approx_kl            | 0.1850668 |
|    clip_fraction        | 0.657     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.24      |
|    explained_variance   | 0.554     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0568   |
|    n_updates            | 6160      |
|    policy_gradient_loss | -0.0162   |
|    std                  | 0.0866    |
|    value_loss           | 0.00235   |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 967        |
|    ep_rew_mean          | 3.51e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 618        |
|    time_elapsed         | 8174       |
|    total_timesteps      | 1265664    |
| train/                  |            |
|    approx_kl            | 0.18894768 |
|    clip_fraction        | 0.662      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.25       |
|    explained_variance   | 0.545      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0876    |
|    n_updates            | 6170       |
|    policy_gradient_loss | -0.0179    |
|    std                  | 0.0866     |
|    value_loss           | 0.00291    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 972        |
|    ep_rew_mean          | 3.53e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 619        |
|    time_elapsed         | 8183       |
|    total_timesteps      | 1267712    |
| train/                  |            |
|    approx_kl            | 0.16125566 |
|    clip_fraction        | 0.659      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.25       |
|    explained_variance   | 0.634      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0262    |
|    n_updates            | 6180       |
|    policy_gradient_loss | -0.0157    |
|    std                  | 0.0865     |
|    value_loss           | 0.00297    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 972        |
|    ep_rew_mean          | 3.56e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 620        |
|    time_elapsed         | 8193       |
|    total_timesteps      | 1269760    |
| train/                  |            |
|    approx_kl            | 0.17647547 |
|    clip_fraction        | 0.671      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.27       |
|    explained_variance   | 0.778      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0582    |
|    n_updates            | 6190       |
|    policy_gradient_loss | -0.0178    |
|    std                  | 0.0862     |
|    value_loss           | 0.00542    |
----------------------------------------
Eval num_timesteps=1270000, episode_reward=4056.29 +/- 518.30
Episode length: 979.04 +/- 102.68
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 979        |
|    mean_reward          | 4.06e+03   |
| time/                   |            |
|    total_timesteps      | 1270000    |
| train/                  |            |
|    approx_kl            | 0.20617563 |
|    clip_fraction        | 0.67       |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.29       |
|    explained_variance   | 0.501      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0128    |
|    n_updates            | 6200       |
|    policy_gradient_loss | -0.0237    |
|    std                  | 0.0862     |
|    value_loss           | 0.00521    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 972      |
|    ep_rew_mean     | 3.58e+03 |
| time/              |          |
|    fps             | 154      |
|    iterations      | 621      |
|    time_elapsed    | 8223     |
|    total_timesteps | 1271808  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 972        |
|    ep_rew_mean          | 3.62e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 622        |
|    time_elapsed         | 8233       |
|    total_timesteps      | 1273856    |
| train/                  |            |
|    approx_kl            | 0.18660045 |
|    clip_fraction        | 0.676      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.26       |
|    explained_variance   | 0.546      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0857    |
|    n_updates            | 6210       |
|    policy_gradient_loss | -0.0156    |
|    std                  | 0.0867     |
|    value_loss           | 0.00346    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 979        |
|    ep_rew_mean          | 3.64e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 623        |
|    time_elapsed         | 8242       |
|    total_timesteps      | 1275904    |
| train/                  |            |
|    approx_kl            | 0.18734707 |
|    clip_fraction        | 0.675      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.25       |
|    explained_variance   | 0.645      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0565    |
|    n_updates            | 6220       |
|    policy_gradient_loss | -0.022     |
|    std                  | 0.0864     |
|    value_loss           | 0.00478    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 979        |
|    ep_rew_mean          | 3.62e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 624        |
|    time_elapsed         | 8252       |
|    total_timesteps      | 1277952    |
| train/                  |            |
|    approx_kl            | 0.58228314 |
|    clip_fraction        | 0.678      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.26       |
|    explained_variance   | 0.977      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0107    |
|    n_updates            | 6230       |
|    policy_gradient_loss | 0.00722    |
|    std                  | 0.0865     |
|    value_loss           | 0.0107     |
----------------------------------------
Eval num_timesteps=1280000, episode_reward=3879.01 +/- 919.67
Episode length: 956.84 +/- 152.27
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 957        |
|    mean_reward          | 3.88e+03   |
| time/                   |            |
|    total_timesteps      | 1280000    |
| train/                  |            |
|    approx_kl            | 0.19794028 |
|    clip_fraction        | 0.686      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.24       |
|    explained_variance   | 0.958      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0421    |
|    n_updates            | 6240       |
|    policy_gradient_loss | -0.0184    |
|    std                  | 0.0867     |
|    value_loss           | 0.00807    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 985      |
|    ep_rew_mean     | 3.7e+03  |
| time/              |          |
|    fps             | 154      |
|    iterations      | 625      |
|    time_elapsed    | 8282     |
|    total_timesteps | 1280000  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 986        |
|    ep_rew_mean          | 3.71e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 626        |
|    time_elapsed         | 8291       |
|    total_timesteps      | 1282048    |
| train/                  |            |
|    approx_kl            | 0.18973997 |
|    clip_fraction        | 0.663      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.26       |
|    explained_variance   | 0.63       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0631    |
|    n_updates            | 6250       |
|    policy_gradient_loss | -0.0227    |
|    std                  | 0.0864     |
|    value_loss           | 0.0074     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 986        |
|    ep_rew_mean          | 3.72e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 627        |
|    time_elapsed         | 8301       |
|    total_timesteps      | 1284096    |
| train/                  |            |
|    approx_kl            | 0.18614551 |
|    clip_fraction        | 0.654      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.28       |
|    explained_variance   | 0.503      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0548    |
|    n_updates            | 6260       |
|    policy_gradient_loss | -0.025     |
|    std                  | 0.0862     |
|    value_loss           | 0.00396    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 986        |
|    ep_rew_mean          | 3.73e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 628        |
|    time_elapsed         | 8310       |
|    total_timesteps      | 1286144    |
| train/                  |            |
|    approx_kl            | 0.19159654 |
|    clip_fraction        | 0.694      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.31       |
|    explained_variance   | 0.416      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0683    |
|    n_updates            | 6270       |
|    policy_gradient_loss | -0.0229    |
|    std                  | 0.0859     |
|    value_loss           | 0.00397    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 983        |
|    ep_rew_mean          | 3.72e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 629        |
|    time_elapsed         | 8320       |
|    total_timesteps      | 1288192    |
| train/                  |            |
|    approx_kl            | 0.17902789 |
|    clip_fraction        | 0.669      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.34       |
|    explained_variance   | 0.656      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0641    |
|    n_updates            | 6280       |
|    policy_gradient_loss | -0.0139    |
|    std                  | 0.0855     |
|    value_loss           | 0.00325    |
----------------------------------------
Eval num_timesteps=1290000, episode_reward=3841.74 +/- 1085.67
Episode length: 963.12 +/- 180.67
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 963       |
|    mean_reward          | 3.84e+03  |
| time/                   |           |
|    total_timesteps      | 1290000   |
| train/                  |           |
|    approx_kl            | 0.1615575 |
|    clip_fraction        | 0.68      |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.36      |
|    explained_variance   | 0.672     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0358   |
|    n_updates            | 6290      |
|    policy_gradient_loss | -0.00968  |
|    std                  | 0.0854    |
|    value_loss           | 0.0135    |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 977      |
|    ep_rew_mean     | 3.7e+03  |
| time/              |          |
|    fps             | 154      |
|    iterations      | 630      |
|    time_elapsed    | 8350     |
|    total_timesteps | 1290240  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 977        |
|    ep_rew_mean          | 3.71e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 631        |
|    time_elapsed         | 8360       |
|    total_timesteps      | 1292288    |
| train/                  |            |
|    approx_kl            | 0.16693525 |
|    clip_fraction        | 0.688      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.39       |
|    explained_variance   | 0.486      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0491    |
|    n_updates            | 6300       |
|    policy_gradient_loss | -0.00775   |
|    std                  | 0.0849     |
|    value_loss           | 0.0215     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 977        |
|    ep_rew_mean          | 3.7e+03    |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 632        |
|    time_elapsed         | 8369       |
|    total_timesteps      | 1294336    |
| train/                  |            |
|    approx_kl            | 0.22205159 |
|    clip_fraction        | 0.681      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.4        |
|    explained_variance   | 0.273      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0232    |
|    n_updates            | 6310       |
|    policy_gradient_loss | -0.0188    |
|    std                  | 0.0851     |
|    value_loss           | 0.00582    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 977        |
|    ep_rew_mean          | 3.72e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 633        |
|    time_elapsed         | 8379       |
|    total_timesteps      | 1296384    |
| train/                  |            |
|    approx_kl            | 0.17704825 |
|    clip_fraction        | 0.679      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.4        |
|    explained_variance   | 0.94       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0283    |
|    n_updates            | 6320       |
|    policy_gradient_loss | -0.0126    |
|    std                  | 0.0849     |
|    value_loss           | 0.0176     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 977        |
|    ep_rew_mean          | 3.73e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 634        |
|    time_elapsed         | 8388       |
|    total_timesteps      | 1298432    |
| train/                  |            |
|    approx_kl            | 0.20012912 |
|    clip_fraction        | 0.659      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.44       |
|    explained_variance   | 0.981      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0194    |
|    n_updates            | 6330       |
|    policy_gradient_loss | 0.00063    |
|    std                  | 0.0844     |
|    value_loss           | 0.0146     |
----------------------------------------
Eval num_timesteps=1300000, episode_reward=3586.28 +/- 1206.37
Episode length: 948.60 +/- 174.53
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 949        |
|    mean_reward          | 3.59e+03   |
| time/                   |            |
|    total_timesteps      | 1300000    |
| train/                  |            |
|    approx_kl            | 0.19003044 |
|    clip_fraction        | 0.677      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.45       |
|    explained_variance   | 0.319      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0834    |
|    n_updates            | 6340       |
|    policy_gradient_loss | -0.0153    |
|    std                  | 0.0846     |
|    value_loss           | 0.00517    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 977      |
|    ep_rew_mean     | 3.73e+03 |
| time/              |          |
|    fps             | 154      |
|    iterations      | 635      |
|    time_elapsed    | 8418     |
|    total_timesteps | 1300480  |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 977       |
|    ep_rew_mean          | 3.68e+03  |
| time/                   |           |
|    fps                  | 154       |
|    iterations           | 636       |
|    time_elapsed         | 8428      |
|    total_timesteps      | 1302528   |
| train/                  |           |
|    approx_kl            | 0.2010985 |
|    clip_fraction        | 0.681     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.43      |
|    explained_variance   | 0.974     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0293   |
|    n_updates            | 6350      |
|    policy_gradient_loss | -0.0138   |
|    std                  | 0.0849    |
|    value_loss           | 0.0119    |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 977        |
|    ep_rew_mean          | 3.68e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 637        |
|    time_elapsed         | 8438       |
|    total_timesteps      | 1304576    |
| train/                  |            |
|    approx_kl            | 0.17220746 |
|    clip_fraction        | 0.639      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.42       |
|    explained_variance   | 0.987      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0457    |
|    n_updates            | 6360       |
|    policy_gradient_loss | -0.0129    |
|    std                  | 0.0848     |
|    value_loss           | 0.0085     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 977       |
|    ep_rew_mean          | 3.71e+03  |
| time/                   |           |
|    fps                  | 154       |
|    iterations           | 638       |
|    time_elapsed         | 8447      |
|    total_timesteps      | 1306624   |
| train/                  |           |
|    approx_kl            | 0.2196819 |
|    clip_fraction        | 0.684     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.41      |
|    explained_variance   | 0.402     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0454   |
|    n_updates            | 6370      |
|    policy_gradient_loss | -0.0229   |
|    std                  | 0.0851    |
|    value_loss           | 0.00623   |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 977        |
|    ep_rew_mean          | 3.71e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 639        |
|    time_elapsed         | 8457       |
|    total_timesteps      | 1308672    |
| train/                  |            |
|    approx_kl            | 0.17006399 |
|    clip_fraction        | 0.668      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.4        |
|    explained_variance   | 0.505      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0768    |
|    n_updates            | 6380       |
|    policy_gradient_loss | -0.0284    |
|    std                  | 0.085      |
|    value_loss           | 0.00414    |
----------------------------------------
Eval num_timesteps=1310000, episode_reward=4011.56 +/- 647.12
Episode length: 968.92 +/- 93.91
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 969        |
|    mean_reward          | 4.01e+03   |
| time/                   |            |
|    total_timesteps      | 1310000    |
| train/                  |            |
|    approx_kl            | 0.19164217 |
|    clip_fraction        | 0.674      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.4        |
|    explained_variance   | 0.678      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.052     |
|    n_updates            | 6390       |
|    policy_gradient_loss | -0.0193    |
|    std                  | 0.0852     |
|    value_loss           | 0.00304    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 986      |
|    ep_rew_mean     | 3.75e+03 |
| time/              |          |
|    fps             | 154      |
|    iterations      | 640      |
|    time_elapsed    | 8487     |
|    total_timesteps | 1310720  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 989        |
|    ep_rew_mean          | 3.75e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 641        |
|    time_elapsed         | 8496       |
|    total_timesteps      | 1312768    |
| train/                  |            |
|    approx_kl            | 0.17084718 |
|    clip_fraction        | 0.675      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.36       |
|    explained_variance   | 0.883      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0656    |
|    n_updates            | 6400       |
|    policy_gradient_loss | -0.0135    |
|    std                  | 0.0857     |
|    value_loss           | 0.0117     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 989        |
|    ep_rew_mean          | 3.77e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 642        |
|    time_elapsed         | 8506       |
|    total_timesteps      | 1314816    |
| train/                  |            |
|    approx_kl            | 0.69193506 |
|    clip_fraction        | 0.676      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.35       |
|    explained_variance   | 0.99       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.052     |
|    n_updates            | 6410       |
|    policy_gradient_loss | -0.017     |
|    std                  | 0.0857     |
|    value_loss           | 0.00416    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 989        |
|    ep_rew_mean          | 3.8e+03    |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 643        |
|    time_elapsed         | 8515       |
|    total_timesteps      | 1316864    |
| train/                  |            |
|    approx_kl            | 0.19460717 |
|    clip_fraction        | 0.676      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.35       |
|    explained_variance   | 0.712      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00571    |
|    n_updates            | 6420       |
|    policy_gradient_loss | -0.0189    |
|    std                  | 0.0856     |
|    value_loss           | 0.00469    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 973        |
|    ep_rew_mean          | 3.74e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 644        |
|    time_elapsed         | 8524       |
|    total_timesteps      | 1318912    |
| train/                  |            |
|    approx_kl            | 0.18687671 |
|    clip_fraction        | 0.685      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.37       |
|    explained_variance   | 0.582      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.018     |
|    n_updates            | 6430       |
|    policy_gradient_loss | -0.0225    |
|    std                  | 0.0856     |
|    value_loss           | 0.00565    |
----------------------------------------
Eval num_timesteps=1320000, episode_reward=3338.04 +/- 1112.60
Episode length: 863.24 +/- 265.37
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 863       |
|    mean_reward          | 3.34e+03  |
| time/                   |           |
|    total_timesteps      | 1320000   |
| train/                  |           |
|    approx_kl            | 0.1474506 |
|    clip_fraction        | 0.659     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.36      |
|    explained_variance   | 0.911     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0354   |
|    n_updates            | 6440      |
|    policy_gradient_loss | -0.0146   |
|    std                  | 0.0855    |
|    value_loss           | 0.0443    |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 973      |
|    ep_rew_mean     | 3.67e+03 |
| time/              |          |
|    fps             | 154      |
|    iterations      | 645      |
|    time_elapsed    | 8554     |
|    total_timesteps | 1320960  |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 973       |
|    ep_rew_mean          | 3.66e+03  |
| time/                   |           |
|    fps                  | 154       |
|    iterations           | 646       |
|    time_elapsed         | 8563      |
|    total_timesteps      | 1323008   |
| train/                  |           |
|    approx_kl            | 4.9093733 |
|    clip_fraction        | 0.765     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.39      |
|    explained_variance   | 0.984     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.033    |
|    n_updates            | 6450      |
|    policy_gradient_loss | -0.0215   |
|    std                  | 0.0848    |
|    value_loss           | 0.0102    |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 973        |
|    ep_rew_mean          | 3.66e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 647        |
|    time_elapsed         | 8573       |
|    total_timesteps      | 1325056    |
| train/                  |            |
|    approx_kl            | 0.21327682 |
|    clip_fraction        | 0.682      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.43       |
|    explained_variance   | 0.939      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.031     |
|    n_updates            | 6460       |
|    policy_gradient_loss | -0.0172    |
|    std                  | 0.0849     |
|    value_loss           | 0.0317     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 973        |
|    ep_rew_mean          | 3.66e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 648        |
|    time_elapsed         | 8582       |
|    total_timesteps      | 1327104    |
| train/                  |            |
|    approx_kl            | 0.19964652 |
|    clip_fraction        | 0.699      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.42       |
|    explained_variance   | 0.204      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0547    |
|    n_updates            | 6470       |
|    policy_gradient_loss | -0.0113    |
|    std                  | 0.0851     |
|    value_loss           | 0.00646    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 973        |
|    ep_rew_mean          | 3.66e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 649        |
|    time_elapsed         | 8592       |
|    total_timesteps      | 1329152    |
| train/                  |            |
|    approx_kl            | 0.18665716 |
|    clip_fraction        | 0.675      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.41       |
|    explained_variance   | 0.588      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0478    |
|    n_updates            | 6480       |
|    policy_gradient_loss | -0.0202    |
|    std                  | 0.0851     |
|    value_loss           | 0.00385    |
----------------------------------------
Eval num_timesteps=1330000, episode_reward=3971.16 +/- 424.39
Episode length: 998.24 +/- 8.62
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 998        |
|    mean_reward          | 3.97e+03   |
| time/                   |            |
|    total_timesteps      | 1330000    |
| train/                  |            |
|    approx_kl            | 0.16976762 |
|    clip_fraction        | 0.666      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.42       |
|    explained_variance   | 0.614      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0394    |
|    n_updates            | 6490       |
|    policy_gradient_loss | -0.0143    |
|    std                  | 0.0848     |
|    value_loss           | 0.0113     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 973      |
|    ep_rew_mean     | 3.66e+03 |
| time/              |          |
|    fps             | 154      |
|    iterations      | 650      |
|    time_elapsed    | 8621     |
|    total_timesteps | 1331200  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 973        |
|    ep_rew_mean          | 3.64e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 651        |
|    time_elapsed         | 8631       |
|    total_timesteps      | 1333248    |
| train/                  |            |
|    approx_kl            | 0.21022585 |
|    clip_fraction        | 0.665      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.43       |
|    explained_variance   | 0.985      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0519    |
|    n_updates            | 6500       |
|    policy_gradient_loss | -0.00764   |
|    std                  | 0.0849     |
|    value_loss           | 0.00972    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 973        |
|    ep_rew_mean          | 3.64e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 652        |
|    time_elapsed         | 8640       |
|    total_timesteps      | 1335296    |
| train/                  |            |
|    approx_kl            | 0.32593673 |
|    clip_fraction        | 0.694      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.44       |
|    explained_variance   | 0.98       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0251    |
|    n_updates            | 6510       |
|    policy_gradient_loss | -0.025     |
|    std                  | 0.0846     |
|    value_loss           | 0.00346    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 973        |
|    ep_rew_mean          | 3.61e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 653        |
|    time_elapsed         | 8650       |
|    total_timesteps      | 1337344    |
| train/                  |            |
|    approx_kl            | 0.19018008 |
|    clip_fraction        | 0.68       |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.44       |
|    explained_variance   | 0.574      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0466    |
|    n_updates            | 6520       |
|    policy_gradient_loss | -0.0208    |
|    std                  | 0.0848     |
|    value_loss           | 0.00317    |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 961       |
|    ep_rew_mean          | 3.57e+03  |
| time/                   |           |
|    fps                  | 154       |
|    iterations           | 654       |
|    time_elapsed         | 8659      |
|    total_timesteps      | 1339392   |
| train/                  |           |
|    approx_kl            | 0.2956059 |
|    clip_fraction        | 0.651     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.45      |
|    explained_variance   | 0.98      |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0759   |
|    n_updates            | 6530      |
|    policy_gradient_loss | -0.0176   |
|    std                  | 0.0845    |
|    value_loss           | 0.0115    |
---------------------------------------
Eval num_timesteps=1340000, episode_reward=3689.19 +/- 1053.69
Episode length: 953.12 +/- 188.03
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 953        |
|    mean_reward          | 3.69e+03   |
| time/                   |            |
|    total_timesteps      | 1340000    |
| train/                  |            |
|    approx_kl            | 0.16365223 |
|    clip_fraction        | 0.692      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.48       |
|    explained_variance   | 0.431      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0327    |
|    n_updates            | 6540       |
|    policy_gradient_loss | -0.00566   |
|    std                  | 0.0843     |
|    value_loss           | 0.0316     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 961      |
|    ep_rew_mean     | 3.53e+03 |
| time/              |          |
|    fps             | 154      |
|    iterations      | 655      |
|    time_elapsed    | 8689     |
|    total_timesteps | 1341440  |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 961       |
|    ep_rew_mean          | 3.52e+03  |
| time/                   |           |
|    fps                  | 154       |
|    iterations           | 656       |
|    time_elapsed         | 8698      |
|    total_timesteps      | 1343488   |
| train/                  |           |
|    approx_kl            | 0.2656018 |
|    clip_fraction        | 0.69      |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.49      |
|    explained_variance   | 0.969     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0562   |
|    n_updates            | 6550      |
|    policy_gradient_loss | -0.0162   |
|    std                  | 0.0842    |
|    value_loss           | 0.0224    |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 957        |
|    ep_rew_mean          | 3.51e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 657        |
|    time_elapsed         | 8708       |
|    total_timesteps      | 1345536    |
| train/                  |            |
|    approx_kl            | 0.22807191 |
|    clip_fraction        | 0.701      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.49       |
|    explained_variance   | 0.959      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0315    |
|    n_updates            | 6560       |
|    policy_gradient_loss | -0.00561   |
|    std                  | 0.0843     |
|    value_loss           | 0.0178     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 957        |
|    ep_rew_mean          | 3.49e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 658        |
|    time_elapsed         | 8717       |
|    total_timesteps      | 1347584    |
| train/                  |            |
|    approx_kl            | 0.18406487 |
|    clip_fraction        | 0.677      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.49       |
|    explained_variance   | 0.303      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0292    |
|    n_updates            | 6570       |
|    policy_gradient_loss | -0.0149    |
|    std                  | 0.0841     |
|    value_loss           | 0.0201     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 957        |
|    ep_rew_mean          | 3.5e+03    |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 659        |
|    time_elapsed         | 8726       |
|    total_timesteps      | 1349632    |
| train/                  |            |
|    approx_kl            | 0.15951112 |
|    clip_fraction        | 0.673      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.51       |
|    explained_variance   | 0.978      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0551    |
|    n_updates            | 6580       |
|    policy_gradient_loss | -0.0122    |
|    std                  | 0.0841     |
|    value_loss           | 0.014      |
----------------------------------------
Eval num_timesteps=1350000, episode_reward=3502.25 +/- 1117.21
Episode length: 964.52 +/- 147.45
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 965        |
|    mean_reward          | 3.5e+03    |
| time/                   |            |
|    total_timesteps      | 1350000    |
| train/                  |            |
|    approx_kl            | 0.17101215 |
|    clip_fraction        | 0.678      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.5        |
|    explained_variance   | 0.979      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0102    |
|    n_updates            | 6590       |
|    policy_gradient_loss | -0.0147    |
|    std                  | 0.0844     |
|    value_loss           | 0.0136     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 953      |
|    ep_rew_mean     | 3.46e+03 |
| time/              |          |
|    fps             | 154      |
|    iterations      | 660      |
|    time_elapsed    | 8756     |
|    total_timesteps | 1351680  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 953        |
|    ep_rew_mean          | 3.45e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 661        |
|    time_elapsed         | 8766       |
|    total_timesteps      | 1353728    |
| train/                  |            |
|    approx_kl            | 0.19474511 |
|    clip_fraction        | 0.675      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.48       |
|    explained_variance   | 0.912      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0222    |
|    n_updates            | 6600       |
|    policy_gradient_loss | -0.0164    |
|    std                  | 0.0845     |
|    value_loss           | 0.0234     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 953        |
|    ep_rew_mean          | 3.45e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 662        |
|    time_elapsed         | 8775       |
|    total_timesteps      | 1355776    |
| train/                  |            |
|    approx_kl            | 0.20885658 |
|    clip_fraction        | 0.685      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.46       |
|    explained_variance   | 0.961      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.028     |
|    n_updates            | 6610       |
|    policy_gradient_loss | -0.0209    |
|    std                  | 0.0847     |
|    value_loss           | 0.0191     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 953        |
|    ep_rew_mean          | 3.42e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 663        |
|    time_elapsed         | 8784       |
|    total_timesteps      | 1357824    |
| train/                  |            |
|    approx_kl            | 0.17989255 |
|    clip_fraction        | 0.69       |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.45       |
|    explained_variance   | 0.952      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0435    |
|    n_updates            | 6620       |
|    policy_gradient_loss | -0.0153    |
|    std                  | 0.0846     |
|    value_loss           | 0.0126     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 946       |
|    ep_rew_mean          | 3.39e+03  |
| time/                   |           |
|    fps                  | 154       |
|    iterations           | 664       |
|    time_elapsed         | 8794      |
|    total_timesteps      | 1359872   |
| train/                  |           |
|    approx_kl            | 0.1933913 |
|    clip_fraction        | 0.694     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.47      |
|    explained_variance   | 0.997     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0016   |
|    n_updates            | 6630      |
|    policy_gradient_loss | -0.0103   |
|    std                  | 0.0846    |
|    value_loss           | 0.00253   |
---------------------------------------
Eval num_timesteps=1360000, episode_reward=3451.49 +/- 1152.75
Episode length: 865.48 +/- 260.73
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 865        |
|    mean_reward          | 3.45e+03   |
| time/                   |            |
|    total_timesteps      | 1360000    |
| train/                  |            |
|    approx_kl            | 0.17084059 |
|    clip_fraction        | 0.695      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.46       |
|    explained_variance   | 0.313      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0402    |
|    n_updates            | 6640       |
|    policy_gradient_loss | -0.00338   |
|    std                  | 0.0845     |
|    value_loss           | 0.0198     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 942      |
|    ep_rew_mean     | 3.37e+03 |
| time/              |          |
|    fps             | 154      |
|    iterations      | 665      |
|    time_elapsed    | 8824     |
|    total_timesteps | 1361920  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 942        |
|    ep_rew_mean          | 3.37e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 666        |
|    time_elapsed         | 8833       |
|    total_timesteps      | 1363968    |
| train/                  |            |
|    approx_kl            | 0.22542162 |
|    clip_fraction        | 0.68       |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.46       |
|    explained_variance   | 0.727      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0665    |
|    n_updates            | 6650       |
|    policy_gradient_loss | -0.0155    |
|    std                  | 0.0845     |
|    value_loss           | 0.0258     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 942        |
|    ep_rew_mean          | 3.37e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 667        |
|    time_elapsed         | 8842       |
|    total_timesteps      | 1366016    |
| train/                  |            |
|    approx_kl            | 0.18882918 |
|    clip_fraction        | 0.678      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.49       |
|    explained_variance   | 0.54       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0623    |
|    n_updates            | 6660       |
|    policy_gradient_loss | -0.0263    |
|    std                  | 0.0842     |
|    value_loss           | 0.00539    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 942        |
|    ep_rew_mean          | 3.38e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 668        |
|    time_elapsed         | 8852       |
|    total_timesteps      | 1368064    |
| train/                  |            |
|    approx_kl            | 0.24313653 |
|    clip_fraction        | 0.696      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.49       |
|    explained_variance   | 0.34       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0102     |
|    n_updates            | 6670       |
|    policy_gradient_loss | -0.0252    |
|    std                  | 0.0844     |
|    value_loss           | 0.00577    |
----------------------------------------
Eval num_timesteps=1370000, episode_reward=3246.63 +/- 1378.48
Episode length: 933.52 +/- 196.51
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 934        |
|    mean_reward          | 3.25e+03   |
| time/                   |            |
|    total_timesteps      | 1370000    |
| train/                  |            |
|    approx_kl            | 0.17790149 |
|    clip_fraction        | 0.671      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.48       |
|    explained_variance   | 0.598      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0898    |
|    n_updates            | 6680       |
|    policy_gradient_loss | -0.0237    |
|    std                  | 0.0842     |
|    value_loss           | 0.00452    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 942      |
|    ep_rew_mean     | 3.38e+03 |
| time/              |          |
|    fps             | 154      |
|    iterations      | 669      |
|    time_elapsed    | 8881     |
|    total_timesteps | 1370112  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 942        |
|    ep_rew_mean          | 3.4e+03    |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 670        |
|    time_elapsed         | 8891       |
|    total_timesteps      | 1372160    |
| train/                  |            |
|    approx_kl            | 0.18969342 |
|    clip_fraction        | 0.663      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.49       |
|    explained_variance   | 0.609      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00471    |
|    n_updates            | 6690       |
|    policy_gradient_loss | -0.0146    |
|    std                  | 0.0844     |
|    value_loss           | 0.00366    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 943        |
|    ep_rew_mean          | 3.41e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 671        |
|    time_elapsed         | 8900       |
|    total_timesteps      | 1374208    |
| train/                  |            |
|    approx_kl            | 0.18515877 |
|    clip_fraction        | 0.667      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.48       |
|    explained_variance   | 0.651      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0126    |
|    n_updates            | 6700       |
|    policy_gradient_loss | -0.0187    |
|    std                  | 0.0843     |
|    value_loss           | 0.00462    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 943        |
|    ep_rew_mean          | 3.41e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 672        |
|    time_elapsed         | 8910       |
|    total_timesteps      | 1376256    |
| train/                  |            |
|    approx_kl            | 0.21094549 |
|    clip_fraction        | 0.674      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.48       |
|    explained_variance   | 0.492      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0755    |
|    n_updates            | 6710       |
|    policy_gradient_loss | -0.0254    |
|    std                  | 0.0845     |
|    value_loss           | 0.00445    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 943        |
|    ep_rew_mean          | 3.39e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 673        |
|    time_elapsed         | 8919       |
|    total_timesteps      | 1378304    |
| train/                  |            |
|    approx_kl            | 0.20114887 |
|    clip_fraction        | 0.682      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.47       |
|    explained_variance   | 0.944      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0538    |
|    n_updates            | 6720       |
|    policy_gradient_loss | -0.0132    |
|    std                  | 0.0846     |
|    value_loss           | 0.0176     |
----------------------------------------
Eval num_timesteps=1380000, episode_reward=2857.35 +/- 1293.88
Episode length: 904.16 +/- 207.30
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 904        |
|    mean_reward          | 2.86e+03   |
| time/                   |            |
|    total_timesteps      | 1380000    |
| train/                  |            |
|    approx_kl            | 0.19808632 |
|    clip_fraction        | 0.68       |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.48       |
|    explained_variance   | 0.756      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0635    |
|    n_updates            | 6730       |
|    policy_gradient_loss | -0.0179    |
|    std                  | 0.0844     |
|    value_loss           | 0.00643    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 943      |
|    ep_rew_mean     | 3.36e+03 |
| time/              |          |
|    fps             | 154      |
|    iterations      | 674      |
|    time_elapsed    | 8954     |
|    total_timesteps | 1380352  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 947        |
|    ep_rew_mean          | 3.37e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 675        |
|    time_elapsed         | 8966       |
|    total_timesteps      | 1382400    |
| train/                  |            |
|    approx_kl            | 0.19275573 |
|    clip_fraction        | 0.66       |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.5        |
|    explained_variance   | 0.986      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0423    |
|    n_updates            | 6740       |
|    policy_gradient_loss | -0.0158    |
|    std                  | 0.084      |
|    value_loss           | 0.00875    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 947        |
|    ep_rew_mean          | 3.36e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 676        |
|    time_elapsed         | 8975       |
|    total_timesteps      | 1384448    |
| train/                  |            |
|    approx_kl            | 0.18772003 |
|    clip_fraction        | 0.677      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.52       |
|    explained_variance   | 0.527      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0137     |
|    n_updates            | 6750       |
|    policy_gradient_loss | -0.0243    |
|    std                  | 0.0841     |
|    value_loss           | 0.00513    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 953        |
|    ep_rew_mean          | 3.35e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 677        |
|    time_elapsed         | 8985       |
|    total_timesteps      | 1386496    |
| train/                  |            |
|    approx_kl            | 0.22367938 |
|    clip_fraction        | 0.691      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.53       |
|    explained_variance   | 0.511      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0866    |
|    n_updates            | 6760       |
|    policy_gradient_loss | -0.0201    |
|    std                  | 0.0839     |
|    value_loss           | 0.00665    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 953        |
|    ep_rew_mean          | 3.31e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 678        |
|    time_elapsed         | 8995       |
|    total_timesteps      | 1388544    |
| train/                  |            |
|    approx_kl            | 0.21497294 |
|    clip_fraction        | 0.68       |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.52       |
|    explained_variance   | 0.985      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0208    |
|    n_updates            | 6770       |
|    policy_gradient_loss | -0.015     |
|    std                  | 0.0839     |
|    value_loss           | 0.00934    |
----------------------------------------
Eval num_timesteps=1390000, episode_reward=2803.21 +/- 1393.18
Episode length: 928.80 +/- 197.87
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 929        |
|    mean_reward          | 2.8e+03    |
| time/                   |            |
|    total_timesteps      | 1390000    |
| train/                  |            |
|    approx_kl            | 0.16671295 |
|    clip_fraction        | 0.653      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.54       |
|    explained_variance   | 0.979      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0209    |
|    n_updates            | 6780       |
|    policy_gradient_loss | -0.0101    |
|    std                  | 0.0837     |
|    value_loss           | 0.0162     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 953      |
|    ep_rew_mean     | 3.34e+03 |
| time/              |          |
|    fps             | 154      |
|    iterations      | 679      |
|    time_elapsed    | 9025     |
|    total_timesteps | 1390592  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 953        |
|    ep_rew_mean          | 3.32e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 680        |
|    time_elapsed         | 9034       |
|    total_timesteps      | 1392640    |
| train/                  |            |
|    approx_kl            | 0.20306487 |
|    clip_fraction        | 0.695      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.52       |
|    explained_variance   | 0.892      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.103     |
|    n_updates            | 6790       |
|    policy_gradient_loss | -0.0192    |
|    std                  | 0.0841     |
|    value_loss           | 0.0176     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 936        |
|    ep_rew_mean          | 3.28e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 681        |
|    time_elapsed         | 9044       |
|    total_timesteps      | 1394688    |
| train/                  |            |
|    approx_kl            | 0.23992454 |
|    clip_fraction        | 0.687      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.53       |
|    explained_variance   | 0.967      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0265    |
|    n_updates            | 6800       |
|    policy_gradient_loss | -0.0125    |
|    std                  | 0.0838     |
|    value_loss           | 0.0129     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 936       |
|    ep_rew_mean          | 3.3e+03   |
| time/                   |           |
|    fps                  | 154       |
|    iterations           | 682       |
|    time_elapsed         | 9054      |
|    total_timesteps      | 1396736   |
| train/                  |           |
|    approx_kl            | 0.1829601 |
|    clip_fraction        | 0.675     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.55      |
|    explained_variance   | 0.856     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.00364  |
|    n_updates            | 6810      |
|    policy_gradient_loss | -0.00923  |
|    std                  | 0.0834    |
|    value_loss           | 0.0433    |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 936        |
|    ep_rew_mean          | 3.27e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 683        |
|    time_elapsed         | 9063       |
|    total_timesteps      | 1398784    |
| train/                  |            |
|    approx_kl            | 0.20505874 |
|    clip_fraction        | 0.688      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.6        |
|    explained_variance   | 0.287      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0656    |
|    n_updates            | 6820       |
|    policy_gradient_loss | -0.0238    |
|    std                  | 0.0831     |
|    value_loss           | 0.0054     |
----------------------------------------
Eval num_timesteps=1400000, episode_reward=3513.45 +/- 1118.81
Episode length: 952.24 +/- 163.91
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 952        |
|    mean_reward          | 3.51e+03   |
| time/                   |            |
|    total_timesteps      | 1400000    |
| train/                  |            |
|    approx_kl            | 0.20371068 |
|    clip_fraction        | 0.682      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.6        |
|    explained_variance   | 0.987      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0576    |
|    n_updates            | 6830       |
|    policy_gradient_loss | -0.0117    |
|    std                  | 0.083      |
|    value_loss           | 0.0112     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 936      |
|    ep_rew_mean     | 3.24e+03 |
| time/              |          |
|    fps             | 154      |
|    iterations      | 684      |
|    time_elapsed    | 9095     |
|    total_timesteps | 1400832  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 936        |
|    ep_rew_mean          | 3.24e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 685        |
|    time_elapsed         | 9105       |
|    total_timesteps      | 1402880    |
| train/                  |            |
|    approx_kl            | 0.17604528 |
|    clip_fraction        | 0.665      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.62       |
|    explained_variance   | 0.989      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00842   |
|    n_updates            | 6840       |
|    policy_gradient_loss | -0.00922   |
|    std                  | 0.0827     |
|    value_loss           | 0.00863    |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 936       |
|    ep_rew_mean          | 3.25e+03  |
| time/                   |           |
|    fps                  | 154       |
|    iterations           | 686       |
|    time_elapsed         | 9114      |
|    total_timesteps      | 1404928   |
| train/                  |           |
|    approx_kl            | 0.2026723 |
|    clip_fraction        | 0.698     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.63      |
|    explained_variance   | 0.0877    |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0924   |
|    n_updates            | 6850      |
|    policy_gradient_loss | -0.0181   |
|    std                  | 0.0829    |
|    value_loss           | 0.00366   |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 936        |
|    ep_rew_mean          | 3.22e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 687        |
|    time_elapsed         | 9124       |
|    total_timesteps      | 1406976    |
| train/                  |            |
|    approx_kl            | 0.19276187 |
|    clip_fraction        | 0.688      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.59       |
|    explained_variance   | 0.715      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0268    |
|    n_updates            | 6860       |
|    policy_gradient_loss | -0.0245    |
|    std                  | 0.0834     |
|    value_loss           | 0.0126     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 936        |
|    ep_rew_mean          | 3.2e+03    |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 688        |
|    time_elapsed         | 9134       |
|    total_timesteps      | 1409024    |
| train/                  |            |
|    approx_kl            | 0.19318129 |
|    clip_fraction        | 0.683      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.57       |
|    explained_variance   | 0.996      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0331    |
|    n_updates            | 6870       |
|    policy_gradient_loss | -0.0145    |
|    std                  | 0.0836     |
|    value_loss           | 0.00283    |
----------------------------------------
Eval num_timesteps=1410000, episode_reward=3830.85 +/- 849.96
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 3.83e+03   |
| time/                   |            |
|    total_timesteps      | 1410000    |
| train/                  |            |
|    approx_kl            | 0.22184971 |
|    clip_fraction        | 0.685      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.55       |
|    explained_variance   | 0.974      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0298    |
|    n_updates            | 6880       |
|    policy_gradient_loss | -0.0215    |
|    std                  | 0.0836     |
|    value_loss           | 0.0117     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 930      |
|    ep_rew_mean     | 3.18e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 689      |
|    time_elapsed    | 9164     |
|    total_timesteps | 1411072  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 938        |
|    ep_rew_mean          | 3.23e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 690        |
|    time_elapsed         | 9173       |
|    total_timesteps      | 1413120    |
| train/                  |            |
|    approx_kl            | 0.18604003 |
|    clip_fraction        | 0.688      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.54       |
|    explained_variance   | 0.4        |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0246    |
|    n_updates            | 6890       |
|    policy_gradient_loss | -0.0133    |
|    std                  | 0.0837     |
|    value_loss           | 0.0161     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 938        |
|    ep_rew_mean          | 3.27e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 691        |
|    time_elapsed         | 9183       |
|    total_timesteps      | 1415168    |
| train/                  |            |
|    approx_kl            | 0.17326567 |
|    clip_fraction        | 0.676      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.55       |
|    explained_variance   | 0.599      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0477    |
|    n_updates            | 6900       |
|    policy_gradient_loss | -0.0149    |
|    std                  | 0.0836     |
|    value_loss           | 0.0139     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 938        |
|    ep_rew_mean          | 3.28e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 692        |
|    time_elapsed         | 9192       |
|    total_timesteps      | 1417216    |
| train/                  |            |
|    approx_kl            | 0.21376121 |
|    clip_fraction        | 0.701      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.54       |
|    explained_variance   | -0.237     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0548    |
|    n_updates            | 6910       |
|    policy_gradient_loss | -0.0156    |
|    std                  | 0.084      |
|    value_loss           | 0.00507    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 933        |
|    ep_rew_mean          | 3.26e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 693        |
|    time_elapsed         | 9202       |
|    total_timesteps      | 1419264    |
| train/                  |            |
|    approx_kl            | 0.18105961 |
|    clip_fraction        | 0.662      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.53       |
|    explained_variance   | 0.545      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0184    |
|    n_updates            | 6920       |
|    policy_gradient_loss | -0.0206    |
|    std                  | 0.0839     |
|    value_loss           | 0.00362    |
----------------------------------------
Eval num_timesteps=1420000, episode_reward=3957.85 +/- 754.49
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 3.96e+03   |
| time/                   |            |
|    total_timesteps      | 1420000    |
| train/                  |            |
|    approx_kl            | 0.18773876 |
|    clip_fraction        | 0.682      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.5        |
|    explained_variance   | 0.423      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0585    |
|    n_updates            | 6930       |
|    policy_gradient_loss | -0.00948   |
|    std                  | 0.0842     |
|    value_loss           | 0.0166     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 933      |
|    ep_rew_mean     | 3.26e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 694      |
|    time_elapsed    | 9232     |
|    total_timesteps | 1421312  |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 933       |
|    ep_rew_mean          | 3.25e+03  |
| time/                   |           |
|    fps                  | 154       |
|    iterations           | 695       |
|    time_elapsed         | 9241      |
|    total_timesteps      | 1423360   |
| train/                  |           |
|    approx_kl            | 0.1638118 |
|    clip_fraction        | 0.67      |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.48      |
|    explained_variance   | 0.956     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0414   |
|    n_updates            | 6940      |
|    policy_gradient_loss | -0.016    |
|    std                  | 0.0844    |
|    value_loss           | 0.0157    |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 933        |
|    ep_rew_mean          | 3.28e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 696        |
|    time_elapsed         | 9251       |
|    total_timesteps      | 1425408    |
| train/                  |            |
|    approx_kl            | 0.18556646 |
|    clip_fraction        | 0.664      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.48       |
|    explained_variance   | 0.989      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0521    |
|    n_updates            | 6950       |
|    policy_gradient_loss | -0.0233    |
|    std                  | 0.0843     |
|    value_loss           | 0.00528    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 931        |
|    ep_rew_mean          | 3.28e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 697        |
|    time_elapsed         | 9260       |
|    total_timesteps      | 1427456    |
| train/                  |            |
|    approx_kl            | 0.19492337 |
|    clip_fraction        | 0.681      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.45       |
|    explained_variance   | 0.319      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.024     |
|    n_updates            | 6960       |
|    policy_gradient_loss | -0.0138    |
|    std                  | 0.0849     |
|    value_loss           | 0.00463    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 931        |
|    ep_rew_mean          | 3.28e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 698        |
|    time_elapsed         | 9269       |
|    total_timesteps      | 1429504    |
| train/                  |            |
|    approx_kl            | 0.17520072 |
|    clip_fraction        | 0.674      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.42       |
|    explained_variance   | 0.432      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0478    |
|    n_updates            | 6970       |
|    policy_gradient_loss | -0.0151    |
|    std                  | 0.0849     |
|    value_loss           | 0.0224     |
----------------------------------------
Eval num_timesteps=1430000, episode_reward=4002.96 +/- 763.91
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 4e+03      |
| time/                   |            |
|    total_timesteps      | 1430000    |
| train/                  |            |
|    approx_kl            | 0.18487212 |
|    clip_fraction        | 0.685      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.42       |
|    explained_variance   | 0.314      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0668    |
|    n_updates            | 6980       |
|    policy_gradient_loss | -0.0197    |
|    std                  | 0.085      |
|    value_loss           | 0.00406    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 936      |
|    ep_rew_mean     | 3.31e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 699      |
|    time_elapsed    | 9299     |
|    total_timesteps | 1431552  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 943        |
|    ep_rew_mean          | 3.34e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 700        |
|    time_elapsed         | 9308       |
|    total_timesteps      | 1433600    |
| train/                  |            |
|    approx_kl            | 0.15726914 |
|    clip_fraction        | 0.663      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.42       |
|    explained_variance   | 0.975      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0258    |
|    n_updates            | 6990       |
|    policy_gradient_loss | -0.0144    |
|    std                  | 0.0849     |
|    value_loss           | 0.0143     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 943        |
|    ep_rew_mean          | 3.37e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 701        |
|    time_elapsed         | 9318       |
|    total_timesteps      | 1435648    |
| train/                  |            |
|    approx_kl            | 0.19362026 |
|    clip_fraction        | 0.675      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.44       |
|    explained_variance   | 0.487      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0704    |
|    n_updates            | 7000       |
|    policy_gradient_loss | -0.0209    |
|    std                  | 0.0847     |
|    value_loss           | 0.00461    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 943        |
|    ep_rew_mean          | 3.39e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 702        |
|    time_elapsed         | 9327       |
|    total_timesteps      | 1437696    |
| train/                  |            |
|    approx_kl            | 0.16032419 |
|    clip_fraction        | 0.658      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.46       |
|    explained_variance   | 0.98       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00912   |
|    n_updates            | 7010       |
|    policy_gradient_loss | -0.015     |
|    std                  | 0.0843     |
|    value_loss           | 0.0137     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 947        |
|    ep_rew_mean          | 3.4e+03    |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 703        |
|    time_elapsed         | 9337       |
|    total_timesteps      | 1439744    |
| train/                  |            |
|    approx_kl            | 0.18814886 |
|    clip_fraction        | 0.679      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.51       |
|    explained_variance   | 0.574      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0547    |
|    n_updates            | 7020       |
|    policy_gradient_loss | -0.0147    |
|    std                  | 0.0838     |
|    value_loss           | 0.00485    |
----------------------------------------
Eval num_timesteps=1440000, episode_reward=4048.06 +/- 820.40
Episode length: 980.24 +/- 96.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 980        |
|    mean_reward          | 4.05e+03   |
| time/                   |            |
|    total_timesteps      | 1440000    |
| train/                  |            |
|    approx_kl            | 0.20556629 |
|    clip_fraction        | 0.683      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.52       |
|    explained_variance   | 0.625      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0526    |
|    n_updates            | 7030       |
|    policy_gradient_loss | -0.0183    |
|    std                  | 0.084      |
|    value_loss           | 0.00434    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 941      |
|    ep_rew_mean     | 3.38e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 704      |
|    time_elapsed    | 9366     |
|    total_timesteps | 1441792  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 941        |
|    ep_rew_mean          | 3.38e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 705        |
|    time_elapsed         | 9376       |
|    total_timesteps      | 1443840    |
| train/                  |            |
|    approx_kl            | 0.19526762 |
|    clip_fraction        | 0.66       |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.51       |
|    explained_variance   | 0.961      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0141     |
|    n_updates            | 7040       |
|    policy_gradient_loss | -0.0135    |
|    std                  | 0.0839     |
|    value_loss           | 0.0309     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 945        |
|    ep_rew_mean          | 3.38e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 706        |
|    time_elapsed         | 9385       |
|    total_timesteps      | 1445888    |
| train/                  |            |
|    approx_kl            | 0.18485205 |
|    clip_fraction        | 0.638      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.54       |
|    explained_variance   | 0.988      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0563    |
|    n_updates            | 7050       |
|    policy_gradient_loss | -0.0205    |
|    std                  | 0.0834     |
|    value_loss           | 0.011      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 945        |
|    ep_rew_mean          | 3.4e+03    |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 707        |
|    time_elapsed         | 9395       |
|    total_timesteps      | 1447936    |
| train/                  |            |
|    approx_kl            | 0.21455249 |
|    clip_fraction        | 0.705      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.54       |
|    explained_variance   | 0.876      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0593    |
|    n_updates            | 7060       |
|    policy_gradient_loss | -0.0174    |
|    std                  | 0.0838     |
|    value_loss           | 0.00823    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 945        |
|    ep_rew_mean          | 3.4e+03    |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 708        |
|    time_elapsed         | 9404       |
|    total_timesteps      | 1449984    |
| train/                  |            |
|    approx_kl            | 0.18680283 |
|    clip_fraction        | 0.667      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.53       |
|    explained_variance   | 0.552      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0118     |
|    n_updates            | 7070       |
|    policy_gradient_loss | -0.0208    |
|    std                  | 0.084      |
|    value_loss           | 0.00319    |
----------------------------------------
Eval num_timesteps=1450000, episode_reward=4138.45 +/- 693.95
Episode length: 977.20 +/- 111.70
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 977        |
|    mean_reward          | 4.14e+03   |
| time/                   |            |
|    total_timesteps      | 1450000    |
| train/                  |            |
|    approx_kl            | 0.21667719 |
|    clip_fraction        | 0.694      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.52       |
|    explained_variance   | 0.15       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0482    |
|    n_updates            | 7080       |
|    policy_gradient_loss | -0.0168    |
|    std                  | 0.0841     |
|    value_loss           | 0.00373    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 945      |
|    ep_rew_mean     | 3.43e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 709      |
|    time_elapsed    | 9434     |
|    total_timesteps | 1452032  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 945        |
|    ep_rew_mean          | 3.43e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 710        |
|    time_elapsed         | 9443       |
|    total_timesteps      | 1454080    |
| train/                  |            |
|    approx_kl            | 0.17828201 |
|    clip_fraction        | 0.669      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.48       |
|    explained_variance   | 0.578      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0511    |
|    n_updates            | 7090       |
|    policy_gradient_loss | -0.0219    |
|    std                  | 0.0847     |
|    value_loss           | 0.00334    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 952        |
|    ep_rew_mean          | 3.44e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 711        |
|    time_elapsed         | 9453       |
|    total_timesteps      | 1456128    |
| train/                  |            |
|    approx_kl            | 0.19081545 |
|    clip_fraction        | 0.67       |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.47       |
|    explained_variance   | 0.599      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0299    |
|    n_updates            | 7100       |
|    policy_gradient_loss | -0.0172    |
|    std                  | 0.0845     |
|    value_loss           | 0.00373    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 949        |
|    ep_rew_mean          | 3.43e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 712        |
|    time_elapsed         | 9462       |
|    total_timesteps      | 1458176    |
| train/                  |            |
|    approx_kl            | 0.18371105 |
|    clip_fraction        | 0.652      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.47       |
|    explained_variance   | 0.991      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0393    |
|    n_updates            | 7110       |
|    policy_gradient_loss | -0.00876   |
|    std                  | 0.0845     |
|    value_loss           | 0.00895    |
----------------------------------------
Eval num_timesteps=1460000, episode_reward=4219.28 +/- 287.76
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 4.22e+03   |
| time/                   |            |
|    total_timesteps      | 1460000    |
| train/                  |            |
|    approx_kl            | 0.16844988 |
|    clip_fraction        | 0.678      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.5        |
|    explained_variance   | 0.128      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0194    |
|    n_updates            | 7120       |
|    policy_gradient_loss | -0.013     |
|    std                  | 0.084      |
|    value_loss           | 0.0173     |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 949      |
|    ep_rew_mean     | 3.42e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 713      |
|    time_elapsed    | 9492     |
|    total_timesteps | 1460224  |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 949       |
|    ep_rew_mean          | 3.41e+03  |
| time/                   |           |
|    fps                  | 153       |
|    iterations           | 714       |
|    time_elapsed         | 9501      |
|    total_timesteps      | 1462272   |
| train/                  |           |
|    approx_kl            | 0.1701882 |
|    clip_fraction        | 0.652     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.54      |
|    explained_variance   | 0.967     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0129   |
|    n_updates            | 7130      |
|    policy_gradient_loss | -0.0114   |
|    std                  | 0.0835    |
|    value_loss           | 0.0282    |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 949        |
|    ep_rew_mean          | 3.41e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 715        |
|    time_elapsed         | 9510       |
|    total_timesteps      | 1464320    |
| train/                  |            |
|    approx_kl            | 0.21168701 |
|    clip_fraction        | 0.685      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.54       |
|    explained_variance   | 0.2        |
|    learning_rate        | 0.0003     |
|    loss                 | 0.000167   |
|    n_updates            | 7140       |
|    policy_gradient_loss | -0.014     |
|    std                  | 0.0838     |
|    value_loss           | 0.00808    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 949        |
|    ep_rew_mean          | 3.38e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 716        |
|    time_elapsed         | 9520       |
|    total_timesteps      | 1466368    |
| train/                  |            |
|    approx_kl            | 0.18608513 |
|    clip_fraction        | 0.67       |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.54       |
|    explained_variance   | 0.937      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0264    |
|    n_updates            | 7150       |
|    policy_gradient_loss | -0.0193    |
|    std                  | 0.0836     |
|    value_loss           | 0.014      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 949        |
|    ep_rew_mean          | 3.38e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 717        |
|    time_elapsed         | 9529       |
|    total_timesteps      | 1468416    |
| train/                  |            |
|    approx_kl            | 0.18810207 |
|    clip_fraction        | 0.668      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.57       |
|    explained_variance   | 0.998      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0246    |
|    n_updates            | 7160       |
|    policy_gradient_loss | -0.0123    |
|    std                  | 0.0835     |
|    value_loss           | 0.0024     |
----------------------------------------
Eval num_timesteps=1470000, episode_reward=3992.08 +/- 968.01
Episode length: 971.16 +/- 141.29
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 971        |
|    mean_reward          | 3.99e+03   |
| time/                   |            |
|    total_timesteps      | 1470000    |
| train/                  |            |
|    approx_kl            | 0.21576719 |
|    clip_fraction        | 0.674      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.57       |
|    explained_variance   | 0.555      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0486    |
|    n_updates            | 7170       |
|    policy_gradient_loss | -0.0107    |
|    std                  | 0.0838     |
|    value_loss           | 0.00477    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 949      |
|    ep_rew_mean     | 3.37e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 718      |
|    time_elapsed    | 9559     |
|    total_timesteps | 1470464  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 949        |
|    ep_rew_mean          | 3.38e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 719        |
|    time_elapsed         | 9568       |
|    total_timesteps      | 1472512    |
| train/                  |            |
|    approx_kl            | 0.17894587 |
|    clip_fraction        | 0.685      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.54       |
|    explained_variance   | 0.511      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0267    |
|    n_updates            | 7180       |
|    policy_gradient_loss | -0.0176    |
|    std                  | 0.0838     |
|    value_loss           | 0.00382    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 949        |
|    ep_rew_mean          | 3.39e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 720        |
|    time_elapsed         | 9578       |
|    total_timesteps      | 1474560    |
| train/                  |            |
|    approx_kl            | 0.16811419 |
|    clip_fraction        | 0.672      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.52       |
|    explained_variance   | 0.568      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0704    |
|    n_updates            | 7190       |
|    policy_gradient_loss | -0.0184    |
|    std                  | 0.0841     |
|    value_loss           | 0.00283    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 949        |
|    ep_rew_mean          | 3.41e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 721        |
|    time_elapsed         | 9587       |
|    total_timesteps      | 1476608    |
| train/                  |            |
|    approx_kl            | 0.17710035 |
|    clip_fraction        | 0.654      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.5        |
|    explained_variance   | 0.622      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0772    |
|    n_updates            | 7200       |
|    policy_gradient_loss | -0.0203    |
|    std                  | 0.0843     |
|    value_loss           | 0.00482    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 949        |
|    ep_rew_mean          | 3.41e+03   |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 722        |
|    time_elapsed         | 9597       |
|    total_timesteps      | 1478656    |
| train/                  |            |
|    approx_kl            | 0.24285379 |
|    clip_fraction        | 0.701      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.48       |
|    explained_variance   | 0.823      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0112    |
|    n_updates            | 7210       |
|    policy_gradient_loss | -0.0179    |
|    std                  | 0.0844     |
|    value_loss           | 0.0199     |
----------------------------------------
Eval num_timesteps=1480000, episode_reward=3746.37 +/- 1007.84
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 3.75e+03   |
| time/                   |            |
|    total_timesteps      | 1480000    |
| train/                  |            |
|    approx_kl            | 0.20854141 |
|    clip_fraction        | 0.672      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.49       |
|    explained_variance   | 0.967      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0169    |
|    n_updates            | 7220       |
|    policy_gradient_loss | -0.0127    |
|    std                  | 0.0842     |
|    value_loss           | 0.0209     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 949      |
|    ep_rew_mean     | 3.34e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 723      |
|    time_elapsed    | 9629     |
|    total_timesteps | 1480704  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 949        |
|    ep_rew_mean          | 3.4e+03    |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 724        |
|    time_elapsed         | 9639       |
|    total_timesteps      | 1482752    |
| train/                  |            |
|    approx_kl            | 0.11949022 |
|    clip_fraction        | 0.571      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.5        |
|    explained_variance   | 0.988      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0357    |
|    n_updates            | 7230       |
|    policy_gradient_loss | -0.0168    |
|    std                  | 0.0839     |
|    value_loss           | 0.00842    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 949        |
|    ep_rew_mean          | 3.42e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 725        |
|    time_elapsed         | 9649       |
|    total_timesteps      | 1484800    |
| train/                  |            |
|    approx_kl            | 0.21974261 |
|    clip_fraction        | 0.709      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.53       |
|    explained_variance   | 0.253      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0306    |
|    n_updates            | 7240       |
|    policy_gradient_loss | -0.0208    |
|    std                  | 0.0839     |
|    value_loss           | 0.00684    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 949        |
|    ep_rew_mean          | 3.44e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 726        |
|    time_elapsed         | 9659       |
|    total_timesteps      | 1486848    |
| train/                  |            |
|    approx_kl            | 0.20330954 |
|    clip_fraction        | 0.678      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.5        |
|    explained_variance   | -0.0428    |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0135    |
|    n_updates            | 7250       |
|    policy_gradient_loss | -0.0139    |
|    std                  | 0.0844     |
|    value_loss           | 0.00581    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 949        |
|    ep_rew_mean          | 3.44e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 727        |
|    time_elapsed         | 9668       |
|    total_timesteps      | 1488896    |
| train/                  |            |
|    approx_kl            | 0.18740267 |
|    clip_fraction        | 0.662      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.48       |
|    explained_variance   | 0.622      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0437    |
|    n_updates            | 7260       |
|    policy_gradient_loss | -0.0334    |
|    std                  | 0.0844     |
|    value_loss           | 0.00551    |
----------------------------------------
Eval num_timesteps=1490000, episode_reward=3728.51 +/- 1060.28
Episode length: 988.40 +/- 56.83
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 988        |
|    mean_reward          | 3.73e+03   |
| time/                   |            |
|    total_timesteps      | 1490000    |
| train/                  |            |
|    approx_kl            | 0.18112254 |
|    clip_fraction        | 0.667      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.49       |
|    explained_variance   | 0.57       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0987    |
|    n_updates            | 7270       |
|    policy_gradient_loss | -0.0252    |
|    std                  | 0.0843     |
|    value_loss           | 0.0031     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 957      |
|    ep_rew_mean     | 3.47e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 728      |
|    time_elapsed    | 9698     |
|    total_timesteps | 1490944  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 966        |
|    ep_rew_mean          | 3.5e+03    |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 729        |
|    time_elapsed         | 9709       |
|    total_timesteps      | 1492992    |
| train/                  |            |
|    approx_kl            | 0.18736808 |
|    clip_fraction        | 0.669      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.48       |
|    explained_variance   | 0.978      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0129    |
|    n_updates            | 7280       |
|    policy_gradient_loss | -0.0128    |
|    std                  | 0.0843     |
|    value_loss           | 0.0103     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 966        |
|    ep_rew_mean          | 3.53e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 730        |
|    time_elapsed         | 9719       |
|    total_timesteps      | 1495040    |
| train/                  |            |
|    approx_kl            | 0.19425279 |
|    clip_fraction        | 0.673      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.48       |
|    explained_variance   | 0.383      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0919    |
|    n_updates            | 7290       |
|    policy_gradient_loss | -0.0264    |
|    std                  | 0.0846     |
|    value_loss           | 0.00389    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 966        |
|    ep_rew_mean          | 3.55e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 731        |
|    time_elapsed         | 9728       |
|    total_timesteps      | 1497088    |
| train/                  |            |
|    approx_kl            | 0.22153647 |
|    clip_fraction        | 0.686      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.45       |
|    explained_variance   | 0.505      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0953    |
|    n_updates            | 7300       |
|    policy_gradient_loss | -0.0198    |
|    std                  | 0.0849     |
|    value_loss           | 0.00301    |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 966       |
|    ep_rew_mean          | 3.55e+03  |
| time/                   |           |
|    fps                  | 153       |
|    iterations           | 732       |
|    time_elapsed         | 9738      |
|    total_timesteps      | 1499136   |
| train/                  |           |
|    approx_kl            | 0.1723457 |
|    clip_fraction        | 0.661     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.44      |
|    explained_variance   | 0.989     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0313   |
|    n_updates            | 7310      |
|    policy_gradient_loss | -0.0209   |
|    std                  | 0.0847    |
|    value_loss           | 0.00588   |
---------------------------------------
Eval num_timesteps=1500000, episode_reward=3343.35 +/- 1251.21
Episode length: 906.28 +/- 216.31
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 906        |
|    mean_reward          | 3.34e+03   |
| time/                   |            |
|    total_timesteps      | 1500000    |
| train/                  |            |
|    approx_kl            | 0.20673695 |
|    clip_fraction        | 0.688      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.43       |
|    explained_variance   | 0.274      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0821    |
|    n_updates            | 7320       |
|    policy_gradient_loss | -0.0236    |
|    std                  | 0.0849     |
|    value_loss           | 0.00389    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 966      |
|    ep_rew_mean     | 3.56e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 733      |
|    time_elapsed    | 9768     |
|    total_timesteps | 1501184  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 966        |
|    ep_rew_mean          | 3.59e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 734        |
|    time_elapsed         | 9778       |
|    total_timesteps      | 1503232    |
| train/                  |            |
|    approx_kl            | 0.21239126 |
|    clip_fraction        | 0.675      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.41       |
|    explained_variance   | 0.529      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0684    |
|    n_updates            | 7330       |
|    policy_gradient_loss | -0.0203    |
|    std                  | 0.0852     |
|    value_loss           | 0.00293    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 966        |
|    ep_rew_mean          | 3.58e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 735        |
|    time_elapsed         | 9788       |
|    total_timesteps      | 1505280    |
| train/                  |            |
|    approx_kl            | 0.16724879 |
|    clip_fraction        | 0.663      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.4        |
|    explained_variance   | 0.673      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0392    |
|    n_updates            | 7340       |
|    policy_gradient_loss | -0.02      |
|    std                  | 0.0851     |
|    value_loss           | 0.00296    |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 966      |
|    ep_rew_mean          | 3.56e+03 |
| time/                   |          |
|    fps                  | 153      |
|    iterations           | 736      |
|    time_elapsed         | 9798     |
|    total_timesteps      | 1507328  |
| train/                  |          |
|    approx_kl            | 0.187695 |
|    clip_fraction        | 0.666    |
|    clip_range           | 0.2      |
|    entropy_loss         | 8.4      |
|    explained_variance   | 0.98     |
|    learning_rate        | 0.0003   |
|    loss                 | -0.0415  |
|    n_updates            | 7350     |
|    policy_gradient_loss | -0.024   |
|    std                  | 0.0849   |
|    value_loss           | 0.0123   |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 975        |
|    ep_rew_mean          | 3.6e+03    |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 737        |
|    time_elapsed         | 9807       |
|    total_timesteps      | 1509376    |
| train/                  |            |
|    approx_kl            | 0.20639774 |
|    clip_fraction        | 0.671      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.42       |
|    explained_variance   | 0.984      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0644    |
|    n_updates            | 7360       |
|    policy_gradient_loss | -0.0119    |
|    std                  | 0.085      |
|    value_loss           | 0.0159     |
----------------------------------------
Eval num_timesteps=1510000, episode_reward=3872.11 +/- 1025.16
Episode length: 934.88 +/- 225.71
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 935        |
|    mean_reward          | 3.87e+03   |
| time/                   |            |
|    total_timesteps      | 1510000    |
| train/                  |            |
|    approx_kl            | 0.16431813 |
|    clip_fraction        | 0.678      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.43       |
|    explained_variance   | 0.119      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0152    |
|    n_updates            | 7370       |
|    policy_gradient_loss | -0.0182    |
|    std                  | 0.0846     |
|    value_loss           | 0.0189     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 975      |
|    ep_rew_mean     | 3.6e+03  |
| time/              |          |
|    fps             | 153      |
|    iterations      | 738      |
|    time_elapsed    | 9839     |
|    total_timesteps | 1511424  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 975        |
|    ep_rew_mean          | 3.6e+03    |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 739        |
|    time_elapsed         | 9850       |
|    total_timesteps      | 1513472    |
| train/                  |            |
|    approx_kl            | 0.17980325 |
|    clip_fraction        | 0.669      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.43       |
|    explained_variance   | 0.555      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0803    |
|    n_updates            | 7380       |
|    policy_gradient_loss | -0.031     |
|    std                  | 0.085      |
|    value_loss           | 0.00476    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 975        |
|    ep_rew_mean          | 3.58e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 740        |
|    time_elapsed         | 9859       |
|    total_timesteps      | 1515520    |
| train/                  |            |
|    approx_kl            | 0.16342261 |
|    clip_fraction        | 0.661      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.43       |
|    explained_variance   | 0.982      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0157    |
|    n_updates            | 7390       |
|    policy_gradient_loss | -0.0158    |
|    std                  | 0.0847     |
|    value_loss           | 0.0157     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 979        |
|    ep_rew_mean          | 3.6e+03    |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 741        |
|    time_elapsed         | 9869       |
|    total_timesteps      | 1517568    |
| train/                  |            |
|    approx_kl            | 0.20435977 |
|    clip_fraction        | 0.7        |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.46       |
|    explained_variance   | 0.924      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0475    |
|    n_updates            | 7400       |
|    policy_gradient_loss | -0.0103    |
|    std                  | 0.0842     |
|    value_loss           | 0.0134     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 979        |
|    ep_rew_mean          | 3.58e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 742        |
|    time_elapsed         | 9878       |
|    total_timesteps      | 1519616    |
| train/                  |            |
|    approx_kl            | 0.19905736 |
|    clip_fraction        | 0.693      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.47       |
|    explained_variance   | 0.941      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0862    |
|    n_updates            | 7410       |
|    policy_gradient_loss | -0.0267    |
|    std                  | 0.0845     |
|    value_loss           | 0.00505    |
----------------------------------------
Eval num_timesteps=1520000, episode_reward=3395.52 +/- 1219.88
Episode length: 865.60 +/- 253.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 866        |
|    mean_reward          | 3.4e+03    |
| time/                   |            |
|    total_timesteps      | 1520000    |
| train/                  |            |
|    approx_kl            | 0.21306275 |
|    clip_fraction        | 0.669      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.47       |
|    explained_variance   | 0.987      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0263    |
|    n_updates            | 7420       |
|    policy_gradient_loss | -0.0229    |
|    std                  | 0.0842     |
|    value_loss           | 0.0106     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 974      |
|    ep_rew_mean     | 3.56e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 743      |
|    time_elapsed    | 9909     |
|    total_timesteps | 1521664  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 971        |
|    ep_rew_mean          | 3.55e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 744        |
|    time_elapsed         | 9918       |
|    total_timesteps      | 1523712    |
| train/                  |            |
|    approx_kl            | 0.19321935 |
|    clip_fraction        | 0.692      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.5        |
|    explained_variance   | 0.378      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00819   |
|    n_updates            | 7430       |
|    policy_gradient_loss | -0.0137    |
|    std                  | 0.0841     |
|    value_loss           | 0.0278     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 966        |
|    ep_rew_mean          | 3.53e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 745        |
|    time_elapsed         | 9928       |
|    total_timesteps      | 1525760    |
| train/                  |            |
|    approx_kl            | 0.19072416 |
|    clip_fraction        | 0.67       |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.52       |
|    explained_variance   | 0.476      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.032     |
|    n_updates            | 7440       |
|    policy_gradient_loss | -0.0192    |
|    std                  | 0.0836     |
|    value_loss           | 0.0314     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 963        |
|    ep_rew_mean          | 3.53e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 746        |
|    time_elapsed         | 9937       |
|    total_timesteps      | 1527808    |
| train/                  |            |
|    approx_kl            | 0.19874313 |
|    clip_fraction        | 0.693      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.54       |
|    explained_variance   | 0.47       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0597    |
|    n_updates            | 7450       |
|    policy_gradient_loss | -0.0136    |
|    std                  | 0.0837     |
|    value_loss           | 0.0393     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 963        |
|    ep_rew_mean          | 3.52e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 747        |
|    time_elapsed         | 9947       |
|    total_timesteps      | 1529856    |
| train/                  |            |
|    approx_kl            | 0.21944019 |
|    clip_fraction        | 0.694      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.56       |
|    explained_variance   | 0.526      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00703   |
|    n_updates            | 7460       |
|    policy_gradient_loss | -0.0149    |
|    std                  | 0.0832     |
|    value_loss           | 0.0216     |
----------------------------------------
Eval num_timesteps=1530000, episode_reward=3341.19 +/- 1254.61
Episode length: 920.88 +/- 168.25
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 921       |
|    mean_reward          | 3.34e+03  |
| time/                   |           |
|    total_timesteps      | 1530000   |
| train/                  |           |
|    approx_kl            | 1.5533869 |
|    clip_fraction        | 0.725     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.59      |
|    explained_variance   | 0.974     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0456   |
|    n_updates            | 7470      |
|    policy_gradient_loss | -0.0212   |
|    std                  | 0.0829    |
|    value_loss           | 0.011     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 947      |
|    ep_rew_mean     | 3.46e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 748      |
|    time_elapsed    | 9977     |
|    total_timesteps | 1531904  |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 943       |
|    ep_rew_mean          | 3.37e+03  |
| time/                   |           |
|    fps                  | 153       |
|    iterations           | 749       |
|    time_elapsed         | 9987      |
|    total_timesteps      | 1533952   |
| train/                  |           |
|    approx_kl            | 0.1690679 |
|    clip_fraction        | 0.647     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.59      |
|    explained_variance   | 0.929     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0235   |
|    n_updates            | 7480      |
|    policy_gradient_loss | -0.0173   |
|    std                  | 0.0829    |
|    value_loss           | 0.0574    |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 949        |
|    ep_rew_mean          | 3.38e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 750        |
|    time_elapsed         | 9997       |
|    total_timesteps      | 1536000    |
| train/                  |            |
|    approx_kl            | 0.18708557 |
|    clip_fraction        | 0.666      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.6        |
|    explained_variance   | 0.973      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00764    |
|    n_updates            | 7490       |
|    policy_gradient_loss | -0.00784   |
|    std                  | 0.0831     |
|    value_loss           | 0.0252     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 939       |
|    ep_rew_mean          | 3.37e+03  |
| time/                   |           |
|    fps                  | 153       |
|    iterations           | 751       |
|    time_elapsed         | 10006     |
|    total_timesteps      | 1538048   |
| train/                  |           |
|    approx_kl            | 0.2062563 |
|    clip_fraction        | 0.691     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.6       |
|    explained_variance   | 0.982     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0268   |
|    n_updates            | 7500      |
|    policy_gradient_loss | -0.00795  |
|    std                  | 0.083     |
|    value_loss           | 0.015     |
---------------------------------------
Eval num_timesteps=1540000, episode_reward=3369.29 +/- 1324.79
Episode length: 872.40 +/- 281.81
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 872       |
|    mean_reward          | 3.37e+03  |
| time/                   |           |
|    total_timesteps      | 1540000   |
| train/                  |           |
|    approx_kl            | 0.2197112 |
|    clip_fraction        | 0.696     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.6       |
|    explained_variance   | 0.388     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.00204  |
|    n_updates            | 7510      |
|    policy_gradient_loss | -0.0198   |
|    std                  | 0.0829    |
|    value_loss           | 0.0233    |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 934      |
|    ep_rew_mean     | 3.33e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 752      |
|    time_elapsed    | 10036    |
|    total_timesteps | 1540096  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 934        |
|    ep_rew_mean          | 3.31e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 753        |
|    time_elapsed         | 10046      |
|    total_timesteps      | 1542144    |
| train/                  |            |
|    approx_kl            | 0.15872616 |
|    clip_fraction        | 0.679      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.57       |
|    explained_variance   | 0.951      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.056     |
|    n_updates            | 7520       |
|    policy_gradient_loss | -0.0123    |
|    std                  | 0.0833     |
|    value_loss           | 0.0437     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 934       |
|    ep_rew_mean          | 3.31e+03  |
| time/                   |           |
|    fps                  | 153       |
|    iterations           | 754       |
|    time_elapsed         | 10055     |
|    total_timesteps      | 1544192   |
| train/                  |           |
|    approx_kl            | 0.6496361 |
|    clip_fraction        | 0.715     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.55      |
|    explained_variance   | 0.971     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0974   |
|    n_updates            | 7530      |
|    policy_gradient_loss | -0.0144   |
|    std                  | 0.0837    |
|    value_loss           | 0.00486   |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 925       |
|    ep_rew_mean          | 3.27e+03  |
| time/                   |           |
|    fps                  | 153       |
|    iterations           | 755       |
|    time_elapsed         | 10064     |
|    total_timesteps      | 1546240   |
| train/                  |           |
|    approx_kl            | 0.2050645 |
|    clip_fraction        | 0.697     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.52      |
|    explained_variance   | 0.457     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0742   |
|    n_updates            | 7540      |
|    policy_gradient_loss | -0.0212   |
|    std                  | 0.084     |
|    value_loss           | 0.00408   |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 924        |
|    ep_rew_mean          | 3.27e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 756        |
|    time_elapsed         | 10074      |
|    total_timesteps      | 1548288    |
| train/                  |            |
|    approx_kl            | 0.19132757 |
|    clip_fraction        | 0.673      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.5        |
|    explained_variance   | 0.233      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0281    |
|    n_updates            | 7550       |
|    policy_gradient_loss | -0.0088    |
|    std                  | 0.0842     |
|    value_loss           | 0.0161     |
----------------------------------------
Eval num_timesteps=1550000, episode_reward=3580.18 +/- 1048.63
Episode length: 902.76 +/- 229.55
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 903       |
|    mean_reward          | 3.58e+03  |
| time/                   |           |
|    total_timesteps      | 1550000   |
| train/                  |           |
|    approx_kl            | 0.1688332 |
|    clip_fraction        | 0.656     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.5       |
|    explained_variance   | 0.976     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0162   |
|    n_updates            | 7560      |
|    policy_gradient_loss | -0.0187   |
|    std                  | 0.084     |
|    value_loss           | 0.0208    |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 931      |
|    ep_rew_mean     | 3.28e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 757      |
|    time_elapsed    | 10104    |
|    total_timesteps | 1550336  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 927        |
|    ep_rew_mean          | 3.25e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 758        |
|    time_elapsed         | 10113      |
|    total_timesteps      | 1552384    |
| train/                  |            |
|    approx_kl            | 0.23731002 |
|    clip_fraction        | 0.7        |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.5        |
|    explained_variance   | 0.682      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0528    |
|    n_updates            | 7570       |
|    policy_gradient_loss | -0.0217    |
|    std                  | 0.084      |
|    value_loss           | 0.00709    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 927        |
|    ep_rew_mean          | 3.24e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 759        |
|    time_elapsed         | 10123      |
|    total_timesteps      | 1554432    |
| train/                  |            |
|    approx_kl            | 0.20673041 |
|    clip_fraction        | 0.67       |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.5        |
|    explained_variance   | 0.94       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0488    |
|    n_updates            | 7580       |
|    policy_gradient_loss | -0.0192    |
|    std                  | 0.084      |
|    value_loss           | 0.0392     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 921        |
|    ep_rew_mean          | 3.19e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 760        |
|    time_elapsed         | 10132      |
|    total_timesteps      | 1556480    |
| train/                  |            |
|    approx_kl            | 0.18692821 |
|    clip_fraction        | 0.666      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.52       |
|    explained_variance   | 0.983      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0267    |
|    n_updates            | 7590       |
|    policy_gradient_loss | -0.0177    |
|    std                  | 0.0834     |
|    value_loss           | 0.0104     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 921        |
|    ep_rew_mean          | 3.22e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 761        |
|    time_elapsed         | 10141      |
|    total_timesteps      | 1558528    |
| train/                  |            |
|    approx_kl            | 0.19879833 |
|    clip_fraction        | 0.686      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.57       |
|    explained_variance   | 0.975      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00536   |
|    n_updates            | 7600       |
|    policy_gradient_loss | -0.00988   |
|    std                  | 0.0831     |
|    value_loss           | 0.0223     |
----------------------------------------
Eval num_timesteps=1560000, episode_reward=3631.24 +/- 1042.62
Episode length: 996.64 +/- 16.46
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 997       |
|    mean_reward          | 3.63e+03  |
| time/                   |           |
|    total_timesteps      | 1560000   |
| train/                  |           |
|    approx_kl            | 0.1971142 |
|    clip_fraction        | 0.682     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.59      |
|    explained_variance   | 0.412     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0432   |
|    n_updates            | 7610      |
|    policy_gradient_loss | -0.0226   |
|    std                  | 0.0831    |
|    value_loss           | 0.00822   |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 921      |
|    ep_rew_mean     | 3.22e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 762      |
|    time_elapsed    | 10171    |
|    total_timesteps | 1560576  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 921        |
|    ep_rew_mean          | 3.16e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 763        |
|    time_elapsed         | 10181      |
|    total_timesteps      | 1562624    |
| train/                  |            |
|    approx_kl            | 0.21276122 |
|    clip_fraction        | 0.688      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.59       |
|    explained_variance   | 0.471      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0602    |
|    n_updates            | 7620       |
|    policy_gradient_loss | -0.0257    |
|    std                  | 0.0831     |
|    value_loss           | 0.00495    |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 921       |
|    ep_rew_mean          | 3.16e+03  |
| time/                   |           |
|    fps                  | 153       |
|    iterations           | 764       |
|    time_elapsed         | 10190     |
|    total_timesteps      | 1564672   |
| train/                  |           |
|    approx_kl            | 0.1818456 |
|    clip_fraction        | 0.603     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.59      |
|    explained_variance   | 0.977     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0424   |
|    n_updates            | 7630      |
|    policy_gradient_loss | -0.0123   |
|    std                  | 0.0831    |
|    value_loss           | 0.0175    |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 921       |
|    ep_rew_mean          | 3.16e+03  |
| time/                   |           |
|    fps                  | 153       |
|    iterations           | 765       |
|    time_elapsed         | 10200     |
|    total_timesteps      | 1566720   |
| train/                  |           |
|    approx_kl            | 0.2550968 |
|    clip_fraction        | 0.707     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.59      |
|    explained_variance   | -1.17     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0139   |
|    n_updates            | 7640      |
|    policy_gradient_loss | -0.0205   |
|    std                  | 0.0833    |
|    value_loss           | 0.0046    |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 911        |
|    ep_rew_mean          | 3.13e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 766        |
|    time_elapsed         | 10209      |
|    total_timesteps      | 1568768    |
| train/                  |            |
|    approx_kl            | 0.18430299 |
|    clip_fraction        | 0.687      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.57       |
|    explained_variance   | 0.505      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.111     |
|    n_updates            | 7650       |
|    policy_gradient_loss | -0.0224    |
|    std                  | 0.0834     |
|    value_loss           | 0.0046     |
----------------------------------------
Eval num_timesteps=1570000, episode_reward=3863.54 +/- 895.79
Episode length: 972.24 +/- 135.38
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 972        |
|    mean_reward          | 3.86e+03   |
| time/                   |            |
|    total_timesteps      | 1570000    |
| train/                  |            |
|    approx_kl            | 0.21616702 |
|    clip_fraction        | 0.689      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.57       |
|    explained_variance   | 0.543      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0266    |
|    n_updates            | 7660       |
|    policy_gradient_loss | -0.0238    |
|    std                  | 0.0831     |
|    value_loss           | 0.0208     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 907      |
|    ep_rew_mean     | 3.14e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 767      |
|    time_elapsed    | 10239    |
|    total_timesteps | 1570816  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 907        |
|    ep_rew_mean          | 3.18e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 768        |
|    time_elapsed         | 10248      |
|    total_timesteps      | 1572864    |
| train/                  |            |
|    approx_kl            | 0.21946317 |
|    clip_fraction        | 0.71       |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.61       |
|    explained_variance   | 0.405      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0412    |
|    n_updates            | 7670       |
|    policy_gradient_loss | -0.011     |
|    std                  | 0.0827     |
|    value_loss           | 0.0214     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 907        |
|    ep_rew_mean          | 3.15e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 769        |
|    time_elapsed         | 10258      |
|    total_timesteps      | 1574912    |
| train/                  |            |
|    approx_kl            | 0.18064554 |
|    clip_fraction        | 0.685      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.63       |
|    explained_variance   | 0.653      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0737    |
|    n_updates            | 7680       |
|    policy_gradient_loss | -0.0208    |
|    std                  | 0.0828     |
|    value_loss           | 0.00498    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 907        |
|    ep_rew_mean          | 3.15e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 770        |
|    time_elapsed         | 10267      |
|    total_timesteps      | 1576960    |
| train/                  |            |
|    approx_kl            | 0.19264278 |
|    clip_fraction        | 0.681      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.62       |
|    explained_variance   | 0.976      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0156    |
|    n_updates            | 7690       |
|    policy_gradient_loss | -0.02      |
|    std                  | 0.0829     |
|    value_loss           | 0.0168     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 907        |
|    ep_rew_mean          | 3.14e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 771        |
|    time_elapsed         | 10277      |
|    total_timesteps      | 1579008    |
| train/                  |            |
|    approx_kl            | 0.20819233 |
|    clip_fraction        | 0.684      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.59       |
|    explained_variance   | 0.316      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0929    |
|    n_updates            | 7700       |
|    policy_gradient_loss | -0.019     |
|    std                  | 0.0832     |
|    value_loss           | 0.00542    |
----------------------------------------
Eval num_timesteps=1580000, episode_reward=3817.27 +/- 920.38
Episode length: 968.48 +/- 132.70
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 968       |
|    mean_reward          | 3.82e+03  |
| time/                   |           |
|    total_timesteps      | 1580000   |
| train/                  |           |
|    approx_kl            | 0.2318691 |
|    clip_fraction        | 0.682     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.59      |
|    explained_variance   | 0.625     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0341   |
|    n_updates            | 7710      |
|    policy_gradient_loss | -0.0218   |
|    std                  | 0.0832    |
|    value_loss           | 0.00617   |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 907      |
|    ep_rew_mean     | 3.15e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 772      |
|    time_elapsed    | 10306    |
|    total_timesteps | 1581056  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 907        |
|    ep_rew_mean          | 3.15e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 773        |
|    time_elapsed         | 10316      |
|    total_timesteps      | 1583104    |
| train/                  |            |
|    approx_kl            | 0.20729437 |
|    clip_fraction        | 0.671      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.58       |
|    explained_variance   | 0.655      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0216    |
|    n_updates            | 7720       |
|    policy_gradient_loss | -0.0184    |
|    std                  | 0.0833     |
|    value_loss           | 0.00454    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 903        |
|    ep_rew_mean          | 3.13e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 774        |
|    time_elapsed         | 10325      |
|    total_timesteps      | 1585152    |
| train/                  |            |
|    approx_kl            | 0.19231799 |
|    clip_fraction        | 0.677      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.56       |
|    explained_variance   | 0.553      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0634    |
|    n_updates            | 7730       |
|    policy_gradient_loss | -0.0267    |
|    std                  | 0.0834     |
|    value_loss           | 0.00451    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 903        |
|    ep_rew_mean          | 3.15e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 775        |
|    time_elapsed         | 10335      |
|    total_timesteps      | 1587200    |
| train/                  |            |
|    approx_kl            | 0.14542139 |
|    clip_fraction        | 0.684      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.56       |
|    explained_variance   | 0.525      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0277    |
|    n_updates            | 7740       |
|    policy_gradient_loss | -0.0195    |
|    std                  | 0.0831     |
|    value_loss           | 0.0112     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 903        |
|    ep_rew_mean          | 3.15e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 776        |
|    time_elapsed         | 10344      |
|    total_timesteps      | 1589248    |
| train/                  |            |
|    approx_kl            | 0.21416543 |
|    clip_fraction        | 0.672      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.58       |
|    explained_variance   | 0.51       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0853    |
|    n_updates            | 7750       |
|    policy_gradient_loss | -0.0212    |
|    std                  | 0.0833     |
|    value_loss           | 0.00403    |
----------------------------------------
Eval num_timesteps=1590000, episode_reward=3661.36 +/- 1066.55
Episode length: 939.36 +/- 195.86
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 939        |
|    mean_reward          | 3.66e+03   |
| time/                   |            |
|    total_timesteps      | 1590000    |
| train/                  |            |
|    approx_kl            | 0.23363271 |
|    clip_fraction        | 0.672      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.57       |
|    explained_variance   | 0.535      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0305    |
|    n_updates            | 7760       |
|    policy_gradient_loss | -0.0248    |
|    std                  | 0.0831     |
|    value_loss           | 0.00403    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 903      |
|    ep_rew_mean     | 3.15e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 777      |
|    time_elapsed    | 10374    |
|    total_timesteps | 1591296  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 903        |
|    ep_rew_mean          | 3.12e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 778        |
|    time_elapsed         | 10383      |
|    total_timesteps      | 1593344    |
| train/                  |            |
|    approx_kl            | 0.18770248 |
|    clip_fraction        | 0.679      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.57       |
|    explained_variance   | 0.589      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0473    |
|    n_updates            | 7770       |
|    policy_gradient_loss | -0.0213    |
|    std                  | 0.0833     |
|    value_loss           | 0.00364    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 903        |
|    ep_rew_mean          | 3.12e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 779        |
|    time_elapsed         | 10393      |
|    total_timesteps      | 1595392    |
| train/                  |            |
|    approx_kl            | 0.17514019 |
|    clip_fraction        | 0.686      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.57       |
|    explained_variance   | 0.988      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0456    |
|    n_updates            | 7780       |
|    policy_gradient_loss | -0.0203    |
|    std                  | 0.083      |
|    value_loss           | 0.00773    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 894        |
|    ep_rew_mean          | 3.11e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 780        |
|    time_elapsed         | 10402      |
|    total_timesteps      | 1597440    |
| train/                  |            |
|    approx_kl            | 0.17961542 |
|    clip_fraction        | 0.682      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.6        |
|    explained_variance   | 0.986      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0135     |
|    n_updates            | 7790       |
|    policy_gradient_loss | -0.0158    |
|    std                  | 0.0827     |
|    value_loss           | 0.0119     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 900        |
|    ep_rew_mean          | 3.13e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 781        |
|    time_elapsed         | 10412      |
|    total_timesteps      | 1599488    |
| train/                  |            |
|    approx_kl            | 0.19559765 |
|    clip_fraction        | 0.686      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.63       |
|    explained_variance   | 0.287      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0145    |
|    n_updates            | 7800       |
|    policy_gradient_loss | -0.0163    |
|    std                  | 0.0826     |
|    value_loss           | 0.0163     |
----------------------------------------
Eval num_timesteps=1600000, episode_reward=3512.97 +/- 1202.49
Episode length: 947.04 +/- 157.15
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 947       |
|    mean_reward          | 3.51e+03  |
| time/                   |           |
|    total_timesteps      | 1600000   |
| train/                  |           |
|    approx_kl            | 0.2302052 |
|    clip_fraction        | 0.686     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.66      |
|    explained_variance   | 0.971     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.039    |
|    n_updates            | 7810      |
|    policy_gradient_loss | -0.0158   |
|    std                  | 0.0822    |
|    value_loss           | 0.0238    |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 900      |
|    ep_rew_mean     | 3.11e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 782      |
|    time_elapsed    | 10443    |
|    total_timesteps | 1601536  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 900        |
|    ep_rew_mean          | 3.07e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 783        |
|    time_elapsed         | 10453      |
|    total_timesteps      | 1603584    |
| train/                  |            |
|    approx_kl            | 0.22075039 |
|    clip_fraction        | 0.671      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.7        |
|    explained_variance   | 0.98       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0344    |
|    n_updates            | 7820       |
|    policy_gradient_loss | -0.0168    |
|    std                  | 0.0818     |
|    value_loss           | 0.0182     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 900        |
|    ep_rew_mean          | 3.04e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 784        |
|    time_elapsed         | 10462      |
|    total_timesteps      | 1605632    |
| train/                  |            |
|    approx_kl            | 0.23080076 |
|    clip_fraction        | 0.661      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.73       |
|    explained_variance   | 0.988      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00779   |
|    n_updates            | 7830       |
|    policy_gradient_loss | -0.0191    |
|    std                  | 0.0814     |
|    value_loss           | 0.0121     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 900        |
|    ep_rew_mean          | 3.04e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 785        |
|    time_elapsed         | 10472      |
|    total_timesteps      | 1607680    |
| train/                  |            |
|    approx_kl            | 0.22912061 |
|    clip_fraction        | 0.657      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.76       |
|    explained_variance   | 0.987      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0577    |
|    n_updates            | 7840       |
|    policy_gradient_loss | -0.0136    |
|    std                  | 0.0811     |
|    value_loss           | 0.0146     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 900       |
|    ep_rew_mean          | 3.07e+03  |
| time/                   |           |
|    fps                  | 153       |
|    iterations           | 786       |
|    time_elapsed         | 10481     |
|    total_timesteps      | 1609728   |
| train/                  |           |
|    approx_kl            | 0.2095949 |
|    clip_fraction        | 0.684     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.77      |
|    explained_variance   | 0.409     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0636   |
|    n_updates            | 7850      |
|    policy_gradient_loss | -0.0192   |
|    std                  | 0.0812    |
|    value_loss           | 0.00594   |
---------------------------------------
Eval num_timesteps=1610000, episode_reward=3407.50 +/- 1351.40
Episode length: 963.16 +/- 180.48
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 963       |
|    mean_reward          | 3.41e+03  |
| time/                   |           |
|    total_timesteps      | 1610000   |
| train/                  |           |
|    approx_kl            | 0.1877456 |
|    clip_fraction        | 0.685     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.78      |
|    explained_variance   | 0.485     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0687   |
|    n_updates            | 7860      |
|    policy_gradient_loss | -0.021    |
|    std                  | 0.081     |
|    value_loss           | 0.00561   |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 906      |
|    ep_rew_mean     | 3.09e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 787      |
|    time_elapsed    | 10511    |
|    total_timesteps | 1611776  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 907        |
|    ep_rew_mean          | 3.1e+03    |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 788        |
|    time_elapsed         | 10521      |
|    total_timesteps      | 1613824    |
| train/                  |            |
|    approx_kl            | 0.19054878 |
|    clip_fraction        | 0.679      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.79       |
|    explained_variance   | 0.417      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0468    |
|    n_updates            | 7870       |
|    policy_gradient_loss | -0.0235    |
|    std                  | 0.081      |
|    value_loss           | 0.00438    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 909        |
|    ep_rew_mean          | 3.1e+03    |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 789        |
|    time_elapsed         | 10531      |
|    total_timesteps      | 1615872    |
| train/                  |            |
|    approx_kl            | 0.21306914 |
|    clip_fraction        | 0.675      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.79       |
|    explained_variance   | 0.452      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0134     |
|    n_updates            | 7880       |
|    policy_gradient_loss | -0.0193    |
|    std                  | 0.0809     |
|    value_loss           | 0.0203     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 913       |
|    ep_rew_mean          | 3.12e+03  |
| time/                   |           |
|    fps                  | 153       |
|    iterations           | 790       |
|    time_elapsed         | 10540     |
|    total_timesteps      | 1617920   |
| train/                  |           |
|    approx_kl            | 0.1776076 |
|    clip_fraction        | 0.677     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.81      |
|    explained_variance   | 0.954     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0441   |
|    n_updates            | 7890      |
|    policy_gradient_loss | -0.011    |
|    std                  | 0.0807    |
|    value_loss           | 0.0108    |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 907        |
|    ep_rew_mean          | 3.08e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 791        |
|    time_elapsed         | 10550      |
|    total_timesteps      | 1619968    |
| train/                  |            |
|    approx_kl            | 0.19372538 |
|    clip_fraction        | 0.667      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.84       |
|    explained_variance   | 0.439      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0513    |
|    n_updates            | 7900       |
|    policy_gradient_loss | -0.013     |
|    std                  | 0.0805     |
|    value_loss           | 0.0207     |
----------------------------------------
Eval num_timesteps=1620000, episode_reward=2830.65 +/- 1444.13
Episode length: 922.04 +/- 207.52
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 922        |
|    mean_reward          | 2.83e+03   |
| time/                   |            |
|    total_timesteps      | 1620000    |
| train/                  |            |
|    approx_kl            | 0.18550041 |
|    clip_fraction        | 0.671      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.87       |
|    explained_variance   | 0.963      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0497    |
|    n_updates            | 7910       |
|    policy_gradient_loss | -0.0159    |
|    std                  | 0.08       |
|    value_loss           | 0.027      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 913      |
|    ep_rew_mean     | 3.12e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 792      |
|    time_elapsed    | 10580    |
|    total_timesteps | 1622016  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 917        |
|    ep_rew_mean          | 3.17e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 793        |
|    time_elapsed         | 10590      |
|    total_timesteps      | 1624064    |
| train/                  |            |
|    approx_kl            | 0.23659182 |
|    clip_fraction        | 0.715      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.87       |
|    explained_variance   | -0.647     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0785    |
|    n_updates            | 7920       |
|    policy_gradient_loss | -0.0141    |
|    std                  | 0.0805     |
|    value_loss           | 0.00497    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 921        |
|    ep_rew_mean          | 3.22e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 794        |
|    time_elapsed         | 10599      |
|    total_timesteps      | 1626112    |
| train/                  |            |
|    approx_kl            | 0.19461745 |
|    clip_fraction        | 0.691      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.84       |
|    explained_variance   | 0.803      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0543    |
|    n_updates            | 7930       |
|    policy_gradient_loss | -0.00972   |
|    std                  | 0.0803     |
|    value_loss           | 0.0332     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 921        |
|    ep_rew_mean          | 3.21e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 795        |
|    time_elapsed         | 10609      |
|    total_timesteps      | 1628160    |
| train/                  |            |
|    approx_kl            | 0.25008333 |
|    clip_fraction        | 0.699      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.89       |
|    explained_variance   | 0.0443     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.085     |
|    n_updates            | 7940       |
|    policy_gradient_loss | -0.0212    |
|    std                  | 0.0799     |
|    value_loss           | 0.00464    |
----------------------------------------
Eval num_timesteps=1630000, episode_reward=3526.77 +/- 1139.68
Episode length: 907.64 +/- 217.68
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 908        |
|    mean_reward          | 3.53e+03   |
| time/                   |            |
|    total_timesteps      | 1630000    |
| train/                  |            |
|    approx_kl            | 0.19417837 |
|    clip_fraction        | 0.595      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.92       |
|    explained_variance   | 0.97       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0319    |
|    n_updates            | 7950       |
|    policy_gradient_loss | -0.0166    |
|    std                  | 0.0795     |
|    value_loss           | 0.0238     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 921      |
|    ep_rew_mean     | 3.17e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 796      |
|    time_elapsed    | 10639    |
|    total_timesteps | 1630208  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 936        |
|    ep_rew_mean          | 3.23e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 797        |
|    time_elapsed         | 10648      |
|    total_timesteps      | 1632256    |
| train/                  |            |
|    approx_kl            | 0.23564985 |
|    clip_fraction        | 0.662      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.94       |
|    explained_variance   | 0.986      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0707    |
|    n_updates            | 7960       |
|    policy_gradient_loss | -0.0215    |
|    std                  | 0.0794     |
|    value_loss           | 0.0123     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 936       |
|    ep_rew_mean          | 3.23e+03  |
| time/                   |           |
|    fps                  | 153       |
|    iterations           | 798       |
|    time_elapsed         | 10658     |
|    total_timesteps      | 1634304   |
| train/                  |           |
|    approx_kl            | 0.2176755 |
|    clip_fraction        | 0.706     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.94      |
|    explained_variance   | 0.132     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.051    |
|    n_updates            | 7970      |
|    policy_gradient_loss | -0.0175   |
|    std                  | 0.0795    |
|    value_loss           | 0.00955   |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 927        |
|    ep_rew_mean          | 3.2e+03    |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 799        |
|    time_elapsed         | 10671      |
|    total_timesteps      | 1636352    |
| train/                  |            |
|    approx_kl            | 0.23764008 |
|    clip_fraction        | 0.647      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.95       |
|    explained_variance   | 0.98       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.044     |
|    n_updates            | 7980       |
|    policy_gradient_loss | -0.0157    |
|    std                  | 0.0791     |
|    value_loss           | 0.0197     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 936        |
|    ep_rew_mean          | 3.23e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 800        |
|    time_elapsed         | 10682      |
|    total_timesteps      | 1638400    |
| train/                  |            |
|    approx_kl            | 0.21713379 |
|    clip_fraction        | 0.703      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.98       |
|    explained_variance   | 0.406      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0637    |
|    n_updates            | 7990       |
|    policy_gradient_loss | -0.0167    |
|    std                  | 0.0791     |
|    value_loss           | 0.0187     |
----------------------------------------
Eval num_timesteps=1640000, episode_reward=3170.64 +/- 1409.80
Episode length: 930.84 +/- 197.19
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 931        |
|    mean_reward          | 3.17e+03   |
| time/                   |            |
|    total_timesteps      | 1640000    |
| train/                  |            |
|    approx_kl            | 0.21754408 |
|    clip_fraction        | 0.697      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.95       |
|    explained_variance   | 0.466      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0752    |
|    n_updates            | 8000       |
|    policy_gradient_loss | -0.022     |
|    std                  | 0.0795     |
|    value_loss           | 0.00772    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 921      |
|    ep_rew_mean     | 3.21e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 801      |
|    time_elapsed    | 10712    |
|    total_timesteps | 1640448  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 917        |
|    ep_rew_mean          | 3.2e+03    |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 802        |
|    time_elapsed         | 10722      |
|    total_timesteps      | 1642496    |
| train/                  |            |
|    approx_kl            | 0.20190448 |
|    clip_fraction        | 0.702      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.9        |
|    explained_variance   | 0.54       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00557    |
|    n_updates            | 8010       |
|    policy_gradient_loss | -0.0163    |
|    std                  | 0.0799     |
|    value_loss           | 0.0335     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 921        |
|    ep_rew_mean          | 3.23e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 803        |
|    time_elapsed         | 10731      |
|    total_timesteps      | 1644544    |
| train/                  |            |
|    approx_kl            | 0.19925879 |
|    clip_fraction        | 0.697      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.9        |
|    explained_variance   | 0.482      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0375    |
|    n_updates            | 8020       |
|    policy_gradient_loss | -0.00705   |
|    std                  | 0.0797     |
|    value_loss           | 0.0235     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 921        |
|    ep_rew_mean          | 3.25e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 804        |
|    time_elapsed         | 10741      |
|    total_timesteps      | 1646592    |
| train/                  |            |
|    approx_kl            | 0.26752186 |
|    clip_fraction        | 0.695      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.93       |
|    explained_variance   | 0.503      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0433    |
|    n_updates            | 8030       |
|    policy_gradient_loss | -0.0299    |
|    std                  | 0.0795     |
|    value_loss           | 0.00445    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 922        |
|    ep_rew_mean          | 3.28e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 805        |
|    time_elapsed         | 10750      |
|    total_timesteps      | 1648640    |
| train/                  |            |
|    approx_kl            | 0.21636277 |
|    clip_fraction        | 0.693      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.93       |
|    explained_variance   | 0.568      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.045     |
|    n_updates            | 8040       |
|    policy_gradient_loss | -0.0271    |
|    std                  | 0.0796     |
|    value_loss           | 0.00559    |
----------------------------------------
Eval num_timesteps=1650000, episode_reward=3035.28 +/- 1401.11
Episode length: 843.24 +/- 273.90
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 843       |
|    mean_reward          | 3.04e+03  |
| time/                   |           |
|    total_timesteps      | 1650000   |
| train/                  |           |
|    approx_kl            | 0.2019151 |
|    clip_fraction        | 0.693     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.93      |
|    explained_variance   | 0.565     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0387   |
|    n_updates            | 8050      |
|    policy_gradient_loss | -0.0197   |
|    std                  | 0.0793    |
|    value_loss           | 0.0227    |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 922      |
|    ep_rew_mean     | 3.26e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 806      |
|    time_elapsed    | 10781    |
|    total_timesteps | 1650688  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 920        |
|    ep_rew_mean          | 3.24e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 807        |
|    time_elapsed         | 10791      |
|    total_timesteps      | 1652736    |
| train/                  |            |
|    approx_kl            | 0.17996193 |
|    clip_fraction        | 0.673      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.94       |
|    explained_variance   | 0.987      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.047     |
|    n_updates            | 8060       |
|    policy_gradient_loss | -0.0107    |
|    std                  | 0.0793     |
|    value_loss           | 0.0132     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 920        |
|    ep_rew_mean          | 3.28e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 808        |
|    time_elapsed         | 10800      |
|    total_timesteps      | 1654784    |
| train/                  |            |
|    approx_kl            | 0.22227299 |
|    clip_fraction        | 0.705      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.97       |
|    explained_variance   | 0.955      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00139    |
|    n_updates            | 8070       |
|    policy_gradient_loss | -0.00741   |
|    std                  | 0.0791     |
|    value_loss           | 0.0356     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 920        |
|    ep_rew_mean          | 3.25e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 809        |
|    time_elapsed         | 10810      |
|    total_timesteps      | 1656832    |
| train/                  |            |
|    approx_kl            | 0.17107087 |
|    clip_fraction        | 0.665      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.97       |
|    explained_variance   | 0.978      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0163    |
|    n_updates            | 8080       |
|    policy_gradient_loss | -0.0152    |
|    std                  | 0.079      |
|    value_loss           | 0.0238     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 920        |
|    ep_rew_mean          | 3.26e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 810        |
|    time_elapsed         | 10819      |
|    total_timesteps      | 1658880    |
| train/                  |            |
|    approx_kl            | 0.25529486 |
|    clip_fraction        | 0.716      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.97       |
|    explained_variance   | 0.992      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0713    |
|    n_updates            | 8090       |
|    policy_gradient_loss | -0.0159    |
|    std                  | 0.0794     |
|    value_loss           | 0.00434    |
----------------------------------------
Eval num_timesteps=1660000, episode_reward=3995.05 +/- 775.69
Episode length: 985.20 +/- 53.07
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 985        |
|    mean_reward          | 4e+03      |
| time/                   |            |
|    total_timesteps      | 1660000    |
| train/                  |            |
|    approx_kl            | 0.22861324 |
|    clip_fraction        | 0.706      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.94       |
|    explained_variance   | 0.467      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0587    |
|    n_updates            | 8100       |
|    policy_gradient_loss | -0.0303    |
|    std                  | 0.0796     |
|    value_loss           | 0.00348    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 920      |
|    ep_rew_mean     | 3.27e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 811      |
|    time_elapsed    | 10849    |
|    total_timesteps | 1660928  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 929        |
|    ep_rew_mean          | 3.31e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 812        |
|    time_elapsed         | 10859      |
|    total_timesteps      | 1662976    |
| train/                  |            |
|    approx_kl            | 0.21238886 |
|    clip_fraction        | 0.678      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.93       |
|    explained_variance   | 0.578      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0338    |
|    n_updates            | 8110       |
|    policy_gradient_loss | -0.02      |
|    std                  | 0.0796     |
|    value_loss           | 0.00332    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 934        |
|    ep_rew_mean          | 3.3e+03    |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 813        |
|    time_elapsed         | 10868      |
|    total_timesteps      | 1665024    |
| train/                  |            |
|    approx_kl            | 0.24164224 |
|    clip_fraction        | 0.694      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.92       |
|    explained_variance   | 0.632      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0943    |
|    n_updates            | 8120       |
|    policy_gradient_loss | -0.0241    |
|    std                  | 0.0797     |
|    value_loss           | 0.00403    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 934        |
|    ep_rew_mean          | 3.31e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 814        |
|    time_elapsed         | 10878      |
|    total_timesteps      | 1667072    |
| train/                  |            |
|    approx_kl            | 0.19972484 |
|    clip_fraction        | 0.672      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.91       |
|    explained_variance   | 0.987      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0256    |
|    n_updates            | 8130       |
|    policy_gradient_loss | -0.0157    |
|    std                  | 0.0798     |
|    value_loss           | 0.0118     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 934        |
|    ep_rew_mean          | 3.33e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 815        |
|    time_elapsed         | 10887      |
|    total_timesteps      | 1669120    |
| train/                  |            |
|    approx_kl            | 0.19692555 |
|    clip_fraction        | 0.695      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.9        |
|    explained_variance   | 0.49       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0567    |
|    n_updates            | 8140       |
|    policy_gradient_loss | -0.024     |
|    std                  | 0.08       |
|    value_loss           | 0.00408    |
----------------------------------------
Eval num_timesteps=1670000, episode_reward=3668.76 +/- 1104.03
Episode length: 914.08 +/- 236.01
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 914        |
|    mean_reward          | 3.67e+03   |
| time/                   |            |
|    total_timesteps      | 1670000    |
| train/                  |            |
|    approx_kl            | 0.18013546 |
|    clip_fraction        | 0.686      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.86       |
|    explained_variance   | 0.516      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0538    |
|    n_updates            | 8150       |
|    policy_gradient_loss | -0.0245    |
|    std                  | 0.0805     |
|    value_loss           | 0.00405    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 934      |
|    ep_rew_mean     | 3.34e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 816      |
|    time_elapsed    | 10917    |
|    total_timesteps | 1671168  |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 934       |
|    ep_rew_mean          | 3.34e+03  |
| time/                   |           |
|    fps                  | 153       |
|    iterations           | 817       |
|    time_elapsed         | 10926     |
|    total_timesteps      | 1673216   |
| train/                  |           |
|    approx_kl            | 0.1815284 |
|    clip_fraction        | 0.684     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.83      |
|    explained_variance   | 0.649     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0697   |
|    n_updates            | 8160      |
|    policy_gradient_loss | -0.0284   |
|    std                  | 0.0806    |
|    value_loss           | 0.00434   |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 934        |
|    ep_rew_mean          | 3.35e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 818        |
|    time_elapsed         | 10936      |
|    total_timesteps      | 1675264    |
| train/                  |            |
|    approx_kl            | 0.22877142 |
|    clip_fraction        | 0.684      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.81       |
|    explained_variance   | 0.441      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0719    |
|    n_updates            | 8170       |
|    policy_gradient_loss | -0.0246    |
|    std                  | 0.0809     |
|    value_loss           | 0.00441    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 934        |
|    ep_rew_mean          | 3.35e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 819        |
|    time_elapsed         | 10945      |
|    total_timesteps      | 1677312    |
| train/                  |            |
|    approx_kl            | 0.20944002 |
|    clip_fraction        | 0.696      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.78       |
|    explained_variance   | 0.753      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0649    |
|    n_updates            | 8180       |
|    policy_gradient_loss | -0.0267    |
|    std                  | 0.0812     |
|    value_loss           | 0.00436    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 938        |
|    ep_rew_mean          | 3.37e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 820        |
|    time_elapsed         | 10954      |
|    total_timesteps      | 1679360    |
| train/                  |            |
|    approx_kl            | 0.21165621 |
|    clip_fraction        | 0.674      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.76       |
|    explained_variance   | 0.602      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0818    |
|    n_updates            | 8190       |
|    policy_gradient_loss | -0.0363    |
|    std                  | 0.0812     |
|    value_loss           | 0.00446    |
----------------------------------------
Eval num_timesteps=1680000, episode_reward=3227.83 +/- 1254.91
Episode length: 935.76 +/- 193.03
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 936        |
|    mean_reward          | 3.23e+03   |
| time/                   |            |
|    total_timesteps      | 1680000    |
| train/                  |            |
|    approx_kl            | 0.20922655 |
|    clip_fraction        | 0.685      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.74       |
|    explained_variance   | 0.777      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0416    |
|    n_updates            | 8200       |
|    policy_gradient_loss | -0.0243    |
|    std                  | 0.0816     |
|    value_loss           | 0.0045     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 936      |
|    ep_rew_mean     | 3.36e+03 |
| time/              |          |
|    fps             | 153      |
|    iterations      | 821      |
|    time_elapsed    | 10984    |
|    total_timesteps | 1681408  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 936        |
|    ep_rew_mean          | 3.36e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 822        |
|    time_elapsed         | 10994      |
|    total_timesteps      | 1683456    |
| train/                  |            |
|    approx_kl            | 0.18958329 |
|    clip_fraction        | 0.673      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.74       |
|    explained_variance   | 0.505      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0056     |
|    n_updates            | 8210       |
|    policy_gradient_loss | -0.017     |
|    std                  | 0.0814     |
|    value_loss           | 0.0214     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 928       |
|    ep_rew_mean          | 3.36e+03  |
| time/                   |           |
|    fps                  | 153       |
|    iterations           | 823       |
|    time_elapsed         | 11003     |
|    total_timesteps      | 1685504   |
| train/                  |           |
|    approx_kl            | 0.2311976 |
|    clip_fraction        | 0.71      |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.73      |
|    explained_variance   | -0.066    |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0383   |
|    n_updates            | 8220      |
|    policy_gradient_loss | -0.0222   |
|    std                  | 0.0818    |
|    value_loss           | 0.00665   |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 928        |
|    ep_rew_mean          | 3.37e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 824        |
|    time_elapsed         | 11013      |
|    total_timesteps      | 1687552    |
| train/                  |            |
|    approx_kl            | 0.18781957 |
|    clip_fraction        | 0.686      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.72       |
|    explained_variance   | 0.548      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0378    |
|    n_updates            | 8230       |
|    policy_gradient_loss | -0.0179    |
|    std                  | 0.0816     |
|    value_loss           | 0.0184     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 936        |
|    ep_rew_mean          | 3.41e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 825        |
|    time_elapsed         | 11022      |
|    total_timesteps      | 1689600    |
| train/                  |            |
|    approx_kl            | 0.20950894 |
|    clip_fraction        | 0.684      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.72       |
|    explained_variance   | 0.488      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0404    |
|    n_updates            | 8240       |
|    policy_gradient_loss | -0.0304    |
|    std                  | 0.0817     |
|    value_loss           | 0.00681    |
----------------------------------------
Eval num_timesteps=1690000, episode_reward=3909.62 +/- 847.59
Episode length: 968.44 +/- 107.21
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 968        |
|    mean_reward          | 3.91e+03   |
| time/                   |            |
|    total_timesteps      | 1690000    |
| train/                  |            |
|    approx_kl            | 0.24848652 |
|    clip_fraction        | 0.686      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.72       |
|    explained_variance   | 0.643      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0194    |
|    n_updates            | 8250       |
|    policy_gradient_loss | -0.0278    |
|    std                  | 0.0818     |
|    value_loss           | 0.00408    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 936      |
|    ep_rew_mean     | 3.4e+03  |
| time/              |          |
|    fps             | 153      |
|    iterations      | 826      |
|    time_elapsed    | 11052    |
|    total_timesteps | 1691648  |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 936       |
|    ep_rew_mean          | 3.43e+03  |
| time/                   |           |
|    fps                  | 153       |
|    iterations           | 827       |
|    time_elapsed         | 11061     |
|    total_timesteps      | 1693696   |
| train/                  |           |
|    approx_kl            | 0.1981216 |
|    clip_fraction        | 0.675     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.72      |
|    explained_variance   | 0.522     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0647   |
|    n_updates            | 8260      |
|    policy_gradient_loss | -0.0272   |
|    std                  | 0.0815    |
|    value_loss           | 0.00458   |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 936        |
|    ep_rew_mean          | 3.44e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 828        |
|    time_elapsed         | 11070      |
|    total_timesteps      | 1695744    |
| train/                  |            |
|    approx_kl            | 0.20399687 |
|    clip_fraction        | 0.683      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.75       |
|    explained_variance   | 0.828      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0588    |
|    n_updates            | 8270       |
|    policy_gradient_loss | -0.0131    |
|    std                  | 0.0813     |
|    value_loss           | 0.0135     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 936        |
|    ep_rew_mean          | 3.48e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 829        |
|    time_elapsed         | 11080      |
|    total_timesteps      | 1697792    |
| train/                  |            |
|    approx_kl            | 0.20301875 |
|    clip_fraction        | 0.682      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.79       |
|    explained_variance   | 0.997      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0481    |
|    n_updates            | 8280       |
|    policy_gradient_loss | -0.0255    |
|    std                  | 0.0808     |
|    value_loss           | 0.00312    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 936        |
|    ep_rew_mean          | 3.46e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 830        |
|    time_elapsed         | 11089      |
|    total_timesteps      | 1699840    |
| train/                  |            |
|    approx_kl            | 0.20066787 |
|    clip_fraction        | 0.688      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.81       |
|    explained_variance   | 0.979      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.06      |
|    n_updates            | 8290       |
|    policy_gradient_loss | -0.0143    |
|    std                  | 0.0807     |
|    value_loss           | 0.0165     |
----------------------------------------
Eval num_timesteps=1700000, episode_reward=3036.44 +/- 1498.60
Episode length: 888.76 +/- 257.11
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 889        |
|    mean_reward          | 3.04e+03   |
| time/                   |            |
|    total_timesteps      | 1700000    |
| train/                  |            |
|    approx_kl            | 0.19135126 |
|    clip_fraction        | 0.694      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.84       |
|    explained_variance   | 0.983      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00546   |
|    n_updates            | 8300       |
|    policy_gradient_loss | -0.00686   |
|    std                  | 0.0803     |
|    value_loss           | 0.0192     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 923      |
|    ep_rew_mean     | 3.4e+03  |
| time/              |          |
|    fps             | 153      |
|    iterations      | 831      |
|    time_elapsed    | 11120    |
|    total_timesteps | 1701888  |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 923      |
|    ep_rew_mean          | 3.4e+03  |
| time/                   |          |
|    fps                  | 153      |
|    iterations           | 832      |
|    time_elapsed         | 11130    |
|    total_timesteps      | 1703936  |
| train/                  |          |
|    approx_kl            | 0.200842 |
|    clip_fraction        | 0.685    |
|    clip_range           | 0.2      |
|    entropy_loss         | 8.86     |
|    explained_variance   | 0.49     |
|    learning_rate        | 0.0003   |
|    loss                 | -0.0342  |
|    n_updates            | 8310     |
|    policy_gradient_loss | -0.015   |
|    std                  | 0.0799   |
|    value_loss           | 0.0445   |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 924       |
|    ep_rew_mean          | 3.37e+03  |
| time/                   |           |
|    fps                  | 153       |
|    iterations           | 833       |
|    time_elapsed         | 11139     |
|    total_timesteps      | 1705984   |
| train/                  |           |
|    approx_kl            | 0.2235369 |
|    clip_fraction        | 0.705     |
|    clip_range           | 0.2       |
|    entropy_loss         | 8.92      |
|    explained_variance   | 0.861     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0203   |
|    n_updates            | 8320      |
|    policy_gradient_loss | -0.0254   |
|    std                  | 0.0794    |
|    value_loss           | 0.022     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 917        |
|    ep_rew_mean          | 3.31e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 834        |
|    time_elapsed         | 11149      |
|    total_timesteps      | 1708032    |
| train/                  |            |
|    approx_kl            | 0.30493924 |
|    clip_fraction        | 0.724      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.95       |
|    explained_variance   | 0.995      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00215    |
|    n_updates            | 8330       |
|    policy_gradient_loss | -0.0137    |
|    std                  | 0.0795     |
|    value_loss           | 0.00391    |
----------------------------------------
Eval num_timesteps=1710000, episode_reward=2315.61 +/- 1512.30
Episode length: 826.92 +/- 316.87
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 827        |
|    mean_reward          | 2.32e+03   |
| time/                   |            |
|    total_timesteps      | 1710000    |
| train/                  |            |
|    approx_kl            | 0.18096915 |
|    clip_fraction        | 0.674      |
|    clip_range           | 0.2        |
|    entropy_loss         | 8.96       |
|    explained_variance   | 0.971      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0117    |
|    n_updates            | 8340       |
|    policy_gradient_loss | -0.0154    |
|    std                  | 0.0789     |
|    value_loss           | 0.0302     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 917      |
|    ep_rew_mean     | 3.31e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 835      |
|    time_elapsed    | 11179    |
|    total_timesteps | 1710080  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 926        |
|    ep_rew_mean          | 3.37e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 836        |
|    time_elapsed         | 11188      |
|    total_timesteps      | 1712128    |
| train/                  |            |
|    approx_kl            | 0.24757944 |
|    clip_fraction        | 0.71       |
|    clip_range           | 0.2        |
|    entropy_loss         | 9          |
|    explained_variance   | -0.17      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00139   |
|    n_updates            | 8350       |
|    policy_gradient_loss | -0.0193    |
|    std                  | 0.0789     |
|    value_loss           | 0.0123     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 926        |
|    ep_rew_mean          | 3.33e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 837        |
|    time_elapsed         | 11199      |
|    total_timesteps      | 1714176    |
| train/                  |            |
|    approx_kl            | 0.20042351 |
|    clip_fraction        | 0.697      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.01       |
|    explained_variance   | 0.676      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0896    |
|    n_updates            | 8360       |
|    policy_gradient_loss | -0.0324    |
|    std                  | 0.0785     |
|    value_loss           | 0.0074     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 924        |
|    ep_rew_mean          | 3.33e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 838        |
|    time_elapsed         | 11209      |
|    total_timesteps      | 1716224    |
| train/                  |            |
|    approx_kl            | 0.26874462 |
|    clip_fraction        | 0.657      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.05       |
|    explained_variance   | 0.978      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0613    |
|    n_updates            | 8370       |
|    policy_gradient_loss | -0.0186    |
|    std                  | 0.0781     |
|    value_loss           | 0.0235     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 924        |
|    ep_rew_mean          | 3.32e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 839        |
|    time_elapsed         | 11218      |
|    total_timesteps      | 1718272    |
| train/                  |            |
|    approx_kl            | 0.22449136 |
|    clip_fraction        | 0.703      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.06       |
|    explained_variance   | 0.458      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00383   |
|    n_updates            | 8380       |
|    policy_gradient_loss | -0.0206    |
|    std                  | 0.0782     |
|    value_loss           | 0.0192     |
----------------------------------------
Eval num_timesteps=1720000, episode_reward=3027.21 +/- 1455.87
Episode length: 866.32 +/- 298.26
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 866        |
|    mean_reward          | 3.03e+03   |
| time/                   |            |
|    total_timesteps      | 1720000    |
| train/                  |            |
|    approx_kl            | 0.22432372 |
|    clip_fraction        | 0.689      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.08       |
|    explained_variance   | 0.959      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0281    |
|    n_updates            | 8390       |
|    policy_gradient_loss | -0.0168    |
|    std                  | 0.0781     |
|    value_loss           | 0.0208     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 914      |
|    ep_rew_mean     | 3.33e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 840      |
|    time_elapsed    | 11249    |
|    total_timesteps | 1720320  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 908        |
|    ep_rew_mean          | 3.33e+03   |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 841        |
|    time_elapsed         | 11259      |
|    total_timesteps      | 1722368    |
| train/                  |            |
|    approx_kl            | 0.21712002 |
|    clip_fraction        | 0.705      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.06       |
|    explained_variance   | 0.515      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0126    |
|    n_updates            | 8400       |
|    policy_gradient_loss | -0.0159    |
|    std                  | 0.0785     |
|    value_loss           | 0.0371     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 908        |
|    ep_rew_mean          | 3.31e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 842        |
|    time_elapsed         | 11268      |
|    total_timesteps      | 1724416    |
| train/                  |            |
|    approx_kl            | 0.22634846 |
|    clip_fraction        | 0.709      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.03       |
|    explained_variance   | 0.868      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0552    |
|    n_updates            | 8410       |
|    policy_gradient_loss | -0.0291    |
|    std                  | 0.0785     |
|    value_loss           | 0.0466     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 908        |
|    ep_rew_mean          | 3.34e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 843        |
|    time_elapsed         | 11278      |
|    total_timesteps      | 1726464    |
| train/                  |            |
|    approx_kl            | 0.24291128 |
|    clip_fraction        | 0.663      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.04       |
|    explained_variance   | 0.986      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0295    |
|    n_updates            | 8420       |
|    policy_gradient_loss | -0.0129    |
|    std                  | 0.0783     |
|    value_loss           | 0.0177     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 917        |
|    ep_rew_mean          | 3.35e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 844        |
|    time_elapsed         | 11287      |
|    total_timesteps      | 1728512    |
| train/                  |            |
|    approx_kl            | 0.26623183 |
|    clip_fraction        | 0.719      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.03       |
|    explained_variance   | 0.0803     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0213    |
|    n_updates            | 8430       |
|    policy_gradient_loss | -0.0119    |
|    std                  | 0.0788     |
|    value_loss           | 0.0088     |
----------------------------------------
Eval num_timesteps=1730000, episode_reward=3758.75 +/- 920.52
Episode length: 1000.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 1e+03     |
|    mean_reward          | 3.76e+03  |
| time/                   |           |
|    total_timesteps      | 1730000   |
| train/                  |           |
|    approx_kl            | 0.2194198 |
|    clip_fraction        | 0.639     |
|    clip_range           | 0.2       |
|    entropy_loss         | 9.02      |
|    explained_variance   | 0.977     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0398   |
|    n_updates            | 8440      |
|    policy_gradient_loss | -0.0169   |
|    std                  | 0.0784    |
|    value_loss           | 0.0181    |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 917      |
|    ep_rew_mean     | 3.34e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 845      |
|    time_elapsed    | 11317    |
|    total_timesteps | 1730560  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 917        |
|    ep_rew_mean          | 3.33e+03   |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 846        |
|    time_elapsed         | 11327      |
|    total_timesteps      | 1732608    |
| train/                  |            |
|    approx_kl            | 0.21756598 |
|    clip_fraction        | 0.706      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.04       |
|    explained_variance   | 0.958      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.07      |
|    n_updates            | 8450       |
|    policy_gradient_loss | -0.0161    |
|    std                  | 0.0785     |
|    value_loss           | 0.0157     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 932        |
|    ep_rew_mean          | 3.38e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 847        |
|    time_elapsed         | 11336      |
|    total_timesteps      | 1734656    |
| train/                  |            |
|    approx_kl            | 0.22670908 |
|    clip_fraction        | 0.709      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.03       |
|    explained_variance   | 0.952      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0532     |
|    n_updates            | 8460       |
|    policy_gradient_loss | -0.0266    |
|    std                  | 0.0787     |
|    value_loss           | 0.00659    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 937        |
|    ep_rew_mean          | 3.39e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 848        |
|    time_elapsed         | 11346      |
|    total_timesteps      | 1736704    |
| train/                  |            |
|    approx_kl            | 0.20988542 |
|    clip_fraction        | 0.696      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.01       |
|    explained_variance   | 0.953      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00534   |
|    n_updates            | 8470       |
|    policy_gradient_loss | -0.0117    |
|    std                  | 0.0788     |
|    value_loss           | 0.0311     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 937        |
|    ep_rew_mean          | 3.36e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 849        |
|    time_elapsed         | 11356      |
|    total_timesteps      | 1738752    |
| train/                  |            |
|    approx_kl            | 0.22579071 |
|    clip_fraction        | 0.699      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.03       |
|    explained_variance   | 0.964      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0679    |
|    n_updates            | 8480       |
|    policy_gradient_loss | -0.0171    |
|    std                  | 0.0784     |
|    value_loss           | 0.018      |
----------------------------------------
Eval num_timesteps=1740000, episode_reward=3381.73 +/- 1148.44
Episode length: 986.40 +/- 66.63
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 986        |
|    mean_reward          | 3.38e+03   |
| time/                   |            |
|    total_timesteps      | 1740000    |
| train/                  |            |
|    approx_kl            | 0.26009172 |
|    clip_fraction        | 0.673      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.04       |
|    explained_variance   | 0.986      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0209    |
|    n_updates            | 8490       |
|    policy_gradient_loss | -0.0221    |
|    std                  | 0.0785     |
|    value_loss           | 0.014      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 937      |
|    ep_rew_mean     | 3.35e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 850      |
|    time_elapsed    | 11386    |
|    total_timesteps | 1740800  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 942        |
|    ep_rew_mean          | 3.37e+03   |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 851        |
|    time_elapsed         | 11396      |
|    total_timesteps      | 1742848    |
| train/                  |            |
|    approx_kl            | 0.22046362 |
|    clip_fraction        | 0.7        |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.04       |
|    explained_variance   | 0.816      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0381    |
|    n_updates            | 8500       |
|    policy_gradient_loss | -0.0164    |
|    std                  | 0.0785     |
|    value_loss           | 0.0301     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 942        |
|    ep_rew_mean          | 3.37e+03   |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 852        |
|    time_elapsed         | 11405      |
|    total_timesteps      | 1744896    |
| train/                  |            |
|    approx_kl            | 0.24312171 |
|    clip_fraction        | 0.71       |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.05       |
|    explained_variance   | 0.969      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0309    |
|    n_updates            | 8510       |
|    policy_gradient_loss | -0.013     |
|    std                  | 0.0784     |
|    value_loss           | 0.0116     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 944        |
|    ep_rew_mean          | 3.37e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 853        |
|    time_elapsed         | 11415      |
|    total_timesteps      | 1746944    |
| train/                  |            |
|    approx_kl            | 0.21341379 |
|    clip_fraction        | 0.689      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.07       |
|    explained_variance   | 0.988      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0505    |
|    n_updates            | 8520       |
|    policy_gradient_loss | -0.0163    |
|    std                  | 0.078      |
|    value_loss           | 0.0108     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 939       |
|    ep_rew_mean          | 3.36e+03  |
| time/                   |           |
|    fps                  | 153       |
|    iterations           | 854       |
|    time_elapsed         | 11424     |
|    total_timesteps      | 1748992   |
| train/                  |           |
|    approx_kl            | 0.2345537 |
|    clip_fraction        | 0.702     |
|    clip_range           | 0.2       |
|    entropy_loss         | 9.08      |
|    explained_variance   | 0.969     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0454   |
|    n_updates            | 8530      |
|    policy_gradient_loss | -0.0141   |
|    std                  | 0.0783    |
|    value_loss           | 0.0223    |
---------------------------------------
Eval num_timesteps=1750000, episode_reward=3560.57 +/- 1006.82
Episode length: 961.60 +/- 151.25
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 962        |
|    mean_reward          | 3.56e+03   |
| time/                   |            |
|    total_timesteps      | 1750000    |
| train/                  |            |
|    approx_kl            | 0.20527339 |
|    clip_fraction        | 0.71       |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.05       |
|    explained_variance   | 0.808      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0928    |
|    n_updates            | 8540       |
|    policy_gradient_loss | -0.0102    |
|    std                  | 0.0786     |
|    value_loss           | 0.0279     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 939      |
|    ep_rew_mean     | 3.39e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 855      |
|    time_elapsed    | 11455    |
|    total_timesteps | 1751040  |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 939       |
|    ep_rew_mean          | 3.38e+03  |
| time/                   |           |
|    fps                  | 152       |
|    iterations           | 856       |
|    time_elapsed         | 11464     |
|    total_timesteps      | 1753088   |
| train/                  |           |
|    approx_kl            | 0.7119973 |
|    clip_fraction        | 0.711     |
|    clip_range           | 0.2       |
|    entropy_loss         | 9.02      |
|    explained_variance   | 0.985     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0551   |
|    n_updates            | 8550      |
|    policy_gradient_loss | -0.0299   |
|    std                  | 0.0789    |
|    value_loss           | 0.00526   |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 939       |
|    ep_rew_mean          | 3.35e+03  |
| time/                   |           |
|    fps                  | 152       |
|    iterations           | 857       |
|    time_elapsed         | 11474     |
|    total_timesteps      | 1755136   |
| train/                  |           |
|    approx_kl            | 0.1671322 |
|    clip_fraction        | 0.684     |
|    clip_range           | 0.2       |
|    entropy_loss         | 9.02      |
|    explained_variance   | 0.969     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0483   |
|    n_updates            | 8560      |
|    policy_gradient_loss | -0.0174   |
|    std                  | 0.0786    |
|    value_loss           | 0.0133    |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 934        |
|    ep_rew_mean          | 3.29e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 858        |
|    time_elapsed         | 11484      |
|    total_timesteps      | 1757184    |
| train/                  |            |
|    approx_kl            | 0.23980609 |
|    clip_fraction        | 0.692      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.04       |
|    explained_variance   | 0.968      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0276    |
|    n_updates            | 8570       |
|    policy_gradient_loss | -0.00994   |
|    std                  | 0.0786     |
|    value_loss           | 0.0229     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 934        |
|    ep_rew_mean          | 3.27e+03   |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 859        |
|    time_elapsed         | 11493      |
|    total_timesteps      | 1759232    |
| train/                  |            |
|    approx_kl            | 0.17503735 |
|    clip_fraction        | 0.635      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.05       |
|    explained_variance   | 0.961      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0614    |
|    n_updates            | 8580       |
|    policy_gradient_loss | -0.0163    |
|    std                  | 0.0783     |
|    value_loss           | 0.0353     |
----------------------------------------
Eval num_timesteps=1760000, episode_reward=3165.12 +/- 1471.06
Episode length: 957.04 +/- 157.11
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 957        |
|    mean_reward          | 3.17e+03   |
| time/                   |            |
|    total_timesteps      | 1760000    |
| train/                  |            |
|    approx_kl            | 0.22890799 |
|    clip_fraction        | 0.678      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.09       |
|    explained_variance   | 0.98       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0436    |
|    n_updates            | 8590       |
|    policy_gradient_loss | -0.0167    |
|    std                  | 0.0781     |
|    value_loss           | 0.017      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 934      |
|    ep_rew_mean     | 3.27e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 860      |
|    time_elapsed    | 11523    |
|    total_timesteps | 1761280  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 932        |
|    ep_rew_mean          | 3.26e+03   |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 861        |
|    time_elapsed         | 11533      |
|    total_timesteps      | 1763328    |
| train/                  |            |
|    approx_kl            | 0.23267388 |
|    clip_fraction        | 0.695      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.12       |
|    explained_variance   | 0.488      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0313    |
|    n_updates            | 8600       |
|    policy_gradient_loss | -0.0158    |
|    std                  | 0.0777     |
|    value_loss           | 0.0141     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 926        |
|    ep_rew_mean          | 3.24e+03   |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 862        |
|    time_elapsed         | 11543      |
|    total_timesteps      | 1765376    |
| train/                  |            |
|    approx_kl            | 0.22916661 |
|    clip_fraction        | 0.714      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.13       |
|    explained_variance   | 0.597      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.046     |
|    n_updates            | 8610       |
|    policy_gradient_loss | -0.0174    |
|    std                  | 0.0778     |
|    value_loss           | 0.0168     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 926        |
|    ep_rew_mean          | 3.19e+03   |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 863        |
|    time_elapsed         | 11552      |
|    total_timesteps      | 1767424    |
| train/                  |            |
|    approx_kl            | 0.22066468 |
|    clip_fraction        | 0.699      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.15       |
|    explained_variance   | 0.762      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0642    |
|    n_updates            | 8620       |
|    policy_gradient_loss | -0.0164    |
|    std                  | 0.0772     |
|    value_loss           | 0.0313     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 926       |
|    ep_rew_mean          | 3.14e+03  |
| time/                   |           |
|    fps                  | 153       |
|    iterations           | 864       |
|    time_elapsed         | 11562     |
|    total_timesteps      | 1769472   |
| train/                  |           |
|    approx_kl            | 0.4526297 |
|    clip_fraction        | 0.711     |
|    clip_range           | 0.2       |
|    entropy_loss         | 9.2       |
|    explained_variance   | 0.965     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0486   |
|    n_updates            | 8630      |
|    policy_gradient_loss | -0.0203   |
|    std                  | 0.0769    |
|    value_loss           | 0.0179    |
---------------------------------------
Eval num_timesteps=1770000, episode_reward=3968.06 +/- 622.12
Episode length: 980.44 +/- 69.51
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 980       |
|    mean_reward          | 3.97e+03  |
| time/                   |           |
|    total_timesteps      | 1770000   |
| train/                  |           |
|    approx_kl            | 0.2329388 |
|    clip_fraction        | 0.678     |
|    clip_range           | 0.2       |
|    entropy_loss         | 9.23      |
|    explained_variance   | 0.983     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0449   |
|    n_updates            | 8640      |
|    policy_gradient_loss | -0.00974  |
|    std                  | 0.0767    |
|    value_loss           | 0.0144    |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 926      |
|    ep_rew_mean     | 3.14e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 865      |
|    time_elapsed    | 11592    |
|    total_timesteps | 1771520  |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 928       |
|    ep_rew_mean          | 3.09e+03  |
| time/                   |           |
|    fps                  | 152       |
|    iterations           | 866       |
|    time_elapsed         | 11602     |
|    total_timesteps      | 1773568   |
| train/                  |           |
|    approx_kl            | 0.2369385 |
|    clip_fraction        | 0.706     |
|    clip_range           | 0.2       |
|    entropy_loss         | 9.24      |
|    explained_variance   | 0.981     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0393   |
|    n_updates            | 8650      |
|    policy_gradient_loss | -0.0167   |
|    std                  | 0.0766    |
|    value_loss           | 0.0128    |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 928        |
|    ep_rew_mean          | 3.08e+03   |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 867        |
|    time_elapsed         | 11612      |
|    total_timesteps      | 1775616    |
| train/                  |            |
|    approx_kl            | 0.21609037 |
|    clip_fraction        | 0.712      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.25       |
|    explained_variance   | 0.984      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0418    |
|    n_updates            | 8660       |
|    policy_gradient_loss | -0.00769   |
|    std                  | 0.0765     |
|    value_loss           | 0.0165     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 928        |
|    ep_rew_mean          | 3.07e+03   |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 868        |
|    time_elapsed         | 11621      |
|    total_timesteps      | 1777664    |
| train/                  |            |
|    approx_kl            | 0.20495799 |
|    clip_fraction        | 0.683      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.25       |
|    explained_variance   | 0.971      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0352    |
|    n_updates            | 8670       |
|    policy_gradient_loss | -0.0128    |
|    std                  | 0.0766     |
|    value_loss           | 0.0213     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 936        |
|    ep_rew_mean          | 3.1e+03    |
| time/                   |            |
|    fps                  | 153        |
|    iterations           | 869        |
|    time_elapsed         | 11631      |
|    total_timesteps      | 1779712    |
| train/                  |            |
|    approx_kl            | 0.24553369 |
|    clip_fraction        | 0.711      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.26       |
|    explained_variance   | 0.866      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0489    |
|    n_updates            | 8680       |
|    policy_gradient_loss | -0.0177    |
|    std                  | 0.0762     |
|    value_loss           | 0.0167     |
----------------------------------------
Eval num_timesteps=1780000, episode_reward=3679.55 +/- 1214.98
Episode length: 980.96 +/- 93.28
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 981        |
|    mean_reward          | 3.68e+03   |
| time/                   |            |
|    total_timesteps      | 1780000    |
| train/                  |            |
|    approx_kl            | 0.22409974 |
|    clip_fraction        | 0.702      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.28       |
|    explained_variance   | 0.605      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0254    |
|    n_updates            | 8690       |
|    policy_gradient_loss | -0.0212    |
|    std                  | 0.0763     |
|    value_loss           | 0.0033     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 931      |
|    ep_rew_mean     | 3.09e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 870      |
|    time_elapsed    | 11661    |
|    total_timesteps | 1781760  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 931        |
|    ep_rew_mean          | 3.09e+03   |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 871        |
|    time_elapsed         | 11671      |
|    total_timesteps      | 1783808    |
| train/                  |            |
|    approx_kl            | 0.19404612 |
|    clip_fraction        | 0.687      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.26       |
|    explained_variance   | 0.699      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0469    |
|    n_updates            | 8700       |
|    policy_gradient_loss | -0.0167    |
|    std                  | 0.0763     |
|    value_loss           | 0.0142     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 931       |
|    ep_rew_mean          | 3.09e+03  |
| time/                   |           |
|    fps                  | 152       |
|    iterations           | 872       |
|    time_elapsed         | 11680     |
|    total_timesteps      | 1785856   |
| train/                  |           |
|    approx_kl            | 0.2695614 |
|    clip_fraction        | 0.718     |
|    clip_range           | 0.2       |
|    entropy_loss         | 9.25      |
|    explained_variance   | 0.394     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0765   |
|    n_updates            | 8710      |
|    policy_gradient_loss | -0.0215   |
|    std                  | 0.0765    |
|    value_loss           | 0.00454   |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 931        |
|    ep_rew_mean          | 3.11e+03   |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 873        |
|    time_elapsed         | 11690      |
|    total_timesteps      | 1787904    |
| train/                  |            |
|    approx_kl            | 0.24987854 |
|    clip_fraction        | 0.704      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.27       |
|    explained_variance   | 0.657      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0591    |
|    n_updates            | 8720       |
|    policy_gradient_loss | -0.0271    |
|    std                  | 0.0762     |
|    value_loss           | 0.00391    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 931        |
|    ep_rew_mean          | 3.12e+03   |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 874        |
|    time_elapsed         | 11699      |
|    total_timesteps      | 1789952    |
| train/                  |            |
|    approx_kl            | 0.20787705 |
|    clip_fraction        | 0.686      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.28       |
|    explained_variance   | 0.601      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0214    |
|    n_updates            | 8730       |
|    policy_gradient_loss | -0.0201    |
|    std                  | 0.0762     |
|    value_loss           | 0.00447    |
----------------------------------------
Eval num_timesteps=1790000, episode_reward=3973.21 +/- 945.00
Episode length: 941.76 +/- 204.17
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 942        |
|    mean_reward          | 3.97e+03   |
| time/                   |            |
|    total_timesteps      | 1790000    |
| train/                  |            |
|    approx_kl            | 0.23026434 |
|    clip_fraction        | 0.701      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.23       |
|    explained_variance   | 0.658      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00801    |
|    n_updates            | 8740       |
|    policy_gradient_loss | -0.0217    |
|    std                  | 0.077      |
|    value_loss           | 0.00274    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 928      |
|    ep_rew_mean     | 3.16e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 875      |
|    time_elapsed    | 11729    |
|    total_timesteps | 1792000  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 930        |
|    ep_rew_mean          | 3.18e+03   |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 876        |
|    time_elapsed         | 11739      |
|    total_timesteps      | 1794048    |
| train/                  |            |
|    approx_kl            | 0.21540809 |
|    clip_fraction        | 0.695      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.2        |
|    explained_variance   | 0.626      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0355     |
|    n_updates            | 8750       |
|    policy_gradient_loss | -0.0122    |
|    std                  | 0.0766     |
|    value_loss           | 0.0172     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 942        |
|    ep_rew_mean          | 3.23e+03   |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 877        |
|    time_elapsed         | 11748      |
|    total_timesteps      | 1796096    |
| train/                  |            |
|    approx_kl            | 0.26464534 |
|    clip_fraction        | 0.709      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.23       |
|    explained_variance   | 0.264      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0658    |
|    n_updates            | 8760       |
|    policy_gradient_loss | -0.0232    |
|    std                  | 0.0765     |
|    value_loss           | 0.00462    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 942        |
|    ep_rew_mean          | 3.23e+03   |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 878        |
|    time_elapsed         | 11758      |
|    total_timesteps      | 1798144    |
| train/                  |            |
|    approx_kl            | 0.21972069 |
|    clip_fraction        | 0.698      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.25       |
|    explained_variance   | 0.647      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0474    |
|    n_updates            | 8770       |
|    policy_gradient_loss | -0.0203    |
|    std                  | 0.0763     |
|    value_loss           | 0.00369    |
----------------------------------------
Eval num_timesteps=1800000, episode_reward=3613.98 +/- 1255.00
Episode length: 965.16 +/- 170.68
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 965        |
|    mean_reward          | 3.61e+03   |
| time/                   |            |
|    total_timesteps      | 1800000    |
| train/                  |            |
|    approx_kl            | 0.20159304 |
|    clip_fraction        | 0.7        |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.25       |
|    explained_variance   | 0.673      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0679    |
|    n_updates            | 8780       |
|    policy_gradient_loss | -0.0167    |
|    std                  | 0.0764     |
|    value_loss           | 0.00373    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 942      |
|    ep_rew_mean     | 3.27e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 879      |
|    time_elapsed    | 11788    |
|    total_timesteps | 1800192  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 950        |
|    ep_rew_mean          | 3.29e+03   |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 880        |
|    time_elapsed         | 11797      |
|    total_timesteps      | 1802240    |
| train/                  |            |
|    approx_kl            | 0.24473217 |
|    clip_fraction        | 0.697      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.25       |
|    explained_variance   | 0.629      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0311    |
|    n_updates            | 8790       |
|    policy_gradient_loss | -0.0261    |
|    std                  | 0.0764     |
|    value_loss           | 0.00584    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 950        |
|    ep_rew_mean          | 3.29e+03   |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 881        |
|    time_elapsed         | 11806      |
|    total_timesteps      | 1804288    |
| train/                  |            |
|    approx_kl            | 0.19070417 |
|    clip_fraction        | 0.679      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.23       |
|    explained_variance   | 0.969      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00951   |
|    n_updates            | 8800       |
|    policy_gradient_loss | -0.0125    |
|    std                  | 0.0767     |
|    value_loss           | 0.0244     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 950       |
|    ep_rew_mean          | 3.26e+03  |
| time/                   |           |
|    fps                  | 152       |
|    iterations           | 882       |
|    time_elapsed         | 11816     |
|    total_timesteps      | 1806336   |
| train/                  |           |
|    approx_kl            | 0.2240917 |
|    clip_fraction        | 0.676     |
|    clip_range           | 0.2       |
|    entropy_loss         | 9.24      |
|    explained_variance   | 0.988     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0682   |
|    n_updates            | 8810      |
|    policy_gradient_loss | -0.0145   |
|    std                  | 0.0762    |
|    value_loss           | 0.00927   |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 943        |
|    ep_rew_mean          | 3.27e+03   |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 883        |
|    time_elapsed         | 11825      |
|    total_timesteps      | 1808384    |
| train/                  |            |
|    approx_kl            | 0.26139915 |
|    clip_fraction        | 0.693      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.27       |
|    explained_variance   | 0.993      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0603    |
|    n_updates            | 8820       |
|    policy_gradient_loss | -0.0213    |
|    std                  | 0.0764     |
|    value_loss           | 0.00388    |
----------------------------------------
Eval num_timesteps=1810000, episode_reward=4067.22 +/- 767.69
Episode length: 992.20 +/- 38.21
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 992        |
|    mean_reward          | 4.07e+03   |
| time/                   |            |
|    total_timesteps      | 1810000    |
| train/                  |            |
|    approx_kl            | 0.19796303 |
|    clip_fraction        | 0.695      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.27       |
|    explained_variance   | 0.438      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0654    |
|    n_updates            | 8830       |
|    policy_gradient_loss | -0.0145    |
|    std                  | 0.0761     |
|    value_loss           | 0.0136     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 951      |
|    ep_rew_mean     | 3.3e+03  |
| time/              |          |
|    fps             | 152      |
|    iterations      | 884      |
|    time_elapsed    | 11855    |
|    total_timesteps | 1810432  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 945        |
|    ep_rew_mean          | 3.27e+03   |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 885        |
|    time_elapsed         | 11865      |
|    total_timesteps      | 1812480    |
| train/                  |            |
|    approx_kl            | 0.23753378 |
|    clip_fraction        | 0.713      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.29       |
|    explained_variance   | 0.676      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0237    |
|    n_updates            | 8840       |
|    policy_gradient_loss | -0.0146    |
|    std                  | 0.0761     |
|    value_loss           | 0.00602    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 947        |
|    ep_rew_mean          | 3.28e+03   |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 886        |
|    time_elapsed         | 11874      |
|    total_timesteps      | 1814528    |
| train/                  |            |
|    approx_kl            | 0.23009393 |
|    clip_fraction        | 0.702      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.31       |
|    explained_variance   | 0.528      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0598    |
|    n_updates            | 8850       |
|    policy_gradient_loss | -0.0152    |
|    std                  | 0.0757     |
|    value_loss           | 0.0212     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 950        |
|    ep_rew_mean          | 3.31e+03   |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 887        |
|    time_elapsed         | 11884      |
|    total_timesteps      | 1816576    |
| train/                  |            |
|    approx_kl            | 0.20060423 |
|    clip_fraction        | 0.687      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.33       |
|    explained_variance   | 0.941      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0414    |
|    n_updates            | 8860       |
|    policy_gradient_loss | -0.00898   |
|    std                  | 0.0757     |
|    value_loss           | 0.0328     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 952       |
|    ep_rew_mean          | 3.29e+03  |
| time/                   |           |
|    fps                  | 152       |
|    iterations           | 888       |
|    time_elapsed         | 11893     |
|    total_timesteps      | 1818624   |
| train/                  |           |
|    approx_kl            | 0.2677335 |
|    clip_fraction        | 0.717     |
|    clip_range           | 0.2       |
|    entropy_loss         | 9.33      |
|    explained_variance   | 0.112     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0873   |
|    n_updates            | 8870      |
|    policy_gradient_loss | -0.0116   |
|    std                  | 0.0757    |
|    value_loss           | 0.00451   |
---------------------------------------
Eval num_timesteps=1820000, episode_reward=3741.49 +/- 1128.15
Episode length: 990.56 +/- 46.25
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 991        |
|    mean_reward          | 3.74e+03   |
| time/                   |            |
|    total_timesteps      | 1820000    |
| train/                  |            |
|    approx_kl            | 0.18301871 |
|    clip_fraction        | 0.655      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.32       |
|    explained_variance   | 0.974      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0373    |
|    n_updates            | 8880       |
|    policy_gradient_loss | -0.0131    |
|    std                  | 0.0757     |
|    value_loss           | 0.0242     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 951      |
|    ep_rew_mean     | 3.3e+03  |
| time/              |          |
|    fps             | 152      |
|    iterations      | 889      |
|    time_elapsed    | 11923    |
|    total_timesteps | 1820672  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 951        |
|    ep_rew_mean          | 3.31e+03   |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 890        |
|    time_elapsed         | 11932      |
|    total_timesteps      | 1822720    |
| train/                  |            |
|    approx_kl            | 0.21798119 |
|    clip_fraction        | 0.7        |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.33       |
|    explained_variance   | 0.524      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0365    |
|    n_updates            | 8890       |
|    policy_gradient_loss | -0.0144    |
|    std                  | 0.0757     |
|    value_loss           | 0.0177     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 951       |
|    ep_rew_mean          | 3.35e+03  |
| time/                   |           |
|    fps                  | 152       |
|    iterations           | 891       |
|    time_elapsed         | 11942     |
|    total_timesteps      | 1824768   |
| train/                  |           |
|    approx_kl            | 0.2694376 |
|    clip_fraction        | 0.712     |
|    clip_range           | 0.2       |
|    entropy_loss         | 9.35      |
|    explained_variance   | 0.524     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0714   |
|    n_updates            | 8900      |
|    policy_gradient_loss | -0.0234   |
|    std                  | 0.0755    |
|    value_loss           | 0.00399   |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 944       |
|    ep_rew_mean          | 3.33e+03  |
| time/                   |           |
|    fps                  | 152       |
|    iterations           | 892       |
|    time_elapsed         | 11951     |
|    total_timesteps      | 1826816   |
| train/                  |           |
|    approx_kl            | 0.2901974 |
|    clip_fraction        | 0.727     |
|    clip_range           | 0.2       |
|    entropy_loss         | 9.36      |
|    explained_variance   | 0.646     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0733   |
|    n_updates            | 8910      |
|    policy_gradient_loss | -0.0205   |
|    std                  | 0.0754    |
|    value_loss           | 0.00372   |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 944        |
|    ep_rew_mean          | 3.33e+03   |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 893        |
|    time_elapsed         | 11961      |
|    total_timesteps      | 1828864    |
| train/                  |            |
|    approx_kl            | 0.21477264 |
|    clip_fraction        | 0.71       |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.36       |
|    explained_variance   | 0.544      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.064     |
|    n_updates            | 8920       |
|    policy_gradient_loss | -0.00843   |
|    std                  | 0.0755     |
|    value_loss           | 0.0201     |
----------------------------------------
Eval num_timesteps=1830000, episode_reward=3563.95 +/- 1158.89
Episode length: 965.48 +/- 123.18
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 965       |
|    mean_reward          | 3.56e+03  |
| time/                   |           |
|    total_timesteps      | 1830000   |
| train/                  |           |
|    approx_kl            | 0.2238447 |
|    clip_fraction        | 0.706     |
|    clip_range           | 0.2       |
|    entropy_loss         | 9.32      |
|    explained_variance   | 0.931     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.00773  |
|    n_updates            | 8930      |
|    policy_gradient_loss | -0.0154   |
|    std                  | 0.0758    |
|    value_loss           | 0.0218    |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 937      |
|    ep_rew_mean     | 3.31e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 894      |
|    time_elapsed    | 11991    |
|    total_timesteps | 1830912  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 937        |
|    ep_rew_mean          | 3.34e+03   |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 895        |
|    time_elapsed         | 12002      |
|    total_timesteps      | 1832960    |
| train/                  |            |
|    approx_kl            | 0.22222969 |
|    clip_fraction        | 0.705      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.29       |
|    explained_variance   | 0.955      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.000445  |
|    n_updates            | 8940       |
|    policy_gradient_loss | -0.00989   |
|    std                  | 0.0761     |
|    value_loss           | 0.0334     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 935        |
|    ep_rew_mean          | 3.35e+03   |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 896        |
|    time_elapsed         | 12011      |
|    total_timesteps      | 1835008    |
| train/                  |            |
|    approx_kl            | 0.25858003 |
|    clip_fraction        | 0.707      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.26       |
|    explained_variance   | 0.447      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0122    |
|    n_updates            | 8950       |
|    policy_gradient_loss | -0.0191    |
|    std                  | 0.0766     |
|    value_loss           | 0.00473    |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 935       |
|    ep_rew_mean          | 3.36e+03  |
| time/                   |           |
|    fps                  | 152       |
|    iterations           | 897       |
|    time_elapsed         | 12021     |
|    total_timesteps      | 1837056   |
| train/                  |           |
|    approx_kl            | 0.2028596 |
|    clip_fraction        | 0.687     |
|    clip_range           | 0.2       |
|    entropy_loss         | 9.24      |
|    explained_variance   | 0.46      |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0428   |
|    n_updates            | 8960      |
|    policy_gradient_loss | -0.014    |
|    std                  | 0.0765    |
|    value_loss           | 0.0239    |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 935       |
|    ep_rew_mean          | 3.39e+03  |
| time/                   |           |
|    fps                  | 152       |
|    iterations           | 898       |
|    time_elapsed         | 12030     |
|    total_timesteps      | 1839104   |
| train/                  |           |
|    approx_kl            | 0.2458135 |
|    clip_fraction        | 0.707     |
|    clip_range           | 0.2       |
|    entropy_loss         | 9.25      |
|    explained_variance   | 0.513     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.0297    |
|    n_updates            | 8970      |
|    policy_gradient_loss | -0.0196   |
|    std                  | 0.0765    |
|    value_loss           | 0.00404   |
---------------------------------------
Eval num_timesteps=1840000, episode_reward=3195.61 +/- 1483.22
Episode length: 856.80 +/- 303.38
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 857       |
|    mean_reward          | 3.2e+03   |
| time/                   |           |
|    total_timesteps      | 1840000   |
| train/                  |           |
|    approx_kl            | 0.2294379 |
|    clip_fraction        | 0.708     |
|    clip_range           | 0.2       |
|    entropy_loss         | 9.25      |
|    explained_variance   | 0.519     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0458   |
|    n_updates            | 8980      |
|    policy_gradient_loss | -0.0152   |
|    std                  | 0.0764    |
|    value_loss           | 0.00732   |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 935      |
|    ep_rew_mean     | 3.41e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 899      |
|    time_elapsed    | 12060    |
|    total_timesteps | 1841152  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 940        |
|    ep_rew_mean          | 3.38e+03   |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 900        |
|    time_elapsed         | 12070      |
|    total_timesteps      | 1843200    |
| train/                  |            |
|    approx_kl            | 0.21763667 |
|    clip_fraction        | 0.652      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.26       |
|    explained_variance   | 0.986      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0336    |
|    n_updates            | 8990       |
|    policy_gradient_loss | -0.0195    |
|    std                  | 0.0762     |
|    value_loss           | 0.0145     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 931        |
|    ep_rew_mean          | 3.33e+03   |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 901        |
|    time_elapsed         | 12079      |
|    total_timesteps      | 1845248    |
| train/                  |            |
|    approx_kl            | 0.25822756 |
|    clip_fraction        | 0.679      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.28       |
|    explained_variance   | 0.981      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0664    |
|    n_updates            | 9000       |
|    policy_gradient_loss | -0.0116    |
|    std                  | 0.0762     |
|    value_loss           | 0.022      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 916        |
|    ep_rew_mean          | 3.3e+03    |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 902        |
|    time_elapsed         | 12088      |
|    total_timesteps      | 1847296    |
| train/                  |            |
|    approx_kl            | 0.20496991 |
|    clip_fraction        | 0.707      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.27       |
|    explained_variance   | 0.901      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0128     |
|    n_updates            | 9010       |
|    policy_gradient_loss | -0.0117    |
|    std                  | 0.0763     |
|    value_loss           | 0.0269     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 922        |
|    ep_rew_mean          | 3.36e+03   |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 903        |
|    time_elapsed         | 12098      |
|    total_timesteps      | 1849344    |
| train/                  |            |
|    approx_kl            | 0.19314513 |
|    clip_fraction        | 0.702      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.26       |
|    explained_variance   | 0.368      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00645   |
|    n_updates            | 9020       |
|    policy_gradient_loss | -0.0136    |
|    std                  | 0.0764     |
|    value_loss           | 0.0554     |
----------------------------------------
Eval num_timesteps=1850000, episode_reward=3078.91 +/- 1432.86
Episode length: 850.20 +/- 286.53
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 850        |
|    mean_reward          | 3.08e+03   |
| time/                   |            |
|    total_timesteps      | 1850000    |
| train/                  |            |
|    approx_kl            | 0.27139843 |
|    clip_fraction        | 0.722      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.27       |
|    explained_variance   | -0.00422   |
|    learning_rate        | 0.0003     |
|    loss                 | -0.012     |
|    n_updates            | 9030       |
|    policy_gradient_loss | -0.0225    |
|    std                  | 0.076      |
|    value_loss           | 0.0109     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 922      |
|    ep_rew_mean     | 3.41e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 904      |
|    time_elapsed    | 12126    |
|    total_timesteps | 1851392  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 922        |
|    ep_rew_mean          | 3.41e+03   |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 905        |
|    time_elapsed         | 12135      |
|    total_timesteps      | 1853440    |
| train/                  |            |
|    approx_kl            | 0.24269672 |
|    clip_fraction        | 0.702      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.29       |
|    explained_variance   | 0.644      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0607    |
|    n_updates            | 9040       |
|    policy_gradient_loss | -0.0253    |
|    std                  | 0.0762     |
|    value_loss           | 0.00379    |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 916      |
|    ep_rew_mean          | 3.34e+03 |
| time/                   |          |
|    fps                  | 152      |
|    iterations           | 906      |
|    time_elapsed         | 12145    |
|    total_timesteps      | 1855488  |
| train/                  |          |
|    approx_kl            | 1.190595 |
|    clip_fraction        | 0.731    |
|    clip_range           | 0.2      |
|    entropy_loss         | 9.29     |
|    explained_variance   | 0.913    |
|    learning_rate        | 0.0003   |
|    loss                 | -0.0881  |
|    n_updates            | 9050     |
|    policy_gradient_loss | -0.0345  |
|    std                  | 0.0757   |
|    value_loss           | 0.017    |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 912       |
|    ep_rew_mean          | 3.33e+03  |
| time/                   |           |
|    fps                  | 152       |
|    iterations           | 907       |
|    time_elapsed         | 12154     |
|    total_timesteps      | 1857536   |
| train/                  |           |
|    approx_kl            | 1.4363906 |
|    clip_fraction        | 0.752     |
|    clip_range           | 0.2       |
|    entropy_loss         | 9.32      |
|    explained_variance   | 0.92      |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0515   |
|    n_updates            | 9060      |
|    policy_gradient_loss | -0.0135   |
|    std                  | 0.0756    |
|    value_loss           | 0.0377    |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 912        |
|    ep_rew_mean          | 3.36e+03   |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 908        |
|    time_elapsed         | 12164      |
|    total_timesteps      | 1859584    |
| train/                  |            |
|    approx_kl            | 0.23174453 |
|    clip_fraction        | 0.706      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.34       |
|    explained_variance   | 0.961      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0491    |
|    n_updates            | 9070       |
|    policy_gradient_loss | -0.0202    |
|    std                  | 0.0755     |
|    value_loss           | 0.0272     |
----------------------------------------
Eval num_timesteps=1860000, episode_reward=3356.12 +/- 1140.53
Episode length: 925.04 +/- 163.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 925        |
|    mean_reward          | 3.36e+03   |
| time/                   |            |
|    total_timesteps      | 1860000    |
| train/                  |            |
|    approx_kl            | 0.21093279 |
|    clip_fraction        | 0.681      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.32       |
|    explained_variance   | 0.962      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0597    |
|    n_updates            | 9080       |
|    policy_gradient_loss | -0.0142    |
|    std                  | 0.0757     |
|    value_loss           | 0.0269     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 912      |
|    ep_rew_mean     | 3.37e+03 |
| time/              |          |
|    fps             | 152      |
|    iterations      | 909      |
|    time_elapsed    | 12194    |
|    total_timesteps | 1861632  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 912        |
|    ep_rew_mean          | 3.35e+03   |
| time/                   |            |
|    fps                  | 152        |
|    iterations           | 910        |
|    time_elapsed         | 12204      |
|    total_timesteps      | 1863680    |
| train/                  |            |
|    approx_kl            | 0.22052845 |
|    clip_fraction        | 0.721      |
|    clip_range           | 0.2        |
|    entropy_loss         | 9.34       |
|    explained_variance   | 0.981      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.033     |
|    n_updates            | 9090       |
|    policy_gradient_loss | -0.0128    |
|    std                  | 0.0755     |
|    value_loss           | 0.0186     |
----------------------------------------
slurmstepd: error: *** JOB 591881 ON dgk816 CANCELLED AT 2024-01-28T20:48:05 ***
